# Detected language: en (p=1.00)

[0.00s -> 3.36s]  Today I'm excited to talk about bridging informal and formal
[3.36s -> 6.00s]  mathematical reasoning with AI.
[6.00s -> 10.78s]  And so probably throughout this course,
[10.78s -> 12.84s]  you've seen many different ways
[12.84s -> 17.16s]  where these AI agents can start to have a lot of impact
[17.16s -> 18.92s]  in different areas.
[18.92s -> 21.80s]  And so one interesting question is,
[21.80s -> 25.04s]  to what extent can they impact more expert domains?
[25.04s -> 28.48s]  So say, finance, science, medicine,
[28.48s -> 30.68s]  and the domain that I'll talk about today,
[30.68s -> 33.44s]  which is mathematics.
[33.44s -> 37.28s]  Now, with mathematics, there's a variety of things
[37.28s -> 40.48s]  that you could imagine doing with an agent or a language
[40.48s -> 41.44s]  model.
[41.44s -> 43.92s]  You could try to have an open-ended dialogue
[43.92s -> 44.96s]  with the model.
[44.96s -> 47.28s]  You could try to have it come up with counterexamples
[47.28s -> 49.76s]  for you, help you write proofs.
[49.76s -> 55.16s]  And your imagination is basically the limit.
[55.16s -> 56.56s]  And what I want to argue today
[56.56s -> 60.60s]  is that, for math in particular, how you represent
[60.60s -> 64.88s]  the math is actually extremely important to think about.
[64.88s -> 67.62s]  So one way to represent math is what
[67.62s -> 70.12s]  is called informal mathematics.
[70.12s -> 73.68s]  Here, math is represented as raw data.
[73.68s -> 76.28s]  So it could be text, it could be an image,
[76.28s -> 79.48s]  it could be even audio if you're talking with someone
[79.48s -> 80.78s]  about math.
[80.78s -> 83.98s]  And doing this is extremely flexible.
[83.98s -> 87.82s]  And in some sense, most of the math that you've encountered
[87.82s -> 90.58s]  or that you've used is probably
[90.58s -> 93.38s]  in some kind of informal format.
[93.38s -> 96.98s]  So even something like a latex solution or an archive paper,
[96.98s -> 100.18s]  we would consider to be informal.
[100.18s -> 104.06s]  Now, when we think about using AI to generate or operate
[104.06s -> 109.66s]  in informal math, there is a really important problem,
[109.66s -> 113.22s]  which is that we don't have any guarantees that the math is
[113.26s -> 114.98s]  correct or not.
[114.98s -> 118.38s]  So like here is an example of a language model
[118.38s -> 120.54s]  producing a solution.
[120.54s -> 123.02s]  And the answer at the end is actually correct,
[123.02s -> 125.74s]  but it makes these kind of subtle mistakes
[125.74s -> 128.34s]  in the intermediate steps.
[128.34s -> 131.50s]  And so for really simple math, this might not actually
[131.50s -> 133.18s]  be an issue, and the language model
[133.18s -> 135.18s]  might still be useful.
[135.18s -> 138.54s]  But if we really want to trust it in, say, education
[138.54s -> 141.22s]  or in research-level math, then it
[141.26s -> 145.90s]  could get very tedious and very difficult
[145.90s -> 150.34s]  to know whether the outputs are correct or not.
[150.34s -> 152.58s]  So this motivates the other end
[152.58s -> 155.82s]  of the spectrum, which is called formal mathematics.
[155.82s -> 158.94s]  Here, math is written as source code in a programming
[158.94s -> 160.14s]  language.
[160.14s -> 161.90s]  And basically, the way it works
[161.90s -> 166.14s]  is you can write a specification or a lemma or theorem,
[166.14s -> 168.62s]  like 1 plus 1 equals 2.
[168.62s -> 170.70s]  Then you can write a proof.
[170.70s -> 175.10s]  And the really cool thing is that if all the code compiles,
[175.10s -> 181.02s]  then you have a formal guarantee that the proof is correct.
[181.02s -> 183.82s]  And so this is a lot different than the informal math
[183.82s -> 187.06s]  because now we can have certainty if, say, a language
[187.06s -> 190.06s]  model generates a proof, that it is actually
[190.06s -> 195.34s]  a reliable and correct proof of the theorem.
[195.34s -> 198.66s]  And there's been a variety of these theorem-proofing languages
[198.66s -> 199.62s]  developed.
[199.66s -> 204.22s]  I'll mostly focus on a language called Lean, which recently is
[204.22s -> 209.06s]  having a really exciting growth and really exciting
[209.06s -> 211.98s]  intersection with the mathematical community, which
[211.98s -> 213.90s]  I'll talk about in a bit.
[213.90s -> 217.06s]  And for one of the topics that I'll talk about,
[217.06s -> 220.26s]  I'll also mention this language called Isabelle
[220.26s -> 222.46s]  because it has some features that
[222.46s -> 226.02s]  make it kind of amenable to writing different types of proofs
[226.02s -> 229.50s]  with AI systems.
[229.54s -> 232.30s]  So if you haven't seen one of these before,
[232.30s -> 234.42s]  I wanted to actually show you what
[234.42s -> 238.06s]  one of these formal proof assistants looked like.
[238.06s -> 241.42s]  And so to do this, we'll try to prove this really simple
[241.42s -> 244.54s]  theorem, which is transitivity.
[244.54s -> 248.22s]  So if R is a subset of S and S is a subset of T,
[248.22s -> 251.90s]  then R is a subset of T.
[251.90s -> 256.42s]  So I'll actually show you this as a demo.
[256.42s -> 260.94s]  And so here what I've done is I've opened up the S code.
[260.94s -> 265.98s]  And so as I mentioned, this is literally programming,
[265.98s -> 267.50s]  like writing code.
[267.50s -> 271.10s]  And here you can see the theorem statement.
[271.10s -> 274.66s]  So if R is a subset of S and S is a subset of T,
[274.66s -> 277.74s]  then R is a subset of T.
[277.74s -> 282.30s]  And these are often called interactive proof assistants
[282.30s -> 286.38s]  because what happens is, as I go to write a proof,
[286.38s -> 289.46s]  it actually tells me over here what is
[289.46s -> 291.86s]  the current state of the proof.
[291.86s -> 295.42s]  So the idea isn't to learn every bit of the formal system,
[295.42s -> 298.18s]  but I'm kind of just showing you the important parts that
[298.18s -> 300.30s]  will be relevant for the talk.
[300.30s -> 302.90s]  So here we can see these different variables,
[302.90s -> 308.14s]  and we can see what we have remaining to prove over here.
[308.14s -> 310.38s]  Now, the thing is that it takes some expertise
[310.38s -> 313.46s]  to actually write a proof in Lean.
[313.46s -> 317.10s]  So for example, if I know some Lean, then one thing I can do
[317.10s -> 320.22s]  is this command here.
[320.22s -> 322.02s]  And you can notice that it actually
[322.02s -> 323.86s]  changed the state of the proof.
[323.86s -> 327.38s]  So now I have these two kind of variables up here,
[327.38s -> 330.42s]  and the goal has also changed.
[330.42s -> 332.90s]  Then again, if you have some expertise,
[332.90s -> 337.42s]  then you can actually know that this idea of transitivity
[337.42s -> 340.86s]  has already been programmed into Lean.
[340.86s -> 346.18s]  So here I wrote this transitivity rule here,
[346.18s -> 347.58s]  or lemma.
[347.58s -> 349.18s]  And now you can see up here that it
[349.18s -> 350.94s]  says that there's no goals left,
[350.94s -> 354.46s]  so I've kind of completed the proof.
[354.46s -> 356.42s]  So we'll actually touch on a lot of things
[356.42s -> 358.86s]  that I've talked about here throughout the talk.
[358.86s -> 362.50s]  We'll talk about the fact that it requires some expertise
[362.50s -> 366.42s]  to actually write a proof in one of these proof assistants.
[366.42s -> 368.46s]  And if you look at this proof, it
[368.46s -> 371.06s]  might look a bit different than one
[371.06s -> 374.06s]  that you would see written down in a textbook
[374.06s -> 375.74s]  or something like that.
[375.74s -> 380.38s]  So we'll revisit these ideas throughout the talk.
[380.38s -> 385.30s]  So now, going back to the talk,
[385.30s -> 388.70s]  we could ask, OK, I showed you this very simple example,
[388.70s -> 391.94s]  but is this kind of toy, or is this actually
[391.94s -> 396.10s]  useful for more complex mathematics?
[396.30s -> 399.42s]  So a really exciting thing is that, increasingly, there's
[399.42s -> 403.86s]  a larger and larger intersection with the mathematical community.
[403.86s -> 407.82s]  So here's an example of the mathematician Terrence Tao,
[407.82s -> 412.66s]  and he formalized in Lean the proof of a theorem from one
[412.66s -> 416.18s]  of his actual papers.
[416.18s -> 418.38s]  And a really exciting thing that's
[418.38s -> 421.46s]  kind of playing into this is this project,
[421.46s -> 423.34s]  which is called MathLobe.
[423.34s -> 425.42s]  So if you noticed in the demo I gave,
[425.42s -> 429.78s]  this idea of transitivity was already kind of programmed in,
[429.78s -> 431.54s]  and that's the idea of MathLobe.
[431.54s -> 434.98s]  So lots of people are contributing and kind
[434.98s -> 437.42s]  of building up foundations that other people can
[437.42s -> 443.14s]  use to make it easier to write more and more complex math.
[445.66s -> 449.74s]  And if you look at what mathematicians write or talk
[449.74s -> 452.82s]  to them and listen to what they say,
[452.82s -> 454.66s]  then these formal proof assistants
[454.66s -> 457.66s]  are exciting for a few different reasons.
[457.66s -> 460.70s]  So one is that they can potentially enable
[460.70s -> 463.54s]  a new form of collaboration.
[463.54s -> 465.42s]  So what you can do is you can break down
[465.42s -> 471.70s]  a kind of big problem or big proof into multiple pieces,
[471.70s -> 475.34s]  and then anyone can go on and essentially submit code
[475.34s -> 477.50s]  to try to solve one of the pieces
[477.50s -> 480.86s]  to, say, prove one of the kind of helper theorems
[480.86s -> 482.98s]  or helper lemmas.
[482.98s -> 485.86s]  And then the cool thing is that we know for a fact
[485.86s -> 490.10s]  that we can trust the code, since Lean will automatically
[490.10s -> 491.78s]  check it.
[491.78s -> 494.66s]  And so this is a lot different than the typical way
[494.66s -> 498.54s]  of collaborating on, say, a math paper, where
[498.54s -> 500.06s]  you kind of have to trust the author
[500.06s -> 504.10s]  or read through their results.
[504.10s -> 507.42s]  It also gives you instant feedback, as we saw.
[507.42s -> 510.06s]  So this could be useful in a variety of ways,
[510.06s -> 513.14s]  including when trying to learn math.
[513.14s -> 518.34s]  And of course, it has these guarantees on correctness.
[518.34s -> 519.82s]  So hopefully, I've convinced you
[519.82s -> 522.98s]  that formal math is getting more and more interesting
[522.98s -> 527.66s]  for learning or for the actual mathematical community.
[527.66s -> 530.86s]  But why is it actually important for AI?
[530.86s -> 533.54s]  Well, one thing is that, as we all know,
[533.54s -> 537.58s]  we are not able to automatically check or trust
[537.62s -> 540.82s]  the outputs of AI models.
[540.82s -> 542.74s]  And so what the formal system gives us
[542.74s -> 547.22s]  is some way of just preventing incorrect math.
[547.22s -> 550.30s]  Or it turns out you can actually use this for code
[550.30s -> 552.46s]  as well.
[552.46s -> 555.62s]  Increasingly, we see more and more models trained
[555.62s -> 557.50s]  with reinforcement learning.
[557.50s -> 560.34s]  And I'll actually talk about one of those in the talk.
[560.34s -> 563.42s]  And what you can think of the formal system as being
[563.42s -> 566.30s]  is it gives you this kind of perfect reward signal
[566.30s -> 569.78s]  of whether something is correct or not correct.
[569.78s -> 573.58s]  And this turns out to be very useful for then improving
[573.58s -> 576.54s]  machine learning models further.
[576.54s -> 580.10s]  It also gets at one of the hot topics in the field
[580.10s -> 582.46s]  right now, which is reasoning.
[582.46s -> 584.02s]  And it gives you this nice playground
[584.02s -> 587.70s]  where you can try even very easy reasoning problems
[587.70s -> 592.02s]  to essentially arbitrarily hard ones within the domain of math.
[593.02s -> 596.42s]  And so if we look at the history of language models
[596.42s -> 600.38s]  in formal math, one of the pioneering works
[600.38s -> 604.82s]  happened in 2020 from these two authors from OpenAI.
[604.82s -> 608.22s]  And they developed a system called GPT-F.
[608.22s -> 610.50s]  And so it actually used the language model
[610.50s -> 614.98s]  to kind of predict the next steps of these proofs.
[614.98s -> 618.74s]  And even back then, they got some pretty interesting results.
[618.74s -> 621.06s]  So what they did is they had the system
[621.70s -> 625.70s]  generate a proof, and then they submitted it as a pull request.
[625.70s -> 627.30s]  And here are some of the comments
[627.30s -> 632.46s]  from the kind of maintainers of the formal proofs library.
[632.46s -> 634.98s]  Even this model back then could produce kind of shorter
[634.98s -> 639.30s]  proofs, and some of them were even philosophically more
[639.30s -> 643.06s]  concise than the human-written ones.
[643.06s -> 646.38s]  And then since then, we've seen rapid progress
[646.38s -> 649.38s]  in using methods based on language models
[650.26s -> 652.62s]  for formal theorem proving.
[652.62s -> 654.98s]  So here it is showing the performance
[654.98s -> 657.46s]  on a really common benchmark.
[657.46s -> 660.18s]  These are based on math competition problems.
[660.18s -> 662.66s]  And I actually made this plot a few months ago,
[662.66s -> 664.82s]  but it's already out of date.
[664.82s -> 666.22s]  Actually, just this morning, there
[666.22s -> 672.82s]  was a model released that gets like 80% on this benchmark.
[672.82s -> 675.86s]  And just to give you some flavor of what these look like,
[675.86s -> 678.02s]  again, you don't have to read through the details of this
[678.02s -> 681.86s]  or through most of the examples I show in this talk.
[681.86s -> 685.38s]  But here's an actual output from a model called
[685.38s -> 689.06s]  DeepSeekProver, and it managed to produce
[689.06s -> 692.26s]  this proof of an IMO problem.
[692.26s -> 694.30s]  And so hopefully, it gives you some sense
[694.30s -> 696.90s]  that the outputs of these are starting
[696.90s -> 700.74s]  to get pretty non-trivial.
[700.74s -> 703.06s]  And Terrence Tao, if we go back
[703.06s -> 706.50s]  to members of the mathematical community,
[706.54s -> 708.94s]  wrote that during his formalization project,
[708.94s -> 711.62s]  he was actually using GitHub Copilot,
[711.62s -> 717.62s]  and sometimes was able to infer the directions he was going in
[717.62s -> 720.62s]  and things like that.
[720.62s -> 722.58s]  So with all this, with formal math
[722.58s -> 727.06s]  being so exciting for both mathematics and for AI,
[727.06s -> 730.66s]  the question is, why don't people and AI always
[730.66s -> 731.94s]  use formal math?
[731.94s -> 736.14s]  What is the kind of blocker to making this happen?
[736.18s -> 739.22s]  So I want to argue that the key challenge is
[739.22s -> 743.22s]  that there's this gap between how people
[743.22s -> 749.26s]  are familiar with doing math and the actual formal system.
[749.26s -> 753.98s]  In particular, there's just so many ideas and intuitions,
[753.98s -> 756.42s]  and even the way that we write proofs,
[756.42s -> 760.18s]  that are just difficult or very tedious to express
[760.18s -> 762.34s]  in the formal system.
[762.34s -> 765.74s]  In a formal system like Lean, each step of reasoning
[765.74s -> 769.54s]  needs to be explicitly spelled out in detail.
[769.54s -> 772.94s]  And as we saw even in that very simple example that I gave,
[772.94s -> 776.14s]  you often have to have a deep knowledge of the system,
[776.14s -> 778.78s]  like what things exist in the system,
[778.78s -> 781.82s]  and how to write the code, and so on.
[781.82s -> 783.38s]  And so the theme of this talk will
[783.38s -> 788.74s]  be steps towards bridging the gap between informal reasoning
[788.74s -> 791.02s]  and formal reasoning.
[791.02s -> 793.74s]  Can we use AI and language models
[793.74s -> 796.86s]  to get the best of both worlds, maintain
[796.86s -> 799.10s]  the flexibility of informal reasoning,
[799.10s -> 800.86s]  while having all of these benefits
[800.86s -> 805.74s]  that I mentioned with operating in the formal system?
[805.74s -> 808.74s]  And so I'll talk about three different directions
[808.74s -> 812.90s]  that we and others in the community are pursuing.
[812.90s -> 815.18s]  First, I'll talk about incorporating
[815.18s -> 817.42s]  informal thoughts into the formal theorem
[817.42s -> 819.34s]  proving procedure.
[819.34s -> 823.66s]  I'll talk about training models to think informally
[823.66s -> 826.82s]  with reinforcement learning, and in particular,
[826.82s -> 831.02s]  our recent work, which is called LeanSTAR.
[831.02s -> 836.30s]  Then I'll move to informal provers or informal proofs.
[836.30s -> 838.66s]  And I'll talk about how you can break down
[838.66s -> 841.74s]  the problem of writing one of these proofs
[841.74s -> 844.46s]  as first writing a sketch and then
[844.46s -> 848.10s]  kind of filling in the lower level gaps of the sketch.
[848.10s -> 852.26s]  So I'll talk about our work called draft sketch proof.
[852.26s -> 855.06s]  And then our recent work, which is actually not even
[855.06s -> 859.02s]  released yet, of trying to enable tools that
[859.02s -> 861.38s]  let you fill in the gaps of these sketches
[861.38s -> 864.50s]  in the Lean theorem prover.
[864.50s -> 866.26s]  And then finally, at the end of the talk,
[866.26s -> 870.38s]  I will talk about more of a future direction
[870.38s -> 873.22s]  that we are taking initial steps towards, which
[873.22s -> 875.82s]  is, how do we actually make these systems
[875.82s -> 880.50s]  useful to mathematicians doing research level mathematics?
[880.54s -> 883.02s]  So in particular, I'll talk about one way
[883.02s -> 885.74s]  in which the models could assist in these larger
[885.74s -> 887.22s]  projects.
[887.22s -> 889.62s]  I'll talk about some tools that actually already exist,
[889.62s -> 892.46s]  and you can try after the talk if you want,
[892.46s -> 895.58s]  and a new benchmark that tries
[895.58s -> 899.46s]  to further progress of building these assistants
[899.46s -> 902.02s]  for these complex research level type projects.
[904.62s -> 907.06s]  So with that, let me go to the first part, where
[907.06s -> 910.18s]  I will talk about integrating informal thoughts
[910.18s -> 913.38s]  into formal theorem proving.
[913.38s -> 915.06s]  So here, this will largely be based
[915.06s -> 918.54s]  on our paper called Lean Star, which we'll
[918.54s -> 921.98s]  be presenting soon at iClear.
[921.98s -> 924.10s]  And here, again, we're in the setting
[924.10s -> 927.98s]  of theorem proving in Lean.
[927.98s -> 930.42s]  So here, we have the theorem that I showed you
[930.42s -> 932.18s]  before at the top.
[932.18s -> 934.10s]  And then as I showed you in the demo,
[934.10s -> 936.82s]  you could think of this as a kind of interactive step
[936.82s -> 938.74s]  by step process.
[938.78s -> 940.42s]  So in particular, Lean will give you
[940.42s -> 942.74s]  this state of the proof.
[942.74s -> 944.54s]  And then one thing that you could do
[944.54s -> 948.58s]  is you could send that state to a language model,
[948.58s -> 952.34s]  and it could try to generate the next step of the proof.
[952.34s -> 955.90s]  Then you can provide the next step to Lean,
[955.90s -> 959.42s]  and it can either tell you whether the proof is done,
[959.42s -> 962.02s]  whether there is an error, or as we saw,
[962.02s -> 964.86s]  it can give you the next state of the proof.
[964.86s -> 968.70s]  You could then continue this until you either give up
[968.70s -> 971.42s]  or you reach a complete proof.
[971.42s -> 974.14s]  And so in that sense, you can see one of these proofs
[974.14s -> 977.82s]  as being a sequence of states and next steps,
[977.82s -> 978.90s]  or they're called tactics.
[981.54s -> 985.14s]  So in a bit more detail, what we want to do
[985.14s -> 991.22s]  is train a model on some data set of inputs and outputs.
[991.22s -> 992.90s]  So an example is you could have
[992.90s -> 996.94s]  the model take in the proof state and output the next step.
[996.94s -> 999.86s]  And what you typically do is you extract
[999.86s -> 1002.74s]  a lot of these state and next step examples
[1002.74s -> 1006.50s]  from some corpus of theorems and proofs.
[1006.50s -> 1009.86s]  So for example, you could use the entire math lib project
[1009.86s -> 1011.74s]  that I mentioned earlier,
[1011.74s -> 1014.58s]  or you could even have a model generate its own theorems
[1014.58s -> 1016.38s]  and generate its own proofs.
[1016.38s -> 1021.22s]  And then ultimately, you kind of turn it into a data set.
[1021.22s -> 1022.90s]  Once you've trained a model,
[1022.90s -> 1026.50s]  you then want to use it to generate full proofs.
[1026.50s -> 1028.70s]  So the traditional way of doing this
[1028.70s -> 1031.90s]  is through this kind of tree search procedure.
[1031.90s -> 1035.62s]  Here's an example tree search called best-first search.
[1035.62s -> 1039.02s]  And basically, the idea is you ask the model
[1039.02s -> 1043.06s]  to generate multiple candidates for the next step.
[1043.06s -> 1045.46s]  Then you somehow come up with a score
[1045.46s -> 1048.06s]  for each one of these candidates.
[1048.10s -> 1051.50s]  You choose the step with the highest score.
[1051.50s -> 1057.38s]  So for instance, first, we chose this intro h step.
[1057.38s -> 1059.82s]  Then you can expand those further,
[1059.82s -> 1062.02s]  choose the next highest-scoring sequence.
[1062.02s -> 1064.38s]  As you can see here, it kind of backtracked.
[1064.38s -> 1066.22s]  And then it took this green path,
[1066.22s -> 1069.94s]  which led to a correct proof.
[1069.94s -> 1071.98s]  So this is just one possible strategy
[1071.98s -> 1075.58s]  you could use for generating a full proof
[1075.58s -> 1080.06s]  if your model can only predict the next step.
[1080.06s -> 1082.38s]  So what we are interested in is,
[1082.38s -> 1085.98s]  can we go beyond just training the model
[1085.98s -> 1089.78s]  on formal proofs and to generate formal proofs
[1089.78s -> 1092.42s]  and instead train the model to think
[1092.42s -> 1095.26s]  before each step of the formal proof?
[1095.26s -> 1097.26s]  So in particular, we want to train the model
[1097.26s -> 1099.46s]  to generate what's on the right,
[1099.46s -> 1103.90s]  where before taking a step, it outputs some reasoning,
[1103.90s -> 1106.06s]  and it's kind of free to decide
[1106.06s -> 1108.10s]  whatever it wants to do with the reasoning.
[1108.10s -> 1109.82s]  It could break down the problem.
[1109.82s -> 1111.66s]  It could plan out the next step.
[1111.66s -> 1114.02s]  It could even solve some computation
[1114.02s -> 1118.18s]  that isn't really present in the formal proof.
[1118.18s -> 1120.02s]  So why would you want to do this?
[1120.02s -> 1122.78s]  Well, again, it could give the model some room
[1122.78s -> 1126.54s]  to plan out what it is about to do.
[1126.54s -> 1129.26s]  When you think about it, it could help diversify
[1129.26s -> 1132.30s]  the search space since now the model
[1132.38s -> 1136.18s]  is searching for proofs, not just in the formal space,
[1136.18s -> 1139.30s]  but in the formal space augmented with these thoughts.
[1140.58s -> 1142.26s]  And I won't go into details here,
[1142.26s -> 1144.34s]  but there's been a lot of cool work
[1144.34s -> 1146.70s]  in the language model community
[1146.70s -> 1150.34s]  showing that adding in these kind of chain of thought
[1150.34s -> 1153.30s]  in other domains can actually give a model
[1153.30s -> 1156.50s]  which is more expressive in terms of
[1156.50s -> 1158.50s]  the kinds of problems it can solve.
[1159.50s -> 1162.42s]  So we have a few good reasons to try this out.
[1163.50s -> 1167.78s]  Now, the key issue here is that nowhere on the internet
[1167.78s -> 1170.82s]  is there formal proofs written in Lean
[1170.82s -> 1174.54s]  that have these nice thoughts written out for them.
[1174.54s -> 1178.50s]  And so what we have to do is actually design an algorithm
[1178.50s -> 1181.38s]  so that a model kind of learns on its own
[1181.38s -> 1184.42s]  to produce these thoughts that are useful for the proofs.
[1185.42s -> 1188.30s]  So the algorithm is called LeanStar,
[1188.30s -> 1191.10s]  and it adopts this name from this other work
[1191.10s -> 1192.54s]  called self-taught reasoner.
[1193.46s -> 1195.90s]  And the process basically has two different phases.
[1196.94s -> 1199.02s]  So the high level idea is we want to learn
[1199.02s -> 1202.10s]  to generate these thoughts via reinforcement learning.
[1203.10s -> 1205.78s]  So first we have to initialize the model
[1205.78s -> 1208.86s]  so that it can produce some type of thoughts.
[1208.86s -> 1210.38s]  And then we want to train it further
[1210.38s -> 1213.26s]  so that it gets better at using the thoughts
[1214.18s -> 1215.10s]  to prove theorems.
[1217.06s -> 1221.06s]  So in the first step, we use this kind of clever trick,
[1221.06s -> 1223.38s]  which is we can look at a state
[1223.38s -> 1225.98s]  and the actual next step of the proof,
[1225.98s -> 1230.70s]  and then have a language model just retrospectively
[1230.70s -> 1234.58s]  come up with some thought that describes the transition
[1234.58s -> 1237.02s]  from the state to the next step.
[1237.02s -> 1240.26s]  So what we found is that if you don't give this step,
[1240.26s -> 1242.90s]  then the language model might just output
[1243.50s -> 1245.86s]  a kind of meaningless or incorrect thought,
[1245.86s -> 1247.54s]  but they were kind of good enough
[1247.54s -> 1249.94s]  at coming up with some thought
[1249.94s -> 1252.74s]  which described this transition.
[1254.46s -> 1259.46s]  So then we can annotate a large set of proofs.
[1259.46s -> 1262.50s]  So here, for instance, we take all of math load
[1262.50s -> 1266.14s]  and we can get like hundreds of thousands of examples
[1266.14s -> 1268.78s]  of state thought and next step.
[1269.62s -> 1272.82s]  Then we can use that to train a model.
[1272.82s -> 1276.38s]  And it doesn't necessarily have to use all 100,000,
[1276.38s -> 1278.42s]  by the way, for this initial step.
[1278.42s -> 1280.74s]  You want to just train some initial model
[1280.74s -> 1285.74s]  that knows to produce these thoughts prior to taking steps.
[1287.82s -> 1289.18s]  Then we want to take that model
[1289.18s -> 1291.34s]  and put it into this loop.
[1291.34s -> 1294.94s]  So we have the model generate full proofs.
[1294.94s -> 1297.34s]  Then we ask Lean to tell us
[1297.82s -> 1300.10s]  whether they are correct or not.
[1300.10s -> 1302.18s]  And then we use some type of reinforcement
[1302.18s -> 1304.90s]  learning algorithm to improve the model further.
[1306.58s -> 1310.02s]  So what we need is some method to generate proofs,
[1310.02s -> 1312.18s]  and we need to actually choose some algorithm
[1312.18s -> 1313.50s]  to implement this with.
[1315.26s -> 1319.46s]  So what we discovered is that this commonly used way
[1319.46s -> 1322.42s]  of using the tree search or best for search
[1322.42s -> 1324.22s]  was actually difficult to get to work
[1324.22s -> 1325.82s]  when we added in these thoughts.
[1326.82s -> 1329.26s]  I think one reason is that it gets difficult
[1329.26s -> 1333.78s]  to actually assign a really good score to the thought.
[1333.78s -> 1335.98s]  And so as a result, the tree search
[1335.98s -> 1338.46s]  kind of didn't work as well.
[1340.50s -> 1343.14s]  So what we did is design a new method,
[1343.14s -> 1345.90s]  which is this kind of simple idea
[1345.90s -> 1349.26s]  of generating multiple proofs in parallel.
[1349.26s -> 1353.98s]  So for a given trajectory, you kind of generate a step.
[1353.98s -> 1355.54s]  If you get an error from Lean,
[1356.30s -> 1358.46s]  you just retry on that same path,
[1358.46s -> 1362.18s]  and then you keep going up to a maximum number of steps,
[1362.18s -> 1365.66s]  or you stop if you reach a complete proof.
[1368.54s -> 1370.38s]  Then for the algorithm,
[1370.38s -> 1375.14s]  we actually just use the simplest possible algorithm.
[1375.14s -> 1376.86s]  And so we, as well as other groups,
[1376.86s -> 1381.86s]  are now exploring better reinforcement learning algorithms,
[1381.94s -> 1383.38s]  like online algorithms.
[1384.26s -> 1386.54s]  But here we did something very simple,
[1386.54s -> 1390.82s]  which is you just collect the successful trajectories,
[1390.82s -> 1393.06s]  you add those to your dataset,
[1393.06s -> 1396.10s]  and then you train a new model on this dataset
[1396.10s -> 1398.50s]  of states, thoughts, and tactics.
[1399.70s -> 1402.50s]  So this algorithm goes by various names.
[1402.50s -> 1404.46s]  It's called expert iteration.
[1404.46s -> 1406.54s]  It's also called REST-EM.
[1406.54s -> 1409.10s]  It's also called rejection fine-tuning.
[1409.10s -> 1411.26s]  But the idea is very simple.
[1414.18s -> 1417.50s]  So then typically the way that these models are evaluated
[1417.50s -> 1420.06s]  is on these math competition problems.
[1421.14s -> 1424.18s]  So although we train the model on MathLib,
[1425.06s -> 1427.90s]  here's a common test dataset which is used,
[1427.90s -> 1430.14s]  which is called MiniF2F.
[1430.14s -> 1431.74s]  And here's an example problem
[1431.74s -> 1434.46s]  from the International Math Olympiad.
[1434.46s -> 1437.28s]  So here I've shown the informal version,
[1437.28s -> 1440.42s]  just to show you what the problem is like.
[1440.42s -> 1444.22s]  But then the model here only gets the formal version
[1444.22s -> 1445.62s]  and has to produce a proof.
[1448.46s -> 1451.70s]  So here's some results with an early model
[1451.70s -> 1453.62s]  that we tried in the project.
[1454.60s -> 1458.86s]  So in red, you can see the model that we started with.
[1458.86s -> 1460.66s]  And then in black, you could see the model
[1460.66s -> 1463.38s]  after we performed this initialization step.
[1464.78s -> 1466.36s]  Then in gray, we can see the model
[1466.36s -> 1469.50s]  after we performed the expert iteration.
[1469.50s -> 1471.26s]  And you can see that the Lean-STAR process
[1471.26s -> 1473.78s]  basically took it from being worse
[1473.78s -> 1475.76s]  than this baseline model,
[1475.76s -> 1478.88s]  which was based on this GPT-4 agent,
[1478.88s -> 1480.44s]  to being better than it.
[1482.42s -> 1484.50s]  Then at the end of the project,
[1484.50s -> 1488.52s]  we applied Lean-STAR to the best available base model
[1488.52s -> 1491.52s]  at the time for theme improving.
[1491.52s -> 1493.86s]  And again, we saw these improvements
[1493.86s -> 1496.14s]  going from gray to black.
[1496.14s -> 1498.00s]  And at the time that we did this,
[1498.00s -> 1499.98s]  this was the kind of state-of-the-art
[1499.98s -> 1501.48s]  or this mini F2F dataset.
[1504.68s -> 1507.16s]  One really interesting thing is that
[1507.16s -> 1510.64s]  we found that models with the thoughts
[1510.64s -> 1514.36s]  benefit more from scaling up the search budget
[1514.36s -> 1516.64s]  or the kind of inference budget.
[1516.64s -> 1520.64s]  So here we're seeing as we sample more and more steps,
[1520.64s -> 1522.68s]  either with our sampling method
[1522.68s -> 1525.60s]  or as a baseline with the best for search,
[1525.60s -> 1529.04s]  how the performance looks.
[1529.04s -> 1531.82s]  And you can see that the gains we get from the green line,
[1531.82s -> 1534.38s]  which is Lean-STAR with the thoughts,
[1534.38s -> 1536.92s]  are more pronounced than the model
[1536.92s -> 1538.76s]  that doesn't have the thoughts.
[1539.88s -> 1541.96s]  And so this might be indicating
[1541.96s -> 1544.00s]  the idea that I mentioned before
[1544.00s -> 1545.28s]  that adding in these thoughts
[1545.28s -> 1548.00s]  helps to kind of diversify the search space.
[1550.20s -> 1551.56s]  Here's some examples.
[1551.56s -> 1553.82s]  And again, you don't have to read through the details,
[1553.82s -> 1554.80s]  but if you're curious,
[1554.84s -> 1557.28s]  you can take a look at the paper after.
[1557.28s -> 1559.48s]  One interesting thing here is that
[1559.48s -> 1561.40s]  if you look at the formal code,
[1561.40s -> 1563.20s]  there's actually some steps of reasoning
[1563.20s -> 1564.84s]  that the model is doing
[1564.84s -> 1567.52s]  in the informal thought, shown in gray,
[1567.52s -> 1569.92s]  that aren't really present in the formal code.
[1571.92s -> 1574.96s]  And here's a longer example,
[1574.96s -> 1576.90s]  partly because it looks impressive,
[1576.90s -> 1578.76s]  but also to just show you
[1578.76s -> 1580.90s]  that when you add in these informal thoughts
[1580.90s -> 1582.80s]  with the formal ones,
[1582.80s -> 1587.28s]  the output starts to get fairly non-trivial.
[1590.20s -> 1593.68s]  So after Lean-STAR, the really exciting thing
[1593.68s -> 1596.98s]  is that this idea of augmenting models
[1596.98s -> 1599.32s]  or reasoning models with thoughts
[1599.32s -> 1602.08s]  and training them with reinforcement learning
[1602.08s -> 1605.40s]  has been adopted in the theorem-proving community.
[1606.36s -> 1608.00s]  So in particular,
[1608.00s -> 1611.40s]  very rapidly this idea of incorporating thoughts
[1611.40s -> 1614.16s]  became a part of the state-of-the-art systems.
[1614.16s -> 1617.08s]  So here's the example that I mentioned before
[1617.08s -> 1618.56s]  called DeepSeek Prover,
[1618.56s -> 1621.54s]  where they incorporate in the informal thoughts.
[1622.40s -> 1625.08s]  And then as I mentioned, just this morning,
[1625.08s -> 1628.20s]  there was this state-of-the-art prover released
[1628.20s -> 1631.52s]  by this startup.
[1631.52s -> 1633.84s]  And you can see that they have this idea
[1633.84s -> 1637.24s]  of kind of alternating between informal reasoning
[1637.24s -> 1638.78s]  and snippets of code.
[1638.78s -> 1643.78s]  And then more broadly, these reasoning models
[1643.90s -> 1647.00s]  that generate long chains of thought
[1647.00s -> 1649.38s]  and are trained with reinforcement learning
[1649.38s -> 1654.38s]  have really begun to revolutionize the LLM reasoning.
[1655.34s -> 1657.92s]  So I'm not gonna go into the details here,
[1657.92s -> 1659.90s]  but you have probably heard of these models
[1659.90s -> 1664.18s]  like OpenAI 01 and DeepSeek R1.
[1664.18s -> 1667.26s]  And so it seems like, at least currently,
[1667.26s -> 1670.26s]  having this kind of informal thinking
[1670.26s -> 1673.14s]  is a really key part of the reasoning procedure.
[1675.54s -> 1679.98s]  So to recap, Leanstar kind of builds on this observation
[1679.98s -> 1683.50s]  that training only on the formal code
[1683.50s -> 1686.78s]  may be insufficient to learn the actual thought process
[1686.78s -> 1689.06s]  that's needed to produce the code.
[1689.06s -> 1691.94s]  And it gives a kind of simple algorithm
[1691.94s -> 1693.90s]  for learning to generate the thoughts.
[1693.90s -> 1698.90s]  Now I'll move from informal thoughts
[1699.34s -> 1703.26s]  to informal provers and informal proofs.
[1703.26s -> 1705.14s]  And in particular, we'll talk about methods
[1705.14s -> 1708.42s]  that prove theorems by kind of producing
[1708.42s -> 1710.10s]  this high-level sketch
[1710.10s -> 1712.30s]  and then filling in the gaps of the sketch.
[1714.98s -> 1719.98s]  So here the motivation is to combine the benefits
[1720.44s -> 1722.30s]  of kind of higher-level reasoning
[1722.30s -> 1723.80s]  and lower-level reasoning.
[1724.82s -> 1728.98s]  And one motivation for this is to think about
[1728.98s -> 1731.62s]  how do we actually write one of these formal proofs
[1731.62s -> 1733.70s]  in the formal proof assistant, sorry,
[1733.70s -> 1736.40s]  informal proofs in the formal proof assistant.
[1737.90s -> 1739.22s]  So again, you don't have to worry too much
[1739.22s -> 1741.58s]  about the details of this,
[1741.58s -> 1745.10s]  but here we're trying to prove the statement on the left.
[1745.10s -> 1748.62s]  And what is notable here is that
[1748.62s -> 1751.26s]  we can somewhat break this informal proof
[1751.26s -> 1753.68s]  up into these three different parts.
[1755.94s -> 1758.54s]  Then it turns out that we can write this
[1758.54s -> 1762.42s]  in the formal system using something that is structured
[1762.42s -> 1765.86s]  kind of analogously to the informal proof.
[1765.86s -> 1768.38s]  So this is a system called Isabelle,
[1768.38s -> 1771.50s]  and it has the style where you can write
[1771.50s -> 1776.50s]  these kind of intermediate claims or conjectures.
[1776.52s -> 1778.14s]  And if you look at it,
[1778.14s -> 1780.76s]  they somewhat line up with the different steps.
[1781.12s -> 1784.80s]  Here you have 10 times 280 divided by 40,
[1784.80s -> 1786.76s]  which shows up here.
[1786.76s -> 1789.48s]  And then this is a way of basically writing,
[1789.48s -> 1791.14s]  okay, let's complete the proof.
[1792.88s -> 1794.72s]  Now, the interesting thing here is that
[1794.72s -> 1797.24s]  you still need to produce a proof
[1797.24s -> 1801.68s]  of each one of these kind of higher-level steps.
[1801.68s -> 1803.88s]  So that is shown in green.
[1803.88s -> 1805.32s]  And so you can see here that
[1805.32s -> 1807.24s]  to actually come up with that proof,
[1807.24s -> 1810.22s]  it doesn't really look like natural language at all.
[1810.22s -> 1812.96s]  Here it's actually calling this SMT solver
[1812.96s -> 1814.96s]  and feeding it some facts.
[1816.38s -> 1819.92s]  So interestingly, we have this kind of decomposition
[1819.92s -> 1823.62s]  between high-level and these kind of lower-level things.
[1824.86s -> 1827.10s]  So let me actually say a bit more about
[1827.10s -> 1830.24s]  how you produce these lower-level proofs
[1830.24s -> 1831.60s]  in a system like Isabelle.
[1833.42s -> 1836.26s]  So it turns out that there are these very powerful
[1836.26s -> 1840.14s]  and very useful automation tools called hammers,
[1840.96s -> 1842.50s]  or this one is called sledgehammer.
[1842.50s -> 1844.34s]  And the basic idea is that
[1844.34s -> 1847.78s]  as you're writing a proof, as a human,
[1847.78s -> 1851.74s]  you could write one of these conjectures
[1851.74s -> 1853.90s]  and then you could call the sledgehammer.
[1854.86s -> 1857.26s]  What it does under the covers is
[1857.26s -> 1861.02s]  it calls out to external automated provers,
[1861.02s -> 1863.78s]  ones that are based on first-order logic
[1863.78s -> 1866.60s]  or higher-order logic or SMT solvers.
[1867.52s -> 1870.40s]  And these turn out to be extremely effective
[1870.40s -> 1872.60s]  when you're using the system
[1872.60s -> 1876.52s]  for kind of filling in these little gaps of the proof.
[1878.32s -> 1880.34s]  What these are not good at is,
[1880.34s -> 1882.98s]  let's say you want to solve an IMO problem,
[1883.88s -> 1888.56s]  then the sledgehammer methods just won't succeed.
[1889.62s -> 1893.08s]  The technical reason is that based on how they're set up,
[1893.08s -> 1896.66s]  there is just such a large search space of possible proofs.
[1897.54s -> 1900.32s]  And in particular, if you think about this proof
[1900.32s -> 1903.64s]  as being structured as like these have statements,
[1903.64s -> 1905.44s]  they don't really have the functionality
[1905.44s -> 1907.60s]  to produce statements like that.
[1908.68s -> 1911.82s]  So in practice, these are used kind of interactively
[1911.82s -> 1913.68s]  as you're writing proof as a human.
[1915.48s -> 1917.84s]  So here, the idea is we want to combine
[1917.84s -> 1920.12s]  some kind of high-level prover
[1920.12s -> 1923.18s]  with a lower-level prover like the sledgehammer.
[1924.08s -> 1927.60s]  And this leads to our method,
[1927.60s -> 1929.96s]  which is called draft sketch proof,
[1929.96s -> 1933.86s]  which we presented in iClear in 2023
[1933.86s -> 1937.34s]  and developed and released in late 2022.
[1939.52s -> 1941.16s]  So here, the idea is to come up
[1941.16s -> 1944.04s]  with this kind of three-step procedure.
[1944.04s -> 1947.40s]  First, we're going to draft an informal proof.
[1947.40s -> 1949.08s]  Then we're going to translate it
[1949.08s -> 1952.20s]  into this formal sketch.
[1952.20s -> 1954.44s]  And then we're going to use a low-level prover
[1954.44s -> 1956.52s]  to fill in the gaps of the sketch.
[1958.00s -> 1960.44s]  So to show you this in more detail,
[1960.44s -> 1962.46s]  let's walk through each one of these.
[1963.88s -> 1967.92s]  So first, we start off with an informal theorem
[1967.92s -> 1970.56s]  and a formal theorem statement.
[1970.56s -> 1973.44s]  It's actually really important to provide the system
[1973.44s -> 1975.54s]  with the formal theorem statement
[1975.54s -> 1978.56s]  because when we start to translate things,
[1978.56s -> 1980.76s]  we want to make sure that the model's not cheating
[1980.76s -> 1983.00s]  and it's actually proving the thing
[1983.00s -> 1984.40s]  that we want it to prove.
[1985.44s -> 1989.80s]  Then in the first step, we have the system,
[1989.80s -> 1993.40s]  so it could be a human or it could be an LLM,
[1993.40s -> 1995.62s]  generate some informal proof.
[1997.52s -> 1998.68s]  Then in the next step,
[1998.68s -> 2001.84s]  we have an LLM translate the informal proof
[2001.84s -> 2004.80s]  into what's called a formal sketch.
[2004.80s -> 2006.76s]  It's essentially what I showed you before,
[2006.76s -> 2010.24s]  except now we leave these gaps to be filled,
[2010.24s -> 2011.98s]  which are the lower-level proofs.
[2013.74s -> 2014.84s]  Then in the final stage,
[2014.84s -> 2018.66s]  we try to close the gap with a lower-level prover.
[2018.66s -> 2021.12s]  Here we are actually using the sledgehammer tool
[2021.12s -> 2023.24s]  that I told you about.
[2023.24s -> 2026.48s]  And if you're able to close all of the gaps,
[2026.48s -> 2029.70s]  then you're guaranteed to have a complete proof.
[2032.54s -> 2034.08s]  The interesting thing is that
[2034.08s -> 2035.80s]  this actually looks a lot different
[2035.80s -> 2037.52s]  than what I was showing you before,
[2037.52s -> 2040.52s]  where we have this kind of step-by-step proof search,
[2040.52s -> 2042.94s]  and maybe it's like a tree search.
[2042.94s -> 2047.20s]  Now what we can do is we can diversify the search space
[2047.20s -> 2051.40s]  by just generating many possible informal proofs or drafts
[2052.48s -> 2055.52s]  and or generate many potential translations of those
[2055.52s -> 2057.76s]  into formal sketches.
[2057.76s -> 2059.80s]  And then we can just try to fill in the gaps.
[2059.80s -> 2063.68s]  And if the gaps are filled in any of the sketches,
[2063.68s -> 2067.36s]  then we have a formal proof that we could consider
[2067.36s -> 2068.80s]  as the output of the system.
[2071.24s -> 2073.20s]  So here's showing what happens
[2073.20s -> 2077.34s]  as we scale up the number of calls to the pipeline.
[2077.34s -> 2082.34s]  So here we're either generating many informal proof drafts
[2082.84s -> 2086.60s]  or in the case of using a human written informal proof,
[2086.60s -> 2089.30s]  we're generating many possible translations
[2089.30s -> 2090.64s]  into the formal sketch.
[2091.76s -> 2093.26s]  You could see on the left-hand side
[2093.82s -> 2096.06s]  that if we just call the system once,
[2096.06s -> 2098.48s]  then it actually, I mean, it proves some things,
[2098.48s -> 2101.10s]  but it's not very good.
[2101.10s -> 2102.40s]  And we really see the benefits
[2102.40s -> 2106.86s]  as we scale up the amount of proof search or sampling.
[2106.86s -> 2110.84s]  And up here, we're proving a large number of problems.
[2110.84s -> 2112.86s]  This is on the same mini F2F dataset.
[2114.62s -> 2117.66s]  Now this was in the days of Codex and Minerva,
[2117.66s -> 2120.06s]  if you remember those models.
[2120.06s -> 2121.26s]  And interestingly here,
[2121.26s -> 2123.48s]  if you look on the very right-hand side,
[2123.48s -> 2127.76s]  if we actually sampled enough from the model,
[2127.76s -> 2130.12s]  then we were able to, right at the end,
[2130.12s -> 2133.48s]  surpass the performance of using a human written proof.
[2134.46s -> 2136.62s]  And so this was kind of exciting.
[2136.62s -> 2138.94s]  And probably now that language models are much better,
[2138.94s -> 2143.82s]  we would be able to make that transition even earlier.
[2146.20s -> 2147.26s]  So here's an example
[2147.26s -> 2151.02s]  of proving an international math Olympiad problem.
[2151.62s -> 2153.26s]  So here, the language model produces
[2153.26s -> 2156.16s]  the informal proof shown in green.
[2156.16s -> 2158.14s]  Then the language model produces
[2158.14s -> 2159.94s]  the formal sketch shown in blue.
[2160.82s -> 2161.66s]  You can see that here,
[2161.66s -> 2165.34s]  we actually back then even had these informal
[2165.34s -> 2167.88s]  kind of thoughts in as comments,
[2167.88s -> 2170.86s]  or here it's showing the informal version of the step.
[2172.88s -> 2174.78s]  And then we have the sledgehammer system
[2174.78s -> 2177.38s]  fill in the gaps shown in purple.
[2177.38s -> 2179.94s]  And you can see that sometimes it's pretty non-trivial,
[2179.94s -> 2182.94s]  like here again, it's calling this SMT solver
[2182.94s -> 2186.72s]  and feeding in a bunch of different facts or premises.
[2190.02s -> 2192.06s]  So since then,
[2192.06s -> 2196.78s]  I've put together a tutorial for theorem proving.
[2196.78s -> 2199.04s]  So it goes over the kind of step-by-step methods
[2199.04s -> 2201.34s]  that I mentioned in the first part,
[2201.34s -> 2204.46s]  and also has a notebook that shows you
[2204.46s -> 2207.02s]  how to implement this draft sketch proof method.
[2207.94s -> 2208.78s]  And in particular,
[2208.82s -> 2211.14s]  it just calls that to a language model API.
[2211.14s -> 2213.96s]  So you can try it out with one of the,
[2213.96s -> 2216.66s]  any state-of-the-art model that you want to,
[2216.66s -> 2218.82s]  if you're curious to learn more.
[2221.58s -> 2222.82s]  So to recap,
[2222.82s -> 2226.14s]  I talked about this method called draft sketch proof,
[2226.14s -> 2228.50s]  which generates these high level sketches
[2228.50s -> 2231.06s]  and then tries to fill in the gaps.
[2231.06s -> 2235.46s]  And what this relied on is in this language, Isabelle,
[2235.46s -> 2238.42s]  having this lower level prover called sledgehammer.
[2240.02s -> 2243.94s]  So next I'm going to talk about our very recent work
[2243.94s -> 2247.66s]  on trying to build one of these sledgehammer provers
[2247.66s -> 2250.84s]  for Lean so that we can more easily write
[2250.84s -> 2253.52s]  these kind of sketch-based proofs in Lean.
[2255.50s -> 2260.50s]  So this is based on a paper that is still not public,
[2260.98s -> 2264.52s]  which is called premise selection for a Lean hammer,
[2264.52s -> 2267.20s]  where we build a system called Lean hammer.
[2269.28s -> 2271.48s]  So what is a hammer?
[2271.48s -> 2274.96s]  So a hammer integrates, as I mentioned,
[2274.96s -> 2277.28s]  these external provers,
[2277.28s -> 2279.36s]  and there's a bit of terminology here
[2279.36s -> 2281.36s]  that is a bit tricky
[2281.36s -> 2283.56s]  if you haven't seen the distinction before.
[2284.52s -> 2286.88s]  Specifically what it does is it integrates
[2286.88s -> 2288.96s]  an automated theorem prover
[2288.96s -> 2291.34s]  into an interactive theorem prover.
[2292.56s -> 2294.36s]  So an interactive theorem prover
[2295.24s -> 2297.84s]  is like the one I showed you, like Lean.
[2297.84s -> 2301.16s]  And essentially it's a programming language
[2301.16s -> 2303.12s]  that is able to check the proofs.
[2304.32s -> 2307.18s]  However, the language on its own
[2307.18s -> 2308.56s]  doesn't give you a way
[2308.56s -> 2311.08s]  of automatically producing the proofs.
[2311.08s -> 2313.62s]  You usually have to write them as a human.
[2315.04s -> 2317.34s]  An automated theorem prover
[2317.34s -> 2321.40s]  is something that tries to automatically find proofs.
[2321.40s -> 2323.64s]  And traditionally these are based
[2323.64s -> 2326.52s]  on different kinds of logics.
[2326.52s -> 2329.70s]  So they might be based on higher order logic provers
[2329.70s -> 2331.76s]  or things like SMT solvers.
[2334.00s -> 2337.36s]  And so, as I mentioned before,
[2337.36s -> 2339.16s]  these automated theorem provers
[2339.16s -> 2343.80s]  really struggle with more complex proofs
[2343.80s -> 2346.28s]  due to this large search space
[2346.28s -> 2348.00s]  in their kind of formalism.
[2349.00s -> 2353.64s]  So what we can do to try to help with this problem
[2353.64s -> 2356.40s]  is to solve this really important problem
[2356.40s -> 2358.10s]  which is called premise selection.
[2359.32s -> 2361.48s]  So basically what you do is
[2361.48s -> 2364.12s]  you provide the automated theorem prover
[2364.12s -> 2366.52s]  with many different facts.
[2366.52s -> 2369.24s]  So you can provide it with definitions,
[2369.24s -> 2372.00s]  different theorem, different lemmas,
[2372.00s -> 2374.40s]  and then it goes off and tries to prove
[2374.40s -> 2376.50s]  the theorem that you want.
[2377.50s -> 2380.42s]  And if we look at the number of premises
[2380.42s -> 2382.90s]  in say Lean's Mathlib,
[2382.90s -> 2384.60s]  then it's extremely large.
[2384.60s -> 2387.84s]  So it's, you know, hundreds of thousands of premises.
[2388.70s -> 2390.44s]  And so if you just give all of those
[2390.44s -> 2392.34s]  to the automated theorem prover,
[2392.34s -> 2393.98s]  it will really struggle
[2393.98s -> 2398.98s]  because it has this really large search space.
[2400.50s -> 2402.68s]  So the basic idea of premise selection
[2402.68s -> 2404.46s]  is to somehow cut down
[2404.46s -> 2406.26s]  the number of premises that we give
[2407.30s -> 2410.82s]  and only provide it ones that are likely to be useful
[2410.82s -> 2412.26s]  for proving the theorem.
[2414.16s -> 2415.66s]  So then we can look at
[2415.66s -> 2419.00s]  what is the typical hammer pipeline.
[2419.00s -> 2421.78s]  So here it is at a kind of high level.
[2421.78s -> 2423.14s]  Let's say we're in Lean,
[2423.14s -> 2425.46s]  then we start off with the thing
[2425.46s -> 2427.06s]  we want to prove on the left.
[2428.04s -> 2429.14s]  Then we would pass it
[2429.14s -> 2431.54s]  to some kind of premise selection system.
[2432.50s -> 2435.00s]  Now, once we've selected premises
[2435.00s -> 2437.54s]  like definitions and theorems,
[2437.54s -> 2439.56s]  we have to translate it from Lean
[2439.56s -> 2443.12s]  into the language of the automated theorem prover.
[2444.60s -> 2446.34s]  Let's say that the automated theorem prover
[2446.34s -> 2448.46s]  finds a complete proof.
[2448.46s -> 2451.02s]  Well, then we have to actually translate it back
[2451.02s -> 2452.28s]  into a Lean proof.
[2453.34s -> 2455.02s]  And so the way that that's done
[2455.02s -> 2459.06s]  is through the step which is called proof reconstruction.
[2459.06s -> 2461.40s]  So it basically takes the output
[2462.12s -> 2464.20s]  and tries to produce a proof in Lean.
[2465.12s -> 2466.20s]  Then as our output,
[2466.20s -> 2469.28s]  we would see this nice proof on the right.
[2472.28s -> 2477.12s]  So amazingly, there's been a lot of really cool work
[2477.12s -> 2480.48s]  in the community on these different parts.
[2481.44s -> 2482.80s]  Usually they're developed
[2482.80s -> 2485.70s]  somewhat independently of each other,
[2485.70s -> 2490.22s]  but we have this translation layer called Lean auto.
[2491.92s -> 2493.84s]  That can translate from,
[2493.84s -> 2496.72s]  that can help translate from Lean's dependent type theory
[2497.64s -> 2500.68s]  into the higher order logic.
[2500.68s -> 2502.20s]  An example of automated theorem prover
[2502.20s -> 2505.00s]  is called a zipper position.
[2505.00s -> 2507.60s]  And then for this proof reconstruction,
[2507.60s -> 2511.88s]  this was developed by Josh Klinn and collaborators
[2511.88s -> 2513.94s]  who's part of this Lean hammer project.
[2515.08s -> 2517.60s]  And there's a system called a duper.
[2519.16s -> 2521.16s]  So what we're interested in here
[2521.76s -> 2523.32s]  is two different things.
[2523.32s -> 2525.38s]  First, we want to try to solve
[2525.38s -> 2527.64s]  this premise selection problem.
[2527.64s -> 2530.68s]  And then second, we have to come up with some way
[2530.68s -> 2532.90s]  of actually combining these together.
[2533.74s -> 2534.82s]  When I show it on a slide,
[2534.82s -> 2537.36s]  it looks kind of simple to put them together,
[2537.36s -> 2538.48s]  but it's actually not clear
[2538.48s -> 2540.60s]  what the best way to do this is.
[2540.60s -> 2542.36s]  And even more,
[2542.36s -> 2545.52s]  we wanna kind of go beyond the standard pipeline,
[2545.52s -> 2547.22s]  which I'll talk about in a bit.
[2548.22s -> 2550.90s]  So first, let me talk about the premise selection.
[2551.90s -> 2555.06s]  What we do is to frame this as retrieval
[2555.06s -> 2556.90s]  with a neural language model.
[2557.74s -> 2558.90s]  So in particular,
[2558.90s -> 2562.16s]  we have a kind of standard retrieval setup.
[2563.02s -> 2564.82s]  Here, we embed our input.
[2564.82s -> 2567.78s]  So this will be the goal that we wanna prove.
[2567.78s -> 2570.42s]  And we have a language model
[2570.42s -> 2573.48s]  that produces this embedding shown on the right.
[2574.48s -> 2578.44s]  Then we embed all of our potential premises.
[2578.44s -> 2582.32s]  So this will include theorems, definitions, lemmas,
[2582.32s -> 2584.74s]  and they could be from Mathlib.
[2584.74s -> 2588.40s]  They could also be local premises in your project
[2588.40s -> 2593.40s]  or in the hypotheses that you're going to prove.
[2593.52s -> 2594.36s]  And with that,
[2594.36s -> 2598.28s]  we get this list of embeddings shown on the right.
[2599.82s -> 2602.22s]  Then to select the premises,
[2602.22s -> 2606.70s]  we take the dot product, use cosine similarity
[2606.70s -> 2610.64s]  to select the set of highest ranked premises.
[2612.66s -> 2616.06s]  So here we train with this contrastive loss
[2616.06s -> 2618.38s]  that is often used to train retrieval models.
[2619.30s -> 2624.10s]  So it boils down to collecting these inputs, the states,
[2624.10s -> 2627.72s]  as well as some positive premises and negative premises.
[2628.84s -> 2632.20s]  And it turns out that there's actually a lot of nuance
[2633.04s -> 2634.48s]  in how to do this properly,
[2634.48s -> 2638.64s]  especially when the output is going to be this lean auto,
[2638.64s -> 2642.84s]  sorry, when the interface is with this lean auto system
[2642.84s -> 2644.62s]  in the HAMR pipeline.
[2645.60s -> 2647.68s]  So I won't go into all the details here.
[2647.68s -> 2649.60s]  And when we release the paper,
[2649.60s -> 2651.84s]  it will have all the details,
[2651.84s -> 2656.24s]  but even things like how and whether you simplify terms,
[2657.20s -> 2660.28s]  how exactly you choose these positive premises
[2660.48s -> 2663.80s]  and negative premises turn out to have a large impact
[2663.80s -> 2667.74s]  on the behavior of the retriever.
[2667.74s -> 2670.20s]  And so we'll show in the results in a second
[2670.20s -> 2673.68s]  that based on some previous retrievers that were trained,
[2673.68s -> 2676.40s]  our system that we trained does a lot better
[2676.40s -> 2679.02s]  when we put it into this HAMR pipeline.
[2681.40s -> 2682.60s]  So then the question is,
[2682.60s -> 2685.48s]  how do we combine all of these different pieces?
[2685.48s -> 2687.92s]  And so what we did is not just have
[2687.92s -> 2690.04s]  this kind of linear picture that I showed
[2690.64s -> 2691.84s]  on the previous slide,
[2691.84s -> 2694.44s]  but we actually incorporate these components
[2694.44s -> 2695.82s]  into a tree search.
[2696.74s -> 2699.44s]  So there's a really cool tree search method
[2699.44s -> 2702.72s]  and it's this kind of symbolic tree search called ASAP.
[2703.88s -> 2707.48s]  And yeah, it does this tree search
[2707.48s -> 2710.64s]  over different tactics or steps of the proof.
[2710.64s -> 2712.84s]  And so what we do is kind of wire it up
[2712.84s -> 2716.38s]  so that it can use the selected premises
[2716.38s -> 2718.88s]  to call different tactics and lean.
[2720.04s -> 2721.92s]  And it can, at any time,
[2721.92s -> 2724.28s]  query this automated theorem prover
[2724.28s -> 2726.52s]  using the selected premises.
[2726.52s -> 2729.30s]  And so this step will involve the translation
[2729.30s -> 2730.36s]  that I mentioned,
[2730.36s -> 2732.96s]  as well as the proof reconstruction.
[2735.12s -> 2737.22s]  So now with all of these different parts
[2737.22s -> 2739.00s]  that I've described,
[2739.00s -> 2743.38s]  you could say, how is this actually useful as a user?
[2744.68s -> 2748.80s]  Well, it turns out that we can wrap this all
[2748.80s -> 2752.10s]  into one kind of simple command.
[2752.10s -> 2754.18s]  So at any step of a proof,
[2755.04s -> 2758.32s]  you can just call this hammer tactic
[2758.32s -> 2761.68s]  and then it'll run this tree search that I mentioned,
[2761.68s -> 2764.24s]  call the external prover and all that.
[2764.24s -> 2765.58s]  And then if it succeeds,
[2765.58s -> 2769.24s]  it will display the proof to you on the right.
[2771.40s -> 2775.08s]  And what's cool about this is you could potentially enable
[2775.08s -> 2777.08s]  this kind of sketch-based proving
[2777.12s -> 2779.84s]  that I was talking about before.
[2779.84s -> 2784.28s]  So here I wanna show an actual demo of the system
[2784.28s -> 2787.84s]  where we took a human-written proof sketch
[2787.84s -> 2790.24s]  from this textbook, Mathematics and Lean,
[2791.16s -> 2793.02s]  and we wanna try to fill in the gaps
[2793.02s -> 2795.16s]  with the hammer system.
[2796.52s -> 2799.34s]  So this theorem is the irrationality
[2799.34s -> 2801.14s]  of the square root of two.
[2802.74s -> 2806.36s]  And yeah, sometimes in the formal system,
[2806.36s -> 2809.72s]  you'll write it in a slightly different way,
[2809.72s -> 2814.68s]  but the details are not too important for the demo,
[2814.68s -> 2817.44s]  but you can kind of read through after if you want.
[2819.36s -> 2823.58s]  So here we'll go back into VS Code.
[2824.52s -> 2826.80s]  And here is, first of all,
[2826.80s -> 2830.62s]  the simple theorem that I showed you before.
[2831.62s -> 2836.62s]  And so what we can do is we can call this hammer.
[2838.42s -> 2843.42s]  And the first time you run it should take a few seconds.
[2844.60s -> 2847.74s]  And so what it's done is it's selected the premises
[2847.74s -> 2852.74s]  and called the tree search and all that.
[2854.06s -> 2855.90s]  And now you can see that it came back
[2855.90s -> 2859.22s]  with this proof, this theorem or lemma.
[2860.70s -> 2865.18s]  So this one just says that if two divides M squared,
[2865.18s -> 2867.36s]  then two will divide M.
[2868.42s -> 2870.62s]  So it turns out that this one will actually be useful
[2870.62s -> 2873.60s]  in this irrationality proof below.
[2875.38s -> 2876.78s]  So now we can go step-by-step
[2876.78s -> 2880.60s]  and try to fill in the gaps with the hammer.
[2882.10s -> 2885.92s]  So here it got this one and we can just keep going.
[2885.92s -> 2890.00s]  And interestingly up here,
[2890.00s -> 2892.96s]  it actually used the lemma that we just proved.
[2892.96s -> 2897.58s]  So you can see two divide of two divide square.
[2900.38s -> 2902.10s]  And so here it succeeded again,
[2903.28s -> 2905.04s]  and I'll just keep going for fun.
[2905.04s -> 2910.04s]  So the idea here is that by doing this,
[2917.96s -> 2919.24s]  you don't necessarily have to worry
[2919.24s -> 2921.88s]  about these different details.
[2921.88s -> 2923.64s]  So here's a kind of interesting one
[2923.64s -> 2926.60s]  where it's actually calling the automated theorem prover.
[2927.86s -> 2929.40s]  So you can see all the different facts
[2929.40s -> 2931.14s]  that are being passed to it.
[2931.14s -> 2936.14s]  And here we could see the actual call to duper.
[2938.46s -> 2941.70s]  So duper was this like proof reconstruction method
[2941.70s -> 2944.56s]  that I've mentioned before.
[2944.56s -> 2946.66s]  So if you want, you could treat this as the proof
[2946.66s -> 2948.76s]  or you can just leave this one in there.
[2951.46s -> 2956.02s]  For this step, it turns out you have to do this one step
[2956.02s -> 2958.22s]  of clearing out this hypothesis,
[2958.86s -> 2960.98s]  but then you can call the hammer.
[2963.02s -> 2967.32s]  And just for fun, I'll finish off this proof
[2967.32s -> 2971.10s]  just to show you that it's possible.
[2982.58s -> 2984.54s]  Okay, and then here's the last step
[2984.54s -> 2985.94s]  and we can call the hammer.
[2989.14s -> 2991.70s]  Okay, so now we have a complete proof of the theorem
[2991.70s -> 2994.42s]  and we started off with these kind of high level steps
[2994.42s -> 2998.12s]  and we're able to kind of fill in the gaps.
[3000.18s -> 3004.22s]  So again, here's the kind of summary.
[3004.22s -> 3008.70s]  And then what we could do is evaluate this
[3008.70s -> 3011.64s]  with different premise selectors swapped in.
[3012.64s -> 3016.30s]  So here's some results on theorems
[3016.34s -> 3020.54s]  that we held out from MathLib as a kind of test set.
[3020.54s -> 3023.80s]  And we just run the hammer at the first step of the proof.
[3024.76s -> 3026.74s]  So on the left here, you could see what happens
[3026.74s -> 3028.90s]  if you don't have the premise selection.
[3031.34s -> 3036.34s]  Then here is using a retriever that was from prior work.
[3037.26s -> 3038.94s]  What we did is we retrained it
[3038.94s -> 3043.90s]  on the exact same snapshot of MathLib.
[3043.90s -> 3046.74s]  So it had kind of up-to-date data.
[3046.74s -> 3049.90s]  And it's partially showing that like the specific decisions
[3049.90s -> 3052.38s]  that we make in training our retriever
[3052.38s -> 3054.62s]  were really important for performance.
[3056.18s -> 3058.26s]  Interestingly, there's a symbolic
[3058.26s -> 3060.18s]  premise selection system.
[3060.18s -> 3062.16s]  I believe it's based on the one
[3062.16s -> 3064.36s]  that was in the Isabel Sledgehammer.
[3065.36s -> 3067.90s]  So Kim Morrison from the Lean community
[3069.18s -> 3071.18s]  re-implemented it in Lean.
[3071.18s -> 3074.98s]  And you can see that it actually does pretty decently
[3074.98s -> 3077.00s]  when it's in our hammer pipeline.
[3078.06s -> 3080.66s]  Here is the Lean hammer retriever
[3080.66s -> 3083.48s]  as the fourth bar with the kind of diagonal lines.
[3084.50s -> 3087.86s]  And then interestingly, it ends up being complimentary
[3087.86s -> 3090.96s]  to the symbolic MIPO retriever.
[3090.96s -> 3094.24s]  So you could see what these kind of crosshatch lines,
[3094.24s -> 3095.62s]  you got a performance boost
[3095.62s -> 3098.16s]  if you just take the union of premises.
[3099.16s -> 3100.76s]  And then in absolute terms,
[3100.76s -> 3102.76s]  it's starting to get pretty good.
[3102.76s -> 3104.88s]  So all the way on the right
[3104.88s -> 3106.80s]  is the performance that we get
[3106.80s -> 3110.16s]  if we just use the ground truth premises
[3110.16s -> 3112.58s]  that occur in the human proof.
[3113.60s -> 3114.80s]  And you can see that the performance
[3114.80s -> 3118.20s]  is starting to approach the performance
[3118.20s -> 3119.76s]  that we get if we use those.
[3122.80s -> 3126.32s]  So to recap, I talked about two different approaches
[3126.36s -> 3131.16s]  for combining informal and formal provers
[3131.16s -> 3133.28s]  or even informal proofs.
[3134.36s -> 3136.36s]  I talked about draft sketch proof,
[3136.36s -> 3139.12s]  which involves drafting an informal proof,
[3140.16s -> 3142.04s]  generating a formal sketch,
[3142.04s -> 3144.26s]  and then filling in the low-level details.
[3145.38s -> 3147.28s]  And I talked about Lean hammer,
[3147.28s -> 3151.08s]  which is trying to bring this kind of paradigm to Lean
[3151.08s -> 3152.82s]  or make it easier.
[3152.82s -> 3156.40s]  So in particular, we try to build this hammer
[3156.40s -> 3159.52s]  and it involves this neural premise selection
[3159.52s -> 3160.58s]  and a tree search
[3160.58s -> 3163.08s]  and calling out to the automated theorem prover.
[3165.82s -> 3169.66s]  And one interesting takeaway from this
[3169.66s -> 3171.26s]  is I didn't go into the detail
[3171.26s -> 3173.54s]  of the model that we trained,
[3173.54s -> 3175.62s]  but the largest model that we trained
[3175.62s -> 3178.92s]  was just a 100 million parameter retriever.
[3178.92s -> 3180.78s]  So very small.
[3180.78s -> 3182.46s]  And as you maybe saw in the demo,
[3182.98s -> 3186.10s]  you can get some pretty non-trivial behavior
[3186.10s -> 3189.20s]  or performance from integrating it in.
[3189.20s -> 3192.18s]  So it's kind of exciting because yeah, in these cases,
[3192.18s -> 3194.94s]  even these fairly small, by today's standards,
[3194.94s -> 3198.04s]  neural networks can be fairly powerful.
[3200.34s -> 3202.14s]  So in the last part of the talk,
[3202.14s -> 3206.26s]  I want to talk about trying to use AI
[3206.26s -> 3209.08s]  or techniques that I've talked about
[3209.08s -> 3212.80s]  to actually assist in research level mathematics.
[3212.80s -> 3217.08s]  So not just prove the IMO problems,
[3217.08s -> 3222.04s]  but try to help out in these more complex projects
[3222.04s -> 3225.72s]  that mathematicians or if you're a kind of like Lean
[3226.92s -> 3230.24s]  hobbyist or interested in formalizing
[3230.24s -> 3231.24s]  something difficult.
[3232.92s -> 3235.12s]  So what does it actually look like
[3235.12s -> 3238.36s]  to formalize research level math?
[3238.40s -> 3240.28s]  Well, here we can look at this blog post
[3240.28s -> 3242.98s]  that was written by Terence Tao,
[3242.98s -> 3245.08s]  and he kind of breaks down the steps
[3245.08s -> 3248.80s]  that were involved in formalizing a proof
[3248.80s -> 3251.50s]  from this paper, which is shown on the left.
[3252.84s -> 3254.64s]  So again, the goal was to take
[3254.64s -> 3256.60s]  one of the main theorems from the paper
[3256.60s -> 3258.50s]  and then try to write it in Lean
[3258.50s -> 3260.42s]  and come up with a formal proof.
[3261.44s -> 3263.80s]  And the first step is to write
[3263.80s -> 3266.36s]  what is called a blueprint.
[3266.36s -> 3269.04s]  So here you kind of go step by step
[3269.04s -> 3273.36s]  and think about how would this proof decompose
[3273.36s -> 3277.28s]  into different definitions, into different lemmas,
[3277.28s -> 3279.80s]  and ultimately we can come up
[3279.80s -> 3281.84s]  with the kind of final theorem
[3281.84s -> 3283.66s]  and proof that we care about.
[3284.76s -> 3286.80s]  And as you can see here on the top,
[3286.80s -> 3289.80s]  it's showing a kind of dependency graph
[3289.80s -> 3293.06s]  of all of these theorems and all of these definitions.
[3293.06s -> 3295.68s]  So it gets fairly complex,
[3295.68s -> 3297.52s]  and at the very bottom you have
[3297.52s -> 3299.72s]  the final theorem and final proof.
[3301.24s -> 3302.64s]  And so interestingly here,
[3302.64s -> 3307.64s]  everything is still written in informal language.
[3307.90s -> 3311.32s]  So you could see here the theorem and the proof
[3311.32s -> 3312.72s]  just written in LaTeX.
[3313.76s -> 3315.00s]  And then you try to think about,
[3315.00s -> 3320.00s]  okay, how do we actually realize this in Lean?
[3320.42s -> 3321.76s]  And so what it comes down to
[3321.76s -> 3325.48s]  is a large set of these formal definitions
[3326.12s -> 3328.60s]  and formal lemmas and formal theorems.
[3328.60s -> 3330.24s]  And then ultimately you're able
[3330.24s -> 3332.70s]  to kind of state your final theorem
[3332.70s -> 3334.10s]  and write the proof of it.
[3335.88s -> 3339.58s]  So at the end, you have this proof and this theorem
[3339.58s -> 3342.34s]  that are really dependent on this kind of graph
[3342.34s -> 3343.84s]  of things that I showed you.
[3345.34s -> 3347.32s]  So a question is like,
[3347.32s -> 3350.88s]  at what point of this procedure could AI help?
[3352.04s -> 3354.76s]  So maybe at least for now,
[3354.76s -> 3358.68s]  we don't have it do this whole pipeline end to end,
[3358.68s -> 3359.88s]  but we could think about like,
[3359.88s -> 3363.20s]  what is the simplest thing that we could have it do
[3363.20s -> 3366.64s]  and that we could have a kind of trust.
[3368.16s -> 3369.80s]  So one thing you could do is
[3369.80s -> 3371.66s]  you could look at this blueprint
[3371.66s -> 3375.22s]  and look at just one of these kind of theorems or lemmas
[3375.22s -> 3379.58s]  that is kind of necessary for the proof,
[3379.58s -> 3381.18s]  but it's just one part of it.
[3382.14s -> 3384.98s]  So here's an example where we have this lemma,
[3384.98s -> 3387.28s]  which occurs somewhere in here.
[3387.28s -> 3389.78s]  And if we give this to a language model
[3389.78s -> 3391.78s]  and it produces a proof,
[3391.78s -> 3394.04s]  then again, we can kind of trust the output
[3394.04s -> 3395.90s]  because Lean has checked it.
[3395.90s -> 3398.42s]  And in some sense it's helped the development
[3398.42s -> 3401.34s]  because then the human proof writer
[3401.34s -> 3404.22s]  doesn't have to kind of go through this step.
[3405.94s -> 3408.20s]  So in order to do this,
[3408.20s -> 3409.84s]  we really have to overcome
[3411.62s -> 3415.62s]  at least two different gaps that occur.
[3416.92s -> 3420.24s]  The first I'll call the accessibility gap.
[3420.24s -> 3422.74s]  And this is just the kind of simple observation
[3422.74s -> 3426.54s]  that a lot of times these methods are developed,
[3426.54s -> 3428.32s]  but then they're actually hard to integrate
[3428.32s -> 3430.36s]  into actual tools.
[3430.36s -> 3434.90s]  So for example, the system might be very capable,
[3434.90s -> 3436.76s]  but it might not be open source.
[3437.64s -> 3440.52s]  Or the results might be very impressive,
[3440.52s -> 3442.20s]  but then they're actually very expensive
[3442.20s -> 3443.40s]  or costly to run.
[3444.32s -> 3445.28s]  And so when you think about
[3445.28s -> 3446.96s]  this kind of practical setting,
[3446.96s -> 3449.44s]  it adds constraints onto the methods
[3449.44s -> 3450.80s]  that you have to develop.
[3452.50s -> 3455.16s]  But luckily we actually do have some tools
[3455.16s -> 3458.40s]  already available that could potentially be useful
[3458.40s -> 3460.70s]  for these kind of simple gaps.
[3462.20s -> 3465.64s]  So we developed one of them called LOM Lean,
[3465.64s -> 3468.44s]  and you could go download it and use it
[3468.44s -> 3470.12s]  right now if you want.
[3470.12s -> 3473.88s]  And so the basic idea is to just create this interface
[3473.88s -> 3476.82s]  between Lean and some language model.
[3478.16s -> 3481.02s]  So what it does is it gives you these different commands
[3481.02s -> 3485.28s]  or tactics, like this one queries a language model
[3485.28s -> 3487.70s]  to try to produce the next step of the proof.
[3488.88s -> 3492.38s]  And then we can actually check the outputs of the model.
[3492.38s -> 3494.74s]  So we could discard the incorrect ones
[3494.74s -> 3498.26s]  and just display ones that kind of finish the proof.
[3498.26s -> 3500.06s]  Those are shown in green.
[3500.06s -> 3503.44s]  Or blue ones are ones that kind of don't give an error,
[3503.44s -> 3505.50s]  but don't necessarily finish the proof.
[3507.52s -> 3511.82s]  And in particular, you can even nowadays
[3511.82s -> 3514.30s]  have a model running on your laptop.
[3514.30s -> 3515.78s]  So there's these different libraries
[3515.78s -> 3520.62s]  that have been developed like Ollama or LM Studio.
[3520.62s -> 3522.46s]  And you could basically host the language model
[3522.46s -> 3525.02s]  on your laptop and then use LOM Lean
[3525.02s -> 3526.22s]  to communicate with it.
[3527.34s -> 3532.26s]  Similarly, you can have it communicate with some API.
[3532.26s -> 3534.78s]  So it could be OpenAI, it could be Claude,
[3534.78s -> 3538.06s]  Gemini, together.ai.
[3538.06s -> 3540.90s]  And so now you can actually try to use these models
[3540.90s -> 3543.84s]  to give you suggestions that are checked in Lean.
[3545.58s -> 3550.58s]  So as the last demo, I wanted to just show you this.
[3552.62s -> 3555.68s]  And so let's look for the other window.
[3557.90s -> 3561.18s]  Okay, so let's go back to this really simple theorem
[3561.18s -> 3563.38s]  that I showed at the beginning of the talk.
[3564.58s -> 3566.10s]  And you probably, you might've noticed
[3566.10s -> 3568.66s]  that I imported this LOM Lean here.
[3569.72s -> 3573.78s]  And so now we could call this LOM step command
[3573.78s -> 3574.62s]  that I showed.
[3575.86s -> 3579.30s]  And actually it comes up with this intro command
[3579.30s -> 3581.70s]  that I showed you at the beginning of the talk.
[3582.86s -> 3585.46s]  Then we could call it again.
[3586.62s -> 3590.62s]  And in this case, it was able to finish the proof.
[3593.60s -> 3598.14s]  So another thing you can do is you can say like,
[3598.14s -> 3601.10s]  try to just do this exact command.
[3601.10s -> 3603.54s]  So try to prove it in one step.
[3603.54s -> 3607.46s]  It actually came up with this bit more clever
[3607.46s -> 3609.40s]  kind of one step proof.
[3610.00s -> 3614.00s]  There's another command that just tries to prove it
[3615.32s -> 3618.28s]  in end to end, like fully prove it
[3618.28s -> 3620.58s]  instead of just predicting the next step.
[3623.16s -> 3626.58s]  So here the model comes up with,
[3626.58s -> 3629.22s]  yeah, multiple potential proofs.
[3630.12s -> 3633.24s]  And you could see they're a bit different style maybe,
[3633.24s -> 3634.22s]  a bit longer.
[3635.64s -> 3637.56s]  So you can also do other like fun things
[3637.56s -> 3641.24s]  like shorten this proof
[3643.72s -> 3648.72s]  and put it as a comment and then call the LOM QED.
[3651.48s -> 3652.84s]  So let's see what it does.
[3652.84s -> 3655.24s]  And yeah, so now it gives us some options
[3655.24s -> 3657.36s]  that are shorter.
[3657.36s -> 3659.28s]  Actually, this is pretty short.
[3659.28s -> 3661.68s]  You could just prove it in kind of one call.
[3664.56s -> 3667.08s]  So yeah, this is a tool that you could use.
[3667.56s -> 3670.84s]  Today you just need to have a language model API
[3672.52s -> 3677.10s]  and then yeah, you can import it into a Lean project.
[3680.80s -> 3685.14s]  So interestingly, let's see here.
[3685.14s -> 3687.00s]  The methods are still bottlenecked,
[3687.00s -> 3690.98s]  obviously by how good the model is at proving theorems.
[3692.68s -> 3694.60s]  But like even now,
[3694.60s -> 3697.32s]  I kind of went through Terence Tao's project,
[3697.32s -> 3700.28s]  this PFR project, and just picked a file.
[3700.28s -> 3704.28s]  And yeah, this one was actually able to fill in
[3704.28s -> 3709.24s]  some of these, yeah, small lemmas.
[3709.24s -> 3711.72s]  This was actually the example that I showed you before
[3711.72s -> 3713.06s]  on the previous slide.
[3715.58s -> 3720.56s]  So another thing is I mentioned that the models right now
[3720.56s -> 3722.84s]  are the kind of bottleneck, right?
[3722.84s -> 3725.16s]  We have the interface set up.
[3725.16s -> 3728.52s]  And so now it just comes down to whether the model
[3728.52s -> 3731.84s]  can complete theorems that occur
[3731.84s -> 3733.52s]  in these kinds of projects.
[3734.94s -> 3738.48s]  So this leads to a second kind of gap,
[3738.48s -> 3741.88s]  which is the gap in the way that we benchmark
[3741.88s -> 3743.38s]  these theorem proving models.
[3744.26s -> 3749.04s]  So largely these models are benchmarked on their ability
[3749.04s -> 3752.02s]  to prove these math competition problems,
[3752.06s -> 3753.58s]  like ones from the IMO.
[3754.50s -> 3756.98s]  And what these problems have
[3756.98s -> 3759.00s]  is they're fairly self-contained.
[3759.90s -> 3761.88s]  So you can usually state the problem
[3761.88s -> 3763.68s]  in just like one line of code.
[3764.54s -> 3766.74s]  And then they're kind of designed
[3766.74s -> 3769.30s]  to somewhat use standard results.
[3770.78s -> 3773.30s]  So there's a kind of standard set
[3773.30s -> 3777.26s]  and a lot of them have been implemented in MathLib.
[3777.26s -> 3780.94s]  And then constructing the proof is very difficult.
[3781.14s -> 3783.04s]  Requires a lot of creativity,
[3783.04s -> 3786.96s]  but it's kind of relying on these standard results.
[3788.58s -> 3790.22s]  If we compare that to this project
[3790.22s -> 3792.36s]  that I've been telling you about,
[3792.36s -> 3795.14s]  these have these complex dependencies
[3795.14s -> 3797.90s]  from throughout the project.
[3797.90s -> 3802.36s]  So in particular, this theorem to even state it
[3802.36s -> 3804.94s]  or to prove it, it might actually rely
[3804.94s -> 3808.74s]  on these brand new definitions and brand new lemmas
[3808.74s -> 3810.74s]  that have been created for the project.
[3811.58s -> 3814.50s]  And so unless we like continually train the model
[3814.50s -> 3816.94s]  on all of the current projects,
[3816.94s -> 3820.10s]  it really has to learn to prove theorems
[3820.10s -> 3822.98s]  in this kind of context dependent setting
[3822.98s -> 3824.54s]  that I'm showing on the right.
[3826.60s -> 3831.60s]  So this leads to our new benchmark called mini CTX
[3831.66s -> 3833.70s]  or mini context.
[3833.70s -> 3836.78s]  And we'll also be presenting this at iClear
[3836.78s -> 3838.50s]  as an oral presentation.
[3839.50s -> 3844.10s]  So here what we do is we made this observation
[3844.10s -> 3845.78s]  that I just told you about,
[3845.78s -> 3849.86s]  that when we look at these kind of research level
[3849.86s -> 3853.98s]  or actual formalizations that people do in Lean,
[3853.98s -> 3857.14s]  they are really in this context dependent setting
[3857.14s -> 3859.52s]  where you want to prove a theorem
[3859.52s -> 3863.14s]  and it depends on like a whole repository of code,
[3863.14s -> 3866.34s]  new definitions or new auxiliary lemmas.
[3867.34s -> 3871.34s]  So the idea of the benchmark is to test models
[3871.34s -> 3874.46s]  on actual real Lean projects.
[3874.46s -> 3878.20s]  So in particular, we choose some date cutoff
[3878.20s -> 3880.90s]  and then we look at a project like MathLib
[3880.90s -> 3882.58s]  and we can take all of the theorems
[3882.58s -> 3884.38s]  that were developed after that date.
[3885.54s -> 3889.12s]  Similarly, we can look at when a project was created
[3889.12s -> 3893.54s]  and take theorems and kind of contexts
[3893.54s -> 3895.64s]  from those different projects.
[3895.64s -> 3899.64s]  So this PFR project by Terence Town and collaborators
[3899.64s -> 3901.12s]  that I've been telling you about
[3901.12s -> 3902.32s]  is like one of the projects
[3902.32s -> 3905.56s]  that was in the first version of this benchmark.
[3907.32s -> 3910.22s]  Then the idea is we also make tools
[3910.22s -> 3913.98s]  so that you can automatically extract benchmark problems
[3913.98s -> 3915.96s]  from these projects.
[3915.96s -> 3918.76s]  So what you can do is update the benchmark
[3918.76s -> 3922.16s]  to kind of stay ahead of the training cutoffs
[3922.16s -> 3924.20s]  for these language models.
[3924.20s -> 3928.96s]  So we've actually already released a mini CTX version two
[3928.96s -> 3932.70s]  and it has kind of more recent Lean projects
[3932.70s -> 3935.60s]  that have been developed like in the past couple of months.
[3937.70s -> 3942.00s]  So here we have two different types of contexts
[3942.00s -> 3946.20s]  and these are basically like what dependencies are needed
[3946.20s -> 3948.12s]  to prove a theorem.
[3948.12s -> 3949.88s]  And what we do is we build tooling
[3949.88s -> 3954.88s]  to automatically extract things like dependencies.
[3957.00s -> 3958.40s]  And we can look at like,
[3958.40s -> 3962.56s]  does the theorem depend on things just in the current file
[3962.56s -> 3966.66s]  or does it depend on things across multiple files?
[3966.66s -> 3969.12s]  And then we can also get things like,
[3969.12s -> 3972.42s]  what are the set of available premises
[3972.42s -> 3974.78s]  when you're going to prove this theorem?
[3974.78s -> 3976.56s]  So kind of very realistic setting.
[3977.56s -> 3980.84s]  So in particular, let's look at two different settings.
[3980.84s -> 3984.24s]  One setting is where all of the dependencies
[3984.24s -> 3986.72s]  just appear in the current file.
[3986.72s -> 3989.20s]  And then the other is when the dependencies
[3989.20s -> 3991.28s]  can span multiple files.
[3993.40s -> 3996.64s]  So the first thing we want to do is actually demonstrate
[3996.64s -> 3999.60s]  that this context actually matters.
[3999.60s -> 4003.32s]  So again, I've told you about this really common way
[4003.32s -> 4005.88s]  of training theorem provers,
[4006.08s -> 4009.26s]  which is by just giving them the proof state
[4009.26s -> 4011.96s]  and then having them produce a next step
[4011.96s -> 4014.82s]  or having them kind of produce thoughts if you want.
[4015.92s -> 4020.24s]  So here what we did is develop this simple baseline
[4020.24s -> 4023.46s]  method, which additionally gives the model
[4023.46s -> 4027.50s]  all of the code in the file so far.
[4027.50s -> 4031.32s]  So this can include like new definitions, new lemmas,
[4031.32s -> 4035.08s]  even like new notation or natural language comments.
[4035.12s -> 4037.28s]  And we want to see how this compared
[4037.28s -> 4039.00s]  to just taking in the proof state.
[4041.60s -> 4044.60s]  So interestingly, if you look at a competition problem
[4044.60s -> 4049.40s]  dataset like many F2F, it actually really doesn't matter.
[4049.40s -> 4051.32s]  You can do pretty similarly,
[4051.32s -> 4054.26s]  whether you take in additional context,
[4054.26s -> 4055.94s]  it would just be like the import statements
[4055.94s -> 4060.50s]  for many F2F or if you just take the proof state.
[4060.50s -> 4063.28s]  So this might be one reason why a lot of these state
[4063.32s -> 4067.40s]  or theorem proving methods don't really deal with
[4067.40s -> 4070.52s]  or support any kind of external context.
[4071.56s -> 4076.56s]  However, when we evaluate them on our benchmark mini CTX,
[4076.80s -> 4080.48s]  which has the theorems from real-world projects,
[4080.48s -> 4083.20s]  we can see this dramatic gap in the performance.
[4084.06s -> 4085.46s]  And the reason is pretty obvious
[4085.46s -> 4088.00s]  if you just look at a lean file,
[4088.00s -> 4090.40s]  it's because in these real projects,
[4090.40s -> 4093.04s]  you're defining these kind of new definitions
[4093.64s -> 4095.50s]  and new lemmas like I discussed.
[4097.48s -> 4102.48s]  Interestingly, you can also do this premise selection
[4102.78s -> 4105.46s]  and kind of give the language model the premises.
[4106.84s -> 4109.96s]  And you can see variations based on whether
[4109.96s -> 4113.38s]  the theorem requires just in-file information
[4113.38s -> 4114.86s]  or out-of-file information.
[4116.40s -> 4117.54s]  So all the way on the left,
[4117.54s -> 4122.12s]  we have theorems with very low dependencies.
[4122.12s -> 4125.60s]  The first set of bar graphs shows high dependencies
[4125.60s -> 4127.62s]  on in-file premises.
[4127.62s -> 4130.42s]  And so here you could see that you do pretty well
[4130.42s -> 4133.36s]  by just giving the language model all the code
[4133.36s -> 4135.16s]  in the current file.
[4135.16s -> 4137.00s]  And then in the third set of bar graphs,
[4137.00s -> 4138.36s]  you see what happens
[4138.36s -> 4140.92s]  when we have these cross-file dependencies.
[4140.92s -> 4144.32s]  And you can see that adding in this premise selection
[4144.32s -> 4145.76s]  leads to some improvement.
[4147.28s -> 4151.96s]  So here we are using an older premise selector system.
[4152.84s -> 4155.72s]  So we're excited about integrating our lean hammer
[4155.72s -> 4159.40s]  into this for addressing the cross-file dependencies.
[4160.24s -> 4162.92s]  And in general, there's a kind of wide space
[4162.92s -> 4166.80s]  of methods that could be developed for the setting.
[4169.68s -> 4173.88s]  So I should also mention that we provide the model
[4173.88s -> 4175.22s]  with this file tuning.
[4175.22s -> 4177.88s]  So it's trained to take in the file context
[4178.92s -> 4179.80s]  through Ollama.
[4179.80s -> 4182.60s]  So you can download it, run it on your laptop,
[4182.60s -> 4184.16s]  and use it inside of Lean.
[4185.44s -> 4189.08s]  And then all of the methods that are in LLM Lean
[4189.08s -> 4191.16s]  that are calling the proprietary language models
[4191.16s -> 4192.50s]  or the API-based ones,
[4193.54s -> 4194.80s]  they'll actually prompt the model
[4194.80s -> 4197.50s]  with all of the code in the current file.
[4199.86s -> 4201.10s]  And then as I mentioned,
[4201.10s -> 4204.36s]  everything from the project is open source.
[4204.36s -> 4208.92s]  So the data, the models, our data extraction tool,
[4208.92s -> 4212.32s]  and even the evaluation code,
[4212.32s -> 4216.60s]  which is like a wrapper of the Lean REPL.
[4216.60s -> 4219.44s]  And so you can check out those resources online.
[4222.32s -> 4224.14s]  So as I mentioned in this third part,
[4224.14s -> 4228.54s]  if we look at these kind of real Lean projects
[4228.54s -> 4232.10s]  or what it would take to formalize research level math,
[4232.10s -> 4234.18s]  it opens up some unique challenges.
[4235.14s -> 4237.42s]  These aren't the only challenges, of course,
[4237.42s -> 4239.82s]  but two that are really present
[4239.82s -> 4242.84s]  in the kind of research community right now.
[4242.84s -> 4245.48s]  One is that we still have a gap
[4245.48s -> 4249.90s]  between the AI advances and tools that people can use.
[4250.74s -> 4254.52s]  And then second, the benchmarks don't always reflect
[4254.52s -> 4257.26s]  all of the capabilities that are required
[4257.26s -> 4259.46s]  to do this real world formalization.
[4261.42s -> 4264.84s]  And so this is very much an open research direction.
[4264.84s -> 4266.30s]  And as I mentioned,
[4266.34s -> 4268.84s]  this benchmark is kind of the first step.
[4271.24s -> 4272.68s]  So in summary, in this talk,
[4272.68s -> 4275.14s]  I talked about three different ways
[4275.14s -> 4277.18s]  to try to bridge informal
[4277.18s -> 4279.56s]  and formal mathematical reasoning.
[4279.56s -> 4282.34s]  I talked about incorporating informal thoughts
[4282.34s -> 4284.88s]  by training models to think informally.
[4285.82s -> 4288.24s]  I talked about incorporating informal provers
[4288.24s -> 4293.24s]  or informal proofs through methods that sketch proofs
[4293.54s -> 4295.66s]  and try to fill in the gaps.
[4295.66s -> 4296.50s]  And then towards the end,
[4296.50s -> 4301.50s]  I talked about trying to take, say, a research paper
[4302.66s -> 4304.22s]  and look at what is involved
[4304.22s -> 4306.80s]  in producing a formal version of it
[4306.80s -> 4308.78s]  and looking at what are some initial ways
[4308.78s -> 4311.08s]  where AI can help in the process.
[4312.82s -> 4316.90s]  And so with that, that is all I have for today's talk.
[4316.90s -> 4320.16s]  And I'd like to thank all of the amazing collaborators
[4320.16s -> 4322.38s]  on these various works.
[4322.38s -> 4324.34s]  They're listed here.
[4324.34s -> 4327.46s]  And again, my name is Sean
[4327.46s -> 4329.30s]  and I have my email address here.
[4329.30s -> 4331.50s]  So please feel free to reach out.
