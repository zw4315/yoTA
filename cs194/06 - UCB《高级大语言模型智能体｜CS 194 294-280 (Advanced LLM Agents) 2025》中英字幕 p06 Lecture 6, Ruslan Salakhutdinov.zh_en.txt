# Detected language: en (p=1.00)

[0.00s -> 3.04s]  Today I'm gonna talk about multimodal AI agents
[3.04s -> 5.06s]  and sort of give you a little bit of overview
[5.06s -> 6.82s]  what we've been doing and some of the work
[6.82s -> 8.92s]  that's been happening around that space.
[8.92s -> 10.32s]  It's a very exciting space.
[10.32s -> 12.52s]  I think that a lot of people are thinking
[12.52s -> 15.56s]  that the year 2025, 2026 is gonna be the year of age.
[15.56s -> 18.68s]  So we'll see a lot more work coming out of academia
[18.68s -> 20.58s]  and industry in that space.
[20.58s -> 24.40s]  So when we think about large language models, right,
[24.40s -> 27.08s]  we think a lot of different sort of, you know,
[27.08s -> 30.72s]  innovations that happened in the last few years.
[30.72s -> 32.72s]  You know, we see examples of in-context learning,
[32.72s -> 34.72s]  zero-short learning.
[34.72s -> 37.38s]  You have very good representations of text.
[37.38s -> 40.40s]  You have general long and coherent text
[40.40s -> 41.72s]  that these models can generate,
[41.72s -> 43.56s]  you have sort of world knowledge.
[43.56s -> 46.44s]  And so amazing things has been happening
[46.44s -> 49.32s]  in the space of large language models, right?
[49.32s -> 53.04s]  But what I would like to talk to you about today
[53.04s -> 57.24s]  is this notion of going beyond just the language models.
[57.24s -> 59.56s]  So you can think of language models as, you know,
[59.56s -> 61.08s]  given the question, you know,
[61.08s -> 63.16s]  the language model can generate the answer.
[63.16s -> 65.44s]  Instead, we can try building systems
[65.44s -> 68.28s]  where that basically can automate
[68.28s -> 70.72s]  a lot of laborious tasks, right?
[70.72s -> 73.84s]  So in a lot of productive tasks we perform today
[73.84s -> 75.58s]  on the computer potentially,
[75.58s -> 76.42s]  as well as, you know,
[76.42s -> 78.24s]  many tasks that we perform on the web
[78.24s -> 80.88s]  could potentially be automated, okay?
[80.88s -> 82.44s]  So for example, you know,
[82.68s -> 87.40s]  how many of you have tried setting up AWS instance, right?
[87.40s -> 89.72s]  Or, you know, my students are basically saying
[89.72s -> 91.72s]  it's a really difficult process to do.
[91.72s -> 94.80s]  The question is, couldn't you have an agentic model
[94.80s -> 97.88s]  that goes and sets up a W instance for you, right?
[97.88s -> 100.58s]  So we can start running your experiments.
[100.58s -> 102.16s]  Or, you know, wouldn't it be nice,
[102.16s -> 104.16s]  and I think the technology is getting there a little bit
[104.16s -> 105.56s]  at this point, is, you know,
[105.56s -> 107.10s]  create a set of PowerPoint slides
[107.10s -> 109.00s]  to present the content of this paper, right?
[109.00s -> 110.04s]  So I give you the paper,
[110.08s -> 112.72s]  the agent reads and sort of goes to the PowerPoint
[112.72s -> 114.48s]  and organizes slides and creates
[114.48s -> 117.88s]  and gives you sort of a presentation of the paper.
[117.88s -> 120.00s]  You know, can you automate some of the tasks
[120.00s -> 121.32s]  that we're doing on Excel,
[121.32s -> 124.12s]  going on the web and so forth, right?
[124.12s -> 127.36s]  You can imagine a lot of useful outcome
[127.36s -> 129.84s]  if you're actually able to design models
[129.84s -> 131.50s]  that can do those tasks.
[133.38s -> 134.84s]  In this sort of lecture,
[134.84s -> 137.00s]  I'm gonna be focusing primarily on web agents
[137.00s -> 138.84s]  and sort of give you a little bit of overview
[138.84s -> 142.72s]  of what these models are, how we evaluate these models.
[143.78s -> 146.08s]  And the idea here is that, you know,
[146.08s -> 148.12s]  we have a basic language model,
[148.12s -> 150.14s]  some sort of for a foundation model.
[150.14s -> 152.24s]  Obviously you need some form of text understanding
[152.24s -> 153.56s]  like an HTML,
[153.56s -> 155.80s]  and you also need to have a very good understanding
[155.80s -> 157.70s]  of the visual information,
[157.70s -> 160.28s]  like the actual website itself, right?
[160.28s -> 162.16s]  So you can think of visual encoding
[162.16s -> 164.16s]  plus some form of text understanding
[164.16s -> 165.90s]  that goes into a large language model
[165.90s -> 168.68s]  and that gives you some form of web grounding, right?
[169.40s -> 173.76s]  That you can then use for performing tasks on the web.
[173.76s -> 175.00s]  And there's been a lot of work.
[175.00s -> 176.52s]  I'm not gonna list,
[176.52s -> 179.12s]  there's been a lot of work in the last few years
[179.12s -> 181.28s]  where people are trying to sort of understand
[181.28s -> 184.60s]  and trying to build systems that can do these tasks.
[184.60s -> 186.24s]  Let me show an example, right?
[186.24s -> 190.36s]  An example of a system where I can say,
[190.36s -> 192.68s]  suppose I give the task to my agent.
[193.56s -> 196.32s]  Get me to the page of a good Thai restaurant in Pittsburgh.
[196.32s -> 199.16s]  It should have at least 200 reviews and 4.3 stars.
[199.16s -> 201.84s]  Pick the one with the highest rating, right?
[201.84s -> 204.56s]  And this is what the system does, right?
[204.56s -> 207.04s]  So it's sort of, you know, it goes on Yelp.
[207.96s -> 210.92s]  It sort of searches for Thai restaurants.
[210.92s -> 213.74s]  So it types in autonomously Thai restaurant, right?
[213.74s -> 218.74s]  It's then searching through possible restaurant in Pittsburgh.
[219.52s -> 222.62s]  It sort of finds one of these restaurants
[222.62s -> 224.62s]  which has 4.5 star rating.
[224.62s -> 226.10s]  This is Pusadi Garden.
[226.74s -> 227.86s]  It's actually a pretty good restaurant in Pittsburgh, right?
[227.86s -> 228.86s]  It's a good Thai restaurant.
[228.86s -> 230.38s]  Now it's complete.
[230.38s -> 231.94s]  Now imagine I'm asking it to say,
[231.94s -> 234.84s]  well, get me a reservation at this
[234.84s -> 236.78s]  for two people at the earliest date
[236.78s -> 238.74s]  and use my name, JY Koch,
[238.74s -> 240.50s]  who is the student who built this,
[240.50s -> 241.74s]  and the phone number, right?
[241.74s -> 243.16s]  So the agent goes on Google,
[243.16s -> 245.14s]  finds this particular restaurant,
[245.14s -> 246.20s]  looks at the dates,
[246.20s -> 248.54s]  looks at the next available date,
[248.54s -> 252.56s]  and actually successfully making a reservation, right?
[253.50s -> 254.70s]  And putting the phone number
[254.70s -> 255.80s]  and then basically stops
[256.36s -> 257.20s]  because you need to get a confirmation
[257.20s -> 259.64s]  to actually book something, right?
[259.64s -> 261.08s]  So it basically says, you know,
[261.08s -> 262.24s]  in summary, in the next section,
[262.24s -> 263.24s]  I'll perform a stop,
[263.24s -> 265.18s]  unable to proceed without confirmation code
[265.18s -> 267.76s]  for further instructions to complete the reservation, right?
[267.76s -> 269.40s]  So you sort of have this notion of the agent
[269.40s -> 270.30s]  that takes tasks,
[270.30s -> 272.38s]  it generates chain of thoughts within thinking,
[272.38s -> 275.18s]  and then takes the action.
[275.18s -> 276.82s]  Or I can give the example of,
[276.82s -> 279.00s]  help me navigate to the shirt that has on it, right?
[279.00s -> 280.54s]  So it goes on Amazon.
[282.16s -> 285.16s]  It's trying to basically look for something similar,
[285.20s -> 290.20s]  and finds a shirt that has something similar, right?
[291.80s -> 294.60s]  These are the examples that are heavily cherry picked
[295.64s -> 298.92s]  out of, I think that we've tried maybe like 30 times,
[298.92s -> 301.00s]  and out of 30 times, one of them succeeded, right?
[301.00s -> 303.94s]  So that basically means that these systems do not,
[303.94s -> 306.28s]  are not really working very well at this point,
[306.28s -> 308.46s]  but it has the potential of, you know,
[308.46s -> 310.68s]  give you a flavor of what these systems can do.
[310.68s -> 311.84s]  I think in today's world,
[311.84s -> 313.08s]  like open the eyes operator,
[313.08s -> 315.28s]  kind of like sort of, you know,
[315.28s -> 319.00s]  moving in that direction is one of the very strong models
[319.00s -> 320.10s]  that's out there.
[321.26s -> 323.50s]  So today I'm gonna talk about three different things,
[323.50s -> 324.34s]  right?
[324.34s -> 325.36s]  I'm gonna talk about Visual Web Arena,
[325.36s -> 329.24s]  which is a way of evaluating multimodal agents
[329.24s -> 333.62s]  on some of the realistic visual tasks.
[333.62s -> 336.90s]  I'll talk about some of the inference time algorithm,
[336.90s -> 338.28s]  what we call the research algorithm
[338.28s -> 340.02s]  for large language model agents,
[340.94s -> 344.82s]  which sort of allows you to potentially
[344.82s -> 347.50s]  do interesting search, apply interesting search techniques
[347.50s -> 350.26s]  to find necessary information on the web.
[350.26s -> 351.70s]  And then the last part,
[351.70s -> 354.06s]  I'll talk a little bit about some of the way
[354.06s -> 356.38s]  of scaling up data for training these agents,
[356.38s -> 360.74s]  because one of the aspects of these agents in general
[360.74s -> 361.98s]  is the availability of data.
[361.98s -> 363.10s]  What can you do online
[363.10s -> 365.66s]  and how can you get the data online, right?
[365.66s -> 367.82s]  So let's look at the Visual Web Arena.
[368.82s -> 373.66s]  One of the earlier versions was developed
[373.66s -> 376.84s]  by folks at CMU, right?
[376.84s -> 381.84s]  It was done by Shuyin, Shuyin Zhu and Frank Zhu.
[383.40s -> 385.02s]  They've introduced the notion of Web Arena,
[385.02s -> 388.14s]  which is a fairly realistic environment at the moment.
[388.14s -> 391.22s]  It has popular categories like shopping, Reddit and GitLab,
[391.22s -> 394.86s]  which is equivalent to Amazon and Reddit and GitHub.
[394.86s -> 397.98s]  It's a self-hosted open source, essentially environment,
[397.98s -> 401.90s]  which is a re-implementation of the environment.
[401.90s -> 403.62s]  And the data comes from real websites,
[403.62s -> 406.02s]  from Amazon, Reddit and GitHub.
[406.94s -> 408.42s]  And what's interesting about this environment,
[408.42s -> 409.24s]  and I'll talk about this,
[409.24s -> 410.62s]  the tasks are fairly easy for humans,
[410.62s -> 411.86s]  about 78 success rate,
[411.86s -> 413.26s]  but very difficult for language models.
[413.26s -> 416.14s]  At the time, they've reported numbers like 40%.
[416.14s -> 417.86s]  The only problem with this particular task
[417.86s -> 420.92s]  is the task are designed to use just HTML source code.
[421.56s -> 422.40s]  Right?
[422.40s -> 425.52s]  And we found that a lot of times,
[425.52s -> 428.20s]  whenever you're dealing with HTML and JavaScript,
[428.20s -> 431.48s]  it's a very messy type of representation.
[432.32s -> 434.28s]  Interactive elements that when you're interacting
[434.28s -> 435.12s]  with the environments,
[435.12s -> 436.24s]  they don't get displayed correctly.
[436.24s -> 439.14s]  HTML, that is like Java, CSS code.
[439.14s -> 441.56s]  And it's very hard to kind of like process
[441.56s -> 442.96s]  and in context length,
[442.96s -> 444.96s]  HTML pages can be fairly complex.
[444.96s -> 448.10s]  They can easily fill up to 100,000 tokens, right?
[448.10s -> 452.10s]  If you kind of like trying to look at that.
[452.10s -> 455.98s]  So, and this is how it sort of looks like,
[455.98s -> 460.98s]  you have this kind of like HTML based representation.
[461.38s -> 465.54s]  Spatial layout is also not conveyed very well in HTML.
[465.54s -> 468.34s]  So it looks like just a text only representation.
[469.38s -> 472.18s]  It's very difficult to deal with, right?
[472.18s -> 473.46s]  Just because HTML is messy.
[473.46s -> 477.34s]  So we've tried building what we call visual web arena,
[477.62s -> 480.06s]  which is we try to build and track the process
[480.06s -> 481.22s]  of multimodal agents.
[481.22s -> 483.50s]  Agent that can actually have visual grounding.
[484.54s -> 486.94s]  So we've designed these visually grounded tasks
[486.94s -> 489.02s]  to test the abilities of these models.
[489.02s -> 490.90s]  And it's sort of inspired by web arena.
[490.90s -> 493.40s]  So we call it visual web arena.
[493.40s -> 496.30s]  And you have visual inputs and outputs
[496.30s -> 499.62s]  and that allows you to work with unique and interesting
[499.62s -> 502.50s]  sort of in something that's real world.
[502.50s -> 505.30s]  And again, we sort of have the environments
[505.30s -> 506.94s]  of what we call one-stop shop,
[507.50s -> 510.58s]  which is essentially Amazon like environment, Reddit
[510.58s -> 513.30s]  and OS class, which is more like a correctly stacked
[513.30s -> 516.30s]  type of environment, the class field type of environment.
[516.30s -> 518.70s]  Right, so let me show you.
[518.70s -> 520.46s]  And then you can think about that,
[520.46s -> 523.02s]  you have some representation, I have some visual input
[523.02s -> 526.42s]  and I ask you to solve something
[526.42s -> 528.10s]  that actually requires visual grounding
[528.10s -> 529.78s]  and visual understanding.
[529.78s -> 533.06s]  So let me show you some examples of this.
[533.06s -> 536.02s]  Let's say I ask, I give you the task.
[536.02s -> 537.98s]  I ask you to find this exact bikes.
[537.98s -> 541.38s]  I'm looking for this bike that's listed for 300, 500
[541.38s -> 543.66s]  and post the comment offering $10 less
[543.66s -> 544.98s]  than the asking price.
[544.98s -> 547.58s]  Okay, and this is what the agent has to do.
[547.58s -> 548.98s]  Again, it's a simulator.
[548.98s -> 551.76s]  It's a fully self-hosted environment, right?
[551.76s -> 554.74s]  You sort of go, you navigate, you find this bike
[554.74s -> 559.54s]  and then you basically make a posting by offering,
[559.54s -> 563.22s]  you know, $10 less than what the asking prices, right?
[563.22s -> 565.06s]  That's just one example, right?
[565.10s -> 568.38s]  And then basically you've completed,
[568.38s -> 570.18s]  successfully completed that task.
[570.18s -> 571.62s]  And I can imagine in the future,
[571.62s -> 572.46s]  there's gonna be agents
[572.46s -> 574.14s]  that's gonna be bargaining on your behalf
[574.14s -> 576.44s]  and there's gonna be agents on the other side
[576.44s -> 579.78s]  that's gonna be, you know, making you counter offers.
[579.78s -> 581.18s]  Here's another example.
[581.18s -> 584.08s]  Let's say I ask you buy the cheapest color photo printer
[584.08s -> 586.50s]  and send it to Emily's place as shown in the image.
[586.50s -> 589.22s]  And what you can see this image is upside down,
[590.34s -> 592.86s]  which makes it fairly difficult for existing models
[592.86s -> 594.94s]  to sort of look at this and actually figure out
[595.78s -> 596.60s]  what the address should be, right?
[596.60s -> 598.54s]  So some of these kind of like tasks we designed
[598.54s -> 601.84s]  so that it wouldn't be that easy for the models to solve.
[603.14s -> 604.50s]  And so what the agent needs to do,
[604.50s -> 606.74s]  it sort of needs to go, it needs to find,
[606.74s -> 609.94s]  it needs to sort by price, it gets the printer,
[609.94s -> 612.18s]  it adds to the cart, then it goes
[612.18s -> 614.70s]  and it starts completing, you know, the address.
[614.70s -> 617.70s]  So, you know, it has pulled down menu.
[617.70s -> 620.82s]  So it sort of, you know, looks fairly realistic, right?
[620.82s -> 623.74s]  And then you go and then you place the order.
[623.74s -> 626.90s]  And when you end up in the state, that particular state,
[626.90s -> 628.62s]  that basically means that you've successfully
[628.62s -> 631.10s]  accomplished the task, right?
[631.10s -> 634.68s]  Again, just to reemphasize, it's a simulation.
[634.68s -> 636.38s]  It's not actually doing it on the real web.
[636.38s -> 639.30s]  It's a self-hosted environment.
[639.30s -> 642.46s]  Here's another one where it requires you to sort of jump
[642.46s -> 644.78s]  between two different websites.
[644.78s -> 648.06s]  You can ask what's the 2022 total nominal GDP
[648.06s -> 650.66s]  of the area that produce most sugarcane
[650.66s -> 653.26s]  in the year of 2021 in billion, right?
[653.62s -> 655.02s]  And that's your landing page.
[655.02s -> 657.82s]  What's interesting here is that you essentially asking
[657.82s -> 661.28s]  the model to understand the images.
[661.28s -> 665.22s]  Because if you look at the year 2021, that's over here,
[665.22s -> 668.62s]  and you look, I think in this case,
[668.62s -> 673.14s]  Asia produced more sugarcane than Brazil
[673.14s -> 674.86s]  or the other way around.
[674.86s -> 676.54s]  Brazil produced more sugarcane than Asia.
[676.54s -> 678.00s]  So kind of like have to look at these graphs
[678.00s -> 683.00s]  and understand which country you should be looking at, right?
[683.58s -> 685.68s]  So if you kind of zoom in, you can sort of say,
[685.68s -> 688.74s]  okay, that was, I think that was Asia
[688.74s -> 689.82s]  that produced more sugarcane.
[689.82s -> 691.06s]  So you have to go on Wikipedia
[691.06s -> 693.14s]  and then find the answer, right?
[693.14s -> 696.78s]  And the answer is 339 trillion GDP.
[699.38s -> 701.46s]  So you can kind of see that you have to sort of have
[701.46s -> 703.72s]  this visual grounding, you have to understand images,
[703.72s -> 705.22s]  you have to understand graphs
[706.50s -> 709.54s]  to solve some of these tasks, all right?
[709.54s -> 711.74s]  So the way that the environment is represented,
[711.74s -> 714.40s]  we can think of this environment as a POMDP environment.
[714.40s -> 717.30s]  So this partial observable market decision process.
[717.30s -> 720.90s]  So we have states, you have actions, observations
[720.90s -> 722.38s]  and transition function, right?
[722.38s -> 724.04s]  And so for those of you who've worked
[724.04s -> 726.78s]  in reinforcement learning or who've been sort of dealing
[726.78s -> 730.06s]  with market decision MDPs, that should be familiar.
[730.06s -> 732.38s]  And that was the goal to design the environment
[732.38s -> 734.80s]  in such a way that it becomes an MDP
[734.80s -> 736.98s]  so that you can potentially, you know,
[736.98s -> 741.26s]  train your favorite reinforcement learning algorithms on this.
[741.70s -> 743.50s]  So the environment itself have observations,
[743.50s -> 745.14s]  whether it's an HTML,
[745.14s -> 747.74s]  whether it's the visual representation
[747.74s -> 750.42s]  like the actual website itself,
[750.42s -> 752.18s]  and something that we call the accessibility tree
[752.18s -> 754.74s]  which is a cleaned up representation of HTML.
[755.92s -> 758.16s]  You have a set of actions and the set of actions
[758.16s -> 760.04s]  is actually a fairly diverse set of actions, right?
[760.04s -> 762.02s]  You can clearly click on particular element,
[762.02s -> 764.16s]  you can hover over particular element.
[764.16s -> 765.00s]  This is an interesting one.
[765.00s -> 767.40s]  You can type in a particular element and text, right?
[767.40s -> 768.70s]  So you can think it's not just a set
[768.70s -> 770.90s]  of discrete actions, you know,
[770.90s -> 772.70s]  basically you can type in whatever, right?
[772.70s -> 773.82s]  If you're searching for something
[773.82s -> 777.36s]  or you're filling certain boxes,
[778.36s -> 782.30s]  you can have a new tab so you can jump to a new website
[782.30s -> 784.70s]  you can focus on a particular tab,
[784.70s -> 787.58s]  you can close the tab, you can go particularly URL,
[787.58s -> 789.86s]  you can go forward, go backwards, scroll up, scroll down.
[789.86s -> 791.78s]  And then you have an action called stop and an answer.
[791.78s -> 793.70s]  Stop is in the action where the model basically says,
[793.70s -> 795.22s]  okay, I've solved the task, stop.
[795.22s -> 797.88s]  And then I give you the final answer.
[798.98s -> 800.14s]  In this particular environment,
[800.14s -> 802.10s]  you have deterministic transition function.
[802.10s -> 805.30s]  You have the state that generates the HTML page
[805.30s -> 807.30s]  and given the state and an action,
[807.30s -> 808.58s]  you generate the next state
[808.58s -> 811.34s]  and the next state generation is actually deterministic.
[811.34s -> 813.38s]  Basically meaning that if you're on a particular website
[813.38s -> 815.02s]  and you click on a particular element
[815.02s -> 818.38s]  or you type something, there is no stochasticity
[818.38s -> 821.10s]  so, you know, gets you to the next state.
[821.10s -> 823.06s]  And we also define the reward functions
[823.06s -> 825.38s]  and the reward function is primarily to evaluate
[825.38s -> 828.86s]  when you've successfully solved a task.
[828.86s -> 830.70s]  So it's a fairly sparse reward signal
[830.70s -> 833.34s]  that we get in this environment, okay?
[833.34s -> 835.30s]  But let me show you, just walk you through
[835.30s -> 838.86s]  what the model actually needs to do here, right?
[838.86s -> 840.84s]  So what the model needs to do is it, you know,
[840.84s -> 843.46s]  has to start on the homepage.
[843.46s -> 846.88s]  So here you're trying to find the cheapest printer
[846.88s -> 849.02s]  and you have to navigate to the printer category, right?
[849.02s -> 850.96s]  In terms of the actions that you need to take.
[850.96s -> 852.66s]  Then you have to sort by descending order.
[852.70s -> 856.06s]  So you can click sort by price, right?
[856.06s -> 857.86s]  Then you click on the cheapest color printers.
[857.86s -> 859.72s]  You have to choose what's the cheapest one.
[859.72s -> 860.98s]  So you kind of like have to understand
[860.98s -> 862.38s]  how much each printer cost
[862.38s -> 864.34s]  and you have to choose the cheapest one.
[864.34s -> 866.10s]  Then you have to add it to the shopping cart.
[866.10s -> 867.26s]  That's another step.
[867.26s -> 868.54s]  You have to proceed to checkout.
[868.54s -> 869.36s]  That's another step.
[869.36s -> 871.74s]  Then you have to fill in the form correctly, right?
[871.74s -> 874.86s]  With the information given to you in this image
[876.18s -> 877.80s]  and then you have to place the order.
[877.80s -> 880.18s]  So if you look at the entire trajectory here,
[880.18s -> 882.50s]  it's fairly complex trajectory, right?
[883.20s -> 884.30s]  The model has to sort of reason about
[884.30s -> 885.30s]  what it's seeing on the web.
[885.30s -> 888.54s]  It has to understand what I mean by the cheapest.
[888.54s -> 890.58s]  So it has to have a notion of sorting.
[891.90s -> 894.26s]  Then it has to really understand good multimodal abilities
[894.26s -> 897.62s]  to understand what I'm seeing in the images.
[897.62s -> 899.06s]  What's the address I have to go in
[899.06s -> 900.48s]  and fill in the address, right?
[900.48s -> 902.12s]  With the right information.
[902.12s -> 903.06s]  So if you look at it,
[903.06s -> 906.42s]  it's not a very trivial task to accomplish, right?
[906.42s -> 909.12s]  And that's just one of a thousand tasks
[909.12s -> 910.18s]  that we've designed.
[911.10s -> 913.22s]  So in terms of the distribution of tasks
[913.22s -> 914.56s]  across the websites,
[916.26s -> 918.94s]  we've looked at how difficult those tasks are.
[918.94s -> 921.16s]  I think we have 950 tasks in total,
[921.16s -> 922.76s]  close to a thousand tasks.
[922.76s -> 925.10s]  Then you can see about 15% are easy.
[925.10s -> 926.70s]  Basically what that means is that
[926.70s -> 929.06s]  it's easy in terms of reasoning difficulty
[929.06s -> 931.26s]  and easy in terms of visually understanding
[931.26s -> 932.48s]  what I'm asking you.
[932.48s -> 934.74s]  Basically means you have to do only a few clicks
[934.74s -> 936.46s]  to actually solve the task.
[936.46s -> 938.22s]  And then you sort of have this corner here,
[938.22s -> 940.54s]  which is fairly difficult.
[940.54s -> 941.46s]  Reasoning difficulty,
[941.46s -> 944.04s]  so I really have to understand what I'm seeing in the image
[944.04s -> 945.98s]  and visual difficulty.
[945.98s -> 947.34s]  And reasoning difficulty basically means
[947.34s -> 948.78s]  that I have to click on a lot of things
[948.78s -> 953.44s]  and kind of explore to successfully accomplish
[953.44s -> 954.48s]  this particular task, right?
[954.48s -> 956.58s]  So in this particular environment,
[956.58s -> 958.46s]  you can actually split and try to understand,
[958.46s -> 960.30s]  is it my visual models are missing
[960.30s -> 963.50s]  or is it my reasoning is missing?
[964.50s -> 969.18s]  Here's how we evaluating these in this environment.
[969.18s -> 971.38s]  So we have execution-based evaluation.
[971.38s -> 972.84s]  So for example, a lot of times
[972.84s -> 974.38s]  we wanna find the exact match.
[974.38s -> 975.78s]  So if I'm asking you the question,
[975.78s -> 977.28s]  what's the Ising number of the company
[977.28s -> 978.58s]  that occupies the largest portion
[978.58s -> 980.18s]  of Warren Buffett portfolio?
[980.18s -> 981.74s]  Then I kind of like go to Wikipedia,
[981.74s -> 983.34s]  I find Warren's Buffett portfolio,
[983.34s -> 985.18s]  and then I'd sort of get the information
[985.18s -> 987.46s]  and I need to get this exact number.
[987.46s -> 989.82s]  Sometimes if I said, add something like that
[989.82s -> 993.86s]  to whatever this man is wearing to my wishlist,
[993.86s -> 996.12s]  then I kind of like find something
[996.12s -> 997.94s]  and I basically have visual QA,
[997.94s -> 999.02s]  like is this a polo shirt?
[999.02s -> 999.84s]  Yes or no?
[999.84s -> 1001.26s]  Is this a green shirt?
[1001.26s -> 1002.38s]  And so forth, right?
[1003.26s -> 1004.34s]  And then you have,
[1004.34s -> 1005.62s]  sometimes when you're looking for something,
[1005.62s -> 1008.70s]  you say it has to include above 200
[1008.70s -> 1013.38s]  or above 20,000, below 30,000 and so forth, right?
[1013.38s -> 1015.64s]  So you can kind of like have these verifiers
[1015.64s -> 1019.34s]  that once I give you the final state,
[1019.78s -> 1021.10s]  I can actually run these verifiers
[1021.10s -> 1023.68s]  and sort of tell you, have you solved the task or not?
[1023.68s -> 1024.74s]  And for a lot of these prompts,
[1024.74s -> 1026.86s]  there's only one solution, right?
[1026.86s -> 1029.34s]  Now, because the environment is not the full internet,
[1029.34s -> 1030.70s]  it's fairly constrained,
[1030.70s -> 1032.10s]  but at least you can verify
[1032.10s -> 1034.90s]  whether your model actually successfully solved the task
[1034.90s -> 1035.98s]  or not.
[1035.98s -> 1039.66s]  Now, when we think about LLMs or visual language,
[1039.66s -> 1042.44s]  VLMs agents, visual language models,
[1043.34s -> 1046.86s]  the way to think about this is the following, right?
[1046.86s -> 1049.74s]  One thing I can do is I can look at the HTML
[1049.74s -> 1054.74s]  and try to use that as a representation into my LLM.
[1055.34s -> 1059.06s]  It's also cluttered with a lot of unnecessary information
[1059.06s -> 1060.52s]  has a long and confusing context.
[1060.52s -> 1061.36s]  There's been a lot of work
[1061.36s -> 1062.86s]  where people sort of doing markups,
[1062.86s -> 1066.50s]  where they try to identify the relevant parts of the HTML
[1066.50s -> 1068.50s]  and trying to use that.
[1068.50s -> 1070.22s]  There's another representation,
[1070.22s -> 1071.86s]  is to use something that's called set of marks,
[1071.86s -> 1074.78s]  which is a simplified representations.
[1074.78s -> 1077.34s]  So what it does is it basically puts bounding boxes
[1077.34s -> 1080.34s]  around elements, around clickable elements, right?
[1080.34s -> 1082.70s]  So whether I can click on certain elements or not,
[1082.70s -> 1085.92s]  and that's something that you can get from any HTML,
[1085.92s -> 1086.76s]  right?
[1086.76s -> 1087.82s]  So that's set of marks representation,
[1087.82s -> 1089.46s]  something that you can do.
[1089.46s -> 1091.26s]  Both of these representation have advantages
[1091.26s -> 1093.02s]  and disadvantages, set of marks is useful
[1093.02s -> 1095.10s]  because actually visually I understand
[1095.10s -> 1097.90s]  what I'm seeing in the image and what I can click on,
[1099.34s -> 1101.94s]  but it's also very cluttered type of representation.
[1101.94s -> 1103.66s]  And then there's the third type of representation
[1103.70s -> 1105.18s]  that people are now beginning to use,
[1105.18s -> 1106.72s]  which is coordinate based representation
[1106.72s -> 1108.18s]  where I'm just trying to predict the coordinate
[1108.18s -> 1109.70s]  of where I need to click.
[1109.70s -> 1111.48s]  So ultimately it's probably gonna be combination
[1111.48s -> 1113.54s]  of both HTML, set of marks
[1113.54s -> 1116.10s]  and kind of coordinate based representation.
[1116.10s -> 1117.74s]  And the way you can think about
[1117.74s -> 1119.68s]  these sort of representation is that if,
[1119.68s -> 1121.66s]  let's say I have original webpage,
[1121.66s -> 1124.44s]  I can use the set of marks representation, right?
[1124.44s -> 1125.94s]  So I can put the bounding boxes
[1125.94s -> 1128.62s]  and have IDs for each box
[1128.62s -> 1130.26s]  and sort of have some representation
[1130.26s -> 1131.96s]  what each box is actually doing
[1132.00s -> 1135.60s]  and perhaps have some form of captioning of each image.
[1135.60s -> 1140.16s]  So I have this sort of set of marks elements in the text
[1140.16s -> 1142.76s]  as well as the actual visual representation, right?
[1142.76s -> 1144.80s]  And if I say, if I'm trying to find this post,
[1144.80s -> 1146.64s]  navigate to the comment section of it,
[1146.64s -> 1149.48s]  then you pass it to the LLM or VLM agent.
[1149.48s -> 1151.56s]  And then the agent actually executes
[1151.56s -> 1153.96s]  a precise action to do next.
[1153.96s -> 1157.16s]  For example, I wanna click on element ID 31
[1157.16s -> 1161.20s]  and element ID 31 is one of the elements here, right?
[1161.24s -> 1163.36s]  And so again, the way that we typically
[1163.36s -> 1167.12s]  have a representation, I have a goal, I get an observation,
[1167.12s -> 1169.32s]  I have represented using set of marks
[1169.32s -> 1171.92s]  that goes to the multimodal language models,
[1171.92s -> 1175.32s]  both the text and the image, as well as the goal
[1175.32s -> 1177.40s]  and the model generates chain of thoughts.
[1177.40s -> 1179.60s]  So in this case, it would generate listing step by step.
[1179.60s -> 1181.48s]  The objective is to navigate to the food,
[1181.48s -> 1185.68s]  the post and so forth to navigate to this listing.
[1185.68s -> 1187.28s]  I need to click on the comment link
[1187.28s -> 1188.72s]  associated with the sushi.
[1188.72s -> 1191.08s]  In summary, my next section will be,
[1191.08s -> 1192.60s]  I'll perform action click 34.
[1192.60s -> 1194.84s]  And again, that's the action that you click, right?
[1194.84s -> 1199.28s]  So that's one particular action that the model is taking.
[1201.64s -> 1203.48s]  And then it goes, once you click
[1203.48s -> 1204.68s]  on that particular element,
[1204.68s -> 1207.56s]  the simulator will go to the next webpage,
[1207.56s -> 1212.44s]  the next state, and then you repeat this process, right?
[1212.44s -> 1215.92s]  And here again, the action is you take a particular action
[1215.92s -> 1218.52s]  from the list of actions that I've mentioned before.
[1218.88s -> 1222.80s]  Now, if I look at sort of baseline models
[1222.80s -> 1224.36s]  and kind of try to understand
[1224.36s -> 1227.76s]  which models are working well and which models are not,
[1227.76s -> 1228.64s]  what's interesting is that
[1228.64s -> 1231.36s]  if I only use text only based representation,
[1232.56s -> 1235.24s]  then I hit something like 9% accuracy.
[1235.24s -> 1236.96s]  If I use text plus caption,
[1236.96s -> 1239.68s]  so if I caption any visual information,
[1239.68s -> 1242.20s]  any images that I have on the web pages,
[1242.20s -> 1243.72s]  you know, you have improvement.
[1243.72s -> 1246.24s]  If I actually try to use multimodal model,
[1246.24s -> 1248.00s]  you get further improvement.
[1248.32s -> 1250.12s]  If I use set of marks representation,
[1250.12s -> 1252.20s]  sort of like I understand clickable elements
[1252.20s -> 1253.12s]  and what I can do,
[1253.12s -> 1255.76s]  you get a little bit of improvement as well.
[1255.76s -> 1259.16s]  So you kind of go from 9% to something like 18%.
[1259.16s -> 1260.76s]  And then you get human level performance.
[1260.76s -> 1263.40s]  And the human level performance hits close to, you know,
[1263.40s -> 1264.76s]  in this case for Visual Web Arena,
[1264.76s -> 1269.76s]  it was hitting something like 85, 86 accuracy, right?
[1269.88s -> 1270.96s]  So there is a big gap
[1270.96s -> 1273.80s]  between what people are capable of doing it
[1273.80s -> 1276.28s]  and what existing models are capable of doing.
[1277.28s -> 1278.12s]  This was interesting.
[1278.12s -> 1279.64s]  The way that we've collected the data
[1279.64s -> 1284.20s]  is we actually asked students at CMU to solve these tasks.
[1284.20s -> 1286.08s]  We give them the prompts, we give them the tasks,
[1286.08s -> 1287.12s]  we give them the environment
[1287.12s -> 1288.56s]  and they just interact with the environment
[1288.56s -> 1289.92s]  and then the end of the state.
[1289.92s -> 1292.68s]  And then we evaluate using our execution-based evaluation
[1292.68s -> 1295.68s]  whether they successfully solve the task.
[1295.68s -> 1298.48s]  What's interesting is that we found that, you know,
[1298.48s -> 1301.72s]  humans were not at 100%, right?
[1301.72s -> 1302.56s]  And what's interesting,
[1302.56s -> 1304.08s]  a lot of mistakes that people make
[1304.08s -> 1306.04s]  are kind of silly mistakes.
[1306.04s -> 1309.68s]  So for example, if I ask you to find, you know,
[1309.68s -> 1310.84s]  if I ask you to say, well,
[1310.84s -> 1313.68s]  find me the cheapest bicycle, right?
[1313.68s -> 1316.46s]  That has these specific constraints or these conditions.
[1316.46s -> 1317.68s]  I want it to be black.
[1317.68s -> 1319.16s]  I want it to be of this color.
[1319.16s -> 1321.40s]  I want it to be less than $2,000.
[1321.40s -> 1323.16s]  Go find me the cheapest bike.
[1324.52s -> 1325.66s]  What people tend to do,
[1325.66s -> 1329.80s]  people tend to kind of like go through the simulator.
[1329.80s -> 1331.42s]  They look at, they find one bike,
[1331.42s -> 1333.76s]  they find a second bike and then they basically say,
[1333.76s -> 1336.30s]  okay, I'm tired of looking for anything else, right?
[1336.30s -> 1337.40s]  So I have two bicycles.
[1337.40s -> 1340.20s]  I take the cheapest one and say, I'm done.
[1340.20s -> 1342.72s]  Whereas actually there are 10 bicycles, right?
[1342.72s -> 1343.92s]  That satisfy the constraint.
[1343.92s -> 1345.46s]  So people are just not very good
[1345.46s -> 1347.48s]  at information seeking tasks,
[1347.48s -> 1350.20s]  or at least we didn't pay students enough.
[1350.20s -> 1353.56s]  We gave them pizza to kind of like go and, you know,
[1353.56s -> 1355.96s]  spend more than a few minutes to solve these tasks.
[1355.96s -> 1358.86s]  So majority of the kind of information seeking task
[1358.86s -> 1361.16s]  is where people were not really good at.
[1361.16s -> 1364.20s]  And sometimes people were kind of like a little bit,
[1364.20s -> 1365.52s]  you know, they would solve the task,
[1365.52s -> 1368.22s]  but they would forget to click on, you know,
[1368.22s -> 1369.06s]  place the order.
[1369.06s -> 1370.04s]  So they would solve the task.
[1370.04s -> 1370.96s]  They would add to the cart.
[1370.96s -> 1371.80s]  They find the right thing,
[1371.80s -> 1374.32s]  but they forget to click on, you know, place the order.
[1374.32s -> 1378.60s]  And if they forget to, you know, place the order,
[1378.60s -> 1380.52s]  then our system basically says that,
[1380.52s -> 1381.66s]  well, you haven't solved it, right?
[1381.66s -> 1384.22s]  Because they actually haven't bought the item.
[1385.44s -> 1388.28s]  And so, you know, this is an interesting part
[1388.28s -> 1390.96s]  because I think that agentic systems
[1391.60s -> 1392.44s]  should be able to solve these tasks.
[1392.44s -> 1395.04s]  Agentic system should be much better at information seeking
[1395.04s -> 1397.58s]  and finding sort of the information
[1397.58s -> 1400.32s]  just because it requires less cognitive load,
[1400.32s -> 1402.72s]  whereas people are not very good at doing that.
[1403.64s -> 1405.20s]  If I look at sort of, you know,
[1405.20s -> 1406.84s]  trying to understand, you know,
[1406.84s -> 1409.36s]  where we are with these models,
[1409.36s -> 1412.56s]  you can kind of like see that llama, you know,
[1412.56s -> 1413.86s]  the older versions of llama,
[1413.86s -> 1416.60s]  they all were kind of like really bad.
[1416.60s -> 1419.02s]  If I have accessibility tree plus captions,
[1419.06s -> 1422.38s]  a lot of these models would kind of, you know, go higher.
[1422.38s -> 1424.58s]  And then once I have multi-models,
[1424.58s -> 1426.12s]  you have much better representation.
[1426.12s -> 1429.18s]  And then once I have, you know, the multi-model models,
[1429.18s -> 1431.90s]  in that time looking Gemini Pro and GPT-4,
[1431.90s -> 1434.40s]  I think GPT-4 all now hit something like 90%.
[1434.40s -> 1438.14s]  So like these models do climb, they do better,
[1438.14s -> 1442.26s]  but they still far below what people can do, right?
[1442.26s -> 1444.10s]  Even the best models today
[1444.10s -> 1447.74s]  are sitting around 20% accuracy, right?
[1447.78s -> 1450.06s]  In terms of solving these tasks.
[1451.46s -> 1453.42s]  And here's one example I wanted to show.
[1453.42s -> 1455.70s]  It's an interesting example
[1455.70s -> 1459.42s]  where the GPT model was able to successfully solve it.
[1459.42s -> 1461.88s]  I ask you, I don't like the author of this image
[1461.88s -> 1463.78s]  from the posts, one of the posts.
[1463.78s -> 1466.66s]  Can you help me block them?
[1466.66s -> 1468.02s]  And the engine would actually go,
[1468.02s -> 1469.72s]  it would sort of click on the right things,
[1469.72s -> 1472.78s]  it would find the post, it would go to the settings,
[1472.78s -> 1475.52s]  and through sort of executing multiple clicks,
[1475.52s -> 1478.82s]  it would actually block a specific user, right?
[1478.82s -> 1480.86s]  Just as an example, like you give it this instruction
[1480.86s -> 1484.36s]  and the model would actually go and do that.
[1484.36s -> 1486.56s]  And this sort of has this notion of,
[1486.56s -> 1488.98s]  that I'd like to think about web agent architectures.
[1488.98s -> 1491.04s]  And I'll make that reference later on
[1491.04s -> 1492.76s]  for physical agents.
[1492.76s -> 1495.06s]  But you can think about these sort of architectures
[1495.06s -> 1498.82s]  where, you know, you observe some input, say web page,
[1499.80s -> 1502.08s]  you do some form of parsing, right?
[1502.08s -> 1504.76s]  Of the web page, whether it's visual and HTML
[1504.84s -> 1506.96s]  or some kind of compressed representation of HTML
[1506.96s -> 1508.92s]  plus visual understanding.
[1508.92s -> 1510.96s]  We have an objective, right?
[1510.96s -> 1513.06s]  And the objective is what I need to do.
[1513.06s -> 1515.90s]  And a lot of times what a lot of these models would do
[1515.90s -> 1517.78s]  is they would generate high-level plan, right?
[1517.78s -> 1519.58s]  They would generate a plan of how to execute,
[1519.58s -> 1522.32s]  how you should proceed to solve the task.
[1522.32s -> 1524.42s]  And then you kind of, you know,
[1524.42s -> 1526.16s]  execute the low-level actions,
[1526.16s -> 1528.20s]  which is clicking on a specific element, right?
[1528.20s -> 1530.38s]  And that sort of goes in loop.
[1530.38s -> 1532.20s]  You know, you can refine the high-level plan,
[1532.20s -> 1533.76s]  you can execute the low-level action
[1533.76s -> 1535.96s]  up until you hit a stop action,
[1535.96s -> 1538.30s]  which basically means that the agent is done.
[1538.30s -> 1541.64s]  I think I've solved the task, okay?
[1541.64s -> 1545.02s]  And, you know, you can think of planning as, you know,
[1545.02s -> 1545.86s]  as a system.
[1545.86s -> 1546.68s]  There's been some work
[1546.68s -> 1549.28s]  on building these hierarchical systems where, you know,
[1549.28s -> 1550.86s]  for example, step one,
[1550.86s -> 1554.76s]  I can say, navigate me to a particular category, right?
[1554.76s -> 1556.96s]  Step two, you know,
[1556.96s -> 1559.44s]  I wanna sort based on the rating of that category.
[1559.44s -> 1560.76s]  And that would be two low-level actions,
[1560.76s -> 1562.80s]  you selecting and then you sorting, right?
[1563.02s -> 1564.20s]  And then maybe, you know,
[1564.20s -> 1566.20s]  you select a ninth amount of $20,
[1566.20s -> 1568.52s]  and then maybe you buying a selected item, right?
[1568.52s -> 1569.36s]  You need to buy it,
[1569.36s -> 1570.52s]  and then it's three low-level actions,
[1570.52s -> 1571.36s]  you add to the cart,
[1571.36s -> 1574.40s]  you proceed to the checkout and you do shipping.
[1574.40s -> 1576.60s]  So there is some sort of work right now
[1576.60s -> 1578.40s]  that's trying to have the planning model
[1578.40s -> 1580.68s]  that actually, you know, plans what you need to do,
[1580.68s -> 1582.52s]  and then you execute those.
[1583.66s -> 1584.96s]  So Visual Web Arena,
[1584.96s -> 1586.48s]  we think of it as a step
[1586.48s -> 1589.22s]  towards building general purpose agents, right?
[1589.22s -> 1592.42s]  It's a simulator, so you can evaluate those models.
[1593.28s -> 1594.12s]  Tasks that we designed
[1594.12s -> 1595.68s]  are not very consequential at this point.
[1595.68s -> 1597.10s]  You know, they don't really represent
[1597.10s -> 1599.36s]  significant economic value at this point.
[1599.36s -> 1602.04s]  And we've designed these tasks to be simpler
[1602.04s -> 1604.44s]  because the current large language model agents
[1604.44s -> 1606.84s]  or AI agents do not even do well on these tasks.
[1606.84s -> 1608.80s]  The gap is still fairly significant.
[1609.84s -> 1611.84s]  And the long-term question is
[1611.84s -> 1616.84s]  can we automate productive economically valuable tasks, right?
[1619.72s -> 1622.28s]  One of the interesting failure modes
[1622.64s -> 1623.92s]  that we see in these models,
[1623.92s -> 1625.58s]  and again, we're fixing those,
[1625.58s -> 1627.28s]  a lot of that is sort of progresses
[1627.28s -> 1629.74s]  as the models become better and better.
[1629.74s -> 1631.24s]  But one of the things that we're seeing
[1631.24s -> 1634.96s]  is this notion of long horizon reasoning and planning,
[1634.96s -> 1635.96s]  right?
[1635.96s -> 1639.80s]  So models sometimes oscillate between two web pages
[1639.80s -> 1641.44s]  or sometimes they get stuck in the loop.
[1641.44s -> 1642.96s]  So it's, you know, I'm trying to do something,
[1642.96s -> 1644.84s]  I go to this webpage and then I go back
[1644.84s -> 1646.12s]  and then I go forward and I go back.
[1646.12s -> 1648.48s]  So this is the notion of persistent memory.
[1648.48s -> 1651.72s]  A lot of times sort of, you know, memory is missing.
[1652.00s -> 1655.80s]  So good representation of what I've done so far is missing.
[1655.80s -> 1658.20s]  Of course, I can concatenate every single webpage
[1658.20s -> 1660.48s]  I visited with every single HTML,
[1660.48s -> 1662.28s]  but that becomes fairly cumbersome, right?
[1662.28s -> 1664.28s]  You need to have a good persistent representation
[1664.28s -> 1665.32s]  of the memory.
[1665.32s -> 1668.06s]  A lot of times, you know, models would correctly start
[1668.06s -> 1670.24s]  on performing tasks and then undoing them.
[1670.24s -> 1671.96s]  I don't know why, it's just basically means
[1671.96s -> 1675.00s]  they don't have very good reasoning abilities.
[1675.00s -> 1678.24s]  And a lot of times agents tend to stop exploration
[1678.24s -> 1679.14s]  execution too early.
[1679.14s -> 1682.14s]  So instead of exploring what are the possibilities there,
[1682.14s -> 1684.34s]  they actually try to do something and then you stop
[1684.34s -> 1686.58s]  and you basically execute the stop action and says like,
[1686.58s -> 1688.56s]  I, you know, I can't solve the task.
[1688.56s -> 1690.66s]  I'm not seeing how I can solve the task.
[1692.06s -> 1694.42s]  And this is also some failures in visual processing.
[1694.42s -> 1697.22s]  So sometimes you can click on the wrong items,
[1697.22s -> 1700.46s]  identifying specific items in complex web pages.
[1700.46s -> 1701.62s]  There is also, you know,
[1701.62s -> 1703.62s]  they lack a little bit of spatial reasoning.
[1703.62s -> 1705.34s]  Like if you're asking me the question,
[1705.34s -> 1707.62s]  what are the prices of products in the first row?
[1707.62s -> 1708.78s]  You kind of like have to understand
[1709.30s -> 1710.54s]  what the first row is, but the second row
[1710.54s -> 1711.80s]  and like what's the middle row, right?
[1711.80s -> 1715.08s]  So certain spatial, you know, understanding is missing,
[1715.08s -> 1717.22s]  but I think those things will potentially get better
[1717.22s -> 1721.34s]  and better as we sort of can get the data
[1721.34s -> 1723.76s]  for training these models, right?
[1723.76s -> 1724.78s]  So what we need to do,
[1724.78s -> 1727.82s]  we need to do a lot more to close the gap.
[1727.82s -> 1730.18s]  Definitely reasoning and planning over long horizons.
[1730.18s -> 1732.06s]  And that's, I'll talk a little bit about this,
[1732.06s -> 1735.36s]  but that's one of the key failure modes.
[1735.36s -> 1737.62s]  We also need to allow agents to search.
[1737.62s -> 1739.62s]  You can think of it as executing
[1739.62s -> 1742.38s]  and coordinating multiple instances in parallel
[1742.38s -> 1745.10s]  and asking for clarifications and confirmations, right?
[1745.10s -> 1747.78s]  So a lot of times search is actually, you know,
[1747.78s -> 1750.30s]  you can think of it as test time inference technique
[1750.30s -> 1753.36s]  basically tries to explore possibilities
[1753.36s -> 1756.14s]  to figure out what's the right way to solve the task.
[1756.14s -> 1757.82s]  And asking for clarification,
[1757.82s -> 1759.70s]  this is where uncertainty estimation comes in.
[1759.70s -> 1761.86s]  It's also fairly challenging where you basically,
[1761.86s -> 1763.98s]  the model has to understand that it's confused
[1763.98s -> 1765.78s]  and then he has to go and ask humans
[1766.30s -> 1768.26s]  for clarifications or guidance.
[1768.26s -> 1770.04s]  And obviously you need strong, you know,
[1770.04s -> 1771.94s]  visual language code models
[1771.94s -> 1774.82s]  and also identifying your proper levels of abstractions
[1774.82s -> 1775.66s]  for agents like, you know,
[1775.66s -> 1777.10s]  do you rely on screenshots?
[1777.10s -> 1778.76s]  What you seeing visually?
[1778.76s -> 1781.90s]  Do you rely on HTML or maybe you rely on API?
[1781.90s -> 1782.86s]  So a lot of, you know,
[1782.86s -> 1784.70s]  there's a lot of websites that would have API.
[1784.70s -> 1786.98s]  So maybe instead of actually going through the web,
[1786.98s -> 1790.02s]  you actually go through API calls, right?
[1790.02s -> 1793.70s]  And again, I think that multimodal models here
[1793.70s -> 1794.70s]  becomes very important
[1794.70s -> 1796.04s]  because a lot of real-world task
[1796.04s -> 1798.50s]  will require some form of visual grounding, right?
[1798.50s -> 1800.28s]  So for example, if you, you know,
[1800.28s -> 1802.34s]  if you're interacting with PowerPoint,
[1802.34s -> 1804.18s]  if you're interacting with Photoshop, right?
[1804.18s -> 1806.02s]  A lot of it, yes, you can do it through API,
[1806.02s -> 1807.52s]  but a lot of things are also done
[1807.52s -> 1810.02s]  through visual grounding and visual understanding.
[1810.86s -> 1812.46s]  So we definitely need to train
[1812.46s -> 1815.04s]  and build stronger visual language models.
[1816.74s -> 1818.58s]  So that kind of like gives me this notion
[1818.58s -> 1820.66s]  of visual web arena,
[1820.66s -> 1822.92s]  which is the environment that we use for doing evaluation.
[1822.92s -> 1827.92s]  Now let's talk about the tree search,
[1828.58s -> 1831.76s]  or we can think of it as, again, test time inference.
[1832.88s -> 1837.88s]  One interesting thing about agentic agents in general
[1838.16s -> 1839.84s]  is that you have this notion
[1839.84s -> 1843.24s]  of exponential error compounding, right?
[1843.24s -> 1846.22s]  So for example, you know,
[1846.22s -> 1849.16s]  if your model is accurately can be accurate
[1849.16s -> 1851.84s]  at one step prediction at 90%,
[1851.88s -> 1855.48s]  then if you're executing, you know, 30 actions,
[1855.48s -> 1858.36s]  then your accuracy goes down to 4%, right?
[1859.32s -> 1862.44s]  So you basically need to be very, very accurate.
[1862.44s -> 1863.86s]  So you need to be very precise
[1863.86s -> 1865.72s]  in terms of like executing each step
[1865.72s -> 1867.48s]  in order to be able to successfully, you know,
[1867.48s -> 1869.52s]  solving long horizon tasks.
[1869.52s -> 1870.78s]  And that's pretty well known.
[1870.78s -> 1874.90s]  And anytime you have sequential decision-making process,
[1874.90s -> 1876.80s]  you have this issue, right?
[1876.80s -> 1879.28s]  The errors do compound over time,
[1879.44s -> 1884.36s]  which makes it a very, very difficult task.
[1885.62s -> 1887.92s]  So what happens here?
[1887.92s -> 1892.16s]  Well, local decisions have global consequences, right?
[1892.16s -> 1894.28s]  So for example, let's say I ask you the question,
[1894.28s -> 1895.88s]  add coconut milk to my car.
[1896.80s -> 1900.04s]  Well, I can click on element ID 31,
[1900.04s -> 1902.10s]  or maybe, and that gives me to the next state,
[1902.10s -> 1904.08s]  or maybe I can click element ID 24
[1904.08s -> 1906.32s]  that gets me to the next state, right?
[1906.32s -> 1907.48s]  And then so forth.
[1907.64s -> 1909.64s]  Sort of different choices.
[1909.64s -> 1910.48s]  There is a lot of actions.
[1910.48s -> 1912.44s]  I mean, action space could be exponential,
[1912.44s -> 1914.22s]  especially if I'm doing searching as well, right?
[1914.22s -> 1915.52s]  So I can type text.
[1917.10s -> 1920.72s]  And so you can imagine that each one of these
[1920.72s -> 1924.28s]  sort of leads to a trajectory, right?
[1924.28s -> 1926.68s]  Once I execute the trajectory,
[1926.68s -> 1929.22s]  and then potentially I can evaluate, you know,
[1929.22s -> 1930.72s]  which one is right, which one is wrong.
[1930.72s -> 1931.72s]  And let's say, you know,
[1931.72s -> 1934.36s]  basically this state gives me the right outcome
[1934.36s -> 1936.56s]  and all that states don't.
[1936.56s -> 1938.66s]  And especially, you know, if you're executing actions,
[1938.66s -> 1940.98s]  you know, 30, 40, 50 actions,
[1940.98s -> 1943.16s]  that becomes very challenging.
[1943.16s -> 1945.52s]  And if you have a policy right now that, you know,
[1945.52s -> 1948.20s]  you can think of VLM as your policy
[1948.20s -> 1950.56s]  that basically predicts the probability point five,
[1950.56s -> 1951.60s]  you should click on this section,
[1951.60s -> 1954.28s]  and probability point one, you should click on this section
[1954.28s -> 1956.92s]  then obviously, you know, finding the correct path
[1956.92s -> 1959.76s]  is gonna be very difficult, right?
[1959.76s -> 1962.86s]  So, you know, you basically have to,
[1962.86s -> 1965.12s]  you have to be able to explore the environment
[1965.16s -> 1966.84s]  very efficiently, right?
[1966.84s -> 1971.18s]  In this sort of exponential, in this exponential space.
[1972.48s -> 1976.76s]  Now, one of the things that turns out to work okay-ish,
[1976.76s -> 1978.24s]  or at least as a first step,
[1978.24s -> 1981.56s]  is doing search by repeated sampling, right?
[1981.56s -> 1985.28s]  It's a very simple idea, very easy idea.
[1985.28s -> 1987.68s]  You sample action from your model
[1987.68s -> 1990.04s]  until you hit the stop action, okay?
[1990.04s -> 1991.84s]  So let's say you sample this path.
[1993.08s -> 1994.96s]  And then you evaluate the resulting trajectory.
[1995.66s -> 1996.78s]  So you look at the trajectory and you can say,
[1996.78s -> 1999.36s]  have you solved the task or did you not solve the task?
[1999.36s -> 2000.64s]  Right, if you have a verifiers
[2000.64s -> 2002.46s]  that can tell you that you solved the task,
[2002.46s -> 2006.22s]  then you know whether it's success or not success, right?
[2006.22s -> 2010.94s]  And if it's a not success, then you repeat, right?
[2010.94s -> 2012.44s]  This would be an instance
[2012.44s -> 2014.28s]  of what's called rejection sampling, right?
[2014.28s -> 2018.56s]  You generate the trajectory, you look at the outcome,
[2018.56s -> 2019.72s]  and if you didn't solve it,
[2019.72s -> 2022.46s]  you generate another trajectory, right?
[2023.42s -> 2028.42s]  This is a very simplistic way called rejection sampling.
[2029.54s -> 2032.42s]  You basically sample until you hit the right answer.
[2032.42s -> 2034.18s]  It's fairly inefficient,
[2034.18s -> 2037.44s]  but it's surprising that a lot of work
[2037.44s -> 2038.82s]  that's happening right now, for example,
[2038.82s -> 2040.06s]  in space of reasoning,
[2040.06s -> 2044.22s]  like models like O1, O3, or DeepSeq,
[2044.22s -> 2047.04s]  they're essentially doing exactly this.
[2047.04s -> 2048.94s]  They're essentially doing rejection sampling.
[2048.94s -> 2050.40s]  I give you the math problem,
[2050.40s -> 2053.32s]  I start generating thinking tokens
[2053.32s -> 2054.98s]  up until I get the right answer, right?
[2054.98s -> 2057.60s]  And so I start with simpler prompts.
[2057.60s -> 2061.14s]  I generate sometimes right answers, sometimes wrong answers.
[2061.14s -> 2064.52s]  I use reinforcement learning to reinforce positive
[2064.52s -> 2066.52s]  and then de-reinforce negative
[2066.52s -> 2068.54s]  and sort of start scaling it up.
[2068.54s -> 2070.92s]  So the simple idea of rejection sampling
[2070.92s -> 2074.28s]  is essentially what's driving a lot of innovation right now
[2074.28s -> 2076.74s]  in reasoning capabilities, right?
[2076.74s -> 2080.36s]  Which is amazing and was very surprising to me
[2081.28s -> 2082.78s]  that it actually works.
[2082.78s -> 2084.26s]  So we've sort of started looking
[2084.26s -> 2085.68s]  at exactly the same problem,
[2085.68s -> 2089.38s]  but for us in this particular domain,
[2089.38s -> 2092.24s]  it's not that you can generate thinking tokens
[2092.24s -> 2094.20s]  and then you basically get the answer.
[2094.20s -> 2096.74s]  Here you actually have to execute actions
[2096.74s -> 2097.58s]  in the environment
[2097.58s -> 2100.44s]  and you change the state of the environment, right?
[2100.44s -> 2103.92s]  Which makes it much more difficult.
[2103.92s -> 2105.44s]  So here you do rejection sampling
[2105.44s -> 2109.36s]  and hopefully at some point you'll hit the right answer.
[2109.36s -> 2114.36s]  What happens is that repeated sampling tends to help, right?
[2115.00s -> 2117.04s]  So here's the number of 10 runs.
[2117.04s -> 2120.96s]  And this is what we call pass at 10,
[2120.96s -> 2122.92s]  which basically means that
[2122.92s -> 2125.62s]  if you're running your model 10 times,
[2128.68s -> 2131.68s]  in terms of you hit like 15% probability
[2131.68s -> 2134.42s]  of getting the right answer, right?
[2134.42s -> 2135.88s]  So the more you sample,
[2135.88s -> 2137.88s]  the probability that you'll hit the right answer
[2137.88s -> 2140.18s]  among these samples is kind of is increasing
[2140.18s -> 2143.40s]  and that's what this graph is showing, all right?
[2143.40s -> 2148.40s]  And however, the space is exponentially large, right?
[2149.30s -> 2152.04s]  So can we guide this exploration?
[2152.04s -> 2154.88s]  And the key idea here is to apply the value function
[2154.88s -> 2156.16s]  to intermediate nodes.
[2157.12s -> 2158.46s]  It's a very old idea,
[2159.64s -> 2163.56s]  but you can apply it actually in this space as well.
[2163.56s -> 2164.72s]  So how does this work?
[2165.72s -> 2168.88s]  So the idea is to basically do a form
[2168.88s -> 2173.00s]  of a best first search algorithm with a few tweaks.
[2173.00s -> 2175.42s]  So what are the ingredients of the algorithm?
[2175.42s -> 2177.40s]  So the baseline agent proposes actions.
[2177.40s -> 2179.10s]  The baseline agent actually says,
[2179.10s -> 2182.22s]  okay, here's two actions that I can take, right?
[2182.22s -> 2183.60s]  These are the most probable action
[2183.60s -> 2185.64s]  according to the base model,
[2185.64s -> 2187.38s]  according to your original policy.
[2188.90s -> 2192.80s]  You have to have a way to backtrack in the environment,
[2192.80s -> 2193.64s]  right?
[2193.64s -> 2196.06s]  So that basically means in this state,
[2196.06s -> 2199.52s]  you wanna be able to backtrack to the original state.
[2199.52s -> 2200.90s]  This is sometimes difficult to do,
[2200.90s -> 2205.20s]  especially in web environments,
[2205.20s -> 2207.36s]  because some actions you can't backtrack from
[2207.36s -> 2210.68s]  and these actions that we call destructive actions,
[2210.68s -> 2213.92s]  like if I place the order,
[2213.92s -> 2216.98s]  I can't just go back and unplace it, right?
[2216.98s -> 2218.00s]  That's just one example.
[2218.00s -> 2220.10s]  So we'll talk a little bit about this.
[2220.10s -> 2221.84s]  And then you also have to have a value function.
[2221.84s -> 2223.20s]  You can think of a value function
[2223.80s -> 2226.80s]  that takes the input, whatever your presentation is,
[2226.80s -> 2230.32s]  plus it takes a sequence of previous observations
[2230.32s -> 2233.78s]  or previous steps and outputs a score.
[2235.02s -> 2237.76s]  And you can think a value function,
[2237.76s -> 2241.20s]  essentially looking at the expected value,
[2241.20s -> 2243.96s]  expected reward, think of it as,
[2243.96s -> 2246.60s]  in our settings, think of it as the probability
[2246.60s -> 2248.30s]  of successfully solving the task, right?
[2248.30s -> 2249.64s]  So it's a number between zero and one
[2249.64s -> 2251.88s]  that basically says if I'm in this state
[2251.88s -> 2254.64s]  and my value function is 0.5,
[2254.64s -> 2259.08s]  then the probability of me succeeding is 50%.
[2259.08s -> 2262.14s]  And if the value function in this state is 0.3,
[2262.14s -> 2264.48s]  then the probability of me succeeding is 30%, right?
[2264.48s -> 2267.00s]  So maybe this state is better than this state.
[2267.00s -> 2269.54s]  So you have to have a good value function, right?
[2269.54s -> 2272.80s]  And these are kind of values that you can associate.
[2272.80s -> 2274.32s]  And what we've done in this work
[2274.32s -> 2277.32s]  is we're basically using LLM as a judge.
[2277.32s -> 2280.76s]  So we, in this case, you take a GPT 4.0,
[2280.76s -> 2283.68s]  you take the full trace, the full trajectory,
[2283.68s -> 2286.76s]  and you're asking the model to say, you know,
[2286.76s -> 2289.64s]  is, you know, how good the state is
[2289.64s -> 2291.94s]  in terms of solving a particular task.
[2291.94s -> 2294.52s]  So there is a way to sort of, you know,
[2294.52s -> 2296.96s]  use this LLM as a judge.
[2296.96s -> 2299.78s]  There's a few tricks of self consistency that you can use
[2299.78s -> 2303.04s]  but essentially you can just use a large language model
[2303.04s -> 2305.16s]  as a judge to judge each state.
[2305.16s -> 2309.08s]  Ultimately, I do believe that the next generation models
[2309.08s -> 2310.84s]  will create their own value functions.
[2310.84s -> 2312.48s]  You'll train your own value function
[2312.48s -> 2316.10s]  that basically will guide this exploration, okay?
[2316.10s -> 2317.62s]  So how does this work?
[2317.62s -> 2320.20s]  Let's say that I give you a task, right?
[2320.20s -> 2322.62s]  The task instruction is, can you add this
[2322.62s -> 2325.08s]  and the other canned fruit of the same brand
[2325.08s -> 2328.04s]  that looks like this, but red instead of brown
[2328.04s -> 2330.84s]  to the comparison page, okay?
[2330.84s -> 2331.92s]  So how does this work?
[2331.92s -> 2334.76s]  Well, you take the action, right?
[2334.76s -> 2335.84s]  And then at this point,
[2335.84s -> 2338.12s]  you have three possible actions to take, right?
[2338.12s -> 2339.56s]  They all have a probability,
[2339.56s -> 2342.44s]  they all have a value function of 0.45, right?
[2342.44s -> 2345.04s]  So you pick one of them, you proceed
[2345.04s -> 2347.40s]  and then you go to the next kind of state
[2347.40s -> 2348.84s]  and your value function decreases.
[2348.84s -> 2350.36s]  So you basically say, okay, I'm actually,
[2350.36s -> 2353.44s]  maybe I'm on the wrong path to solving this task.
[2353.44s -> 2357.00s]  And then I backtrack and I take another action, right?
[2357.00s -> 2358.64s]  So I backtrack to the previous state
[2358.64s -> 2360.60s]  and I take the other action.
[2360.60s -> 2363.72s]  And let's say here I go in my probability increases,
[2363.72s -> 2366.06s]  I go in my probability increases
[2366.06s -> 2368.22s]  and then I hit a particular state
[2368.22s -> 2371.42s]  where I'm not actually gonna solve this task, right?
[2371.42s -> 2374.14s]  Because my value of the state is actually pretty small
[2374.14s -> 2378.26s]  because I ended up in a very wrong state.
[2378.26s -> 2380.74s]  So then I have to be able to backtrack again
[2380.74s -> 2382.94s]  from this state, I have to be able to backtrack
[2382.94s -> 2385.58s]  back to the original state, right?
[2385.58s -> 2390.58s]  And then go and sort of, again, take the next states
[2391.66s -> 2394.00s]  and then if it's bad, backtrack
[2394.04s -> 2396.52s]  and eventually solve the task, right?
[2396.52s -> 2400.96s]  So you can sort of see that it's more expensive.
[2401.80s -> 2404.16s]  There are different ways of exploring,
[2404.16s -> 2407.60s]  but the key here that drives a lot of this exploration
[2407.60s -> 2410.28s]  is the value of the state, right?
[2410.28s -> 2412.04s]  Which basically is telling you how good
[2412.04s -> 2414.72s]  the particular state is in terms of solving a task.
[2414.72s -> 2417.70s]  And you can kind of like spot the errors early on
[2417.70s -> 2420.86s]  and say, no, no, no, backtrack and restart again.
[2421.74s -> 2422.94s]  So it's a little bit better
[2422.94s -> 2426.04s]  than just doing random rejection sampling
[2426.04s -> 2430.76s]  because here you're doing guided exploration.
[2432.26s -> 2434.22s]  It's very similar to, you know,
[2434.22s -> 2437.34s]  some of you are familiar with AlphaGo setting, right?
[2437.34s -> 2440.42s]  Where you basically have an environment
[2440.42s -> 2442.36s]  where you have a value of the state
[2442.36s -> 2445.02s]  and then you're trying to explore which actions to take
[2445.02s -> 2446.56s]  and you sort of evaluate those states
[2446.56s -> 2448.76s]  given the value function that you have.
[2449.76s -> 2451.72s]  And so if we look at the results,
[2451.72s -> 2456.50s]  what we found is that, you know, for Web Arena,
[2456.50s -> 2459.40s]  you know, there is pretty decent improvement
[2459.40s -> 2462.08s]  in terms of the ability to solve these tasks.
[2462.08s -> 2463.44s]  For the Visual Web Arena,
[2463.44s -> 2466.62s]  we also see, you know, quite reasonable improvements
[2466.62s -> 2468.00s]  by using this exploration.
[2468.00s -> 2469.36s]  It's more expensive, but,
[2470.52s -> 2475.52s]  and so we do see that these sort of search at test time
[2475.80s -> 2479.76s]  actually improves model's ability to solve the task
[2479.76s -> 2482.00s]  or at least to solve some of the tasks.
[2482.00s -> 2484.32s]  You can still see that we're still very far away
[2484.32s -> 2486.96s]  from hitting like 90% accuracy, right?
[2487.88s -> 2490.12s]  But nonetheless, it's actually a progress
[2490.12s -> 2492.80s]  where we progressively improving.
[2492.80s -> 2495.96s]  And we do sort of see that if you look at the success,
[2495.96s -> 2498.56s]  if you look at the success rate, right?
[2498.56s -> 2501.12s]  C zero indicates no search.
[2501.12s -> 2503.96s]  And then, you know, the more no expansions you have,
[2504.00s -> 2506.14s]  the better your performance is.
[2506.14s -> 2508.56s]  And then you can also sort of look at the success rate
[2508.56s -> 2512.60s]  relative to, you know, how you wanna expand, you know,
[2512.60s -> 2515.68s]  do you control the depth versus the breadth
[2515.68s -> 2519.52s]  and sort of, again, how much you wanna explore
[2519.52s -> 2521.42s]  versus what's the branching factor.
[2522.60s -> 2524.42s]  And then if we kind of, you know,
[2524.42s -> 2526.60s]  keep exploring and doing the branching,
[2526.60s -> 2528.20s]  then the accuracy tends to go up
[2528.20s -> 2530.76s]  just because the model is able to explore
[2530.76s -> 2534.68s]  possible different possibilities,
[2534.68s -> 2535.52s]  like a different environment.
[2535.52s -> 2538.96s]  So a lot of times what we see in sort of,
[2538.96s -> 2540.36s]  in these settings is that, you know,
[2540.36s -> 2543.52s]  if I ask you to buy a blue polo shirt, you know,
[2543.52s -> 2545.88s]  if you don't do this search, the model, let's say,
[2545.88s -> 2547.64s]  goes and let's say it clicks on the wrong thing
[2547.64s -> 2549.12s]  and it ends up on the webpage
[2549.12s -> 2552.04s]  that only has blue polo shirts, right?
[2552.04s -> 2553.32s]  So you're asking black polo shirt
[2553.32s -> 2555.24s]  and gives you blue polo shirts.
[2555.24s -> 2556.06s]  And then the model says,
[2556.06s -> 2558.30s]  well, there are no black polo shirts
[2558.30s -> 2560.08s]  because I'm only seeing blue polo shirts.
[2560.12s -> 2562.64s]  I can't solve the task, done, right?
[2562.64s -> 2564.16s]  And obviously this is the case
[2564.16s -> 2566.40s]  that if you can backtrack and sort of explore,
[2566.40s -> 2568.96s]  you will find the right answer, right?
[2568.96s -> 2570.72s]  So this notion of search
[2570.72s -> 2574.52s]  is actually becomes fairly important, right, and such.
[2574.52s -> 2576.40s]  And so, and we also found that
[2576.40s -> 2580.56s]  having a good value function is essential, right?
[2580.56s -> 2581.84s]  There is still a lot of headroom
[2581.84s -> 2583.48s]  for improving the base policy.
[2583.48s -> 2585.16s]  Obviously your base policy has to be good.
[2585.16s -> 2587.22s]  It can't just take random actions.
[2587.22s -> 2588.54s]  If your base policies,
[2588.54s -> 2590.20s]  if your base model is actually pretty weak,
[2590.20s -> 2592.82s]  then you'll just be taking random actions
[2592.82s -> 2594.76s]  and there isn't only that much you can do
[2594.76s -> 2596.30s]  with exploration,
[2598.18s -> 2601.26s]  but you sort of need to improve both, right?
[2601.26s -> 2602.42s]  And you can kind of like see
[2602.42s -> 2605.18s]  if you use different value functions,
[2605.18s -> 2607.14s]  then the performance is actually improved.
[2607.14s -> 2608.56s]  Like with no search,
[2608.56s -> 2611.30s]  if you sort of like say Lava, which is a weaker version,
[2611.30s -> 2612.24s]  you get the improvement.
[2612.24s -> 2615.26s]  If you use something for all type of models,
[2615.26s -> 2616.86s]  then you have,
[2617.82s -> 2619.38s]  so if you have a better value function,
[2619.38s -> 2621.42s]  kind of like looks at the full trajectory,
[2621.42s -> 2625.32s]  then it's, you have improvements in performance.
[2625.32s -> 2628.62s]  And the interesting thing is that using LLM as a judge,
[2628.62s -> 2631.50s]  judging whether the trajectory is good or bad
[2631.50s -> 2633.62s]  is much easier than predicting
[2633.62s -> 2635.90s]  what the next action you should take, right?
[2636.86s -> 2639.22s]  Or what the next sort of element you should click on,
[2639.22s -> 2640.66s]  what you should be searching on.
[2640.66s -> 2643.18s]  And so that's why I sort of,
[2643.22s -> 2646.58s]  starting using value function as an LLM initial,
[2646.58s -> 2648.58s]  I think it's a reasonable thing to do,
[2648.58s -> 2651.46s]  but obviously you wanna be able to improve this.
[2651.46s -> 2653.50s]  Here's just some examples, right?
[2653.50s -> 2654.54s]  You can basically say,
[2654.54s -> 2656.90s]  I recall seeing this exact item on the site,
[2656.90s -> 2658.94s]  help me find the most recent post of it.
[2658.94s -> 2661.72s]  I recall seeing it in either collectibles or in tick section,
[2661.72s -> 2662.56s]  right?
[2662.56s -> 2664.98s]  So the models would kind of like go the starting state,
[2664.98s -> 2666.26s]  it would sort of explore
[2666.26s -> 2670.48s]  and then eventually find that particular posting, right?
[2670.48s -> 2671.74s]  Or this one where I can say,
[2671.78s -> 2672.66s]  hey, I like this,
[2672.66s -> 2674.66s]  I need something like this in my apartment,
[2674.66s -> 2678.42s]  can you add one to my wishlist?
[2678.42s -> 2680.02s]  So the model kind of like have to go
[2680.02s -> 2683.22s]  and to sort of like search through different environments,
[2683.22s -> 2686.58s]  find this specific item and add it to your wishlist,
[2686.58s -> 2687.88s]  right?
[2687.88s -> 2690.42s]  It will be great if you have something like that, right?
[2690.42s -> 2691.46s]  You take a picture of something
[2691.46s -> 2693.22s]  and you basically tell your agent,
[2693.22s -> 2696.84s]  hey, go and find it on Amazon, Best Buy, wherever,
[2697.74s -> 2699.30s]  give me the best price for this, right?
[2699.54s -> 2702.48s]  And see where I can buy it.
[2703.70s -> 2704.92s]  Just as an example.
[2705.98s -> 2708.62s]  Now, in terms of limitations of this,
[2708.62s -> 2711.24s]  well, search is pretty slow, right?
[2712.40s -> 2717.22s]  So you obviously need a fast way of doing backtracking.
[2717.22s -> 2718.54s]  We sort of did the backtracking
[2718.54s -> 2719.98s]  in a relatively naive way.
[2719.98s -> 2722.14s]  You store all actions in a queue
[2722.14s -> 2724.50s]  and then take them again to get to the original state,
[2724.50s -> 2725.34s]  right?
[2725.34s -> 2726.94s]  So if you're taking 20 kind of like actions,
[2726.94s -> 2728.38s]  you store what you've done so far
[2728.42s -> 2731.42s]  and then to go back, you rerun that again.
[2731.42s -> 2734.26s]  So it's not very efficient, what we've done.
[2734.26s -> 2735.82s]  I think it's just requires sort of like
[2735.82s -> 2738.86s]  infrastructure work.
[2738.86s -> 2740.12s]  And the other interesting piece
[2740.12s -> 2742.24s]  is dealing with destructive actions, right?
[2742.24s -> 2745.50s]  Certain things on the web are very difficult to undo,
[2746.90s -> 2748.86s]  especially if you're operating on the real web
[2748.86s -> 2751.06s]  for testing these models.
[2751.06s -> 2753.82s]  You can order the item and then unorder it, right?
[2753.82s -> 2755.54s]  It's not like you can order the item
[2755.54s -> 2757.30s]  and then your model says, you know what?
[2757.34s -> 2759.58s]  That was actually the wrong order.
[2759.58s -> 2761.02s]  Let's try ordering something else.
[2761.02s -> 2762.28s]  You can't do that, right?
[2763.76s -> 2766.30s]  And so the other thing that you can't unfortunately do
[2766.30s -> 2768.42s]  in the real web is it's very hard
[2768.42s -> 2772.98s]  to do some form of learning in the real web
[2772.98s -> 2775.78s]  because anything that changes the state of the environment
[2775.78s -> 2777.98s]  is actually fairly difficult, right?
[2777.98s -> 2782.48s]  I can't go on United and start booking flights
[2782.48s -> 2784.48s]  from Pittsburgh to San Francisco
[2784.48s -> 2786.78s]  to learn how to book the flights, right?
[2786.78s -> 2788.54s]  Because if I'm sort of like exploring
[2788.54s -> 2790.40s]  and I'm kind of like saying, why don't I click here?
[2790.40s -> 2791.70s]  Well, maybe I should click here
[2791.70s -> 2794.18s]  and then maybe I should kind of like
[2794.18s -> 2796.22s]  try to book this flight and then maybe it's wrong
[2796.22s -> 2797.30s]  and try to book this other flight.
[2797.30s -> 2800.00s]  And so it becomes a little bit tricky to do
[2800.00s -> 2802.28s]  because essentially United will block you
[2802.28s -> 2804.04s]  or United will basically say,
[2804.04s -> 2806.74s]  oh, there's so many people are trying to book flights
[2806.74s -> 2808.34s]  from Pittsburgh to San Francisco.
[2808.34s -> 2811.54s]  Maybe we should like increase the prices, right?
[2811.54s -> 2812.66s]  So you have to be careful
[2812.66s -> 2816.12s]  how you actually operating in the real world.
[2817.08s -> 2818.58s]  So what's the current work?
[2818.58s -> 2821.00s]  Obviously search as a policy improvement function.
[2821.00s -> 2824.94s]  You can use search as a way of finding the correct trace
[2824.94s -> 2826.46s]  or the correct trajectory.
[2826.46s -> 2828.30s]  And you can use this potentially
[2828.30s -> 2830.44s]  either in reinforcement type of learning algorithm
[2830.44s -> 2835.44s]  or actually in SFT to try to fine tune on this.
[2836.14s -> 2837.96s]  Improving value function by fine tuning
[2837.96s -> 2838.80s]  instead of prompting.
[2838.80s -> 2841.62s]  So if you can prove the value function
[2841.62s -> 2845.64s]  by using Monte Carlo rollouts, you can do that.
[2846.64s -> 2848.36s]  Obviously exploring trades off
[2848.36s -> 2850.04s]  between improving baseline agent,
[2850.04s -> 2851.96s]  how much your base model has to be
[2851.96s -> 2854.52s]  versus how much more search you have to do
[2854.52s -> 2855.56s]  at inference time, right?
[2855.56s -> 2857.68s]  And today we sort of see this notion
[2857.68s -> 2860.20s]  of test time inference, scaling loss,
[2860.20s -> 2862.84s]  where, well, if I do search for more,
[2862.84s -> 2864.40s]  I can probably get a better answer.
[2864.40s -> 2865.92s]  And I think that it's true,
[2865.92s -> 2868.48s]  but it's sort of both models need to improve, right?
[2868.48s -> 2871.08s]  Your base model needs to be better
[2871.08s -> 2873.88s]  and also search needs to be more efficient.
[2874.40s -> 2877.18s]  And obviously, one of the biggest questions,
[2877.18s -> 2880.60s]  if we don't have a simulator of the web environment, right?
[2880.60s -> 2882.22s]  How can we collect data at scale?
[2882.22s -> 2885.72s]  And that's one of the interesting problems
[2885.72s -> 2887.92s]  that we also started looking at.
[2887.92s -> 2891.30s]  What can we do and how we can collect the data at scale?
[2891.30s -> 2894.88s]  Because the interesting thing about agentic models
[2894.88s -> 2897.44s]  in general is that it's the kind of data
[2897.44s -> 2899.64s]  that's very difficult to find on the web, right?
[2899.64s -> 2902.24s]  So what we see with existing LLMs is that,
[2902.24s -> 2906.32s]  I can crawl the web, I can scrape images and HTML,
[2906.32s -> 2907.80s]  and then I can pre-train these model
[2907.80s -> 2910.56s]  just doing the next talk and prediction, right?
[2910.56s -> 2913.22s]  For agentic work, it's very difficult, right?
[2913.22s -> 2914.50s]  It's very difficult for me to say,
[2914.50s -> 2916.92s]  hey, give me a whole bunch of examples
[2916.92s -> 2919.24s]  and show me how am I should be booking my flight
[2919.24s -> 2922.28s]  from Pittsburgh to San Francisco, right?
[2922.28s -> 2924.84s]  Or show me in this setting, you know,
[2924.84s -> 2927.64s]  I like like, you know, hey, I like something like this,
[2927.64s -> 2929.04s]  add me to my wishlist, right?
[2929.04s -> 2931.74s]  It's not like you can find a lot of these examples
[2931.74s -> 2936.72s]  on the web and, you know, of examples of people
[2936.72s -> 2938.98s]  showing you how to solve these tasks, right?
[2938.98s -> 2942.92s]  So this notion of giving the task and the full trajectory
[2942.92s -> 2946.16s]  of how you should take actions and solve the task
[2946.16s -> 2949.70s]  is actually very limited data that we have today, right?
[2949.70s -> 2952.20s]  In fact, we don't have any of that data.
[2952.20s -> 2954.72s]  A lot of companies, they essentially collecting this data
[2954.72s -> 2957.12s]  in-house by asking people to, you know,
[2957.12s -> 2960.88s]  solve these tasks and do like massive annotations.
[2960.88s -> 2962.68s]  So the question for us was,
[2962.68s -> 2964.86s]  how can we collect the data at scale?
[2964.86s -> 2966.56s]  And that gives me to the third point,
[2966.56s -> 2971.56s]  which is how can we at least try thinking about
[2971.84s -> 2972.94s]  what we can do here?
[2974.28s -> 2976.60s]  So as I've mentioned before,
[2976.60s -> 2979.88s]  agents suffer from a data problem, right?
[2979.88s -> 2982.38s]  And you can see the gap is still pretty big.
[2982.86s -> 2986.58s]  And when we think about LLMs,
[2986.58s -> 2988.22s]  the way that we training them today,
[2988.22s -> 2990.58s]  a lot of times they often trained online.
[2990.58s -> 2992.06s]  I just collect bunch of data
[2993.42s -> 2996.36s]  and then I deploy them as zero shots as agents, right?
[2996.36s -> 2998.06s]  And then, you know, I collect a lot of data.
[2998.06s -> 3000.34s]  I do some form of supervised fine tuning.
[3001.24s -> 3002.90s]  At least that's what's happening in academia.
[3002.90s -> 3005.10s]  And then, you know, I try to deploy them
[3005.10s -> 3007.98s]  and see how they work, right?
[3007.98s -> 3012.98s]  The question is, can we somehow go on the real web
[3013.20s -> 3015.68s]  and generate synthetic tasks
[3015.68s -> 3019.90s]  to unlock this large scale training of agents, okay?
[3019.90s -> 3024.82s]  And, you know, the question is, you know,
[3024.82s -> 3027.94s]  how can we, again, get these models
[3027.94s -> 3029.66s]  to generate something synthetic
[3029.66s -> 3031.92s]  and actually, you know, build something
[3031.92s -> 3034.30s]  that we can train on and improve our agents
[3034.30s -> 3036.70s]  without human intervention
[3036.70s -> 3039.52s]  or without actually, you know, task generated by humans
[3039.52s -> 3043.36s]  because it's fairly expensive to ask humans
[3043.36s -> 3046.16s]  to generate or, you know, create those tasks.
[3047.54s -> 3050.10s]  So one of the things that we've been trying to build
[3050.10s -> 3051.26s]  is we've been trying to build
[3051.26s -> 3053.26s]  this internet scale training for agents
[3053.26s -> 3058.14s]  that we call Insta, which is, you know,
[3058.14s -> 3062.44s]  the idea here is we using llama models
[3062.44s -> 3066.90s]  to generate and verify synthetic agentic tasks.
[3066.90s -> 3070.20s]  So we're thinking about three stages, right?
[3070.20s -> 3073.24s]  There is a task generation stage, right?
[3073.24s -> 3074.66s]  For example, I can ask the model to say,
[3074.66s -> 3076.56s]  find me a code base for generating images
[3076.56s -> 3079.50s]  with flex point one, right?
[3081.06s -> 3081.90s]  That's the first task.
[3081.90s -> 3083.52s]  I'll show you examples of how we can do that.
[3083.52s -> 3086.20s]  The second task is evaluation.
[3086.20s -> 3088.24s]  Actually executing this task
[3088.24s -> 3090.44s]  and then trying to see whether, you know,
[3090.44s -> 3091.92s]  the model solved the task.
[3092.92s -> 3095.48s]  And then the third step is actually collection big,
[3096.84s -> 3098.60s]  basically collecting it at scale.
[3098.60s -> 3100.10s]  But you can think of this environment
[3100.10s -> 3101.94s]  is that the model proposes tasks,
[3101.94s -> 3103.50s]  the model executes those tasks,
[3103.50s -> 3106.24s]  the model then evaluates those tasks.
[3106.24s -> 3108.70s]  And then, you know, if it successfully says,
[3108.70s -> 3110.48s]  yep, I propose the task,
[3110.48s -> 3112.52s]  I executed this task on the real web,
[3112.52s -> 3115.28s]  I evaluate it, I think I've solved the task,
[3115.28s -> 3117.64s]  then that becomes a very useful data
[3117.68s -> 3121.44s]  for training our agents.
[3121.44s -> 3124.28s]  Okay, so let's see how we can do.
[3126.12s -> 3128.36s]  So for example, given the web domain,
[3128.36s -> 3131.40s]  for example, you know, there's a domain,
[3131.40s -> 3133.68s]  just random domain, Mercy Ferries.
[3133.68s -> 3136.36s]  It's a website in the UK.
[3136.36s -> 3139.44s]  And we can ask the system to propose realistic task
[3139.44s -> 3141.50s]  that an average user could complete in one session.
[3141.50s -> 3142.70s]  So there's a certain system prompt
[3142.70s -> 3146.20s]  that we asking the model to generate the task.
[3146.60s -> 3150.36s]  And what's interesting that if you look at Llama 70b 3.1,
[3150.36s -> 3152.60s]  I think we also training on Llama 3.3,
[3152.60s -> 3154.68s]  which is actually better, has better results.
[3154.68s -> 3157.36s]  So these models, you know, continue improving.
[3157.36s -> 3158.84s]  So if I ask the model to describe,
[3158.84s -> 3160.28s]  what is this website about?
[3160.28s -> 3161.92s]  It's actually pretty good.
[3161.92s -> 3163.18s]  You know, it sort of says, well,
[3163.18s -> 3165.04s]  this particular website is official website
[3165.04s -> 3167.36s]  for famous Mercy Ferries service
[3167.36s -> 3169.56s]  in Liverpool, England and so forth.
[3169.56s -> 3172.80s]  Certain things you can do, you can plan a journey,
[3172.80s -> 3175.72s]  you know, you can book tickets and sort of, you know,
[3176.16s -> 3177.94s]  and sort of gives you ideas
[3177.94s -> 3179.80s]  of what you can do with this website.
[3180.76s -> 3182.72s]  And so that gave us this notion of,
[3182.72s -> 3185.12s]  if the model understands what this website is about,
[3185.12s -> 3189.00s]  maybe I can ask it to actually generate the task.
[3189.00s -> 3191.54s]  And what we found is that, you know,
[3191.54s -> 3195.16s]  we can scale it across many, many different websites
[3195.16s -> 3196.76s]  from common crawl.
[3196.76s -> 3199.52s]  I think we started with about million websites
[3199.52s -> 3200.88s]  and we started thinking about like,
[3200.88s -> 3203.32s]  what kind of tasks these models can generate?
[3203.60s -> 3206.64s]  A lot of tasks actually involve
[3206.64s -> 3209.02s]  some form of information retrieval, some sort of search.
[3209.02s -> 3211.92s]  You're finding the right ticket information,
[3211.92s -> 3215.56s]  you're finding booking, you know, opening hours.
[3215.56s -> 3219.44s]  You find sort of specific information on,
[3219.44s -> 3221.16s]  you know, a particular topic, right?
[3222.12s -> 3224.76s]  But crucially, we do not modify
[3224.76s -> 3226.04s]  the state of the internet.
[3226.04s -> 3230.16s]  So that was one of the sort of settings for us
[3230.16s -> 3232.96s]  where we asking the model to come up with the task
[3233.48s -> 3235.52s]  that don't modify the state of the environment.
[3235.52s -> 3238.32s]  So for example, booking something we can do,
[3239.56s -> 3241.90s]  or clicking on something that actually changes
[3241.90s -> 3244.64s]  the state of the environment, we can do.
[3245.56s -> 3247.88s]  This specifically was done, you know,
[3247.88s -> 3250.82s]  to avoid any sort of complications of us being blocked.
[3250.82s -> 3252.68s]  And as I mentioned before, you know,
[3252.68s -> 3255.68s]  we can go on, you know, united.com or booking.com
[3255.68s -> 3258.94s]  and start like, you know, running a lot of tasks,
[3258.94s -> 3262.00s]  like booking a lot of hotels randomly, right?
[3262.00s -> 3263.58s]  So we can only navigate to these websites,
[3263.58s -> 3268.50s]  but we actually cannot change the state of the environment.
[3269.52s -> 3271.48s]  What we found is that a lot of tasks
[3271.48s -> 3274.40s]  that the models actually come up with are diverse
[3274.40s -> 3277.64s]  and many require multiple sets of reasoning, right?
[3277.64s -> 3281.24s]  So for example, you know, if I go to fonts.adobe.com,
[3281.24s -> 3283.56s]  some of the generated task is browse fonts suitable
[3283.56s -> 3285.44s]  for a children's book.
[3285.44s -> 3287.52s]  As I have to understand like what makes a font suitable
[3287.52s -> 3289.04s]  for a children's book, right?
[3290.00s -> 3295.00s]  A lot of tasks can identify facts that's likely to contain.
[3295.12s -> 3298.98s]  So for example, if I'm going to ancient-symbols.com,
[3298.98s -> 3301.28s]  you know, the generated task would be look up the meaning
[3301.28s -> 3305.26s]  of the word OM symbol in ancient cultures, right?
[3305.26s -> 3307.08s]  So if you kind of like, you know,
[3307.08s -> 3309.52s]  you have to go on this website, this is the task,
[3309.52s -> 3311.12s]  and I have to crawl through this website
[3311.12s -> 3312.48s]  to actually find what's the meaning
[3312.48s -> 3314.04s]  of that particular symbol.
[3315.04s -> 3319.44s]  Or I can sort of, you know, go to this particular
[3320.92s -> 3323.48s]  obscure Scottish design studio
[3323.48s -> 3325.72s]  and ask you the latest fabric designs
[3325.72s -> 3328.12s]  by, you know, by this particular studio, right?
[3328.12s -> 3329.60s]  So I end up on this website
[3329.60s -> 3333.92s]  and I have to find the latest designs, fabric designs.
[3333.92s -> 3336.20s]  And kind of, this is kind of like how it looks like.
[3336.20s -> 3338.84s]  I actually have to end up on this particular webpage
[3338.84s -> 3341.84s]  because that lists the latest fabric designs
[3342.64s -> 3344.62s]  by that particular studio, right?
[3344.62s -> 3347.26s]  So these tasks are grounded even for sites
[3347.26s -> 3350.16s]  in the tail of the data distributions, right?
[3350.16s -> 3353.68s]  So these are kind of like, we want it to go for breadth,
[3353.68s -> 3356.68s]  not necessarily to kind of, you know, only cover,
[3356.68s -> 3359.96s]  you know, 100 most commonly visited websites,
[3359.96s -> 3362.06s]  but also going to these sort of, you know,
[3362.06s -> 3365.56s]  which gives us the diversity of the environments
[3365.56s -> 3370.56s]  and different websites and different generated tasks, okay?
[3372.04s -> 3375.60s]  So that's kind of, you know, the first step,
[3375.60s -> 3378.04s]  trying to generate the tasks, right?
[3379.16s -> 3381.92s]  Now the second state is, okay,
[3383.80s -> 3387.32s]  how do we know when these tasks are solved, right?
[3387.32s -> 3390.28s]  And that gives us the task evaluation part.
[3390.28s -> 3393.20s]  And the way we do this is we basically say, okay,
[3394.08s -> 3396.96s]  if we're given the task, generated task,
[3396.96s -> 3399.92s]  we can execute this task using the current model.
[3399.92s -> 3401.92s]  Let's say you have a GPT model,
[3401.92s -> 3403.68s]  or you have your llama model.
[3403.68s -> 3407.10s]  In this case, it was a llama model that we're using.
[3407.10s -> 3408.80s]  You observe a sequence of actions
[3408.80s -> 3410.72s]  and the last observation,
[3410.72s -> 3412.56s]  and you now estimate the probability
[3412.56s -> 3414.86s]  of a task being successful, right?
[3414.86s -> 3416.96s]  So you're basically asking the model,
[3416.96s -> 3420.24s]  given the last state and the sequence of actions,
[3420.24s -> 3421.66s]  you're asking it to estimate
[3421.66s -> 3423.54s]  the probability of the success.
[3423.54s -> 3425.36s]  This is, again, the same idea
[3425.36s -> 3426.58s]  as using large language model.
[3426.58s -> 3428.62s]  As a judge, you know,
[3428.62s -> 3431.06s]  here we actually evaluating the full trajectory,
[3431.06s -> 3433.32s]  but you can think of it as, you know,
[3433.32s -> 3436.34s]  in the previous part, when we were looking at the search,
[3436.34s -> 3438.30s]  we essentially were using the same piece,
[3438.30s -> 3440.90s]  but only evaluating partial trajectories
[3440.90s -> 3442.98s]  to sort of figure out like what we should explore
[3442.98s -> 3444.22s]  and what we shouldn't explore.
[3444.22s -> 3446.74s]  Here, we actually trying to evaluate the full trajectory,
[3446.74s -> 3448.80s]  but obviously you can combine search
[3448.80s -> 3449.84s]  with this technique as well.
[3449.84s -> 3451.50s]  So you can kind of search around
[3451.50s -> 3455.30s]  and sort of try to find the best outcome.
[3455.30s -> 3457.26s]  And you prompt llama to rate the confidence
[3457.26s -> 3460.06s]  of the task itself, you know, from zero to one.
[3461.22s -> 3466.22s]  And what we found is that out of, for example,
[3466.70s -> 3469.26s]  out of 150,000 tasks, about, you know,
[3469.26s -> 3473.84s]  15% are rated as success with high confidence by llama,
[3473.84s -> 3475.86s]  roughly 22,000 tasks.
[3475.86s -> 3478.12s]  We actually did verify, you know,
[3478.12s -> 3481.74s]  how good using llama as a judge.
[3481.74s -> 3485.58s]  And I think that in terms of the success,
[3485.58s -> 3487.54s]  it was about 90%, right?
[3487.54s -> 3490.26s]  So for example, you know, when the model says,
[3490.26s -> 3492.62s]  I'm pretty sure I've solved the task,
[3492.62s -> 3493.88s]  with human evaluations,
[3493.88s -> 3497.78s]  we're seeing close to 90% accuracy among those ones.
[3497.78s -> 3499.62s]  So it basically means whenever llama says,
[3499.62s -> 3501.18s]  yes, I've solved the task,
[3501.18s -> 3503.62s]  90% of the time it actually solved the task,
[3503.62s -> 3505.46s]  10% of the time, no, it didn't solve the task.
[3505.46s -> 3508.34s]  So, you know, these verifiers are not perfect,
[3508.34s -> 3509.54s]  but they're pretty decent
[3509.54s -> 3511.18s]  in terms of approximately telling you
[3511.18s -> 3514.66s]  whether you solved the task or not, right?
[3514.66s -> 3516.46s]  So that kind of like gives you this notion
[3516.46s -> 3521.46s]  of showing that you've successfully found the task,
[3522.86s -> 3525.26s]  executed it, and then verified it.
[3525.26s -> 3527.74s]  Let me give you sort of visual representation
[3527.74s -> 3529.22s]  of what that looks like.
[3530.70s -> 3532.62s]  So, you know, on a different project,
[3532.62s -> 3534.98s]  we have a project where we're working with ecologists
[3534.98s -> 3537.60s]  on sort of identifying invasive plants
[3538.70s -> 3541.10s]  in different environments.
[3542.10s -> 3545.26s]  And we basically thought, well, okay,
[3545.26s -> 3549.74s]  let's look at this website, Invasive Plants Atlas,
[3549.74s -> 3552.90s]  and prompt the model to generate a task
[3552.90s -> 3554.50s]  and see if the model can solve the task.
[3554.50s -> 3556.10s]  So the model basically generates a task,
[3556.10s -> 3559.54s]  find invasive plant species native to North America, okay?
[3559.54s -> 3562.02s]  So that's more like information extraction.
[3562.02s -> 3563.70s]  And the agent response is,
[3563.70s -> 3566.02s]  to find an invasive plant species in North America,
[3566.02s -> 3568.90s]  I will first click on link all species
[3568.90s -> 3570.42s]  to view the list of all species.
[3570.46s -> 3573.90s]  Okay, so it takes, and based on this information
[3573.90s -> 3575.62s]  and clicks on all species, right?
[3575.62s -> 3577.78s]  And that's what the action looks like.
[3577.78s -> 3581.46s]  It's a little JSON that you have an action key click,
[3581.46s -> 3584.14s]  you have an action arguments that can go in
[3584.14s -> 3586.26s]  and you have a target element ID,
[3586.26s -> 3589.32s]  the ID that you associated with that particular click.
[3591.10s -> 3592.54s]  Then it basically says,
[3592.54s -> 3595.22s]  to find invasive plant species native to North America,
[3595.22s -> 3598.86s]  you know, I will first click on the link home
[3598.86s -> 3601.46s]  and because it's trying to go to the sources
[3601.46s -> 3605.50s]  and it sort of misses the point
[3605.50s -> 3608.94s]  because, you know, there is sources here, right?
[3608.94s -> 3610.82s]  But it's actually in system going home
[3610.82s -> 3612.02s]  and then to find the sources.
[3612.02s -> 3613.14s]  So it's sort of misread,
[3613.14s -> 3615.42s]  so it made a mistake in this case, right?
[3616.26s -> 3618.70s]  Since the link to sources is not on the current webpage,
[3618.70s -> 3620.42s]  but it is, so it's making a mistake,
[3620.42s -> 3621.90s]  I will first click on the home
[3621.90s -> 3623.62s]  and go back to the main page.
[3623.62s -> 3625.50s]  So it goes back to the main page
[3625.50s -> 3629.62s]  and then it sort of identifies the sources, right?
[3629.62s -> 3632.02s]  So it kind of, you know, clicks on the sources.
[3633.26s -> 3636.14s]  It actually gets to the right piece
[3636.14s -> 3638.46s]  to find invasive plants native to North America,
[3638.46s -> 3640.62s]  I will first click on F on the A
[3640.62s -> 3643.14s]  under the native French taxonomic references.
[3643.14s -> 3645.38s]  So it sort of execute pieces
[3645.38s -> 3650.38s]  and it does, you know, clicks on the correct element.
[3650.40s -> 3653.30s]  And then once it gets to the correct element,
[3653.30s -> 3654.70s]  it then basically says,
[3654.70s -> 3659.70s]  I need to sort based on US, you know,
[3659.86s -> 3662.00s]  plants that are native to the US,
[3662.00s -> 3664.10s]  gets it in the JSON format
[3664.10s -> 3667.02s]  and then gives you the answer, right?
[3667.02s -> 3669.22s]  Since the list is already sorted by US Navativity
[3669.22s -> 3670.70s]  by Senate order, that's it.
[3670.70s -> 3673.92s]  I can find, there's the first like 165 plant species
[3673.92s -> 3675.60s]  that are native to North America, right?
[3675.60s -> 3677.70s]  So this gives you the list
[3677.70s -> 3679.84s]  and the answer is basically I give you the webpage
[3679.84s -> 3682.62s]  and I tell them the first 165 plant species on the list
[3682.66s -> 3684.98s]  invasive plant species native to North America, right?
[3684.98s -> 3688.78s]  So in terms of like me finding information seeking,
[3688.78s -> 3692.78s]  again, this was completely synthetically generated task
[3692.78s -> 3696.14s]  where the model proposed the task.
[3696.14s -> 3700.58s]  It's now executed the task, even though it made a mistake
[3700.58s -> 3702.90s]  and then it gave you the action.
[3702.90s -> 3704.30s]  And in this case,
[3705.30s -> 3707.04s]  despite sort of like reasoning,
[3707.04s -> 3708.14s]  some of the reasoning failures
[3708.14s -> 3709.34s]  because it clicked on the wrong thing,
[3709.34s -> 3710.60s]  but then it recovered.
[3711.24s -> 3713.28s]  It found the target information.
[3713.28s -> 3715.24s]  And in this case, LAMA verify evaluates
[3715.24s -> 3718.36s]  this trajectory successful with confidence one, right?
[3718.36s -> 3720.64s]  And again, whatever it does, this verification,
[3720.64s -> 3722.92s]  it's about 90% accurate, maybe close to,
[3722.92s -> 3724.56s]  maybe 85, 90% accurate
[3724.56s -> 3727.60s]  when we sort of did the studies, human studies.
[3729.40s -> 3731.12s]  So that sort of gives you, you know,
[3731.12s -> 3734.72s]  an interesting synthetic generation, right?
[3735.96s -> 3739.60s]  Where you proposing the task, you executing this task
[3739.60s -> 3742.00s]  and then you verifying, did you solve the task or not?
[3742.00s -> 3745.78s]  And again, only 14% or 15% of the tasks
[3745.78s -> 3748.04s]  that the model proposed and executes,
[3748.04s -> 3751.00s]  only 15% of them, you know, the model basically says,
[3751.00s -> 3752.74s]  yes, I think I solved the task.
[3752.74s -> 3755.50s]  85% of them, you can solve the task, right?
[3755.50s -> 3758.76s]  So, but that's okay because it's all done automatically.
[3758.76s -> 3761.76s]  There is no human in the loop here.
[3761.76s -> 3763.26s]  Let me show you some examples,
[3763.26s -> 3765.28s]  other examples of what the model does.
[3765.28s -> 3766.36s]  So here's the example,
[3766.36s -> 3769.40s]  finding the opening hours of la Sagare de Familia, right?
[3770.04s -> 3772.68s]  It's a fairly famous church in Barcelona.
[3772.68s -> 3774.94s]  So it sort of, you know, proposes the task,
[3774.94s -> 3779.64s]  it browses the web, it finds and it finds the answer.
[3779.64s -> 3780.48s]  Right?
[3780.48s -> 3782.30s]  So, you know, so again, you know,
[3782.30s -> 3785.52s]  this is the task that it proposes, it goes to the website,
[3785.52s -> 3788.96s]  it actually finds, you know, la Sagare de Familia,
[3788.96s -> 3790.52s]  it clicks it, it finds,
[3790.52s -> 3792.30s]  and it basically from the table finds
[3792.30s -> 3793.60s]  what the right answer is.
[3793.60s -> 3794.52s]  Well, find the information
[3794.52s -> 3797.24s]  on the European Union's climate action policies.
[3797.24s -> 3798.88s]  So it goes to European Union Commission,
[3799.20s -> 3801.72s]  it crawls the web, and then, you know,
[3801.72s -> 3805.06s]  this is a success where it actually finds the documents
[3805.06s -> 3808.44s]  related to the climate action progress
[3808.44s -> 3810.72s]  or climate action policies, right?
[3810.72s -> 3814.92s]  And again, these tasks are completely created
[3814.92s -> 3818.54s]  by model proposing what the task should be,
[3818.54s -> 3820.38s]  model executing this task,
[3820.38s -> 3821.76s]  and then the model verifying
[3821.76s -> 3825.26s]  whether it successfully computed the task or not, right?
[3825.26s -> 3827.34s]  So we sort of went through these two stages.
[3827.34s -> 3831.34s]  And again, I'm not saying that that's a perfect setting.
[3831.34s -> 3834.70s]  I think that, you know, if you incorporate search,
[3834.70s -> 3836.48s]  if you have better models,
[3837.42s -> 3839.82s]  and then you sort of, you know, iterated multiple times,
[3839.82s -> 3843.86s]  I think the quality of generation of these tasks
[3843.86s -> 3846.98s]  could improve substantially.
[3846.98s -> 3849.48s]  So let me talk a little bit about the data collection,
[3849.48s -> 3850.32s]  right?
[3850.32s -> 3852.06s]  So what happens with the data collection?
[3852.06s -> 3854.38s]  Now we can scale up the data collection.
[3855.18s -> 3858.10s]  So we've used the common crawl page rank
[3858.10s -> 3859.76s]  to find the most important websites.
[3859.76s -> 3862.52s]  We start with the top 1 million web pages.
[3864.42s -> 3869.42s]  We filtered it down to about 150,000 live websites
[3869.82s -> 3872.18s]  by, you know, filtering harmful content.
[3872.18s -> 3873.14s]  So we're prompting the model.
[3873.14s -> 3875.70s]  So if we think that there is a harmful content
[3875.70s -> 3878.22s]  on the website, we basically ignore it.
[3878.22s -> 3880.34s]  So we're about 97% actually pretty high
[3880.34s -> 3882.66s]  in terms of detecting and filtering harmful content.
[3882.66s -> 3885.06s]  This is using Llama models.
[3885.06s -> 3890.06s]  We are about 89% success rate in generating feasible tasks
[3890.18s -> 3893.22s]  and about 80, so it's like 90% in generating feasible
[3893.22s -> 3896.16s]  tasks, which basically means that, you know,
[3897.28s -> 3899.98s]  when we're verifying whether the task is successful
[3899.98s -> 3904.66s]  or not, we 89% and 82% accuracy in judging
[3904.66s -> 3905.74s]  successful task completion.
[3905.74s -> 3908.80s]  Sorry, that's the one where 82% whether the task
[3908.80s -> 3910.92s]  is successfully completed or not.
[3911.92s -> 3916.92s]  And so, and again, we sort of went through 150,000
[3917.04s -> 3919.92s]  live websites and then we, you know, attempting it
[3919.92s -> 3922.08s]  and verifying it and sort of, you know,
[3922.08s -> 3924.80s]  creating data based on whether we successfully
[3924.80s -> 3927.12s]  generate the task and whether we successfully executed
[3927.12s -> 3929.48s]  and then verified success.
[3929.48s -> 3932.44s]  What's interesting is that we found that on sort of
[3932.44s -> 3935.22s]  toyish examples and small examples, mind the web links,
[3935.22s -> 3940.22s]  these are sort of some of the datasets that people use.
[3940.30s -> 3943.42s]  We found that trading on synthetic and human demonstration
[3943.42s -> 3946.18s]  scale faster than just trading on human demonstrations.
[3947.10s -> 3950.54s]  Right, so actually if you're mixing what humans collected
[3950.54s -> 3953.10s]  versus if you're mixing synthetic and humans,
[3953.10s -> 3955.42s]  we can sort of see improvements.
[3955.42s -> 3958.02s]  We also see that adding synthetic data improves
[3958.02s -> 3963.02s]  step accuracy by, you know, by, you know,
[3963.94s -> 3965.60s]  certain numbers, so that's good.
[3965.60s -> 3970.60s]  We also found that if you only use human annotations,
[3970.64s -> 3973.48s]  human annotations do struggle with generalization
[3973.48s -> 3975.60s]  because a lot of times what actually ended up happening
[3975.60s -> 3977.84s]  is that with human annotations are typically done
[3977.84s -> 3982.84s]  on a small subset of highly visited, you know, websites
[3983.36s -> 3986.38s]  and the ability to generalize to, you know,
[3986.38s -> 3987.88s]  the tail of the distribution,
[3987.88s -> 3990.32s]  that's where synthetic data really helps us
[3990.32s -> 3991.94s]  because it can help us generalize
[3991.94s -> 3994.16s]  to the tail of the distribution, right?
[3994.16s -> 3997.76s]  Where it's very difficult for humans to collect the data.
[3997.76s -> 4000.04s]  Obviously, the ultimate choice would be
[4000.04s -> 4003.08s]  to get humans to annotate the entire web.
[4003.08s -> 4004.60s]  That would be the best
[4004.60s -> 4007.40s]  because then we can just do imitation learning.
[4007.40s -> 4009.60s]  But we do find that sort of, you know,
[4009.60s -> 4011.20s]  the ability to crawl the web
[4011.20s -> 4013.34s]  and look at the stale distribution,
[4013.34s -> 4017.52s]  we do see improvements in generalization.
[4017.52s -> 4021.44s]  Now there are 385 million unique domains, right?
[4021.44s -> 4023.86s]  Suggesting maybe another 1,000X more data
[4024.42s -> 4026.26s]  that could be available by scaling further, right?
[4026.26s -> 4029.18s]  We were constrained by compute and academic resources
[4029.18s -> 4031.02s]  when we did this work.
[4031.02s -> 4033.10s]  And of course, there is also sort of this notion
[4033.10s -> 4035.42s]  of moving towards online reinforcement learning.
[4035.42s -> 4036.74s]  So you can think about settings
[4036.74s -> 4039.82s]  where you sort of run this procedure, right?
[4039.82s -> 4041.94s]  You collect the synthetic data
[4041.94s -> 4043.94s]  and then you update the model and do it again.
[4043.94s -> 4045.58s]  So you can sort of like, you know,
[4045.58s -> 4048.14s]  do it in online fashion, right?
[4048.14s -> 4050.52s]  You crawl the web, you generate these tasks,
[4050.52s -> 4052.94s]  you try to solve some of these tasks,
[4052.94s -> 4054.94s]  you update the model parameters and do that again.
[4054.94s -> 4056.46s]  So if you have an online,
[4056.46s -> 4058.54s]  and that could be an online reinforcement learning,
[4058.54s -> 4061.32s]  but done at scale, at the internet scale,
[4061.32s -> 4064.74s]  I think these models would improve significantly.
[4064.74s -> 4067.30s]  And of course, it's very difficult to do that
[4067.30s -> 4070.78s]  on the real web because it's very hard to, you know,
[4070.78s -> 4071.60s]  change, you know,
[4071.60s -> 4074.74s]  you can't change the state of the environment.
[4074.74s -> 4078.22s]  So you have to be careful how you actually scaling up,
[4078.22s -> 4082.70s]  scaling it up when you go to the real world
[4082.70s -> 4084.36s]  or the real web, okay?
[4085.58s -> 4087.38s]  Let me just in the last 10 minutes,
[4087.38s -> 4089.70s]  and I'll leave the room for questions.
[4089.70s -> 4092.84s]  I wanted to sort of point out that this notion
[4092.84s -> 4097.50s]  of agentic environment is also applicable
[4097.50s -> 4102.38s]  to the physical agents or robots in general, right?
[4102.38s -> 4104.78s]  So we've also kind of like very parallel effort.
[4104.78s -> 4108.26s]  We basically thought, okay, these AI agents
[4108.26s -> 4111.06s]  sort of have the same notion,
[4111.06s -> 4112.82s]  whether we're operating on the web
[4112.82s -> 4114.06s]  and taking actions on the web,
[4114.06s -> 4116.28s]  or whether we actually have a physical agent,
[4116.28s -> 4119.40s]  like a robot that takes actions in the real world, right?
[4119.40s -> 4121.14s]  So for example, you know, you can think about,
[4121.14s -> 4122.34s]  you're observing the data,
[4122.34s -> 4124.62s]  which is could be the image plus maybe the depths.
[4124.62s -> 4126.42s]  You do some form of semantic segmentation
[4126.42s -> 4127.82s]  to understand the environment.
[4127.82s -> 4130.26s]  You have an objective, you generate a high level plan,
[4130.26s -> 4132.14s]  and then you generate the low level actions,
[4132.14s -> 4134.62s]  like interacting with the actual environment.
[4134.62s -> 4137.70s]  So we have this work on planning,
[4137.70s -> 4140.34s]  learning what we call plan, sequence and learn,
[4140.34s -> 4141.86s]  where the idea is large language model
[4141.86s -> 4145.96s]  basically gives you a sequence of high level plan,
[4145.96s -> 4147.10s]  what you need to do.
[4147.10s -> 4149.28s]  You have a sequencing or parsing module
[4149.28s -> 4152.54s]  that basically understands the environment, sequences is,
[4152.54s -> 4154.58s]  and then we have a low level action,
[4154.58s -> 4156.18s]  which we learn with reinforcement learning,
[4156.18s -> 4157.94s]  which the little policy actually learns
[4157.94s -> 4160.34s]  how to take a particular action, right?
[4160.34s -> 4162.30s]  So very much in flavor,
[4162.30s -> 4165.02s]  very similar to what the web agents are doing,
[4165.02s -> 4167.64s]  but now we're actually interacting in the real world.
[4167.64s -> 4170.14s]  So for example, a planning module can say,
[4170.98s -> 4174.54s]  okay, here's the task, get me,
[4174.54s -> 4176.84s]  I'm trying to kind of like put the silver knot
[4176.84s -> 4179.38s]  in the silver bag and the gold knot in the gold bag,
[4179.38s -> 4181.42s]  and then give me the simple plan to solve this task.
[4181.42s -> 4185.30s]  And so the LLN basically produces a fairly simple task
[4185.30s -> 4187.96s]  of how I should solve it.
[4187.96s -> 4189.78s]  We have a sequencing model,
[4189.78s -> 4193.50s]  which looks at the observation, there's a depth,
[4194.68s -> 4197.62s]  we do segmentation and sort of a little bit
[4197.62s -> 4198.46s]  of a projection.
[4198.50s -> 4201.90s]  Like have some form of 3D representation of the environment.
[4201.90s -> 4203.88s]  And then it goes through the inverse kinematic
[4203.88s -> 4204.90s]  and we have a motion planner,
[4204.90s -> 4207.18s]  but you can think of this as sort of like, again,
[4207.18s -> 4208.74s]  understanding the environment
[4208.74s -> 4212.30s]  and doing a little bit of motion planning.
[4212.30s -> 4214.86s]  And then the low level action module
[4214.86s -> 4216.80s]  actually learns the local policy, right?
[4216.80s -> 4219.58s]  So here you have reinforcement learning for interactions.
[4219.58s -> 4220.80s]  You kind of like locally learning
[4220.80s -> 4221.98s]  how to interact with them,
[4221.98s -> 4224.50s]  much like when you're clicking on a particular element.
[4224.50s -> 4227.74s]  Here we're actually learning how to control our joint
[4228.06s -> 4232.28s]  angles so that we can accomplish a low level task, right?
[4232.28s -> 4233.86s]  And so this is how it sort of looks like
[4233.86s -> 4237.62s]  where a local model is actually learning how to,
[4237.62s -> 4238.46s]  with reinforcement learning,
[4238.46s -> 4240.98s]  it's actually learning how to interact
[4240.98s -> 4241.94s]  with the environment.
[4241.94s -> 4244.02s]  And so kind of like in the full pipeline,
[4244.02s -> 4245.78s]  very much in similar spirit,
[4245.78s -> 4248.86s]  you have a planning model that plans,
[4251.26s -> 4252.90s]  gives you high level plan.
[4252.90s -> 4254.46s]  For each high level plan,
[4254.46s -> 4257.66s]  you executing this low level actions
[4258.54s -> 4261.14s]  where you basically have pose estimation, motion planning,
[4261.14s -> 4263.82s]  a little bit of reinforcement learning to take the action.
[4263.82s -> 4267.06s]  And then, you have this low level control
[4267.06s -> 4269.50s]  that actually controls low level actions
[4269.50s -> 4270.70s]  via reinforcement learning, right?
[4270.70s -> 4272.38s]  And then you proceed and that's just the first step
[4272.38s -> 4274.42s]  and you go to the next and then you go to the next
[4274.42s -> 4279.42s]  and sort of execute that according to the plan and so forth.
[4279.78s -> 4283.66s]  And we found that these sort of models,
[4283.66s -> 4285.14s]  work reasonably well,
[4285.18s -> 4288.58s]  PSL solves about 25 long horizon robotic tasks
[4288.58s -> 4290.86s]  across, in this case, four benchmarks.
[4292.02s -> 4295.14s]  We, about 85% success rate.
[4295.14s -> 4297.58s]  We also tried extending this
[4297.58s -> 4301.34s]  to the actual real environment.
[4301.34s -> 4305.38s]  So here's the, I give it a task, put mouse in the drawer.
[4305.38s -> 4307.78s]  So the model basically generates the plan.
[4307.78s -> 4309.38s]  And again, it looks at the environment,
[4309.38s -> 4310.34s]  parses the environment
[4310.34s -> 4312.54s]  and then executes low level actions, right?
[4313.54s -> 4318.22s]  And it sort of does a lot of interesting things.
[4318.22s -> 4321.50s]  It can, you know, but the point I do want to make here
[4321.50s -> 4325.06s]  is that whether you operating in the virtual space
[4325.06s -> 4327.74s]  or whether you operating in the real world space,
[4328.98s -> 4333.98s]  you know, the ideas are fairly similar across domain.
[4333.98s -> 4337.06s]  And so here you can generalize to new object,
[4337.06s -> 4338.94s]  object geometries, new categories.
[4338.94s -> 4340.38s]  And so like, you know,
[4340.38s -> 4342.34s]  we've never trained on this particular,
[4343.82s -> 4344.86s]  for this particular object,
[4344.86s -> 4347.70s]  but you can sort of successfully complete it.
[4347.70s -> 4350.82s]  You can deal with multiple novel objects
[4350.82s -> 4352.26s]  with unseen receptacles.
[4352.26s -> 4357.26s]  So, you know, these models can do,
[4358.38s -> 4359.70s]  you know, can do reasonably well.
[4359.70s -> 4361.38s]  It's not perfect by all means.
[4361.38s -> 4362.82s]  I think we're hitting success rates
[4362.82s -> 4366.18s]  of about like 80 to 90%,
[4366.18s -> 4367.68s]  but these models do generalize.
[4367.68s -> 4369.58s]  They can manipulate the formula objects.
[4369.62s -> 4371.22s]  You don't observe them
[4371.22s -> 4373.16s]  when we were training these models in the simulator,
[4373.16s -> 4374.62s]  but, you know, training in the simulator
[4374.62s -> 4378.00s]  does translate into the real world.
[4378.00s -> 4380.42s]  Okay, now to summarize,
[4380.42s -> 4382.68s]  we've talked about visual web arena
[4382.68s -> 4384.76s]  as a benchmark for, you know,
[4384.76s -> 4388.06s]  these realistic tasks designed to evaluate the capabilities
[4388.06s -> 4390.14s]  of autonomous multimodal agents.
[4390.14s -> 4393.20s]  We've talked about inference time search algorithm,
[4393.20s -> 4395.94s]  which sort of designed to enhance the capabilities
[4396.36s -> 4399.82s]  of language models for realistic web tasks, right?
[4399.82s -> 4402.66s]  And how we can, you know, do the search.
[4402.66s -> 4404.62s]  And there's a lot of research
[4404.62s -> 4406.34s]  that needs to be done in that space.
[4406.34s -> 4408.78s]  And then we've talked about the data pipeline
[4408.78s -> 4410.82s]  for large scale generation verification
[4410.82s -> 4412.94s]  of sort of these synthetic tasks
[4412.94s -> 4416.54s]  that the model can create powered by llama models.
[4416.54s -> 4419.14s]  And the interesting thing about all of these settings
[4419.14s -> 4419.96s]  is that, you know,
[4419.96s -> 4422.22s]  you can try to generate these synthetic tasks.
[4422.22s -> 4425.14s]  You can use inference time to generate something better.
[4425.18s -> 4427.26s]  You can, you know, use data collection with humans.
[4427.26s -> 4430.82s]  And ultimately it's a combination of all of these pieces
[4430.82s -> 4433.16s]  that will potentially lead to models
[4433.16s -> 4438.16s]  that can work very well in the real world environments.
[4438.18s -> 4442.90s]  One last thing I do wanna mention is that, you know,
[4442.90s -> 4446.82s]  AI safety and robustness becomes fairly important,
[4446.82s -> 4449.42s]  especially in the age of autonomous systems.
[4449.42s -> 4451.18s]  And what's essentially happening today
[4451.18s -> 4454.02s]  is that these systems are not,
[4454.02s -> 4456.04s]  first of all, they're not very robust.
[4457.34s -> 4460.34s]  You know, like if I ask it to do some task,
[4460.34s -> 4461.94s]  you know, sometimes it completes the task,
[4461.94s -> 4463.58s]  sometimes it doesn't, right?
[4463.58s -> 4464.98s]  And it's very difficult, you know,
[4464.98s -> 4466.58s]  like if I wanna have a system
[4466.58s -> 4469.46s]  that books my flights as an example, right?
[4469.46s -> 4470.58s]  I don't wanna have a system
[4470.58s -> 4472.56s]  that's only 80% correct, right?
[4472.56s -> 4474.38s]  I don't want a system that like, you know,
[4474.38s -> 4475.90s]  80% books the right stuff
[4475.90s -> 4478.26s]  and 20% doesn't book the right,
[4478.26s -> 4479.98s]  books the wrong planes for me, right?
[4479.98s -> 4481.66s]  That's unacceptable.
[4481.66s -> 4483.74s]  So sort of having these agentic capabilities
[4484.34s -> 4486.50s]  that actually very good at executing tasks
[4486.50s -> 4488.78s]  and perhaps asking for clarification questions
[4488.78s -> 4490.36s]  to have some kind of modeling in the loop
[4490.36s -> 4492.70s]  becomes a very important research
[4492.70s -> 4495.82s]  and very important, which is missing.
[4495.82s -> 4497.24s]  I think that's missing today.
[4497.24s -> 4500.26s]  On the AI safety, that's another area of research, right?
[4500.26s -> 4503.22s]  Because a lot of times these agents are very brittle.
[4503.22s -> 4506.50s]  So you can actually, you know,
[4506.50s -> 4508.30s]  adversely kind of modify them.
[4508.30s -> 4510.62s]  And so they're like, this is some work.
[4510.62s -> 4513.34s]  There's a lot more work that's happening in its space.
[4514.26s -> 4515.94s]  But we found this one interesting settings.
[4515.94s -> 4517.94s]  This was done on visual web arena
[4517.94s -> 4522.94s]  where we basically change the representation of images.
[4522.98s -> 4524.12s]  So you have a webpage,
[4524.12s -> 4526.12s]  on the webpage you have your images
[4526.12s -> 4528.62s]  and you change your representation of the images
[4528.62s -> 4530.94s]  in such a way that the captioning system,
[4530.94s -> 4533.90s]  when it captions it actually, you know,
[4533.90s -> 4536.22s]  provides an instruction to the language model
[4536.22s -> 4537.40s]  of what it should do next, right?
[4537.40s -> 4540.70s]  So we can kind of like hijack these agents
[4540.70s -> 4543.22s]  and basically say, you know,
[4543.22s -> 4544.62s]  add the comment, looks great
[4544.62s -> 4546.10s]  before providing the next action.
[4546.10s -> 4549.18s]  So if the model ends up on your webpage, right?
[4549.18s -> 4551.42s]  Instead of like navigating to the next one,
[4551.42s -> 4553.02s]  it will leave the comment saying,
[4553.02s -> 4556.38s]  this is a terrific, you know, this is terrific product
[4556.38s -> 4557.82s]  and then go to the next one, right?
[4557.82s -> 4560.22s]  So you can kind of like force it to generate,
[4560.22s -> 4561.80s]  for example, you know,
[4564.72s -> 4566.46s]  positive feedback for your product, right?
[4566.46s -> 4568.74s]  So it can boost your sort of,
[4570.90s -> 4573.24s]  you know, that a lot of kind of like agents
[4573.24s -> 4574.54s]  or people like your product, right?
[4574.54s -> 4577.56s]  So it's just, it's a little bit toyish at this point,
[4577.56s -> 4580.26s]  but it becomes fairly important because, you know,
[4580.26s -> 4581.52s]  you don't wanna have a system,
[4581.52s -> 4583.14s]  you wanna have a system that's robust
[4583.14s -> 4584.74s]  to sort of these adversarial settings
[4584.74s -> 4587.98s]  where I can modify my state in an adversarial way
[4587.98s -> 4590.78s]  so as to ask, you know, the model
[4590.78s -> 4594.38s]  to take a different action than it's supposed to take,
[4594.38s -> 4595.42s]  right?
[4595.42s -> 4597.18s]  And finally, this is a funny example,
[4597.18s -> 4598.34s]  but I wanted to mention, you know,
[4598.34s -> 4601.02s]  like there's a lot of work in the industry
[4601.02s -> 4602.58s]  on building these types of models.
[4602.58s -> 4604.02s]  Obviously we wanna have assistants
[4604.02s -> 4607.78s]  that can look at the web and do a lot of tasks on you,
[4608.90s -> 4613.90s]  but this was done by Claude Anthropic's computer use.
[4615.10s -> 4616.54s]  And so it kind of, you know,
[4616.54s -> 4618.18s]  they have this funny thing where you say, you know,
[4618.18s -> 4622.12s]  in one episode, Claude accidentally clicked to stop
[4622.12s -> 4624.10s]  a long running screen recording
[4624.10s -> 4625.90s]  causing all footage to be lost.
[4625.90s -> 4627.50s]  In another clock suddenly took a break
[4627.50s -> 4629.94s]  from our coding demo and began to use photos
[4629.94s -> 4632.38s]  of, you know, Yellowstone National Park.
[4632.38s -> 4634.20s]  And the reason why these models do that,
[4634.20s -> 4635.78s]  because, you know, you have a sequence,
[4635.78s -> 4636.78s]  you have a set of actions.
[4636.78s -> 4639.26s]  And so if it's sort of trying to accomplish the task,
[4639.26s -> 4641.38s]  takes the wrong action, right?
[4641.38s -> 4643.46s]  Then it sort of, once it takes the wrong action
[4643.46s -> 4645.54s]  and it doesn't have this search ability
[4645.54s -> 4647.58s]  to kind of like understand, I'm not actually,
[4647.58s -> 4649.42s]  I've taken the action that doesn't,
[4649.42s -> 4651.52s]  is not consistent with my task,
[4651.52s -> 4653.74s]  then it's very hard for it to backtrack potentially,
[4653.74s -> 4654.58s]  right?
[4654.58s -> 4655.40s]  Like once you're taking the actions,
[4655.40s -> 4656.24s]  trying to take another action,
[4656.24s -> 4657.14s]  maybe it's trying to recover
[4657.74s -> 4659.70s]  and then basically cannot recover back
[4659.70s -> 4661.94s]  to the original set.
