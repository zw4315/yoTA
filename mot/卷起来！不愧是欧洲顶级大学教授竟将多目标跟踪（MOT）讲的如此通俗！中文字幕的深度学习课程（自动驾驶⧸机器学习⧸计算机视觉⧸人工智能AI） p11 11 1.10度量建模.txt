# Detected language: en (p=1.00)

[0.64s -> 5.68s]  The single object measurement modeling describes the relation between the object state x and the
[5.68s -> 11.76s]  corresponding measurement. So let's consider an illustration with an autonomous car and in the
[11.76s -> 17.76s]  opposing lane there is a vehicle. This vehicle has some state represented by this cross sign
[18.48s -> 23.12s]  and the autonomous vehicle is equipped with some sensor that detects the car
[23.12s -> 27.84s]  in the opposing lane and the measurement is here represented by the red circle.
[28.48s -> 34.00s]  In general, depending on the type of sensor that is used and the types of objects that we are tracking
[34.00s -> 39.84s]  we will require different types of single object measurement models. So there's not a single
[39.84s -> 44.32s]  measurement model that can always be used regardless of what type of sensor that you're
[44.32s -> 49.68s]  using or the type of targets that you're tracking. Similarly to the motion modeling,
[49.68s -> 56.08s]  the measurement models typically include additive noise. So the measurement said at time k is some
[56.16s -> 62.40s]  function h that takes the object state as input and then we have additive noise and this
[62.40s -> 68.48s]  measurement function h it can be either linear or non-linear. We can also use this to define
[68.48s -> 74.64s]  a so-called measurement likelihood a density for the measurement said at time k given the
[74.64s -> 81.92s]  object state at time k. Let's take an example where we assume that we have a sensor that gives
[81.92s -> 88.32s]  us range and bearing measurements. So we have an autonomous car with the field of view and there's
[88.32s -> 94.24s]  one more vehicle inside the field of view. We can mark the coordinate frame by the sensor
[94.24s -> 100.80s]  by these two axis arrows and then again assuming that the sensor is a range bearing sensor
[100.80s -> 106.48s]  what we measure is the distance from the sensor to the other car and the bearing or the angle
[106.48s -> 112.24s]  from the sensor to the other car. This can be described by the following measurement function
[112.96s -> 121.84s]  where px and py is the object's position and sx and sy is the sensor's position both at time k.
[121.84s -> 127.20s]  So in the measurement function we have first the euclidean distance from the sensor position
[127.20s -> 133.04s]  to the object's position that's given by the top expression and then the inverse tangent
[133.04s -> 139.20s]  expression describes the angle or the bearing from the sensor to the object. So in this example
[139.20s -> 145.04s]  we have explicitly denoted the sensor position and in the remainder of this course it will be
[145.04s -> 150.96s]  implicitly assumed that the sensor position is known. However in many real multiple object
[150.96s -> 156.72s]  tracking applications different methods have to be applied to also estimate the sensor position.
[156.72s -> 163.68s]  For example we can use GPS positioning to know where the sensor is positioned. However
[163.68s -> 170.40s]  sensor positioning is outside the scope of this course. So let's have a look at an example where
[170.40s -> 176.00s]  we have Gaussian distributed measurement noise. So the density for the measurement noise is Gaussian
[176.00s -> 181.92s]  with zero mean and covariance r. If we have a measurement model with additive noise then we
[181.92s -> 187.92s]  get a Gaussian measurement likelihood. So the density for the measurement z given the state
[187.92s -> 193.36s]  x is Gaussian with mean described by the measurement function h with the object state
[193.36s -> 197.76s]  as input and the covariance is the measurement noise covariance r.
