# Detected language: en (p=1.00)

[0.00s -> 4.40s]  Hi! In the next videos, we're going to do a review of Bayesian filtering,
[4.40s -> 8.40s]  since multiple object tracking is generally solved using Bayesian methods.
[9.12s -> 13.60s]  So, what we aim for here is a review of filtering. You should already be familiar
[13.60s -> 17.04s]  with Bayesian filtering. It's one of the prerequisites of this course.
[17.04s -> 23.52s]  So that means recursive estimation, Bayesian statistics, Bayes theorem, linear and non-linear
[23.52s -> 27.44s]  filtering. Those are all concepts you should have covered in previous courses.
[28.00s -> 32.00s]  You also need to be familiar with models for both the motion of objects
[32.00s -> 36.88s]  and also the measurements from the objects. If you don't have this knowledge already,
[36.88s -> 39.60s]  we strongly recommend taking the Chalmers X course,
[40.16s -> 43.84s]  Sensor Fusion and Nonlinear Filtering for Automotive Systems,
[43.84s -> 47.20s]  since this course covers precisely these prerequisites.
[47.20s -> 52.16s]  In Bayesian recursive filtering, there are two steps. The first step is the prediction,
[52.16s -> 57.28s]  where we use the motion model to predict what happens from one time step to the next.
[57.52s -> 62.40s]  So, what's going to happen to the object? How does the object state evolve over time?
[63.04s -> 68.24s]  The second step is the update step, where we use measurements and the measurement model
[68.24s -> 73.44s]  to update the object state densities. This means that we use the measurement information
[73.44s -> 79.60s]  to update our knowledge about the object states. And these two steps are iterated.
[79.60s -> 84.48s]  We do a prediction, and then we update, followed by a prediction and update,
[84.48s -> 90.56s]  and so on and so forth. So, filtering for multiple object tracking is recursive.
[90.56s -> 95.76s]  We repeat the same steps. Before we go into the details of Bayesian filtering,
[95.76s -> 100.32s]  we need to introduce some notation. So first, we denote the time step by k.
[101.12s -> 106.88s]  The object state is denoted by x with a subscript index k. So this simply means that
[106.88s -> 112.24s]  we have the object state at time step k. And the measurement is denoted in a similar way.
[112.24s -> 119.20s]  We have sed with a subscript index k for time. Since we're going to track objects over time,
[119.20s -> 124.08s]  we need to denote a sequence of measurements. And we do that by using sed again,
[124.08s -> 129.52s]  but this time with a subscript index that spans from some initial time step to some final time,
[129.52s -> 134.08s]  or latest time. So here, the sequence starts at time step one,
[134.08s -> 138.16s]  and we have a measurement up to and including time step tau.
[138.88s -> 143.92s]  Posterior densities are denoted by p. And for the sake of clarity,
[143.92s -> 149.04s]  we have put sub indexing on p here, so that it is clear what density we refer to.
[149.60s -> 155.84s]  Here we have the density for the state x at time k, given measurements from time one to time tau.
[156.56s -> 160.24s]  However, if it is clear from context what density we mean,
[160.88s -> 165.04s]  then for the sake of brevity, we're going to skip this sub indexing,
[165.04s -> 168.16s]  as you can see here on the right-hand side of the equality sign.
[169.20s -> 174.64s]  The expected value of state x at time k, given measurements up to time tau,
[174.64s -> 178.48s]  is denoted by x-bar, with a sub indexing k given tau.
[179.28s -> 187.92s]  And lastly, if the pdf p is a Gaussian pdf, we denote the Gaussian pdf with a calligraphic n,
[188.56s -> 193.36s]  and we have the mean value x-bar and the covariance matrix p,
[193.36s -> 198.48s]  both with sub indexing k given tau. So let's illustrate Bayesian filtering
[198.48s -> 204.96s]  with a core example. We are interested in the state of the core, denoted by x, and
[205.68s -> 210.72s]  we use some sensor to get measurements of the core, illustrated by these red circles,
[210.72s -> 215.84s]  denoted by z. So the task in Bayesian filtering is to use these measurements
[215.84s -> 220.88s]  and filter them such that we can estimate the posterior density for the state of the object
[220.88s -> 224.08s]  that we're interested in, that is, the state of the car.
[224.88s -> 230.80s]  We start with some initial density p of x1. Then we get a first measurement,
[230.80s -> 236.64s]  so we do a measurement update and get p of x1 given z1. Now we can do a prediction to the
[236.64s -> 243.44s]  next time step and get p of x2 given z1. We do a measurement update again, so we get p of
[243.44s -> 251.44s]  x2 given z1 and z2, and we then continue this procedure. We iterate the prediction and the
[251.44s -> 256.64s]  update so that we get a sequence of these posterior densities for the object state
[256.64s -> 262.80s]  given the measurements. To do Bayesian multi-object tracking, we need models for the multiple
[262.80s -> 267.36s]  objects, models for how they move, how they enter and leave the surveillance area,
[267.36s -> 270.64s]  and we also need models for how the detector and the sensor works.
[271.60s -> 277.04s]  Such multiple object motion models and multiple object measurement models partly build upon
[277.04s -> 282.24s]  models for individual objects. So it makes sense, therefore, to study motion model
[283.04s -> 288.72s]  that describes the motion of a single object. Likewise, a measurement model that describes
[288.72s -> 292.40s]  what kind of detections or measurements we get from an object is needed.
[293.12s -> 297.68s]  These object models are then integrated into the multi-object models.
[297.68s -> 302.32s]  So we're going to talk more about the multi-object modeling later in this course.
[302.32s -> 306.16s]  Next, we're going to look into the single object motion modeling
[306.16s -> 308.88s]  and the single object measurement modeling.
