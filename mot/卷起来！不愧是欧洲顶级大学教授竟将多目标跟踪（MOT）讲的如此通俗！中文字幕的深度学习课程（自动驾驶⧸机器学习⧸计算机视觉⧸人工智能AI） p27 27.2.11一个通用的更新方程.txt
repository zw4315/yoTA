# Detected language: en (p=1.00)

[0.24s -> 6.48s]  In an earlier video, we presented the measurement model in detail. We have also learned about
[6.48s -> 12.16s]  techniques that can be used to normalize mixtures of densities, and we have even discussed the
[12.16s -> 19.20s]  interpretation of the weights and densities in these mixtures. Given all of these results,
[19.20s -> 25.76s]  we are now ready to present the general update equations in detail. These equations are
[25.76s -> 32.96s]  useful when we later present a complete conceptual solution. Also, two of the algorithms that we
[32.96s -> 38.24s]  present in the next section can be derived directly from the equations in this video,
[38.80s -> 42.24s]  and it is therefore reasonable to look at this part in detail.
[43.12s -> 47.60s]  Before we turn to the technical details, I'd like to clarify what we're about to drive.
[47.60s -> 52.08s]  To do this, let us return to the example that we looked at in the videos about the measurement
[52.08s -> 57.76s]  model. Like before, we have scalar states and measurements. The probability of detection is
[57.76s -> 62.56s]  constant, and the object likelihood has a Gaussian form. The difference is that we now
[62.56s -> 69.04s]  have a prior on X, which is Gaussian with mean 0.5 and variance 0.5, and we are going to
[69.04s -> 74.80s]  compute the posterior density of X. Because we have two measurements, we obtain three hypotheses,
[74.80s -> 80.96s]  corresponding to the object being undetected, Z1 being the object detection, and Z2 being
[80.96s -> 86.40s]  the object detection. Like the measurement model, the posterior can be decomposed into one term for
[86.40s -> 92.08s]  each of the three hypotheses. In the figure, we visualize the prior using a blue dotted curve.
[92.08s -> 96.96s]  The contribution from the hypothesis that the object is undetected is the green point dashed
[96.96s -> 103.68s]  curve. The contribution from the hypothesis that Z1 is an object detection is the cyan colored curve
[103.68s -> 109.04s]  with circles. And the contribution from the hypothesis that Z2 is an object detection is the
[109.04s -> 115.20s]  magenta colored dashed curve. Finally, the posterior is the sum of these three functions,
[115.20s -> 121.52s]  illustrated by a solid black curve. In this video, we derive detailed expressions for W theta
[121.52s -> 128.80s]  and P theta of X for general functions P of X, PD of X, lambda C of C, and the object
[128.80s -> 135.60s]  likelihood G of O given X. That is, even though the above visualization concerns the toy example,
[136.16s -> 141.76s]  our derivations cover the general case with nonlinear functions and high dimensional state
[141.76s -> 146.40s]  and measurement vectors. In an earlier video, we described the measurement model on the following
[146.40s -> 153.04s]  form. Inside the brackets, we have one term, one minus PD of X, corresponding to the hypothesis
[153.04s -> 160.80s]  that theta is equal to zero, and then m more terms for theta equals one to m. Outside the brackets,
[160.80s -> 167.04s]  we then have some factors that are shared by all terms and that do not depend on X. As you know,
[167.04s -> 171.76s]  the posterior is proportional to the prior times the likelihood. We can now plug in the
[171.76s -> 176.96s]  expression for the likelihood and move the constant terms into the proportionality constant.
[176.96s -> 182.48s]  This leaves us with the following expression, where we have a sum over m plus one terms and
[182.48s -> 188.24s]  an unknown normalization constant. A posterior expressed on this form is impractical to use.
[188.24s -> 192.32s]  Instead, we want to express it as a mixture of densities on this form,
[192.32s -> 197.92s]  where the terms contain a weight W theta and a density P theta of X. In the video where we
[197.92s -> 203.60s]  studied how to normalize mixtures of densities, the unnormalized weight for the individual term
[203.60s -> 208.96s]  was just the integral of the original function. For the hypothesis that theta is equal to zero,
[208.96s -> 215.04s]  which means that the object is undetected, the original function is P of X times one minus PD of
[215.04s -> 221.20s]  X and the unnormalized weight W tilde zero is therefore just the integral of that function.
[221.20s -> 226.56s]  We also learned in that video that the density is obtained by normalizing the original function
[226.56s -> 233.04s]  and P zero of X is therefore P of X times one minus PD of X divided by the integral of the
[233.04s -> 238.64s]  same product. Similarly, for the hypothesis where theta is greater than zero, which means that the
[238.64s -> 247.28s]  object is detected, the original functions are P of X times PD of X times G of Z theta given X
[247.28s -> 253.20s]  divided by lambda Z of Z theta. To obtain the weight for one of those hypothesis,
[253.20s -> 259.20s]  we simply compute the integral of that function, where we note that lambda C does not depend on
[259.20s -> 264.88s]  X and can therefore be extracted out from the integral. To obtain the density P theta of X for
[264.88s -> 269.28s]  a hypothesis stating that the object is detected, we take the original function
[269.28s -> 275.84s]  and normalize it by its integral. In this case, the lambda C factor cancels out and we are left
[275.84s -> 282.80s]  with P of X times PD of X times G of Z theta given X divided by the integral of the same
[282.80s -> 289.76s]  function. To obtain the normalized weights W theta, we simply normalize the weights W tilde theta.
[289.76s -> 294.24s]  In the next video, we study the expressions for both the weights and the densities
[294.24s -> 298.64s]  and check how they simplify when we have a constant PD and a linear Gaussian
[298.64s -> 303.92s]  object measurement likelihood. However, even before that, it may be interesting to compare
[303.92s -> 309.60s]  the densities P theta of X to the posterior density when we directly observe the object
[309.60s -> 314.96s]  measurement matrix O. Since we have claimed that P theta of X is the posterior density
[314.96s -> 320.32s]  given the data association, these should be closely related. You could post the video here and try
[320.32s -> 327.84s]  to explain it to yourselves before I proceed. In the section about models, we found that the
[327.84s -> 334.08s]  distribution of the object measurement matrix P of O given X takes the value 1 minus PD of X
[334.64s -> 342.48s]  if O is an empty matrix and PD of X times G of O given X if the matrix capital O is the
[342.48s -> 349.28s]  vector lowercase O. It follows that the posterior of X given O is the prior P of X
[349.28s -> 355.28s]  times the above likelihood function. This means that the posterior takes the value P of X times
[355.28s -> 363.76s]  1 minus PD of X if O is an empty matrix and P of X times PD of X times G of O given X
[363.76s -> 369.92s]  if the matrix O is the vector lowercase O. If we now compare this to the expression for
[369.92s -> 375.52s]  P theta of X, we see an interesting relation. If theta is equal to zero, which implies that
[375.52s -> 381.68s]  the object is undetected, P theta of X is identical to the posterior of X given that O is an empty
[381.68s -> 387.60s]  matrix. This makes sense since O is an empty matrix when the object is undetected. If theta
[387.60s -> 393.20s]  takes an integral value between 1 and M, we know that Z theta is an object measurement, which
[393.20s -> 400.32s]  means that O is equal to Z theta. We also see that P theta of X is identical to P of X given O
[400.32s -> 406.32s]  when we set O equal to Z theta. Hopefully, you agree that all of this makes a lot of sense.
[406.32s -> 411.76s]  The conclusion from this slide is that P theta of X is identical to the posterior of X given
[411.76s -> 417.20s]  the object measurement matrix O if we use the data association hypothesis theta and the matrix
[417.20s -> 430.08s]  Z to determine the object measurement matrix O.
