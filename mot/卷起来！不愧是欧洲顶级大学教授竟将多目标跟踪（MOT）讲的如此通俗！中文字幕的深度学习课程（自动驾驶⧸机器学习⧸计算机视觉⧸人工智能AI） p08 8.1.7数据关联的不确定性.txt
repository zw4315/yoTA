# Detected language: en (p=1.00)

[0.00s -> 5.82s]  Hi, in addition to the sensor detection challenges that we discussed in the previous presentation,
[5.82s -> 9.44s]  there's one more, and that is the data association problem.
[9.44s -> 14.14s]  The gist of the data association problem is that we do not have any information about
[14.14s -> 18.94s]  the origin of the detections, no information about what caused them.
[18.94s -> 24.00s]  So we have no prior information about which detections are from objects that had
[24.00s -> 29.38s]  been detected before, which detections are from objects that just appeared, and
[29.38s -> 32.22s]  which detections are false detections.
[32.22s -> 37.72s]  In some tracking literature, the data association problem is called the correspondence problem,
[37.72s -> 43.30s]  because solving the data association problem can be understood as figuring out which detections
[43.30s -> 48.04s]  correspond to objects and which correspond to false detections.
[48.04s -> 54.26s]  So to better understand what the data association problem is, we're going to consider an example.
[54.26s -> 60.14s]  So let's consider a simple one-dimensional scenario where we have known data association.
[60.14s -> 65.26s]  In this diagram, we have the position state on the horizontal axis, and time is on the
[65.26s -> 66.58s]  vertical axis.
[66.58s -> 68.90s]  First, there are four objects.
[68.90s -> 75.42s]  At time two, a fifth object appears, and at time three, one of the objects disappear.
[75.42s -> 79.94s]  So in total, over these three time steps, we have five different objects, and you
[79.94s -> 84.62s]  can see their corresponding positions over time as these colored crosses.
[84.62s -> 90.50s]  Then, in each time step, we have some measurements, and these measurements are color-coded according
[90.50s -> 92.50s]  to the known association.
[92.50s -> 96.78s]  The orange measurements correspond to the object shown by the orange crosses, the light
[96.78s -> 101.58s]  blue measurements are associated to the light blue object, and so on.
[101.58s -> 105.74s]  And the gray measurements represent clutter, or false detections.
[105.74s -> 110.98s]  So in this case, it's quite simple to track these five objects, because we know precisely
[110.98s -> 116.48s]  which measurements correspond to which object, and we know which measurements are cluttered.
[116.48s -> 120.64s]  So this means that tracking an object's state is just a matter of processing the
[120.64s -> 122.90s]  corresponding measurements.
[122.90s -> 129.32s]  Now, let's consider the same example, but this time with unknown data association.
[129.32s -> 134.10s]  So now, we don't know which measurements are from the same object, which measurements
[134.10s -> 135.98s]  are cluttered, and so on.
[135.98s -> 140.18s]  So at the first time step, we have four measurements.
[140.18s -> 144.72s]  Since we have unknown data association, any of these four measurements could be from
[144.72s -> 148.02s]  an object, or it could be a false detection.
[148.02s -> 152.68s]  So we have a lot of different possibilities already in this first time step.
[152.68s -> 156.02s]  At the second time step, there's five more measurements.
[156.02s -> 161.38s]  Again, we don't know the data association, so we don't know if any of these five measurements
[161.38s -> 166.76s]  correspond to the same objects we might have measured in time step one, or they could be
[166.76s -> 171.50s]  false detections, or they might correspond to some new objects that appeared in the
[171.50s -> 173.22s]  current time step.
[173.22s -> 177.10s]  And then at time step three, we have another six measurements.
[177.10s -> 181.58s]  And again, any of these measurements could be from an object that was detected before
[181.58s -> 186.68s]  in time step two, or maybe it was detected in time step one, but was then misdetected
[186.68s -> 188.24s]  in time step two.
[188.24s -> 192.68s]  Or the measurement could correspond to an object that was detected in both time step one and
[192.68s -> 195.14s]  two, or it could be cluttered.
[195.14s -> 199.62s]  So we have that any measurement at any time step could be a false detection, it
[199.62s -> 203.94s]  could be a detection from a newly appeared object, or it could be a detection of an
[203.94s -> 208.14s]  object that was detected in any one of the previous time steps.
[208.14s -> 212.74s]  So in this case, tracking multiple objects becomes really hard because there are so
[212.74s -> 216.12s]  many data association possibilities.
[216.12s -> 220.98s]  Let's have a look at an example where we compare three different data association methods
[220.98s -> 225.78s]  and illustrate that the tracking performance can be quite different depending on how the
[225.78s -> 227.90s]  data association is handled.
[227.90s -> 232.12s]  For all these methods that we're going to compare, they are applied to data from a
[232.12s -> 233.12s]  LIDAR sensor.
[233.12s -> 238.60s]  And for the time being, we're not going to focus really on what's behind each data
[238.60s -> 240.26s]  association method.
[240.26s -> 244.42s]  Instead, we're going to just focus on the tracking results and compare them.
[244.42s -> 248.72s]  So the ground truth for this scenario is that we have three pedestrians that walk from left
[248.72s -> 252.28s]  to right, as indicated by these three black arrows.
[252.28s -> 256.20s]  And if we start this sequence, we will see that the results are quite different for
[256.20s -> 258.08s]  the three data association methods.
[258.08s -> 263.28s]  In the top diagram, we can see that the data association led to three pedestrians
[263.28s -> 266.16s]  being merged into a single object.
[266.16s -> 270.24s]  So we're no longer able to track the individual pedestrians, but could only track
[270.24s -> 271.96s]  them as a group.
[271.96s -> 276.86s]  In the middle diagram, we see that the tracking algorithm is capable of tracking all three
[276.86s -> 277.86s]  objects.
[277.86s -> 283.02s]  However, the trajectories are not really smooth, not smooth as you would expect from
[283.02s -> 285.54s]  a person just walking forwards.
[285.54s -> 290.22s]  So what we have are quite noisy estimates of the pedestrians' positions.
[290.22s -> 295.32s]  And lastly, in the bottom diagram, we have what is arguably the best result out of
[295.32s -> 296.62s]  these three.
[296.62s -> 301.06s]  That is three trajectories that are a bit smoother than in the second case.
[301.06s -> 306.64s]  So this is just a very simple example where we have applied some tracking to LiDAR data.
[306.64s -> 311.86s]  But nevertheless, it clearly illustrates how important data association can be and
[311.86s -> 316.60s]  that we can get very different results depending on what method we are using.
[316.60s -> 320.52s]  Okay, so what we just saw, that's just one example.
[320.52s -> 325.52s]  But nevertheless, we hope that this illustrates how important data association can be and
[325.52s -> 329.46s]  that we can get very different results depending on what method we're using.
