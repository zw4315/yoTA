# Detected language: en (p=1.00)

[0.00s -> 10.20s]  In this video, we're going to learn about prediction of the n-object density.
[10.20s -> 15.92s]  We have a posterior density, a transition density, and then we have the Chapman Kolmogorov
[15.92s -> 22.16s]  prediction which takes the transition density, the posterior, and marginalizes over the
[22.16s -> 23.64s]  previous state.
[23.64s -> 27.96s]  We will first have a look at how the transition density is modeled in n-object
[27.96s -> 32.44s]  tracking, and then we will see what the predicted density is.
[32.44s -> 37.84s]  Modeling the motion for n-objects means that we need to describe how the states evolve
[37.84s -> 45.42s]  from time k minus one to time k, so we need a transition density for all the n-objects.
[45.42s -> 51.24s]  And we make a simplifying assumption in n-object tracking, which is that the time evolution
[51.24s -> 53.52s]  of the objects is independent.
[53.52s -> 59.72s]  The n-object transition density is a product of a transition density pi for each individual
[59.72s -> 60.72s]  object.
[60.72s -> 67.04s]  And as shown here, typically the same transition density is used for all objects.
[67.04s -> 72.40s]  Let's take an example where we have a Gaussian state transition density for single objects.
[72.40s -> 79.42s]  So the transition density pi is a Gaussian density with some motion function f and process
[79.42s -> 81.36s]  noise covariance q.
[81.44s -> 87.36s]  The transition density for all n-objects is then a product of this Gaussian density for
[87.36s -> 88.88s]  each object.
[88.88s -> 93.92s]  And we should point out here that even though we are using the same motion model
[93.92s -> 100.40s]  f and q for all objects, it does not mean that the estimated motion parameters, such
[100.40s -> 104.68s]  as speed, heading, acceleration, turn rate, etc.
[104.68s -> 109.56s]  It does not mean that those parameters are the same for all objects.
[109.56s -> 114.36s]  Now consider an independent posterior at time k e minus one.
[114.36s -> 119.60s]  The predicted density, assuming independent motion, is given by the Chapman Kolmogorov
[119.60s -> 121.00s]  prediction.
[121.00s -> 125.90s]  And if we insert the transition density and the posterior into the integral, we can
[125.90s -> 132.64s]  rewrite this as a product of a Chapman Kolmogorov prediction for each individual object.
[132.64s -> 137.92s]  In other words, we predict each of the objects independently of the other objects,
[137.96s -> 141.84s]  and the predicted density is an independent density.
[141.84s -> 145.60s]  Now let's consider instead that we have a mixture posterior.
[145.60s -> 151.48s]  Then we can show that the predicted density is a mixture density, where we predict each
[151.48s -> 156.24s]  mixture component independently of all the other mixture components.
[156.24s -> 162.56s]  So we have that each hypothesis can be predicted independently of all other hypotheses, and
[162.56s -> 167.08s]  the hypothesis probabilities, or weights, remain the same.
[167.08s -> 172.26s]  If we have a posterior that is a Gaussian mixture, and a transition density with a linear
[172.26s -> 178.02s]  Gaussian motion model, then the predicted density has predicted weights equal to the
[178.02s -> 184.30s]  posterior weights, and the predicted means and variances are given by the Coleman filter
[184.30s -> 185.30s]  prediction.
[185.30s -> 189.60s]  We can visualize the predicted density using a linear Gaussian example, where we have
[189.60s -> 191.72s]  scalar object states.
[191.72s -> 198.40s]  To make the visualization simple, we have just two objects, and the motion model for
[198.40s -> 203.80s]  each object is a random walk with variance 0.25.
[203.80s -> 208.66s]  The posterior is a Gaussian mixture with four mixture components, and given that we
[208.66s -> 214.88s]  have a random walk motion model, the predicted density then also has four mixture components.
[214.88s -> 219.20s]  The predicted mixture weights are the same as the posterior weights, the means are
[219.20s -> 224.64s]  the same as the posterior means, and for the variances, we add the process noise
[224.64s -> 227.36s]  variance to the posterior variance.
[227.36s -> 232.76s]  So for the visualizations, we will look at both the n-object density as well as
[232.76s -> 236.00s]  the marginal densities for each of the two objects.
[236.00s -> 242.68s]  First, we have the n-object densities, the posterior on the left and the predicted
[242.68s -> 248.00s]  on the right, and this visualization clearly shows that the uncertainty of the two object
[248.00s -> 253.24s]  states has increased in the prediction, which is due to the process noise.
[253.24s -> 258.36s]  We can also look at the marginal densities, and again, the posterior is on the left
[258.36s -> 260.28s]  and the prediction is on the right.
[260.28s -> 265.04s]  Here, we've plotted the Gaussian mixture as a solid line, and the individual Gaussian
[265.04s -> 267.88s]  components are plotted as dashed lines.
[267.88s -> 273.88s]  And again, we can see how the prediction has introduced more uncertainty for each object.
[273.88s -> 278.84s]  Let's also have a look at an example where we have four objects, and the object state
[278.84s -> 282.56s]  consists of 2D position and 2D velocity.
[282.56s -> 289.96s]  Here, we have a constant velocity transition density with a constant velocity motion model
[289.96s -> 293.76s]  f and process noise covariance q.
[293.76s -> 299.88s]  The posterior is Gaussian, and the predicted density is also Gaussian with means and covariances
[299.88s -> 302.56s]  given by the Kalman filter prediction.
[302.56s -> 308.88s]  Because the object state has higher dimension, it's quite difficult to visualize the joint
[308.88s -> 311.40s]  density for the multiple objects.
[311.40s -> 316.16s]  And because of this, we're going to instead visualize the marginal densities.
[316.16s -> 318.44s]  Here we have plotted the four objects.
[318.44s -> 321.24s]  The position is given by the different markers.
[321.24s -> 327.56s]  The ellipses show the uncertainty of the position, in other words, the position covariance.
[327.56s -> 330.60s]  And the straight lines show the velocity vectors.
[330.60s -> 335.92s]  For this example, the predicted marginal densities look like this.
[335.92s -> 341.12s]  Each object has moved according to a constant velocity motion model, so it has moved along
[341.12s -> 347.56s]  the velocity vector, and due to the process noise, the uncertainty of the states has increased,
[347.56s -> 351.96s]  which can be seen here as larger position covariances.
[351.96s -> 356.72s]  To summarize the n-object prediction, we have that the objects move independently
[356.72s -> 358.44s]  of one another.
[358.44s -> 364.24s]  When we have n-object hypotheses, they can be predicted independently, and the hypothesis
[364.24s -> 366.92s]  weights are unaffected by this prediction.
