# Detected language: en (p=1.00)

[0.48s -> 6.96s]  In the previous video, we visualized the complete filtering recursions in single object tracking,
[6.96s -> 13.28s]  and we decomposed the posterior density into one term for every possible sequence of associations.
[14.08s -> 20.56s]  Also, each term was a product of a density that we already know how to compute and a weight
[20.56s -> 27.44s]  which was the probability of the data association sequence. Overall, it may seem that we are close
[27.44s -> 32.88s]  to deriving the complete filtering recursion, since it only remains to derive an expression
[32.88s -> 39.92s]  for the probabilities of the different data association sequences. Still, in the derivations
[39.92s -> 45.68s]  that we're about to perform, we will initially ignore the decomposition and instead start from
[45.68s -> 51.44s]  first principles and use the Chapman-Kolmogorov equation for the prediction step and base rule
[51.44s -> 59.12s]  for the update step. In the end, we will still arrive at the same decomposition but with detailed
[59.12s -> 66.00s]  expressions for both the densities and the weights in each term. Due to the unknown data associations,
[66.00s -> 72.40s]  the tricky part in single object tracking is the measurement update. We therefore start by
[72.40s -> 78.16s]  dedicating several videos to the update step before we put it all together into a complete
[78.16s -> 84.00s]  solution. To derive the update equations, we recall the expression for the measurement likelihood
[84.00s -> 90.16s]  which contains mk plus one terms. For now, we ignore the details in the expressions for the
[90.16s -> 97.04s]  individual terms and simply write the likelihood as a sum over theta k from 0 to mk. To simplify
[97.04s -> 102.48s]  notation, we remove the time index from the variables but please recall that z are the
[102.48s -> 106.96s]  measurements at a single time instance and that theta are the corresponding data association
[106.96s -> 112.96s]  hypotheses. Suppose that we have a prior p of x and want to compute the posterior of x given z.
[112.96s -> 119.28s]  The prior p of x represents the distribution of x before observing z. In a filtering setting,
[119.28s -> 123.84s]  this prior is normally the predicted density since that is the distribution of x before
[123.84s -> 128.64s]  observing the new measurements. The updated density is proportional to the prior times the
[128.64s -> 132.88s]  likelihood. Plugging in the expression for the likelihood, we find that the posterior is
[132.88s -> 137.52s]  proportional to the summation over theta of this product. To find the posterior,
[137.52s -> 142.40s]  we need to figure out how to normalize this summation in order to find the proportionality
[142.40s -> 147.84s]  constant. Like in the previous video, it would also be nice if it could decompose into pdfs
[147.84s -> 153.20s]  and weights that are convenient to compute, for instance using the Kalman filter. The objective in
[153.20s -> 158.80s]  this video is to learn a few tricks that enable us to write the posterior as a summation over
[158.80s -> 164.08s]  theta of the following terms. Three things are important to note here. First, we now have an
[164.08s -> 169.28s]  equality between the posterior and the summation instead of a proportionality sign, which is a
[169.28s -> 175.84s]  good thing. Second, the weight w theta is a probability mass function as a function of theta,
[175.84s -> 181.44s]  which means that it is non-negative and sums to one. Third, p theta of x is a probability
[181.44s -> 187.12s]  density function as a function of x, which means that it is non-negative and integrates to one.
[187.12s -> 192.16s]  We will see in the next video that the way we compute these variables, w theta is the
[192.16s -> 197.92s]  probability of the data association theta, and p theta of x is the posterior of x given that
[197.92s -> 203.04s]  theta is the true data association. The tricks that we present in this video are useful in
[203.04s -> 208.00s]  various different contexts. In particular, you may recall the general idea of using the law
[208.00s -> 213.76s]  of total probability to introduce variables that can help us express a distribution more easily.
[213.76s -> 219.04s]  In many cases, that technique gives us a posterior density written as a sum over
[219.04s -> 224.40s]  unnormalized functions. And we can then use tricks from this video to obtain a nice expression
[224.40s -> 231.76s]  for the posterior. To present these principles or tricks, we omit k, z and m, with the ambition
[231.76s -> 237.44s]  to highlight that the techniques in this video are general. Suppose we have a density p of x,
[237.44s -> 244.00s]  which is proportional to a function g of x, which is the sum of m plus 1 non-negative functions
[244.00s -> 251.76s]  g theta. For instance, in this example, g of x is the sum of g0 of x and g1 of x,
[251.76s -> 259.12s]  where the integral of g0 is 3, and the integral over g1 is 2. A technical detail is that we
[259.12s -> 263.76s]  need these functions to have finite integrals, and at least one of them needs to have a
[263.76s -> 267.52s]  positive integral, in order for us to be able to normalize g.
[268.08s -> 272.80s]  Now, what we would like to do is to express p of x as a mixture of PDFs,
[272.80s -> 282.56s]  that is, as a sum over w0 p0 of x, plus w1 p1 of x, and so on, until wm pm of x.
[282.56s -> 288.16s]  In the example, the solution we are looking for looks like follows, where p0 is a normalized
[288.16s -> 297.04s]  version of g0, p1 is a normalized version of g1, and p of x, which is a weighted sum of p0 and p1,
[297.04s -> 303.44s]  is a normalized version of g. All three functions are PDFs, and the normalization is selected such
[303.44s -> 308.08s]  that they integrate to one. In the next few slides, we will elaborate on this solution,
[308.08s -> 312.56s]  and demonstrate how to obtain the correct weights. Let us start with the basic problem
[312.56s -> 316.64s]  of normalizing a function g of x to obtain a density p of x.
[316.64s -> 322.16s]  If p of x is proportional to g of x, then there is a proportionality constant c,
[322.16s -> 328.64s]  such that p of x is c times g of x. To find p of x, we simply need to identify c.
[328.64s -> 332.56s]  To do this, we can use the fact that densities always integrate to one.
[333.28s -> 336.96s]  It therefore holds that 1 is equal to the integral of p of x.
[337.52s -> 343.92s]  If p is c times g, it therefore holds that 1 is c times the integral of g,
[343.92s -> 347.84s]  and we use this to figure out that c is 1 over the integral of g.
[347.84s -> 352.88s]  The conclusion from this is that p of x is g of x divided by the integral of g.
[352.88s -> 356.00s]  This is a very basic result that you should know about,
[356.00s -> 361.04s]  and we actually already made use of it to express the spatial PDF of a Poisson point process.
[361.04s -> 367.44s]  In the example, g of x has the integral 5, and p of x is therefore g of x divided by 5,
[367.44s -> 370.40s]  and it's easy to see that this has the integral 1.
[370.40s -> 375.44s]  We've seen how to normalize a single function. However, we have a sum of functions,
[375.44s -> 380.16s]  g theta of x, that we want to express as a weighted sum of PDFs.
[380.16s -> 385.60s]  We therefore want to identify PDFs for every theta without changing the total sum.
[386.16s -> 388.48s]  And there's a nice trick that enables us to do this.
[389.12s -> 393.44s]  Suppose w tilde theta denotes the integral of g theta of x,
[394.08s -> 400.08s]  and let p theta of x be a PDF, which is g theta divided by w tilde theta.
[400.08s -> 407.52s]  We can then factorize g theta of x into a constant, w tilde, times the PDF p theta of x,
[407.52s -> 412.48s]  where you can see that the constant w tilde cancels out if we plug in the expression for p
[412.48s -> 416.00s]  theta of x. This may look like an insignificant result,
[416.00s -> 418.96s]  but it's actually very useful in various contexts.
[418.96s -> 423.92s]  We have illustrated this result in the figure to the right, where we have expressed g0,
[423.92s -> 430.40s]  which has the integral 3, as 3 times the density p0 of x, which is the normalized version of g0
[430.40s -> 435.92s]  of x. If we plug this into the expression for g of x, we find that p of x is proportional
[435.92s -> 440.16s]  to sum of these products, w tilde theta times p theta of x.
[440.96s -> 447.84s]  We have illustrated this in our example, where we get that g is 3 times p0, plus 2 times p1,
[448.40s -> 453.68s]  since g0 had the integral 3 and g1 had the integral 2.
[453.68s -> 456.56s]  We are already close to obtaining the desired result.
[456.56s -> 461.68s]  All we have to do now is to normalize the weights such that the entire function becomes a PDF.
[462.48s -> 466.80s]  The purpose with this slide is to prove that normalizing the weights is the right thing
[466.80s -> 472.80s]  to do in order to obtain the density p of x. The math for doing this may look slightly involved,
[472.80s -> 477.52s]  even though the final result is simple. From previous slides, we know that since
[477.52s -> 484.08s]  p of x is proportional to g of x, p of x is g of x divided by the integral of g of x.
[484.64s -> 490.80s]  We also know that g of x can be written as the sum over theta of w tilde theta times p
[490.80s -> 496.08s]  theta of x, where w tilde theta and p theta are defined as follows.
[496.80s -> 502.24s]  So, what is the factor needed to normalize g? Well, it is the integral of g,
[503.04s -> 510.64s]  which is the sum over the integrals of g theta, where the integral of g theta is w tilde theta.
[511.60s -> 515.60s]  So, the normalization factor is the sum over w tilde theta.
[516.32s -> 521.68s]  It therefore turns out that to normalize g of x, it is sufficient to normalize the weights
[521.68s -> 528.88s]  w tilde. To see this, let w theta denote the normalized weights, where we have divided
[528.88s -> 535.44s]  w tilde theta by the sum over w tilde theta. Note that this is analogous to how we normalize
[535.44s -> 541.76s]  g of x, but instead of normalizing the function by dividing by its integral, we normalize
[541.76s -> 549.44s]  this discrete function by dividing by its sum. This ensures that w theta sums to 1, which means
[549.44s -> 555.28s]  that w theta is a probability mass function. Given that the integral over g is the sum
[555.28s -> 562.32s]  over w tilde theta, we get that p of x is g of x divided by the sum over w tilde,
[562.32s -> 568.24s]  where g is the sum over w tilde theta times p theta of x. We can now see that we obtain
[568.24s -> 575.12s]  the desired result, namely that p of x is the sum over w theta times p theta, where
[575.20s -> 582.48s]  w theta is a pmf and p theta is a pdf. Also, the conclusion from this slide is simply that
[582.48s -> 587.60s]  normalizing the weights was the right thing to do. We can illustrate this result using our
[587.60s -> 595.84s]  example. We previously found that g is 3 times p0 plus 2 times p1. To find p, all we had to
[595.84s -> 601.52s]  do was to normalize the weights. In this case, the weights summed to 5, and we obtained the
[601.52s -> 609.12s]  normalized weights by dividing the unnormalized weights by 5, which gives us that p of x is 0.6
[609.12s -> 617.04s]  times p0 of x plus 0.4 times p1 of x. Let us summarize the results that we have obtained.
[617.04s -> 622.48s]  A compact way to express the final result is that if p of x is proportional to the sum
[622.48s -> 629.84s]  over g theta of x, we can write p of x as the sum over w theta times p theta of x.
[629.84s -> 634.88s]  To do this, we set p theta of x to be the normalized version of g theta of x,
[635.68s -> 641.04s]  and w theta to be the normalized version of the integral over g theta of x.
[641.68s -> 647.12s]  Note that we view the integral over g theta of x as a function of theta. For instance,
[647.12s -> 653.28s]  in our example, this function took the value 3 for theta equals 0, and the value 2 for theta
[653.28s -> 659.28s]  equals 1. Normalizing this function gives us a function that takes the values 0.6 for theta
[659.28s -> 664.72s]  equals 0, and 0.4 for theta equals 1. The detailed equations for how to normalize the
[664.72s -> 670.00s]  densities and weights are given here.
