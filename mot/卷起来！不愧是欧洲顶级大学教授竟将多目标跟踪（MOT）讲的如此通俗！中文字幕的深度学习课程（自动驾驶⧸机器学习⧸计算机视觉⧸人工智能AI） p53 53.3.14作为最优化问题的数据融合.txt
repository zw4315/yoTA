# Detected language: en (p=1.00)

[0.00s -> 8.48s]  We've seen earlier that the posterior n-object mixture density is given by the expression
[8.48s -> 9.88s]  shown here.
[9.88s -> 15.44s]  For a given hypothesis, the optimal data association, theta star, is the one that
[15.44s -> 17.16s]  has maximum weight.
[17.16s -> 23.08s]  So the weight of theta star is larger than or equal to the weight of any valid
[23.08s -> 24.66s]  association.
[24.66s -> 32.02s]  The optimization problem that we wish to solve is theta star equal to the valid data association
[32.02s -> 35.42s]  that maximizes the weight of the association.
[35.42s -> 40.30s]  And this weight can be described as a product of the weights for each object.
[40.30s -> 45.84s]  We can solve for the argument that maximizes the logarithm of the product of the weights.
[45.84s -> 52.38s]  And this evaluates to the sum of the logarithm of the weights for each object's association.
[52.38s -> 57.30s]  And the reason that we can apply the logarithm and still have the same optimization problem
[57.30s -> 61.66s]  is that the logarithm is a monotonically increasing function.
[61.66s -> 67.26s]  Equivalent to maximizing the sum of the log weights is to minimize the sum of the
[67.26s -> 68.82s]  negative log weights.
[68.82s -> 73.96s]  So we will show that this minimization problem can be expressed as an assignment
[73.96s -> 80.20s]  problem with a cost matrix L and an assignment matrix A, where the cost of the assignment
[80.20s -> 86.72s]  is trace of A transposed L. And in doing so, it will allow us to apply standard combinatorial
[86.72s -> 90.30s]  optimization algorithms to solve for A star.
[90.30s -> 93.36s]  And from A star, we can obtain theta star.
