# Detected language: en (p=1.00)

[0.64s -> 6.24s]  In the previous video, we looked at a technique to express the posterior density as a weighted
[6.24s -> 12.40s]  sum of densities, one density for each hypothesis. Before we proceed and present
[12.40s -> 18.08s]  the update equations in detail, it would be good to verify that the weights and densities
[18.08s -> 22.88s]  have the interpretations that we've claimed, namely that the weights are the probabilities
[22.88s -> 28.56s]  of the different data association hypotheses and that the PDFs are the posterior densities
[28.56s -> 34.08s]  given a specific data association. Let us start by again clarifying this setting.
[34.08s -> 39.12s]  We are still only looking at a single update step. The posterior density given the measurements
[39.12s -> 43.04s]  is the prior times the likelihood. In single object tracking, the likelihood
[43.04s -> 47.84s]  involves a summation over all possible data association hypotheses.
[47.84s -> 52.96s]  In the previous video, we used g theta to denote the function inside the summation.
[52.96s -> 59.44s]  We then explained how we can express the posterior as a summation over w theta times p theta of x.
[59.44s -> 64.88s]  It was clear that w theta is a probability mass function and that p theta of x is a probability
[64.88s -> 70.16s]  density function and the measurements z. In this video, I'd like to briefly highlight
[70.16s -> 73.44s]  that these properties are reasonable from a certain perspective.
[73.44s -> 79.04s]  Omitting the time index, it is possible to show that the product of w theta and p theta
[79.04s -> 82.00s]  is the joint distribution of x and theta given z.
[82.64s -> 85.92s]  You can find a short proof of this result on the homepage.
[85.92s -> 90.16s]  Based on this result, several interesting relations follow easily.
[90.16s -> 96.00s]  First, if we integrate over x on both sides of this equation, the left hand side becomes
[96.00s -> 100.56s]  w theta since p theta of x is a PDF as a function of x.
[100.56s -> 104.24s]  Whereas the right hand side becomes the probability of theta given x.
[104.24s -> 109.84s]  That is, w theta is the posterior probability of the data of cessation hypothesis theta.
[110.48s -> 116.80s]  Second, if we divide both sides by w theta, the left hand side becomes p theta of x.
[116.80s -> 124.16s]  Whereas the right hand side becomes the joint distribution of x and theta given z divided by w theta.
[124.16s -> 128.48s]  Now, we know that w theta is the probability of theta given z.
[128.48s -> 131.68s]  Using the definition of conditional distributions,
[131.68s -> 134.96s]  this yields that p theta of x is the posterior of x
[134.96s -> 138.72s]  given the measurements and the data of cessation hypothesis theta.
[138.72s -> 142.48s]  Finally, as a sanity check, we can use the above result
[142.48s -> 148.72s]  to verify our expression for the posterior density by marginalizing both sides with respect to theta.
[148.72s -> 152.88s]  The right hand side then becomes the posterior of x given z.
[152.88s -> 159.12s]  Whereas the left hand side becomes the summation over theta of w theta times p theta of x.
[159.12s -> 161.92s]  As you can see, it all fits together very nicely.
[161.92s -> 164.96s]  And to make sense of the equations that we are about to present,
[164.96s -> 168.96s]  it is very useful to keep these interpretations in mind.
