# Detected language: en (p=1.00)

[0.00s -> 6.32s]  Sometimes in multiple object tracking, it is necessary to compute object estimates using
[6.32s -> 8.44s]  the posterior densities that we have.
[8.44s -> 12.76s]  For example, when we want to visualize the multiple object tracking results, plotting
[12.76s -> 17.80s]  the full posterior densities might make the visualization very cluttered and difficult
[17.80s -> 19.00s]  to understand.
[19.00s -> 24.32s]  But if we instead visualize just estimates, then the visualization can be easier to understand.
[24.32s -> 29.12s]  Another example of when estimates are needed is for performance evaluation.
[29.12s -> 33.16s]  In other words, a comparison to the ground truth.
[33.16s -> 39.52s]  Given a posterior density, we can extract an estimate which we denote x-hat with a subscript
[39.52s -> 41.70s]  index k given tau.
[41.70s -> 47.78s]  So we have the estimate at time k given measurements up to and including time tau.
[47.78s -> 53.72s]  Two common estimators in multiple object tracking is the expected value or mean estimate
[53.72s -> 57.74s]  and the maximum a posteriori or map estimate.
[57.74s -> 61.98s]  For the case that the posterior density is a Gaussian density, then we have that the
[61.98s -> 65.82s]  mean estimate and the map estimate are the same.
[65.82s -> 71.12s]  So given that we have computed an estimate, it's also important that we can assess
[71.12s -> 73.10s]  the quality of the estimate.
[73.10s -> 77.22s]  In other words, we need to evaluate the performance of the multiple object tracking
[77.22s -> 78.22s]  algorithm.
[78.22s -> 81.00s]  So we can illustrate this with an example.
[81.00s -> 83.22s]  Let's consider an autonomous vehicle.
[83.22s -> 85.76s]  It has some sensor with some field of view.
[85.78s -> 90.92s]  And inside this field of view, there's a car where the true state is denoted by this
[90.92s -> 92.08s]  cross sign.
[92.08s -> 98.36s]  Now, let's say that we have two different estimates marked by these plus signs.
[98.36s -> 103.00s]  Performance evaluation is about considering the question, how good are the estimates?
[103.00s -> 104.82s]  Which ones are better?
[104.82s -> 110.26s]  If we have multiple objects, which of course is the typical case in multiple object tracking,
[110.26s -> 114.68s]  then we need to ask ourselves how good are the estimates that we have for these multiple
[114.68s -> 115.80s]  objects?
[115.80s -> 120.58s]  And to evaluate the performance of multiple object tracking, we need to be able to evaluate
[120.58s -> 123.72s]  the performance of a single estimate.
[123.72s -> 127.42s]  So it's important to evaluate the performance of an estimate.
[127.42s -> 132.56s]  And a common performance measure is the mean squared error, MSE, which is defined
[132.56s -> 137.50s]  as the expected value of the difference between the estimate and the true state transposed
[137.50s -> 141.12s]  times the difference between the estimate and the true states.
[141.16s -> 145.84s]  And this is equivalent to taking the trace of the expected value of the difference between
[145.84s -> 149.80s]  the estimate and the true state times the difference between the estimate and the
[149.80s -> 151.48s]  true state transposed.
[151.48s -> 155.48s]  And to understand why these two equations are equal, you need to remember that both
[155.48s -> 158.96s]  the estimate and the true states are column vectors.
[158.96s -> 163.52s]  Given a performance measure, we can find the estimate that gives us the minimal error.
[163.52s -> 168.48s]  So for example, the minimum MSE or MMSE estimator.
[168.48s -> 172.68s]  This is given by the argument that minimizes the MSE.
[172.68s -> 176.72s]  We're going to come back to performance evaluation later in the course when we discuss
[176.72s -> 179.84s]  performance evaluation for multiple objects.
[179.84s -> 183.64s]  Okay, that concludes the review of Bayesian filtering.
[183.64s -> 185.08s]  Thank you for watching.
[185.08s -> 188.16s]  Now please try the exercises that follow this presentation.
