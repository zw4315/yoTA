# Detected language: en (p=1.00)

[0.00s -> 6.68s]  Let's say that you'd like to build a system to enable a robot like this to pick up objects.
[6.68s -> 10.44s]  So this is what the robot sees, it sees images from its camera.
[10.44s -> 13.92s]  And the goal is to output coordinates in space using some kind of machine that you're
[13.92s -> 18.48s]  going to build that will allow it to pick up objects successfully.
[18.48s -> 21.32s]  Now this is actually a pretty tricky problem to solve, because while you might think that
[21.32s -> 24.24s]  all you have to do is localize where the objects are in the picture and just output
[24.24s -> 28.36s]  their position, in reality the right way to pick up an object actually has a lot
[28.36s -> 31.28s]  of special cases and exceptions that you need to take into account.
[31.28s -> 36.22s]  So if you want to really understand the problem and design a solution manually, maybe rigid
[36.22s -> 41.88s]  objects are fairly straightforward to pick up, you just put the fingers on either side.
[41.88s -> 46.28s]  But if the object is awkwardly shaped and has a complex mass distribution, then you
[46.28s -> 49.00s]  need to really make sure you pick it up closer to the center of mass so that it
[49.00s -> 50.70s]  doesn't fall out of the gripper.
[50.70s -> 54.46s]  And if the object is soft and deformable, then an entirely different set of strategies
[54.46s -> 57.08s]  might be more appropriate, like pinching it.
[57.08s -> 61.24s]  So anytime we have a situation that has so many special cases, exceptions, and little
[61.24s -> 64.74s]  details, it makes it very appealing to use machine learning.
[64.74s -> 68.36s]  So it'd be really nice to try to set this up as a machine learning problem where instead
[68.36s -> 73.80s]  of having to manually engineer all these little exceptions, you could just run some
[73.80s -> 78.76s]  kind of general purpose machine learning procedure, maybe with convolutional neural networks,
[78.76s -> 83.68s]  to extract suitable grasp locations from an image automatically.
[83.68s -> 86.92s]  The trouble is that the standard tools that we have in supervised learning don't make
[86.92s -> 90.96s]  this very easy because they require us to somehow obtain a data set consisting of pairs
[90.96s -> 95.52s]  of images and suitable grasp locations, but the problem is that even people can't necessarily
[95.52s -> 98.90s]  determine grasp locations very well because they're really a property of the physical
[98.90s -> 103.24s]  interaction between the robot and its environment, not necessarily something that is very well
[103.24s -> 104.96s]  informed by human intuition.
[104.96s -> 109.06s]  To put it simply, we don't have a lot of experience picking things up with robot fingers.
[109.06s -> 115.32s]  So can we somehow use machine learning but avoid the need to manually supervise this process?
[115.32s -> 120.60s]  Well, what if we actually get the robots themselves to collect a lot of trials to attempt
[120.60s -> 124.56s]  different grasps and see what works and what doesn't work?
[124.56s -> 127.36s]  That in essence is the main idea behind reinforcement learning and the methods that
[127.36s -> 133.64s]  we'll discuss in this course will in some ways address different methods for tackling
[133.64s -> 135.36s]  this type of problem.
[135.36s -> 139.86s]  So in a reinforcement learning setting, we wouldn't try to manually specify, in this
[139.86s -> 144.36s]  case, where the robot should grasp objects, instead the machines themselves will collect
[144.40s -> 148.84s]  a data set that doesn't necessarily consist of good examples, but examples that are labeled
[148.84s -> 150.08s]  with our outcome.
[150.08s -> 155.38s]  So it will be images, what the robot did, and whether that led to a failure or a success.
[155.38s -> 158.16s]  More generally, we would refer to this as a reward function, the robot would be
[158.16s -> 162.18s]  rewarded for success and not for failure.
[162.18s -> 165.40s]  And then this would be used in combination with a reinforcement learning algorithm.
[165.40s -> 167.40s]  A reinforcement learning algorithm is doing something very different from
