# Detected language: en (p=1.00)

[0.00s -> 15.00s]  Okay, welcome. Welcome back. So this has zero to do with the class. Although, by the way, do you like the fact, I'm really excited that I'm now a movie star from the video in the lab the other day.
[15.00s -> 25.00s]  I totally forgot that I was on that video. Literally. So there's one other thing, you might be asking yourself, why is he showing us these silly videos?
[25.00s -> 31.00s]  And there's one other thing we're going to have you do in class this week, which is like a five minute survey on the videos.
[31.00s -> 35.00s]  It's actually part of a research project. You will find out more about it in lab this week.
[35.00s -> 43.00s]  What else do I want to show you? Oh, another video. This has nothing to do with class. I just thought it was kind of funny.
[43.00s -> 51.00s]  So last week, let me turn the lights off. Last week, not last week, recently, my wife and I moved into a new house.
[51.00s -> 58.00s]  We had this little back fenced in area. And every day, I would go back there and there'd be a little thing dug under the fence.
[58.00s -> 62.00s]  Something is dug under the fence and gone in the background. And so I have a camera out there now.
[62.00s -> 72.00s]  You want to see what we found? Let's see. Yeah, you can kind of see it from here. There it is.
[72.00s -> 76.00s]  Yeah, really cute. The problem is, if we let the dogs back there, we're really in trouble.
[76.00s -> 84.00s]  If that skunk will win the war, I'm sure. But anyway, that was what I found. When you put cameras up, you find cute things.
[84.00s -> 88.00s]  So I found out I put a bunch of boards down below and it hasn't come back.
[88.00s -> 96.00s]  Although I hear skunks are really, really good at digging and they could care less about boards.
[97.00s -> 107.00s]  So we'll see what happens. We will see what happens. Okay, let's see. How is assignment seven going?
[107.00s -> 114.00s]  Almost there on this one, hopefully. What does it do? Tonight? Tomorrow night. Okay.
[114.00s -> 120.00s]  I do have office hours right after this for about an hour if you want to stop by, if you're having some particular troubles.
[120.00s -> 129.00s]  And then we are on to the final assignment, which is what we're going to talk about today completely and kind of get you up to speed on the final assignment,
[129.00s -> 139.00s]  which I briefly mentioned last week called MapReduce. And MapReduce is an algorithm that we will dig into a little bit today.
[139.00s -> 145.00s]  And then I'll talk to you more about the details of the assignment itself and how you can do it.
[146.00s -> 150.00s]  There are a lot of moving parts. I say that for all these assignments. There's a lot of parts of this one.
[150.00s -> 155.00s]  There's four different tasks again, but it is broken down into tasks.
[155.00s -> 161.00s]  And we'll take a look at a little bit of the code today, too, and I'll point out some highlights and then we'll get going on that.
[161.00s -> 168.00s]  The assignment MapReduce assignment technically is out already. I posted it a little earlier today.
[168.00s -> 172.00s]  So if you want to get working on it, if you haven't, if you've already finished the other one, that's OK.
[172.00s -> 177.00s]  It's due ostensibly next Wednesday, which is the last day of class.
[177.00s -> 181.00s]  I'm going to let anybody who wants to hand it in Thursday do so without any penalty.
[181.00s -> 185.00s]  So you can figure out what that means in the big picture anyway.
[185.00s -> 191.00s]  But just if you want, you can turn it so the no penalties will start until Friday of next week.
[191.00s -> 194.00s]  Yeah, Friday of next week, which would be the 90 percent and then 60 percent for Saturday.
[194.00s -> 200.00s]  So you've got a little extra time for me to use that, but it is technically due Wednesday.
[200.00s -> 203.00s]  All right. Let's chat about this MapReduce algorithm.
[203.00s -> 215.00s]  Now, what I didn't tell you the other day about MapReduce is that MapReduce is a it's an algorithm that was used very extensively at Google.
[215.00s -> 221.00s]  It actually was invented at Google, although it's very similar to things that have been invented in the past.
[221.00s -> 227.00s]  It's not like they completely reinvented the entire thing before, but it was used at Google very extensively.
[227.00s -> 239.00s]  It's also used in a system called Hadoop, which is which is a system that uses MapReduce to solve these big data problems.
[239.00s -> 250.00s]  And what the idea is for MapReduce is you take this data you have to analyze and you farm it out to a bunch of servers and do this map stage where you're taking all these different parts.
[250.00s -> 257.00s]  You're taking these kind of this big set of data, mapping it out to all these different servers, all the different parts of it.
[257.00s -> 261.00s]  And then on the servers, you're doing a reduce to bring it back.
[261.00s -> 268.00s]  You're actually doing this kind of filtering sort of thing where you're you're combining a bunch of things and then sending it back to the main server.
[268.00s -> 273.00s]  So it's it utilizes, in our case, the myth machines.
[273.00s -> 282.00s]  But you can use Hadoop or you can use MapReduce on a giant set of servers if you want with thousands and thousands and thousands of processors.
[282.00s -> 292.00s]  What's nice about it is if you build your program well, and ours aren't necessarily for that purpose, but you build it well, it's very robust for computers going down.
[292.00s -> 300.00s]  So if you go to a Facebook or a Google data center, they have tens of thousands of computers in there.
[300.00s -> 309.00s]  And every single day, many of those hard drives or computers will actually break because tens of thousands, when you scale up, things tend to break.
[309.00s -> 315.00s]  And there's literally people there who are hired to walk around with a cart of hard drives or SSDs or whatever now.
[315.00s -> 321.00s]  And they look at the little computer and it says go to this row and this column in the data center and replace the hard drive.
[321.00s -> 322.00s]  And that's because it broke.
[322.00s -> 332.00s]  And some of your data might be on those broken things, but you have to be robust enough so that the data is actually spread out across a number of systems.
[332.00s -> 337.00s]  But it's the same idea with doing an algorithm that's using tens of thousands of computers.
[337.00s -> 343.00s]  You need to write your application such that if one of the computers goes down, you don't have to restart the entire process.
[343.00s -> 351.00s]  That would be deadly because there's no way something with 60,000 computers could last for more than an hour without one of those computers breaking.
[351.00s -> 352.00s]  So you have to be robust about that.
[352.00s -> 359.00s]  And MapReduce allows you to do those things where you can be robust, although that's not really the point of our assignment.
[359.00s -> 363.00s]  So, I did this, I started this the other day.
[363.00s -> 367.00s]  I'm going to kind of review just to get us back up to speed of where it goes.
[367.00s -> 370.00s]  And I kind of already said this.
[370.00s -> 373.00s]  You've got the map part and the reduced part.
[373.00s -> 379.00s]  And the map part takes the data and comes up with some intermediate result.
[380.00s -> 387.00s]  Now, the intermediate result we're going to have, the example, and this is a classic example, of taking a text of words
[387.00s -> 399.00s]  and basically taking each word and putting it in a list in some file with a little one after it saying there is one word with this number.
[399.00s -> 402.00s]  And why the one? It's so you can add it up later.
[402.00s -> 405.00s]  You could ignore, you could not have the one and just assume it's there, and that's fine too.
[406.00s -> 414.00s]  But in this case, there's going to be an intermediate result, which we'll see, which is just a word and then the number one next to it saying that's what was next.
[414.00s -> 416.00s]  And this is not sorted at all at this point.
[416.00s -> 423.00s]  Then you do this sorting stage where you might take a file and sort all the words.
[423.00s -> 427.00s]  So it'll say like and one, and one, and one, and one.
[427.00s -> 428.00s]  It's all sorted.
[428.00s -> 434.00s]  And then you run a group by key, which basically goes down the list, counts up all the ands,
[434.00s -> 438.00s]  and then writes one and and the total sum, and then does that for all the other words.
[438.00s -> 447.00s]  And then you have to reduce it, which basically collates all those results and then sends them back to the original server.
[447.00s -> 449.00s]  Okay, so that's the big process.
[449.00s -> 452.00s]  The mapping stage depends on what you're mapping.
[452.00s -> 455.00s]  The reducing stage depends on what you're reducing.
[455.00s -> 460.00s]  But the sorting and group by key, if you do the same for every problem, then they're always going to be the same.
[460.00s -> 463.00s]  So you never need to redo those parts of it.
[464.00s -> 468.00s]  Okay, and we'll talk in more detail as we go through this.
[468.00s -> 471.00s]  So here's the little thing now.
[471.00s -> 473.00s]  There's a couple Python programs that we're going to show you.
[473.00s -> 476.00s]  And by the way, this isn't listed in your assignment itself.
[476.00s -> 481.00s]  But if you want to use some of these pythons in your code, you are welcome to.
[481.00s -> 484.00s]  So you don't have to rewrite some of these algorithms yourself.
[484.00s -> 485.00s]  So that's actually okay.
[485.00s -> 491.00s]  It doesn't help the mapping and reducing part, but it helps the actual sorting and so forth.
[491.00s -> 492.00s]  You can use these.
[493.00s -> 498.00s]  But what this does is basically this file goes through a standard in.
[498.00s -> 501.00s]  And it finds all the lines.
[501.00s -> 508.00s]  And then it splits them into by spaces or whatever.
[508.00s -> 515.00s]  And then for each token in that, it will actually make the word lowercase.
[515.00s -> 520.00s]  And then match it and basically print out the word and then print a one next to it.
[520.00s -> 521.00s]  That's all this part is doing.
[521.00s -> 522.00s]  That's all this file is doing.
[522.00s -> 523.00s]  Okay?
[523.00s -> 524.00s]  How do you run it?
[524.00s -> 526.00s]  You say something like this.
[526.00s -> 528.00s]  And we will go do that.
[528.00s -> 529.00s]  Let's see.
[529.00s -> 532.00s]  We need to go in the right folder.
[532.00s -> 535.00s]  You might want to write down some of these.
[535.00s -> 541.00s]  You might want to have these files handy because you will be able to call them without copying them into your folder.
[541.00s -> 543.00s]  You'll see how that works in a minute.
[543.00s -> 544.00s]  Let's see.
[544.00s -> 547.00s]  Spring and then live MapReduce.
[547.00s -> 548.00s]  Okay.
[548.00s -> 549.00s]  Okay.
[549.00s -> 553.00s]  So let's say cat Anna Karenina.
[553.00s -> 558.00s]  And we are going to pipe it through dot slash word count mapper.
[558.00s -> 559.00s]  Okay.
[559.00s -> 560.00s]  And that's all it's doing.
[560.00s -> 561.00s]  Right?
[561.00s -> 562.00s]  It's taking every word and just putting a one next to it.
[562.00s -> 568.00s]  Now, most of the time you would either have this itself go into a file because you're going to do lots of these.
[568.00s -> 571.00s]  Or you would have it, I mean, you probably wouldn't have it just print to the screen.
[571.00s -> 573.00s]  You'd probably have it piped out to some file.
[573.00s -> 574.00s]  That's all it's doing.
[574.00s -> 575.00s]  Take each word.
[575.00s -> 576.00s]  Say one.
[576.00s -> 577.00s]  Word one.
[577.00s -> 578.00s]  That's that.
[578.00s -> 579.00s]  Okay.
[579.00s -> 580.00s]  All right.
[580.00s -> 589.00s]  So after we do that, okay, then you've got this group by key situation where you're trying to take the output and then just sort it.
[589.00s -> 597.00s]  So in this case, all we need to do is just, if we're doing this on the command line, just pipe it through sort and it will do that.
[597.00s -> 604.00s]  And so you can see zoological happened twice, but that's what the end result should have that in there as a two in the end.
[604.00s -> 611.00s]  But now we're going to be able to run through this, use this other program to run through and just grab the, and add them up.
[611.00s -> 615.00s]  And that's the next portion of this.
[615.00s -> 616.00s]  Okay.
[616.00s -> 617.00s]  Okay.
[617.00s -> 626.00s]  So this is another, this is kind of a cool little Python script, by the way, that is not, it's a little bit dense, as it turns out.
[626.00s -> 632.00s]  It's not really that hard to understand once you get it, but it's using things that aren't necessarily, aren't in C++.
[632.00s -> 649.00s]  For instance, this yield, which is kind of, basically this function is used in another function you'll see down here to basically go through each line and grab the first item, which is the word,
[649.00s -> 658.00s]  and then join all the words that are the same using the ones and counting them all up.
[658.00s -> 664.00s]  So that's basically what it's doing, and then it's printing out the actual word and then, oh sorry, this one's not even counting.
[664.00s -> 668.00s]  This one's just printing, taking the word and then putting one, one, one, one, one, one, one.
[668.00s -> 669.00s]  That's what this one's doing.
[669.00s -> 670.00s]  Okay.
[670.00s -> 672.00s]  So let's see what happens when we do this.
[672.00s -> 674.00s]  And if you want to look at the details of the program, you can.
[674.00s -> 684.00s]  But this one would be, then we do this and then do group by, oops, group by key.
[684.00s -> 688.00s]  And this one says, oh, okay, now it's got, it's kind of one step at a time.
[688.00s -> 694.00s]  Now, again, you can probably combine some of these together if you really wanted to, but this is the main algorithm.
[694.00s -> 697.00s]  And if you do it this way, it will work for lots of different problems.
[697.00s -> 704.00s]  So it's not like you have to, if you format all your MapReduce jobs in this format, then it always works.
[704.00s -> 707.00s]  This might not be the case if we did it in some other way.
[707.00s -> 713.00s]  But for instance, your has this many times of, it was in that document.
[713.00s -> 714.00s]  Okay.
[714.00s -> 722.00s]  So once you've gotten that, then you need to write another program, which is in this case word count reducer,
[722.00s -> 730.00s]  which is another one of these strange ones, but it basically does the same sort of thing where it breaks the,
[730.00s -> 737.00s]  it takes each line, gets the first one, which is the word, the first word, the first space delimited value,
[737.00s -> 741.00s]  which is the word, and then for all the other space delimited values and all just ones,
[741.00s -> 743.00s]  and it's going to sum them all up.
[743.00s -> 744.00s]  Okay.
[744.00s -> 750.00s]  So it basically does the sum of all the rest and then prints out the word and then the sum,
[750.00s -> 751.00s]  and there's your answer.
[751.00s -> 755.00s]  And then that is what would get sent back to the server in this case.
[755.00s -> 760.00s]  So remember what we're doing here is not a MapReduce across many servers.
[760.00s -> 762.00s]  It's just on one computer.
[762.00s -> 763.00s]  So what would that one be?
[763.00s -> 771.00s]  That would be dot slash word count reducer, and hopefully there you go.
[771.00s -> 774.00s]  And notice zoological has two words in there and so forth.
[774.00s -> 777.00s]  Yourself has 27 and so forth.
[777.00s -> 781.00s]  And that's the big idea for MapReduce.
[781.00s -> 782.00s]  Okay.
[782.00s -> 789.00s]  Map things out to word one, one, one, one, one, collate all the words and then count up, sum all the words,
[789.00s -> 791.00s]  and then basically send the data back.
[791.00s -> 797.00s]  Problem is you have to do it distributatively, which is, which is the part that that's the assignment's about.
[797.00s -> 798.00s]  Yeah.
[798.00s -> 803.00s]  So the one, one, one, one seems like O on one program, you can take that out and just sum it in the second step.
[803.00s -> 810.00s]  But is it because we're distributing this that they just can only tack on one because like each process won't have access?
[810.00s -> 811.00s]  Yeah, that's a good way of putting it.
[811.00s -> 812.00s]  Yeah.
[812.00s -> 816.00s]  So Sam's comment is very good where the reason we're doing the one, one, one, one in here,
[816.00s -> 819.00s]  it doesn't seem to make sense because you could have just summed it right then, right?
[819.00s -> 820.00s]  Because it's one thread doing it all.
[820.00s -> 825.00s]  But when multiple threads are all trying to contribute to one file, let's say,
[825.00s -> 829.00s]  it's going to, each one has to only contribute a one, so it just tacks one on the end.
[829.00s -> 832.00s]  Now, could it read it in, read the value, and then put it again?
[832.00s -> 833.00s]  Sure.
[833.00s -> 838.00s]  But I mean, there's, in this sense, this is the most generic way to do it.
[839.00s -> 846.00s]  In this pipeline that you have on the previous slide, where do the threads rejoin?
[846.00s -> 847.00s]  Yeah, yeah, yeah.
[847.00s -> 850.00s]  So this is, remember, this isn't the one, this is now a single threaded one.
[850.00s -> 852.00s]  So there's no, where would it happen?
[852.00s -> 855.00s]  They would rejoin under the reduce phase.
[855.00s -> 862.00s]  Basically, the reduce would take its individual, its individual parts, reduce them down,
[862.00s -> 867.00s]  and then when the last one finishes, it basically tells the server, hey, we're all done, grab this file.
[867.00s -> 869.00s]  And then the server goes, okay, I've got the file now.
[869.00s -> 871.00s]  So that's how it works.
[871.00s -> 874.00s]  For the assignment, here's the nice thing about this assignment.
[874.00s -> 878.00s]  This is not necessarily true across the data centers of the world,
[878.00s -> 882.00s]  but for our assignment, we have however many myths that we have,
[882.00s -> 886.00s]  10 or 12 myths or 15 or whatever there are, that many myths,
[886.00s -> 889.00s]  they all share the same file system.
[889.00s -> 893.00s]  So that's the nice part about this, is that if you ask for a file,
[893.00s -> 898.00s]  you can use one path, and it gives you that file off the file system no matter which myth you're on.
[898.00s -> 903.00s]  I mean, you do this every day when you SSH into a myth and go to your CS110 folder.
[903.00s -> 907.00s]  It's the same folder on multiple different myths,
[907.00s -> 911.00s]  because really it's the same underlying distributed file system.
[911.00s -> 917.00s]  So that's the nice thing about this assignment, is yes, we are using multiple myth machines to do this,
[917.00s -> 919.00s]  but we're using one single file system.
[919.00s -> 925.00s]  Now, you might think, oh, how could I do this if we didn't have shared file systems?
[925.00s -> 927.00s]  Well, you just have to pass the data back and forth every time.
[927.00s -> 931.00s]  So if you wanted to say, hey, go do this chunk of data,
[931.00s -> 934.00s]  you would first have to send the data across to that machine.
[934.00s -> 938.00s]  When it's all done, you'd have to gather the data back again.
[938.00s -> 942.00s]  And if you've ever taken, or maybe some of you will take a parallel processing class,
[942.00s -> 944.00s]  you'll see where that becomes important.
[944.00s -> 947.00s]  Why is that a big deal?
[947.00s -> 955.00s]  Well, sometimes it's too expensive to keep the entire file system synchronized across many data centers.
[955.00s -> 961.00s]  It's not that bad these days, but to keep it all synchronized across many data centers is not really that efficient.
[961.00s -> 966.00s]  So it's easier actually to send the data and retrieve it back versus just say, hey, read your local data
[966.00s -> 970.00s]  and I'll get the response once it gets output to the files.
[970.00s -> 972.00s]  So that's that.
[972.00s -> 977.00s]  Okay, so questions on the MapReduce algorithm itself.
[977.00s -> 981.00s]  Besides the question about when do these parts happen.
[981.00s -> 984.00s]  Anybody else have any questions on this?
[984.00s -> 985.00s]  Yes, please.
[985.00s -> 994.00s]  So the group by key, let's just back up one second.
[994.00s -> 996.00s]  Let's see what the group by key does.
[996.00s -> 1001.00s]  The group by key just puts all these ones in there and it hasn't actually collated them yet.
[1001.00s -> 1003.00s]  It hasn't added some to them all up.
[1003.00s -> 1007.00s]  So in our case, the reducer is just doing the summing part.
[1007.00s -> 1009.00s]  That's all it's doing.
[1009.00s -> 1011.00s]  Why do they have to be separate?
[1011.00s -> 1017.00s]  I think it kind of comes down to this idea of many files will be adding to the one,
[1017.00s -> 1021.00s]  like maybe updating one file in particular, or they'll be updating their own files,
[1021.00s -> 1024.00s]  but many threads might be doing that on a machine,
[1024.00s -> 1027.00s]  and so therefore you don't want to try to do the summing at the same time you're adding up.
[1027.00s -> 1029.00s]  It might just be slower.
[1029.00s -> 1035.00s]  Adding a one is easier than saying I'm going to now get the value back and sum it up and so forth.
[1035.00s -> 1040.00s]  I think that's probably the main reason there.
[1040.00s -> 1048.00s]  So let's look at the actual assignment.
[1048.00s -> 1051.00s]  So this assignment, as I said already, is due next Wednesday,
[1051.00s -> 1054.00s]  although there won't be any late days until starting Friday,
[1054.00s -> 1057.00s]  so you can hand in Thursday without any penalty.
[1057.00s -> 1060.00s]  It obviously is going to do the MapReduce algorithm.
[1060.00s -> 1065.00s]  It's going to use the myth machine, so you are going to start on one myth machine,
[1065.00s -> 1067.00s]  run your basic program on the myth machine,
[1067.00s -> 1075.00s]  and then it will basically SSH and launch a program via an SSH.
[1075.00s -> 1077.00s]  You can look in the code and see how it does that,
[1077.00s -> 1081.00s]  and then that program will call back to the server and say,
[1081.00s -> 1084.00s]  please give me some data to tell me what to do.
[1084.00s -> 1091.00s]  So basically the one program is going to farm out all these processes to different myths,
[1091.00s -> 1094.00s]  and then each one will call back to the main myth and say,
[1094.00s -> 1096.00s]  hey, give me some work to do.
[1096.00s -> 1099.00s]  Most of this is already written for you, it turns out.
[1099.00s -> 1101.00s]  There's a lot going on there.
[1101.00s -> 1104.00s]  So we've given you a pretty robust start to the program.
[1104.00s -> 1109.00s]  What that means is that there's going to be a lot of code you have to understand beforehand.
[1109.00s -> 1111.00s]  Now, this has been true in this whole class,
[1111.00s -> 1114.00s]  and I was talking to somebody in office hours, I don't see that person here,
[1114.00s -> 1117.00s]  I was talking to somebody in office hours a couple days ago
[1117.00s -> 1120.00s]  about this idea that we have a ton of code to read through,
[1120.00s -> 1123.00s]  and this happens wherever you go.
[1123.00s -> 1127.00s]  How many people have done internships already in CS in some form or another?
[1127.00s -> 1130.00s]  Have you found that you get to this place and you're like,
[1130.00s -> 1133.00s]  okay, your job is going to be to do some updates to the code base,
[1133.00s -> 1136.00s]  and you look at the code base and it's a billion lines of code.
[1136.00s -> 1138.00s]  Not even kidding, it's a billion lines of code.
[1138.00s -> 1139.00s]  You've got to figure out how to do that,
[1139.00s -> 1143.00s]  and every place you work has a different way they format the code,
[1143.00s -> 1145.00s]  and they have different tools they use,
[1145.00s -> 1147.00s]  and they have different ways to make files,
[1147.00s -> 1149.00s]  and they have different ways to do code reviews,
[1149.00s -> 1151.00s]  and you have to learn all this stuff,
[1151.00s -> 1154.00s]  and it's very similar to going in and saying,
[1154.00s -> 1157.00s]  here's a bunch of code that you're going to try to modify in some way.
[1157.00s -> 1160.00s]  You've got to understand the code more or less first.
[1160.00s -> 1163.00s]  So if you're thinking about, oh, there's a lot of code to read,
[1163.00s -> 1167.00s]  we're not necessarily doing this just for kits.
[1167.00s -> 1171.00s]  We're doing it to kind of get you ready for when you have to do this in real life.
[1171.00s -> 1173.00s]  So this is the robust start.
[1173.00s -> 1174.00s]  We give you a lot of code to look through,
[1174.00s -> 1176.00s]  and we're going to look through some of it in a few minutes.
[1176.00s -> 1178.00s]  There are four tasks.
[1178.00s -> 1180.00s]  Handle each one just like the others in order,
[1180.00s -> 1182.00s]  and it's probably the best way to go.
[1182.00s -> 1185.00s]  Well, one thing you will be adding, of course, is a thread pool.
[1185.00s -> 1191.00s]  So adding a thread pool will make it so that your main distributor program
[1191.00s -> 1192.00s]  can just launch all these threads
[1192.00s -> 1197.00s]  and not have to worry about the threading issue.
[1197.00s -> 1199.00s]  And then each one of the workers can also have multiple threads
[1199.00s -> 1201.00s]  when it gets more work to do.
[1201.00s -> 1203.00s]  So that's kind of a cool part of it.
[1203.00s -> 1204.00s]  Okay?
[1204.00s -> 1206.00s]  And you're going to be doing the reduced part.
[1206.00s -> 1210.00s]  The one part that we've really left up to you is the reduced stage.
[1210.00s -> 1213.00s]  We've given you a pretty open-ended part.
[1213.00s -> 1218.00s]  I mean, if you look at, we'll look at this in a minute as well,
[1218.00s -> 1220.00s]  but let's see.
[1220.00s -> 1224.00s]  If we look at, let me find it here, hang on.
[1224.00s -> 1228.00s]  Assignments, assignment eight,
[1228.00s -> 1232.00s]  MapReduceReducer.cc.
[1232.00s -> 1234.00s]  Okay, there.
[1234.00s -> 1236.00s]  There's your function so far.
[1236.00s -> 1238.00s]  Like, we haven't given you much, right?
[1238.00s -> 1240.00s]  We've given you exactly zero, right, for that.
[1240.00s -> 1243.00s]  So this is your part, your place to shine in this case,
[1243.00s -> 1245.00s]  where you write the reducer.
[1245.00s -> 1246.00s]  But once you understand what has to happen,
[1246.00s -> 1249.00s]  you go, oh, okay, all these distributed files are going to be in this format.
[1249.00s -> 1253.00s]  I need to now collate that and then get them back to the server.
[1253.00s -> 1254.00s]  It's doable.
[1254.00s -> 1257.00s]  Okay, but we'll get there as we go through this.
[1257.00s -> 1258.00s]  Okay?
[1258.00s -> 1261.00s]  All right, so that is that.
[1261.00s -> 1263.00s]  Let's actually talk about the details,
[1263.00s -> 1266.00s]  because you've got to get up to speed on some of these details as well.
[1266.00s -> 1269.00s]  When you clone the assignment,
[1269.00s -> 1272.00s]  okay, in fact, I'm going to do, let's see,
[1273.00s -> 1277.00s]  rm-r, which one do I want?
[1277.00s -> 1279.00s]  I want, is it files?
[1279.00s -> 1280.00s]  Yes.
[1280.00s -> 1281.00s]  I hope it's files, but it's not.
[1281.00s -> 1282.00s]  I'm in trouble.
[1282.00s -> 1284.00s]  So when you start your assignment,
[1284.00s -> 1286.00s]  yeah, rm-rf is back.
[1286.00s -> 1287.00s]  Never, never do this.
[1287.00s -> 1290.00s]  rm-rf star, that would be really bad.
[1290.00s -> 1293.00s]  rm-rf slash star will, like, destroy things.
[1293.00s -> 1297.00s]  Especially if you're a super user, don't do that.
[1297.00s -> 1299.00s]  Trust me, I've done stuff like that before,
[1299.00s -> 1302.00s]  where you accidentally do that, and it just destroys your day.
[1302.00s -> 1303.00s]  I can tell you that.
[1303.00s -> 1305.00s]  So anyway, when you start out,
[1305.00s -> 1307.00s]  you don't have,
[1307.00s -> 1311.00s]  all the files are going to end up in this one particular directory.
[1311.00s -> 1313.00s]  This will help you when you're doing debugging.
[1313.00s -> 1317.00s]  And so what you do is you type make directories,
[1317.00s -> 1320.00s]  and it creates the directories.
[1320.00s -> 1323.00s]  One's called files slash intermediate,
[1323.00s -> 1325.00s]  one's called files slash output.
[1325.00s -> 1328.00s]  And it creates, it deletes them first,
[1328.00s -> 1330.00s]  and then it creates, I guess it could have deleted them that way,
[1330.00s -> 1332.00s]  but it creates them for you.
[1332.00s -> 1334.00s]  And that's where all the data's going to go.
[1334.00s -> 1338.00s]  And then every time you run your program,
[1338.00s -> 1343.00s]  you should clean that folder out by just saying make file three.
[1343.00s -> 1347.00s]  And what that does is it just deletes all the files in there for you.
[1347.00s -> 1348.00s]  And why is that?
[1348.00s -> 1351.00s]  Because you don't want the files that are already there
[1351.00s -> 1355.00s]  to be corrupt, to be there when you're trying to do a new batch of data.
[1355.00s -> 1358.00s]  So always remember to do make file three.
[1358.00s -> 1360.00s]  You only have to do this one once, but you have to do this one
[1360.00s -> 1362.00s]  pretty much every time before you run the program.
[1362.00s -> 1364.00s]  You should do that.
[1364.00s -> 1368.00s]  There are actually five different executables
[1368.00s -> 1370.00s]  that this program entails.
[1370.00s -> 1372.00s]  I've seen people go, what are you talking about?
[1372.00s -> 1374.00s]  It's not that bad.
[1374.00s -> 1379.00s]  They are the MapReduce overview program.
[1379.00s -> 1382.00s]  That's like the one that's going to coordinate everything.
[1382.00s -> 1386.00s]  You've got the MapReduce mapper, which does the mapping.
[1386.00s -> 1390.00s]  You've got the MapReduce reducer, which does the reducing.
[1390.00s -> 1392.00s]  And this is coordinating these.
[1392.00s -> 1394.00s]  Those are the ones that are coordinating all this.
[1394.00s -> 1396.00s]  You've also got a program,
[1396.00s -> 1398.00s]  we've written these two programs for you,
[1398.00s -> 1402.00s]  the word count mapper and the word count reducer.
[1402.00s -> 1406.00s]  Those are similar to the ones that you've already seen in the Python.
[1406.00s -> 1409.00s]  So those are already built there.
[1410.00s -> 1414.00s]  You will have to modify these other ones to make it actually work.
[1418.00s -> 1421.00s]  So because of the way you're doing this,
[1421.00s -> 1424.00s]  you might think, oh, well, how many threads do I need
[1424.00s -> 1426.00s]  and how many different servers do I need and this and that.
[1426.00s -> 1430.00s]  You have a file that's a configuration file.
[1430.00s -> 1433.00s]  In fact, if we look at it right now,
[1433.00s -> 1437.00s]  we will look at odysseyful.cfg.
[1440.00s -> 1443.00s]  Hang on.
[1443.00s -> 1445.00s]  I swear I hit, there we go.
[1445.00s -> 1449.00s]  Okay, let's see, odysseyful.cfg.
[1449.00s -> 1451.00s]  So here's what's in that file.
[1451.00s -> 1453.00s]  It's always going to look exactly like this in a sense.
[1453.00s -> 1456.00s]  You tell it, you have a key that says,
[1456.00s -> 1460.00s]  hey, what file is going to do the actual mapping of the words?
[1460.00s -> 1462.00s]  Well, it's going to be this word count mapper program.
[1462.00s -> 1464.00s]  What file is going to do the reducer, word count reducer?
[1464.00s -> 1467.00s]  How many mappers are we going to have?
[1467.00s -> 1469.00s]  We're going to have eight mappers.
[1469.00s -> 1472.00s]  That's basically eight threads that are going to be on different servers doing their thing.
[1472.00s -> 1474.00s]  And how many different reducers are we going to have?
[1474.00s -> 1476.00s]  We're going to have four reducers.
[1476.00s -> 1478.00s]  Why is it that number, those numbers?
[1478.00s -> 1479.00s]  Kind of arbitrary.
[1479.00s -> 1481.00s]  Normally you'd probably make them equivalent,
[1481.00s -> 1485.00s]  but maybe you know that there's more work to be done doing the mapping part
[1485.00s -> 1488.00s]  and you want more horsepower to do that.
[1488.00s -> 1489.00s]  Might be one of them.
[1489.00s -> 1491.00s]  And then it says what the input path is.
[1491.00s -> 1495.00s]  In this case, it's this odysseyful folder.
[1495.00s -> 1496.00s]  I'll show you what's in there in a second.
[1496.00s -> 1500.00s]  And then you tell what the intermediate path is.
[1500.00s -> 1503.00s]  The intermediate path is after the mappers get done.
[1503.00s -> 1506.00s]  They will put a whole bunch of files in this intermediate path,
[1506.00s -> 1507.00s]  and we'll look at those.
[1507.00s -> 1510.00s]  And then you have an output path,
[1510.00s -> 1513.00s]  which is where the final results go.
[1513.00s -> 1515.00s]  Okay, and we'll see that as well.
[1515.00s -> 1519.00s]  Let's go look at the odysseyful folder.
[1519.00s -> 1524.00s]  If we go to samples and then odysseyful,
[1525.00s -> 1528.00s]  we've got in here, we've already done this for you
[1528.00s -> 1533.00s]  where we've broken up the Odyssey textbook or text into 12 different files.
[1533.00s -> 1535.00s]  Okay, and let's look at one.
[1535.00s -> 1538.00s]  0007.input.
[1538.00s -> 1545.00s]  By the way, before you get to this part,
[1545.00s -> 1549.00s]  see how it's like four zeros and a seven and three zeros and 11?
[1549.00s -> 1551.00s]  You have to write that part yourself.
[1551.00s -> 1556.00s]  How do I figure out how to make a string that has the number of leading zeros that add up to five?
[1556.00s -> 1558.00s]  It's not really that hard. Don't overthink it.
[1558.00s -> 1560.00s]  But just know that you're going to have to do that and go,
[1560.00s -> 1562.00s]  oh, okay, this is the part where it doesn't do it for you.
[1562.00s -> 1564.00s]  And people get stuck on that and go, oh, why isn't it doing that?
[1564.00s -> 1565.00s]  You've just got to do it yourself.
[1565.00s -> 1567.00s]  But anyway, let's look at one of these files.
[1567.00s -> 1569.00s]  This is what it is, just part of the Odyssey.
[1569.00s -> 1572.00s]  Okay, and you can read through it.
[1572.00s -> 1573.00s]  And this is the thing.
[1573.00s -> 1576.00s]  We've broken it into 12 different files
[1576.00s -> 1580.00s]  because we're basically going to farm each one of those files
[1580.00s -> 1584.00s]  off to a different server to do their thing.
[1584.00s -> 1586.00s]  That's how that one works.
[1586.00s -> 1591.00s]  So as you're going along, you can see,
[1591.00s -> 1593.00s]  you won't really have to modify this too much.
[1593.00s -> 1596.00s]  If you want, there's an Odyssey, what is it?
[1596.00s -> 1598.00s]  Odyssey partial or something?
[1598.00s -> 1603.00s]  Yeah, Odyssey partial, which is many fewer files.
[1603.00s -> 1605.00s]  So if you're debugging, it might be better to do this one
[1605.00s -> 1607.00s]  so it doesn't take forever.
[1608.00s -> 1610.00s]  Just keep your eye on changing that.
[1610.00s -> 1612.00s]  You just need to change the cfg file
[1612.00s -> 1617.00s]  or you have to run this Odyssey partial.cfg file when you do this.
[1617.00s -> 1619.00s]  Okay, all right.
[1619.00s -> 1622.00s]  And those are the files I just saw, I already showed you.
[1622.00s -> 1625.00s]  So let's actually run this.
[1625.00s -> 1627.00s]  Okay, so when you're running this,
[1627.00s -> 1629.00s]  I'm going to copy this line because it's kind of long.
[1629.00s -> 1632.00s]  You will get used to copy pasting either this one
[1632.00s -> 1634.00s]  or the one for your program.
[1634.00s -> 1636.00s]  Ah, maybe I won't.
[1636.00s -> 1638.00s]  Almost, and there we go.
[1638.00s -> 1642.00s]  Okay, so I've done make file free.
[1642.00s -> 1644.00s]  I've already done that.
[1644.00s -> 1647.00s]  No, I haven't, or I have, but I've got to be in the right folder.
[1647.00s -> 1649.00s]  Make file free, there we go.
[1649.00s -> 1651.00s]  And then we're going to run this line.
[1651.00s -> 1653.00s]  Now here's what's going on here.
[1653.00s -> 1658.00s]  The first part of this is the MapReducer coordinator.
[1658.00s -> 1661.00s]  That's this part, where is it?
[1661.00s -> 1662.00s]  This part right here.
[1662.00s -> 1664.00s]  We're going to just run the solution when we see it.
[1664.00s -> 1668.00s]  And then the mapper is going to be mr,
[1668.00s -> 1672.00s]  the mrm mapper solution.
[1672.00s -> 1675.00s]  The reducer is going to be mrr solution,
[1675.00s -> 1677.00s]  and then the config file is going to be this.
[1677.00s -> 1678.00s]  And then you go to say,
[1678.00s -> 1680.00s]  so why didn't we just put these things
[1680.00s -> 1682.00s]  inside the configuration you could have,
[1682.00s -> 1685.00s]  but this is actually a pretty generic way to do this,
[1685.00s -> 1687.00s]  where it's a little more generic in this sense.
[1687.00s -> 1689.00s]  You could use some other file here,
[1689.00s -> 1692.00s]  and keep the same config file.
[1692.00s -> 1696.00s]  So that's just what we're doing in this case.
[1696.00s -> 1697.00s]  Okay, let's run this,
[1697.00s -> 1700.00s]  and you will see lots of stuff flying by.
[1700.00s -> 1705.00s]  Okay, so all of this log data is not bad to use
[1705.00s -> 1707.00s]  if you need to figure out what's going on,
[1707.00s -> 1708.00s]  but there's lots of it here.
[1708.00s -> 1710.00s]  And it is eventually,
[1710.00s -> 1712.00s]  this is the full version with threading and all,
[1712.00s -> 1714.00s]  so it's actually relatively quick,
[1714.00s -> 1716.00s]  goes through and eventually it says,
[1716.00s -> 1718.00s]  okay, here's all the output files,
[1718.00s -> 1720.00s]  and what they hash to,
[1720.00s -> 1721.00s]  and it's hashing the output files
[1721.00s -> 1722.00s]  so that you can check the answer.
[1722.00s -> 1724.00s]  Remember all the way back to the first assignment,
[1724.00s -> 1726.00s]  or the file assignment?
[1726.00s -> 1727.00s]  Same sort of thing where you can go,
[1727.00s -> 1729.00s]  oh, mine, the hash is the same,
[1729.00s -> 1730.00s]  we're good to go.
[1730.00s -> 1732.00s]  Okay, so that's what you're gonna wanna do there.
[1732.00s -> 1734.00s]  And as I said,
[1734.00s -> 1737.00s]  your program is calling all of these SSH things.
[1737.00s -> 1740.00s]  Now, let's actually look up how it's doing that.
[1740.00s -> 1744.00s]  SSH star dot cc, there we go.
[1745.00s -> 1748.00s]  So it's basically doing some file.
[1750.00s -> 1753.00s]  File, it's got some streams in there,
[1753.00s -> 1755.00s]  and it's basically just doing something like that
[1755.00s -> 1758.00s]  where it says, oh, okay, that's gonna be you,
[1758.00s -> 1761.00s]  and it's going to tell it how to do SSH to there.
[1761.00s -> 1765.00s]  Okay, so there's lots of fun stuff going on there.
[1767.00s -> 1768.00s]  You might be asking yourself,
[1768.00s -> 1770.00s]  how does it know your password?
[1770.00s -> 1772.00s]  And I actually don't know.
[1772.00s -> 1774.00s]  I forget how it actually does that part.
[1774.00s -> 1776.00s]  I'll have to look up how it does that part.
[1776.00s -> 1777.00s]  What's that?
[1777.00s -> 1778.00s]  It doesn't know your password,
[1778.00s -> 1780.00s]  so it does it without having to know your password.
[1780.00s -> 1782.00s]  I'll have to look it up.
[1782.00s -> 1783.00s]  I forget how.
[1783.00s -> 1784.00s]  Yeah, I'm not sure.
[1784.00s -> 1786.00s]  Anyway, it does that.
[1786.00s -> 1789.00s]  And then, let's see, what else?
[1789.00s -> 1792.00s]  It's all of the different communications
[1792.00s -> 1793.00s]  that are happening here.
[1793.00s -> 1794.00s]  Like it says,
[1794.00s -> 1796.00s]  oh, informing worker at myth 52
[1796.00s -> 1798.00s]  that all file patterns have been processed.
[1798.00s -> 1799.00s]  We're gonna see some of these to do that.
[1799.00s -> 1801.00s]  Keep all these in mind
[1801.00s -> 1802.00s]  because these are gonna help you
[1802.00s -> 1805.00s]  when you're debugging this, okay?
[1805.00s -> 1807.00s]  All right.
[1807.00s -> 1808.00s]  So, that's that.
[1808.00s -> 1812.00s]  Now, let's look at where the output happened, okay?
[1812.00s -> 1816.00s]  So, if we do files slash intermediate.
[1816.00s -> 1821.00s]  Okay, there are a whole bunch of files in here, okay?
[1821.00s -> 1827.00s]  Now, it turns out that this is how they actually work.
[1827.00s -> 1833.00s]  00001.0000.mapped, okay,
[1833.00s -> 1839.00s]  is basically saying from file 00001.input,
[1839.00s -> 1844.00s]  it takes a subset of file, of words
[1844.00s -> 1847.00s]  that are individually hashed
[1847.00s -> 1853.00s]  to go into the 0000mapped file
[1853.00s -> 1857.00s]  and any time you have a .0000.mapped file,
[1857.00s -> 1860.00s]  it means that that word happened to hash
[1860.00s -> 1866.00s]  into that number mod, I believe it's 32.
[1866.00s -> 1868.00s]  So, if we go down here
[1868.00s -> 1870.00s]  and we look up the Mac,
[1870.00s -> 1872.00s]  yeah, it goes zero to 31.
[1872.00s -> 1873.00s]  So, each one of these has 31.
[1873.00s -> 1875.00s]  Now, there were 12 different files.
[1875.00s -> 1879.00s]  There were 32 individual mapped files for this.
[1879.00s -> 1882.00s]  So, 32 times 12 is 384.
[1883.00s -> 1888.00s]  There should be 384 different files in this folder
[1888.00s -> 1890.00s]  than there are in this case, okay?
[1890.00s -> 1892.00s]  We'll talk more details about what that is.
[1892.00s -> 1893.00s]  The first time I looked at this,
[1893.00s -> 1894.00s]  I'm like, what's going on here?
[1894.00s -> 1896.00s]  I'll show you, okay?
[1896.00s -> 1900.00s]  So, if you look at all these files, okay,
[1900.00s -> 1905.00s]  this is what the word count mapper produced, okay?
[1905.00s -> 1907.00s]  And it will look familiar when we actually look at these.
[1907.00s -> 1912.00s]  Okay, the word count mapper placed these files in here
[1912.00s -> 1916.00s]  and they represent the words from the input
[1916.00s -> 1921.00s]  that hashed to that particular number on the end here,
[1921.00s -> 1924.00s]  mod 32 and I'll show you what that hasher means
[1924.00s -> 1927.00s]  and I wrote a little program to test it for you too
[1927.00s -> 1929.00s]  so you can test out a word hash
[1929.00s -> 1930.00s]  if you're having any trouble with that.
[1930.00s -> 1932.00s]  But let me show you, let's see,
[1932.00s -> 1937.00s]  we looked at 12.28 VIM 00012.00028.mapped.
[1940.00s -> 1941.00s]  Does this look familiar?
[1942.00s -> 1945.00s]  This is what the output of the mapper was earlier
[1945.00s -> 1948.00s]  in that it takes, well,
[1948.00s -> 1951.00s]  these are actually a little bit farther down the line.
[1951.00s -> 1957.00s]  This is all of the words from 00, what did I do, 00012.
[1958.00s -> 1963.00s]  From 000, hang on, there we go.
[1963.00s -> 1967.00s]  From 000, hang on, there we go.
[1967.00s -> 1970.00s]  Let's see, hang on, let's do this, fg, there we go.
[1970.00s -> 1974.00s]  All the words from 00012.input
[1974.00s -> 1979.00s]  that mapped to or that when hashed
[1979.00s -> 1986.00s]  ended up with a value of 28 after being modded by 32.
[1986.00s -> 1988.00s]  Let me show you what that means, okay?
[1990.00s -> 1992.00s]  The is in here, is in this list.
[1992.00s -> 1996.00s]  So the, if we run it through some hash function,
[1996.00s -> 1997.00s]  you get a number, right?
[1997.00s -> 1998.00s]  Let's go do this.
[1998.00s -> 2003.00s]  I wrote a file, I wrote a program, let's see.
[2004.00s -> 2008.00s]  It is, let's see, cs1, I'll just run it from here.
[2009.00s -> 2012.00s]  cs110, you can run this too.
[2012.00s -> 2013.00s]  Let's do it from there.
[2013.00s -> 2014.00s]  You can run it like this.
[2014.00s -> 2015.00s]  You can run it like this.
[2015.00s -> 2020.00s]  You do slash user slash class cs110,
[2021.00s -> 2023.00s]  w, no, we don't need that one.
[2023.00s -> 2026.00s]  We can do lecture examples, there we go.
[2026.00s -> 2029.00s]  Lecture examples, MapReduce, oh no, it's not made.
[2029.00s -> 2031.00s]  You do have to make it, sorry.
[2031.00s -> 2033.00s]  You have to make it first when you download it.
[2033.00s -> 2038.00s]  User, let's see, cs110 spring live
[2039.00s -> 2044.00s]  MapReduce hash hasher, okay.
[2044.00s -> 2046.00s]  If you run hasher, it says,
[2046.00s -> 2048.00s]  please provide something to hash.
[2048.00s -> 2052.00s]  So if we provide v, then it will hash into this number.
[2052.00s -> 2053.00s]  What is the hash function?
[2053.00s -> 2055.00s]  It's something built into C++.
[2055.00s -> 2056.00s]  And it might actually be different
[2056.00s -> 2060.00s]  on different operating systems
[2060.00s -> 2061.00s]  and different C++ compilers.
[2061.00s -> 2062.00s]  We're using the same one,
[2062.00s -> 2064.00s]  so it's always gonna be the same for us.
[2064.00s -> 2066.00s]  But this is what v should always hash to.
[2066.00s -> 2068.00s]  If I do it again, it will hash to the same number.
[2068.00s -> 2070.00s]  That number will not fit into 32 buckets.
[2070.00s -> 2075.00s]  So if we mod it by 32, it fits into bucket 28.
[2076.00s -> 2078.00s]  Okay, isn't that what we wanted before?
[2079.00s -> 2084.00s]  Let's see, if we look at greave, G-R-I-E-V-E,
[2084.00s -> 2087.00s]  then let's try the same thing.
[2087.00s -> 2092.00s]  G-R-I-E-V-E, it should also hash into the 28 bucket.
[2092.00s -> 2094.00s]  Okay, so what's happening here?
[2094.00s -> 2098.00s]  We have each individual file out,
[2098.00s -> 2100.00s]  there's 32 files per input file
[2100.00s -> 2103.00s]  that have now been mapped in the following way,
[2103.00s -> 2106.00s]  where all the words in those file,
[2106.00s -> 2108.00s]  in the input file that hashes
[2108.00s -> 2110.00s]  to a particular one of the 32 buckets
[2110.00s -> 2112.00s]  goes in that file with a little one after it.
[2112.00s -> 2114.00s]  That's that, okay?
[2114.00s -> 2118.00s]  And that's what the intermediate files end up with.
[2118.00s -> 2120.00s]  Okay, then there are 384.
[2120.00s -> 2121.00s]  Yes?
[2121.00s -> 2125.00s]  I think that we need to write the code to do the zeros.
[2125.00s -> 2127.00s]  Is that, sorry, where are you gonna?
[2127.00s -> 2128.00s]  No, go ahead.
[2128.00s -> 2132.00s]  The zero meaning part is in the mapped file
[2134.00s -> 2136.00s]  or in the type of file?
[2136.00s -> 2137.00s]  No, no, good question.
[2137.00s -> 2138.00s]  The question is, wait, wait, wait,
[2138.00s -> 2139.00s]  you just said something about
[2139.00s -> 2142.00s]  I have to figure out this zero, zero, zero,
[2142.00s -> 2143.00s]  zero, one, two business.
[2143.00s -> 2145.00s]  Some of it is figured out for you already.
[2145.00s -> 2148.00s]  Some of it, like these ones, you'll have to write yourself.
[2148.00s -> 2152.00s]  And I'll show you how that actually works.
[2152.00s -> 2153.00s]  Well, actually it's not written for you
[2153.00s -> 2155.00s]  because it's originally there.
[2155.00s -> 2156.00s]  You have to figure out how to take a number
[2156.00s -> 2158.00s]  and put leading zeros up to five.
[2158.00s -> 2161.00s]  This is like a 106A question is really what it is.
[2161.00s -> 2162.00s]  It's not that hard.
[2162.00s -> 2163.00s]  That's not what I'm worried about.
[2163.00s -> 2164.00s]  What are you gonna do about it?
[2164.00s -> 2166.00s]  You'll find out when you write the program.
[2166.00s -> 2170.00s]  I mean, it's in the mapping stage is what's happening.
[2170.00s -> 2171.00s]  Yeah, this is happening.
[2171.00s -> 2172.00s]  It's not in the Python program.
[2172.00s -> 2173.00s]  This is gonna be in C++.
[2173.00s -> 2175.00s]  You're gonna figure this out, okay?
[2175.00s -> 2176.00s]  You're not quite using any,
[2176.00s -> 2178.00s]  you're not actually using any Python yet.
[2178.00s -> 2181.00s]  You'll see where that happens a little later, okay?
[2181.00s -> 2182.00s]  But now, are there any questions
[2182.00s -> 2184.00s]  about what the results are
[2184.00s -> 2186.00s]  and why there's 384 files here?
[2186.00s -> 2189.00s]  I haven't really told you why exactly there's 384,
[2189.00s -> 2192.00s]  but what it turns, what it ends up being
[2192.00s -> 2197.00s]  is there are eight mappers and there are four reducers,
[2197.00s -> 2200.00s]  so we're gonna end up with 32 different files
[2200.00s -> 2203.00s]  per input file, okay?
[2203.00s -> 2204.00s]  That's why it is.
[2204.00s -> 2207.00s]  Now, why is it number of mappers times number of reducers?
[2207.00s -> 2209.00s]  This is completely arbitrary, okay?
[2209.00s -> 2213.00s]  It's arbitrary mainly because if we do it this way,
[2213.00s -> 2214.00s]  it's making you break your code
[2214.00s -> 2216.00s]  into lots of different pieces
[2216.00s -> 2218.00s]  that when you're doing your threading part
[2218.00s -> 2223.00s]  can surface some harder-to-find bugs
[2223.00s -> 2226.00s]  like mainly whether you're locking around the right things
[2226.00s -> 2230.00s]  or whatever, so that's the big deal with this one.
[2230.00s -> 2233.00s]  We're saying you have to produce these 32 files
[2233.00s -> 2235.00s]  or eight times four in this case
[2235.00s -> 2238.00s]  because we want you to be able to write your thread
[2238.00s -> 2240.00s]  and make your locks work appropriately,
[2240.00s -> 2243.00s]  so it's a little bit arbitrary in that sense,
[2243.00s -> 2247.00s]  but that's what's going on there, okay?
[2247.00s -> 2250.00s]  All right, so let's look at another file
[2250.00s -> 2252.00s]  just to make sure.
[2252.00s -> 2256.00s]  If we look at, so we just looked at 00012.input.
[2256.00s -> 2261.00s]  If we look at 0005, same 28 again,
[2261.00s -> 2268.00s]  instead of 12, we'll look at 00005.28.
[2268.00s -> 2271.00s]  Well, it will also hopefully have, yeah,
[2271.00s -> 2272.00s]  the is in there, okay?
[2272.00s -> 2275.00s]  Anything with a 28 means that the words
[2275.00s -> 2277.00s]  that end up there happen to hash to 28.
[2277.00s -> 2279.00s]  Now, why are there different these
[2279.00s -> 2282.00s]  in different files at this point?
[2282.00s -> 2286.00s]  Right now, each individual input file
[2286.00s -> 2288.00s]  might have a bunch of these in them.
[2288.00s -> 2290.00s]  In fact, we can find out.
[2290.00s -> 2295.00s]  Let's see, if we do, let's see,
[2295.00s -> 2300.00s]  grep, if we look for v as the, let's see.
[2301.00s -> 2305.00s]  Let's look for, how are we gonna do this?
[2305.00s -> 2307.00s]  It's a little hard to do, it's a little hard
[2307.00s -> 2309.00s]  to get this perfect because of the files,
[2309.00s -> 2312.00s]  but if we look for v in,
[2312.00s -> 2314.00s]  and this will not do commas and things,
[2314.00s -> 2319.00s]  in, let's see, samples.
[2319.00s -> 2323.00s]  Let's see, odyssey, full, star.
[2323.00s -> 2325.00s]  Yeah, it'll say, and then, let's see,
[2325.00s -> 2328.00s]  I think dash l will just list the files
[2328.00s -> 2331.00s]  that they're in, dash l, there we go.
[2331.00s -> 2334.00s]  So it turns out that v happens to be
[2334.00s -> 2336.00s]  in files three through 12.
[2336.00s -> 2338.00s]  Probably two as well, but I didn't do it right.
[2338.00s -> 2341.00s]  So that's how, so they're all in each file.
[2341.00s -> 2343.00s]  So they're all gonna end up in anything
[2343.00s -> 2345.00s]  with the 28 after it.
[2345.00s -> 2346.00s]  Yeah?
[2346.00s -> 2355.00s]  Yeah, good question.
[2355.00s -> 2357.00s]  The question is, whoa, how much faster
[2357.00s -> 2359.00s]  are we talking about when we do this multi-threading?
[2359.00s -> 2362.00s]  So it's a little hard to answer that.
[2362.00s -> 2365.00s]  It will scale well, I'll put it that way,
[2365.00s -> 2367.00s]  just because of the fact that you are
[2367.00s -> 2370.00s]  spreading it out over many different servers.
[2370.00s -> 2372.00s]  We're gonna try our, the starter version,
[2372.00s -> 2374.00s]  which doesn't have any threading in it,
[2374.00s -> 2375.00s]  it doesn't do the whole thing,
[2375.00s -> 2378.00s]  but you'll see it's marginally slower anyway.
[2378.00s -> 2380.00s]  You do get some speed up, and you'll be able
[2380.00s -> 2382.00s]  to see some speed up here when you do it.
[2382.00s -> 2383.00s]  It's hard to quantify it exactly, though.
[2383.00s -> 2385.00s]  For the size of the problem we're doing,
[2385.00s -> 2386.00s]  you might not get a huge speed up,
[2386.00s -> 2388.00s]  but you'll get some.
[2388.00s -> 2389.00s]  Okay.
[2389.00s -> 2392.00s]  So, where do we stand at this point?
[2392.00s -> 2395.00s]  We have now shown that you're going to have
[2395.00s -> 2398.00s]  to map these into many different files
[2398.00s -> 2399.00s]  before you do the reduce stage.
[2399.00s -> 2400.00s]  Yes?
[2400.00s -> 2411.00s]  Yeah, the question is, is there,
[2411.00s -> 2413.00s]  is the reason for hashing so that we can
[2413.00s -> 2417.00s]  split them into kind of evenly spaced files?
[2417.00s -> 2418.00s]  Pretty much.
[2418.00s -> 2421.00s]  Let's actually look at the file sizes here,
[2421.00s -> 2422.00s]  and see.
[2422.00s -> 2425.00s]  They are, so 685 looks like a small one,
[2425.00s -> 2427.00s]  but then it goes up to maybe a few thousand,
[2427.00s -> 2429.00s]  there might be a 10,000 in here, I'm not sure.
[2429.00s -> 2431.00s]  But they're roughly the same size.
[2431.00s -> 2433.00s]  Would there be another way to do it?
[2433.00s -> 2435.00s]  I mean, you could probably figure it out
[2435.00s -> 2437.00s]  for whatever data you have to do.
[2437.00s -> 2440.00s]  You might say, oh, I'll just do A through L
[2440.00s -> 2442.00s]  in this file, and extra words to start with that.
[2442.00s -> 2444.00s]  Probably wouldn't be perfect, though.
[2444.00s -> 2447.00s]  This is probably a little better in that sense.
[2447.00s -> 2450.00s]  Yeah, good question.
[2450.00s -> 2452.00s]  Anybody else?
[2452.00s -> 2456.00s]  Okay, let's look at,
[2456.00s -> 2457.00s]  I'm just wondering if we could count
[2457.00s -> 2460.00s]  all the words in Odyssey easily.
[2460.00s -> 2463.00s]  Let's see.
[2463.00s -> 2467.00s]  I think, let's see, if we do the following.
[2467.00s -> 2468.00s]  No, I won't do it right now.
[2468.00s -> 2470.00s]  We could count all the words
[2470.00s -> 2471.00s]  and see if they're all in there.
[2471.00s -> 2473.00s]  I'll put that in Piazza.
[2473.00s -> 2474.00s]  It would be easier to do that than me
[2474.00s -> 2476.00s]  trying to figure the command out right now.
[2476.00s -> 2477.00s]  But it is possible.
[2477.00s -> 2479.00s]  So, if you want to learn how to use
[2479.00s -> 2482.00s]  the hashing function, we've written it for you
[2482.00s -> 2483.00s]  already in various places and things,
[2483.00s -> 2485.00s]  or just go look at this file
[2485.00s -> 2488.00s]  that I pasted on, or that I put down here.
[2488.00s -> 2490.00s]  That's not it.
[2490.00s -> 2493.00s]  I think I pasted the wrong, oops.
[2493.00s -> 2495.00s]  I think I must have pasted the wrong one.
[2495.00s -> 2497.00s]  I will fix that.
[2497.00s -> 2499.00s]  Hash your program located there.
[2499.00s -> 2500.00s]  Oh, no, that is it.
[2500.00s -> 2501.00s]  Hold on.
[2501.00s -> 2502.00s]  Is that it right there?
[2502.00s -> 2504.00s]  Hang on.
[2504.00s -> 2506.00s]  Nope, it didn't.
[2506.00s -> 2507.00s]  Oh, no, it didn't do it.
[2507.00s -> 2509.00s]  Well, if you click on it, it should come back.
[2509.00s -> 2510.00s]  You can look at that file
[2510.00s -> 2512.00s]  and actually see how it's done.
[2512.00s -> 2513.00s]  It's not that hard.
[2514.00s -> 2516.00s]  Here, I'll show you.
[2516.00s -> 2520.00s]  vim cs110
[2520.00s -> 2523.00s]  spring-live-map-reduce
[2523.00s -> 2526.00s]  and hasher.cc.
[2526.00s -> 2528.00s]  Here, it's pretty easy to use.
[2528.00s -> 2530.00s]  You basically say hash,
[2530.00s -> 2532.00s]  angle bracket string hasher,
[2532.00s -> 2535.00s]  and then pass in the string.
[2535.00s -> 2537.00s]  There you go, and that gives you the hash value.
[2537.00s -> 2539.00s]  So, really straightforward to do.
[2539.00s -> 2540.00s]  Yeah.
[2540.00s -> 2542.00s]  When you do map-reduce,
[2542.00s -> 2544.00s]  do you actually have more and more race conditions
[2544.00s -> 2546.00s]  if you're already mapping out
[2546.00s -> 2549.00s]  all the execution parts of your servers?
[2549.00s -> 2551.00s]  So, the question is, if you're doing map-reduce,
[2551.00s -> 2554.00s]  do you not have any more race conditions
[2554.00s -> 2556.00s]  once you've mapped it out?
[2556.00s -> 2557.00s]  No.
[2557.00s -> 2558.00s]  No.
[2558.00s -> 2564.00s]  I mean, if you're using the distributed file system,
[2564.00s -> 2566.00s]  any time two threads on any myth
[2566.00s -> 2567.00s]  are trying to write to one file,
[2567.00s -> 2569.00s]  they better not write to the same file.
[2569.00s -> 2570.00s]  So, there's definitely a...
[2570.00s -> 2571.00s]  You have to do something there.
[2571.00s -> 2573.00s]  Now, it's going to be a little harder.
[2573.00s -> 2576.00s]  You can't lock across myths, right?
[2576.00s -> 2578.00s]  So, there's other things you have to worry about.
[2578.00s -> 2582.00s]  I think in that case, let's see.
[2582.00s -> 2583.00s]  No.
[2583.00s -> 2584.00s]  If you have multiple threads,
[2584.00s -> 2585.00s]  you could run into that problem.
[2585.00s -> 2588.00s]  So, each individual myth one
[2588.00s -> 2590.00s]  is not going to be writing to the same file
[2590.00s -> 2591.00s]  as some other one.
[2591.00s -> 2592.00s]  So, that's a good thing.
[2592.00s -> 2594.00s]  So, it'll work out in the big...
[2594.00s -> 2596.00s]  You still have to think about it for the threads.
[2596.00s -> 2597.00s]  Just think about...
[2597.00s -> 2598.00s]  Just like you normally do.
[2598.00s -> 2599.00s]  I should just back up.
[2599.00s -> 2600.00s]  Just think about it exactly like you normally do.
[2600.00s -> 2604.00s]  If multiple threads can modify a data structure
[2604.00s -> 2605.00s]  at the same time,
[2605.00s -> 2606.00s]  I'd better stop.
[2606.00s -> 2608.00s]  I'd better lock around those.
[2608.00s -> 2610.00s]  That's where that's the maps we have to think about.
[2610.00s -> 2611.00s]  Okay.
[2613.00s -> 2615.00s]  So, okay.
[2615.00s -> 2619.00s]  So, let's actually run the starter code, okay?
[2619.00s -> 2622.00s]  And see what your starter code actually produces.
[2622.00s -> 2623.00s]  Okay.
[2623.00s -> 2624.00s]  I'm going to do the same thing as before.
[2624.00s -> 2627.00s]  Make file free, okay?
[2627.00s -> 2628.00s]  Okay, that'll clear everything out.
[2628.00s -> 2629.00s]  Don't forget to do that.
[2629.00s -> 2632.00s]  And then, I'm going to just copy this little line here.
[2635.00s -> 2636.00s]  Okay.
[2637.00s -> 2640.00s]  So, this one is basically using your version
[2640.00s -> 2643.00s]  of the one that we give you for starter code.
[2643.00s -> 2646.00s]  And the MRM one, which we give you.
[2646.00s -> 2647.00s]  And the MRR, which we give you.
[2647.00s -> 2650.00s]  And then, it says map only.
[2650.00s -> 2652.00s]  This is because we didn't write any reduce for you.
[2652.00s -> 2656.00s]  And then, the quiet means don't print any details out
[2656.00s -> 2659.00s]  except for these hashes that you'll see that it'll print out.
[2659.00s -> 2660.00s]  Okay?
[2660.00s -> 2662.00s]  So, that's what we're going to run.
[2662.00s -> 2663.00s]  And you can see how fast it is
[2663.00s -> 2666.00s]  if it's faster or slower than before.
[2668.00s -> 2669.00s]  Okay.
[2669.00s -> 2670.00s]  Let's see.
[2670.00s -> 2671.00s]  I'll do it from up here.
[2671.00s -> 2672.00s]  There we go.
[2672.00s -> 2673.00s]  Okay.
[2673.00s -> 2674.00s]  So, it's going, right?
[2674.00s -> 2675.00s]  Now, we have to wait around, wait around, wait around.
[2675.00s -> 2676.00s]  This is only the mapping part, right?
[2676.00s -> 2677.00s]  And there it goes.
[2677.00s -> 2678.00s]  So, that's that.
[2678.00s -> 2680.00s]  So, the mapping part, I guess you can't really tell.
[2680.00s -> 2683.00s]  But it tells you some of the hashes that come out.
[2683.00s -> 2685.00s]  Let's look at the files right now, intermediate.
[2685.00s -> 2687.00s]  By the way, if we looked at the output files, there are none
[2687.00s -> 2689.00s]  because there's no reduce stage yet.
[2689.00s -> 2693.00s]  But if we do intermediate,
[2693.00s -> 2698.00s]  then your solution does not break it into,
[2698.00s -> 2703.00s]  or the starter code does not break things into any of the hashing.
[2703.00s -> 2705.00s]  That's the part you're going to have to do.
[2705.00s -> 2708.00s]  But what it does do is it already maps to,
[2708.00s -> 2712.00s]  like the words for you, 001.mapped.
[2712.00s -> 2714.00s]  And look what it does for you already.
[2714.00s -> 2715.00s]  Right?
[2715.00s -> 2717.00s]  So, in this sense, we don't need to,
[2717.00s -> 2720.00s]  you don't need to use that Python program to do anything here.
[2720.00s -> 2722.00s]  We've already written that for you in C++.
[2722.00s -> 2723.00s]  Okay?
[2723.00s -> 2729.00s]  And this now is fairly far along the path of, like,
[2729.00s -> 2733.00s]  how it's doing the mapping for you.
[2733.00s -> 2734.00s]  Okay?
[2734.00s -> 2737.00s]  And let's do it without the quiet part.
[2737.00s -> 2739.00s]  I'm going to make file free again.
[2739.00s -> 2742.00s]  I'm going to do make file free again.
[2742.00s -> 2743.00s]  File free again.
[2743.00s -> 2746.00s]  And then I want to do this without the quiet
[2746.00s -> 2748.00s]  and you'll see what else, what other things are going on here.
[2748.00s -> 2749.00s]  Okay?
[2749.00s -> 2751.00s]  So, it's still communicating.
[2751.00s -> 2753.00s]  So, it's already doing a lot of that communication stuff.
[2753.00s -> 2757.00s]  So, it's not like it's just doing it locally,
[2757.00s -> 2758.00s]  like the Python scripts.
[2758.00s -> 2760.00s]  It is actually communicating and sending back data.
[2760.00s -> 2762.00s]  So, I mean, a lot of that's already written for you.
[2762.00s -> 2763.00s]  Question?
[2763.00s -> 2764.00s]  Yeah.
[2764.00s -> 2769.00s]  So, you're saying it's not doing the hashing to the individual load ones?
[2769.00s -> 2771.00s]  It's not doing the hashing right.
[2771.00s -> 2776.00s]  And so, when you're looking at that, like, 001,
[2776.00s -> 2781.00s]  there's still, like, seemingly the right number of words in there.
[2781.00s -> 2784.00s]  So, do we need to break it up more than that?
[2784.00s -> 2786.00s]  Or are there too many that are in this one?
[2786.00s -> 2787.00s]  Yeah.
[2787.00s -> 2789.00s]  So, this is only partially the way there.
[2789.00s -> 2793.00s]  Now, you are still going to further need to break it into 32,
[2793.00s -> 2797.00s]  in the case of the four times eight different files,
[2797.00s -> 2799.00s]  for each one of these input ones.
[2799.00s -> 2801.00s]  And you're going to do that by hashing them there.
[2801.00s -> 2804.00s]  And again, part of this is arbitrary about why we're making you do that part.
[2804.00s -> 2809.00s]  It's part of it to have more files that can be spread out among more servers.
[2809.00s -> 2815.00s]  And part of it is to kind of test that you can do locking and multi-threading well.
[2815.00s -> 2817.00s]  Again, we've given you a thread pool.
[2817.00s -> 2818.00s]  It's not like you have to write that part.
[2818.00s -> 2821.00s]  You just have to write the locking and do the proper locking.
[2821.00s -> 2824.00s]  Which really, in the big picture,
[2824.00s -> 2827.00s]  the biggest part about going forward from here,
[2827.00s -> 2829.00s]  you've now written thread pool,
[2829.00s -> 2831.00s]  and you've done regular threads and things before.
[2831.00s -> 2833.00s]  From now on, you'll probably just use a thread pool,
[2833.00s -> 2835.00s]  or maybe use threads individually.
[2835.00s -> 2837.00s]  But now, at this point, the important part is,
[2837.00s -> 2839.00s]  oh, do you really know how to lock in the right places?
[2839.00s -> 2841.00s]  That's the important part.
[2841.00s -> 2842.00s]  Okay.
[2842.00s -> 2844.00s]  All right.
[2844.00s -> 2846.00s]  Other questions?
[2846.00s -> 2848.00s]  Okay.
[2848.00s -> 2850.00s]  So, let's go back here.
[2850.00s -> 2852.00s]  So, that's what our main,
[2852.00s -> 2856.00s]  that's what we've actually done in this program.
[2856.00s -> 2861.00s]  And you can see that the,
[2861.00s -> 2863.00s]  actually, what we can do now, actually,
[2863.00s -> 2866.00s]  is see where the shows up.
[2866.00s -> 2867.00s]  Let's see.
[2867.00s -> 2870.00s]  Find, no, grep,
[2870.00s -> 2873.00s]  and we'll do the,
[2873.00s -> 2875.00s]  oh, we'll do it this way,
[2875.00s -> 2880.00s]  the in file slash intermediate star,
[2880.00s -> 2884.00s]  and dash L.
[2884.00s -> 2888.00s]  This should tell us which files it actually found the in,
[2888.00s -> 2892.00s]  and in this case, yeah, it found it in all but one.
[2892.00s -> 2894.00s]  The only file that didn't have the in was that,
[2894.00s -> 2896.00s]  was one, in this case.
[2896.00s -> 2897.00s]  So, it's already broken it up into,
[2897.00s -> 2899.00s]  it's already taken each individual input file
[2899.00s -> 2905.00s]  and done the first round of mapping for you.
[2905.00s -> 2906.00s]  Okay.
[2906.00s -> 2911.00s]  So,
[2911.00s -> 2912.00s]  where does that leave us now?
[2912.00s -> 2914.00s]  Well, let's look at some of the files.
[2914.00s -> 2916.00s]  Here's the main files that you'll have to look at.
[2916.00s -> 2919.00s]  Now, stage, by the way, there's four tasks.
[2919.00s -> 2921.00s]  Task one is understand the files.
[2921.00s -> 2923.00s]  You don't actually have to do anything for task one,
[2923.00s -> 2924.00s]  except absorb,
[2924.00s -> 2927.00s]  and you have to kind of do that in the best way possible,
[2927.00s -> 2929.00s]  but don't skip task one.
[2929.00s -> 2931.00s]  You'll get crushed,
[2931.00s -> 2933.00s]  because there's too much to understand, right?
[2933.00s -> 2935.00s]  Even though it's just reading.
[2935.00s -> 2937.00s]  Don't try to just jump in and write this stuff, right?
[2937.00s -> 2939.00s]  First, try to understand these things, okay?
[2939.00s -> 2942.00s]  MRM, that is the entry point.
[2942.00s -> 2946.00s]  That's the client of the MapReduce server, okay?
[2946.00s -> 2951.00s]  And the server invokes MRM remotely,
[2951.00s -> 2952.00s]  like on each machine.
[2952.00s -> 2955.00s]  So, each machine gets a MapReduce mapper
[2955.00s -> 2957.00s]  that runs on it, okay?
[2957.00s -> 2961.00s]  And then,
[2961.00s -> 2963.00s]  as I said, the reason this works
[2963.00s -> 2965.00s]  is because of the SFS file system.
[2965.00s -> 2968.00s]  MapReduce mapper is the class
[2969.00s -> 2973.00s]  that actually does all the server business, okay?
[2973.00s -> 2975.00s]  And here's the most interesting part about that.
[2975.00s -> 2979.00s]  Let's go look at MapReduce mapper
[2979.00s -> 2986.00s]  and MapReduce worker, okay?
[2986.00s -> 2989.00s]  If we look at, let's look at, let's see.
[2989.00s -> 2990.00s]  Let me see which one.
[2990.00s -> 2991.00s]  What's the name of the file?
[2991.00s -> 2992.00s]  It's MapReduce.
[2992.00s -> 2997.00s]  We'll look at MapReduce, MapReduce worker first.
[2997.00s -> 2999.00s]  Okay, let's look at MapReduce worker dot h.
[2999.00s -> 3003.00s]  Okay, defines the MapReduce worker base class.
[3003.00s -> 3007.00s]  Now, how many people remember from 106b,
[3007.00s -> 3008.00s]  like the last week of class,
[3008.00s -> 3010.00s]  when you were already checked out,
[3010.00s -> 3012.00s]  where you talked about,
[3012.00s -> 3014.00s]  where you talked about polymorphism
[3014.00s -> 3017.00s]  and you talked about inheritance and all that.
[3017.00s -> 3018.00s]  Anybody remember that?
[3018.00s -> 3021.00s]  Yeah, like one person remembers that, right?
[3021.00s -> 3024.00s]  And so, this is written for you,
[3024.00s -> 3025.00s]  so you don't need to worry about that.
[3025.00s -> 3028.00s]  Basically, we've broken this down and we've said,
[3028.00s -> 3032.00s]  look, there's a server and there's the reducer
[3032.00s -> 3035.00s]  and the mapper.
[3035.00s -> 3037.00s]  They both have to talk to the server
[3037.00s -> 3040.00s]  in pretty much identical ways,
[3040.00s -> 3042.00s]  but not exactly identical.
[3042.00s -> 3043.00s]  They have to say different things and they have to do it.
[3043.00s -> 3046.00s]  So let's create one base class,
[3046.00s -> 3049.00s]  which then does this worker part,
[3049.00s -> 3051.00s]  and then each individual,
[3051.00s -> 3053.00s]  the reducer and the mapper,
[3053.00s -> 3055.00s]  subclass off of this worker and do it.
[3055.00s -> 3057.00s]  So you will have to understand inheritance
[3057.00s -> 3058.00s]  just a little bit for this.
[3058.00s -> 3059.00s]  And when you read through this,
[3059.00s -> 3062.00s]  don't be scared when you see weird things
[3062.00s -> 3065.00s]  that I'll show you in a second, okay?
[3065.00s -> 3067.00s]  So in here, what do we have in here?
[3067.00s -> 3073.00s]  We've got a huge set of parameters for this, okay?
[3073.00s -> 3075.00s]  And then we can request input
[3075.00s -> 3077.00s]  and notice there's client stuff in here.
[3077.00s -> 3079.00s]  Again, this part is mostly written for you.
[3079.00s -> 3081.00s]  We're not asking you to redo
[3081.00s -> 3084.00s]  all the client creation business and so forth, okay?
[3084.00s -> 3086.00s]  It's got the server stuff
[3086.00s -> 3088.00s]  and it's got alert server progress,
[3088.00s -> 3090.00s]  and you should be using some of these
[3090.00s -> 3092.00s]  to print out the right messages
[3092.00s -> 3096.00s]  when you're doing progress and so forth, okay?
[3096.00s -> 3099.00s]  Let's look at the MapReduce mapper,
[3099.00s -> 3102.00s]  and I'll show you the part that might seem a little weird.
[3102.00s -> 3104.00s]  Look at the MapReduce mapper.
[3104.00s -> 3110.00s]  Well, here's the actual constructor for this, okay?
[3110.00s -> 3115.00s]  Notice that it has a MapReduce worker
[3115.00s -> 3117.00s]  as part of its definition.
[3117.00s -> 3119.00s]  This is because it's subclassing
[3119.00s -> 3122.00s]  the MapReduce worker, as it turns out.
[3122.00s -> 3125.00s]  So it's actually nice that it's not,
[3125.00s -> 3127.00s]  it doesn't even have other parameters.
[3127.00s -> 3129.00s]  It's basically passing all of its own parameters
[3129.00s -> 3131.00s]  onto the class of the MapReduce worker,
[3131.00s -> 3135.00s]  and then it updates some of the functions down here.
[3135.00s -> 3138.00s]  Okay, we've got the map going on here,
[3138.00s -> 3141.00s]  and that's it, that's all we have so far, okay?
[3141.00s -> 3144.00s]  I already showed you the MapReduce reducer,
[3144.00s -> 3146.00s]  but I'll show you that again right here,
[3146.00s -> 3150.00s]  reducer cc, same sort of thing here
[3150.00s -> 3153.00s]  where it subclasses MapReduce worker
[3153.00s -> 3157.00s]  and then has this reduce function, okay?
[3157.00s -> 3160.00s]  So there's not too much that you have to go
[3160.00s -> 3163.00s]  and dig through to find out what's happening where,
[3163.00s -> 3166.00s]  but you have to understand what's going on now
[3166.00s -> 3168.00s]  in those files, okay?
[3168.00s -> 3171.00s]  That is task one, okay?
[3171.00s -> 3174.00s]  Understand all of those files.
[3174.00s -> 3176.00s]  Let's see, is there anything else in here?
[3176.00s -> 3178.00s]  Let's look at mrm.cc, oops.
[3178.00s -> 3183.00s]  mrm.cc, okay?
[3183.00s -> 3188.00s]  This is basically saying right now, map.
[3188.00s -> 3189.00s]  That's what it's doing.
[3189.00s -> 3190.00s]  It's gonna, and you're eventually
[3190.00s -> 3192.00s]  going to call reduce after that, okay?
[3192.00s -> 3195.00s]  So you gotta do that and then you have to do reduce.
[3195.00s -> 3197.00s]  What you're also gonna have to do, as it turns out,
[3197.00s -> 3198.00s]  is you're gonna have to modify
[3198.00s -> 3200.00s]  the number of parameters in here.
[3200.00s -> 3202.00s]  You'll find out when you read through the assignment.
[3202.00s -> 3203.00s]  It's basically so you have to,
[3203.00s -> 3205.00s]  if you have to add another parameter
[3205.00s -> 3207.00s]  to do the splitting of the files
[3207.00s -> 3208.00s]  based on those hashes and things.
[3208.00s -> 3211.00s]  So you're gonna have to update that.
[3211.00s -> 3214.00s]  It's kind of listed out in the assignment
[3214.00s -> 3217.00s]  where you have to do that, okay?
[3217.00s -> 3220.00s]  All right, task two.
[3220.00s -> 3223.00s]  Well, now we have to spawn multiple mappers.
[3223.00s -> 3225.00s]  Now, whenever you say spawn multiple,
[3225.00s -> 3229.00s]  you should immediately be thinking thread pool, right?
[3229.00s -> 3230.00s]  This is where you have to start saying,
[3230.00s -> 3231.00s]  you have to say, oh, okay.
[3231.00s -> 3237.00s]  I'm basically going to modify the spawn mappers.
[3237.00s -> 3239.00s]  Where is spawn mappers?
[3239.00s -> 3242.00s]  Spawn mappers in the MapReduce server.
[3242.00s -> 3246.00s]  MapReduce server, okay?
[3246.00s -> 3249.00s]  Spawn mappers, okay?
[3249.00s -> 3252.00s]  And the spawn mappers function right now
[3252.00s -> 3255.00s]  has no thread pool in it, okay?
[3255.00s -> 3259.00s]  But what you are going to do is you are going to
[3259.00s -> 3262.00s]  wrap a thread pool around spawn worker
[3262.00s -> 3265.00s]  such that it then does many workers, okay?
[3265.00s -> 3266.00s]  Why are we doing that?
[3266.00s -> 3269.00s]  Because that will make it much easier to,
[3269.00s -> 3271.00s]  or that will make it much more robust
[3271.00s -> 3275.00s]  in terms of being faster and able to communicate better, okay?
[3275.00s -> 3276.00s]  What do you have to do with that?
[3276.00s -> 3278.00s]  You have to make sure to lock in the right places
[3278.00s -> 3283.00s]  and just all the various, now you know about thread pool
[3283.00s -> 3285.00s]  sorts of things that you have to do.
[3285.00s -> 3288.00s]  You're just going to basically,
[3288.00s -> 3290.00s]  I think I actually had the wrong one.
[3290.00s -> 3293.00s]  There's a method called orchestrate workers
[3293.00s -> 3295.00s]  which uses a handle request.
[3295.00s -> 3296.00s]  I think it's a handle request.
[3296.00s -> 3299.00s]  You're actually going to map in a dot schedule.
[3299.00s -> 3302.00s]  Handle request, there we go.
[3302.00s -> 3305.00s]  There is an orchestrate workers function
[3305.00s -> 3307.00s]  which we'll look at the header file to see that
[3307.00s -> 3309.00s]  and then there's a handle request down here
[3309.00s -> 3312.00s]  and this is the one that we can basically
[3312.00s -> 3315.00s]  right up here is where you're going to end up
[3315.00s -> 3318.00s]  doing your scheduling, okay?
[3318.00s -> 3323.00s]  Let's see, we wanted to look up the header file on this.
[3323.00s -> 3326.00s]  There we go, orchestrate.
[3326.00s -> 3328.00s]  Oh, it doesn't say anything about it.
[3328.00s -> 3329.00s]  Oh no, I thought it did.
[3329.00s -> 3331.00s]  Well, it's in the assignment anyway.
[3331.00s -> 3333.00s]  It may end up, okay.
[3333.00s -> 3334.00s]  Make sure you do your written new text
[3334.00s -> 3337.00s]  and not only lock around things
[3337.00s -> 3340.00s]  that are going to change from multiple threads.
[3340.00s -> 3342.00s]  Look through the code and see where that happens.
[3342.00s -> 3344.00s]  Okay, question?
[3344.00s -> 3356.00s]  In the handle request is basically where you'll need the mutexes, right?
[3356.00s -> 3358.00s]  You'll need it in there and anything that calls
[3358.00s -> 3360.00s]  it might end up locking, needing to be locked
[3360.00s -> 3362.00s]  because there's going to be various files
[3362.00s -> 3363.00s]  that are going to be written to
[3363.00s -> 3368.00s]  and read and so forth that you need to pay attention to that.
[3368.00s -> 3371.00s]  Okay, anybody else?
[3371.00s -> 3377.00s]  Okay, so then task three, this is the hashing part.
[3377.00s -> 3379.00s]  Now this is where you're going to,
[3379.00s -> 3382.00s]  at the moment, and this is actually what you've got already,
[3382.00s -> 3388.00s]  your program only creates the little 000.xx.map files.
[3388.00s -> 3390.00s]  Now we need to do the splitting
[3390.00s -> 3393.00s]  into all of those intermediate files
[3393.00s -> 3395.00s]  that we saw a little bit earlier, okay?
[3395.00s -> 3397.00s]  That's where you're going to have to update
[3397.00s -> 3399.00s]  the build mapper command.
[3399.00s -> 3402.00s]  This is the one where you have to add that other argument, okay?
[3402.00s -> 3404.00s]  And that's going to be the number of hash codes
[3404.00s -> 3406.00s]  used by each mapper.
[3406.00s -> 3408.00s]  And how do you figure that out?
[3408.00s -> 3410.00s]  Well, you figure that out by multiplying
[3410.00s -> 3412.00s]  the number of servers by the number of,
[3412.00s -> 3414.00s]  or the number of mappers by the number of producers.
[3414.00s -> 3416.00s]  That's how you get that number, okay?
[3416.00s -> 3418.00s]  You also have to update mrm.cc to accept another argument
[3418.00s -> 3420.00s]  in its rv, which means you're going to have
[3420.00s -> 3422.00s]  to update map reduce mappers.
[3422.00s -> 3424.00s]  So there's kind of a propagating set of things
[3424.00s -> 3426.00s]  you have to go and go, oh, now that this has
[3426.00s -> 3429.00s]  an updated argument, and this one has to also,
[3429.00s -> 3431.00s]  so it can pass over there, and this one has to also.
[3431.00s -> 3433.00s]  So it's a little bit propagating.
[3433.00s -> 3435.00s]  You'll see when you get to that part.
[3435.00s -> 3438.00s]  But don't be too scared if you start going,
[3438.00s -> 3440.00s]  oh, I've been updating a lot of arguments.
[3440.00s -> 3442.00s]  You'll have to do at least three in this case.
[3442.00s -> 3443.00s]  You'll have to do three in this case.
[3443.00s -> 3445.00s]  And the number of hash codes, as I said,
[3445.00s -> 3447.00s]  number of mappers times the number of reducers,
[3447.00s -> 3449.00s]  and that's more or less for, hey,
[3449.00s -> 3453.00s]  are you doing this correctly with the concurrency stuff?
[3453.00s -> 3456.00s]  All right, and then finally,
[3456.00s -> 3459.00s]  you have to do the reduce part.
[3459.00s -> 3463.00s]  As I said before, this is relatively open-ended
[3463.00s -> 3465.00s]  in that we haven't given you any code for it.
[3465.00s -> 3468.00s]  We've just told you how the algorithm is supposed to work,
[3468.00s -> 3470.00s]  and at this point, you know, oh,
[3470.00s -> 3475.00s]  I now have 384 files that I need to combine
[3475.00s -> 3478.00s]  back into the output files that we've got.
[3478.00s -> 3480.00s]  Now, let me go back.
[3480.00s -> 3482.00s]  I didn't show you earlier.
[3482.00s -> 3484.00s]  I forgot to do that.
[3484.00s -> 3487.00s]  I didn't show you the, let's do this.
[3487.00s -> 3491.00s]  Make file free.
[3491.00s -> 3496.00s]  Okay, and then let's do the original one,
[3496.00s -> 3501.00s]  which is, nope, that's the one right there.
[3501.00s -> 3502.00s]  I want to go back to the one.
[3502.00s -> 3503.00s]  There it is.
[3503.00s -> 3505.00s]  Okay, that's the one.
[3505.00s -> 3508.00s]  And this is the one that's gonna do all the files.
[3508.00s -> 3511.00s]  This is the solution.
[3511.00s -> 3514.00s]  And once it finishes that, there we go.
[3514.00s -> 3518.00s]  Let's look at file slash output.
[3518.00s -> 3522.00s]  The output, there will be, in this case, 32 output files.
[3522.00s -> 3530.00s]  Okay, zero, zero, zero, zero, one dot, or zero dot output.
[3530.00s -> 3532.00s]  Okay, and this is now in alphabetical order,
[3532.00s -> 3534.00s]  the actual total counts.
[3534.00s -> 3537.00s]  This is what you're gonna end up with in the end.
[3537.00s -> 3541.00s]  Okay, and if you really wanted to create one more file
[3541.00s -> 3543.00s]  that is everybody, you just cat all those together,
[3543.00s -> 3546.00s]  because they're gonna be, in this case,
[3546.00s -> 3551.00s]  let's look at zero, zero, zero, three, one dot output.
[3551.00s -> 3553.00s]  Oh, no, this isn't in alphabetical order.
[3553.00s -> 3555.00s]  You'd have to do some more sorting in that case.
[3555.00s -> 3556.00s]  But it's gonna be 32 different ones
[3556.00s -> 3560.00s]  based on the words that you're outputting.
[3560.00s -> 3561.00s]  Okay, and that's the output.
[3561.00s -> 3563.00s]  I guess there'd have to be that one more stage
[3563.00s -> 3564.00s]  where you'd have to do that.
[3564.00s -> 3566.00s]  I don't think we had to do that.
[3566.00s -> 3568.00s]  So, let's see.
[3568.00s -> 3570.00s]  How are we going to do this part?
[3570.00s -> 3573.00s]  Well, you need to, you know kind of what you need to do.
[3573.00s -> 3575.00s]  The reducers need to collate the collection
[3575.00s -> 3577.00s]  of intermediate files with the keys,
[3577.00s -> 3580.00s]  those are the words, with the same hash code,
[3580.00s -> 3585.00s]  sort it, and then group the sorted collation by key,
[3585.00s -> 3589.00s]  then invoke the reducer to actually produce the output files.
[3589.00s -> 3593.00s]  And then you can leave it in those final output file format.
[3593.00s -> 3595.00s]  Here's where you can start to use
[3595.00s -> 3597.00s]  the Python programs that we give you.
[3597.00s -> 3598.00s]  If you don't want to rewrite this,
[3598.00s -> 3600.00s]  if you don't want to do the sorting
[3600.00s -> 3604.00s]  and the collating part, this is where you can go,
[3604.00s -> 3606.00s]  oh, all right, I'll just use the files
[3606.00s -> 3608.00s]  that you've given us already.
[3608.00s -> 3611.00s]  They are located here,
[3611.00s -> 3613.00s]  and you should have that absolute file name
[3613.00s -> 3614.00s]  in your program, as it turns out,
[3614.00s -> 3617.00s]  probably as a constant, but in there.
[3617.00s -> 3620.00s]  So, for instance, the group by key,
[3620.00s -> 3622.00s]  word count reducer, et cetera, you can do that.
[3622.00s -> 3625.00s]  The question is how do you run those Python programs?
[3625.00s -> 3627.00s]  You probably could use subprocess,
[3627.00s -> 3629.00s]  or you could probably use something like that
[3629.00s -> 3630.00s]  that we've done before.
[3630.00s -> 3634.00s]  Turns out there is a function called system,
[3634.00s -> 3637.00s]  which is really easy to use, okay?
[3637.00s -> 3640.00s]  Let me show you how easy it is to use.
[3640.00s -> 3642.00s]  Let's see.
[3642.00s -> 3646.00s]  We are going to go to
[3647.00s -> 3651.00s]  I should have had this in tutoring.
[3651.00s -> 3654.00s]  My lecture, MapReduce, there we go.
[3654.00s -> 3659.00s]  And in here, system example.
[3659.00s -> 3663.00s]  Okay, system example takes an argument,
[3663.00s -> 3666.00s]  which is a command that you would type
[3666.00s -> 3669.00s]  into the command line, and it runs it.
[3669.00s -> 3671.00s]  Right, you don't need to parse it into argv,
[3671.00s -> 3672.00s]  you don't need to do anything,
[3672.00s -> 3674.00s]  it just goes boom, and that's it.
[3674.00s -> 3675.00s]  It doesn't give you the answer back,
[3675.00s -> 3677.00s]  it actually does whatever it does.
[3677.00s -> 3679.00s]  You can't gather the input or the output back,
[3679.00s -> 3682.00s]  you have to actually pipe it out to a file.
[3682.00s -> 3687.00s]  But for instance, I will give you the example here.
[3687.00s -> 3689.00s]  I'm gonna have to retype this a little bit,
[3689.00s -> 3693.00s]  but let me show you what this one would be.
[3693.00s -> 3694.00s]  Make sure you got it there.
[3694.00s -> 3696.00s]  Remember this thing that we had before,
[3696.00s -> 3700.00s]  where we had all of the different,
[3700.00s -> 3703.00s]  we had this whole Python stream here?
[3703.00s -> 3706.00s]  Well, you can run this exact command
[3706.00s -> 3709.00s]  from your C++ program by using that system command.
[3709.00s -> 3710.00s]  So it's pretty straightforward.
[3710.00s -> 3713.00s]  If you ran this, it should, there you go,
[3713.00s -> 3716.00s]  output to, what did I call it, alloutput.txt,
[3716.00s -> 3717.00s]  and there you go.
[3717.00s -> 3720.00s]  So you can run this for each individual file
[3720.00s -> 3722.00s]  by using that system command,
[3722.00s -> 3723.00s]  so you don't have to do the sorting,
[3723.00s -> 3725.00s]  you don't have to do, I mean, in this case,
[3725.00s -> 3727.00s]  you're not gonna do all of this pipeline,
[3727.00s -> 3728.00s]  but you're gonna do part of it,
[3728.00s -> 3730.00s]  and it's a little easier than writing it in C++.
[3730.00s -> 3732.00s]  Feel free to write it in C++,
[3732.00s -> 3734.00s]  that will probably be a little quicker,
[3734.00s -> 3736.00s]  because it's not having to call all these functions
[3736.00s -> 3738.00s]  that are outside of your program,
[3738.00s -> 3740.00s]  but up to you.
[3740.00s -> 3742.00s]  If you wanna do it a little more, a little easier,
[3742.00s -> 3744.00s]  because we've already done something for you,
[3744.00s -> 3745.00s]  go right ahead.
[3745.00s -> 3746.00s]  Yes?
[3746.00s -> 3748.00s]  So remember, this is the first time that I've actually,
[3748.00s -> 3753.00s]  so each, so how do we alphabetize the whole event?
[3753.00s -> 3754.00s]  How do you alphabetize it?
[3754.00s -> 3756.00s]  Sort, right?
[3756.00s -> 3758.00s]  So this is what we've done with the Python program, right?
[3758.00s -> 3761.00s]  Python program in here calls the sort function down here,
[3761.00s -> 3763.00s]  and you would do the same thing.
[3763.00s -> 3764.00s]  You could use the sort,
[3764.00s -> 3766.00s]  you could use C++'s sort function,
[3766.00s -> 3767.00s]  if you have like a,
[3767.00s -> 3769.00s]  or you could read all the files in
[3769.00s -> 3771.00s]  and then sort them that way.
[3771.00s -> 3772.00s]  You could do that as well.
[3772.00s -> 3774.00s]  So but you wouldn't have, like,
[3774.00s -> 3776.00s]  an individual file that has, like,
[3776.00s -> 3778.00s]  A and B in it,
[3778.00s -> 3780.00s]  so it's just a hash that doesn't allow that?
[3780.00s -> 3782.00s]  No, no, the, you would have,
[3782.00s -> 3785.00s]  you are gonna sort the individual files, right?
[3785.00s -> 3787.00s]  And you could do that by reading them in
[3787.00s -> 3789.00s]  and sorting them and pushing them back out to the file,
[3789.00s -> 3790.00s]  that's fine.
[3790.00s -> 3792.00s]  Or you could use this, which does it for you.
[3792.00s -> 3795.00s]  So up to you about which one you wanna do.
[3795.00s -> 3796.00s]  But they will already have,
[3796.00s -> 3800.00s]  so remember what the intermediate files are.
[3800.00s -> 3803.00s]  Let's see, intermediate looks like,
[3803.00s -> 3808.00s]  let's look at one, 0006.00029.
[3808.00s -> 3810.00s]  Oops, dot mapped.
[3810.00s -> 3812.00s]  It already looks like this,
[3812.00s -> 3813.00s]  but that's not sorted.
[3813.00s -> 3815.00s]  It's just as they came in the file.
[3815.00s -> 3816.00s]  That's what you've got.
[3816.00s -> 3818.00s]  So you need to first sort them,
[3818.00s -> 3819.00s]  and then you need to collate them
[3819.00s -> 3820.00s]  by having to do all the ones,
[3820.00s -> 3822.00s]  and then you need to add up all those ones.
[3822.00s -> 3824.00s]  Then other Python programs do it for you.
[3824.00s -> 3826.00s]  Might as well use that if you can.
[3826.00s -> 3828.00s]  You have to figure out what the file names are gonna be,
[3828.00s -> 3829.00s]  and so forth, but that's not,
[3829.00s -> 3831.00s]  that's the basic idea.
[3831.00s -> 3834.00s]  So up to you if you wanna do it either way.
[3834.00s -> 3836.00s]  I'd probably suggest the Python version
[3836.00s -> 3837.00s]  because it's easier to implement.
[3837.00s -> 3839.00s]  So the Python version takes in one file,
[3839.00s -> 3841.00s]  so you have to run it on all of them?
[3841.00s -> 3843.00s]  You have to run it on all of them, yes, you do.
[3843.00s -> 3844.00s]  You do have to run it on all of them, yes.
[3844.00s -> 3847.00s]  All the individual ones, you have to run that on.
[3848.00s -> 3850.00s]  You'll see when you get to the output,
[3850.00s -> 3853.00s]  but yes, you have to run that on all the individual files,
[3853.00s -> 3854.00s]  and then once you have all those files,
[3854.00s -> 3856.00s]  collate them together.
[3857.00s -> 3859.00s]  You'll see, you'll see when you get there
[3859.00s -> 3860.00s]  in the program about that,
[3860.00s -> 3862.00s]  but that's the basic idea.
[3862.00s -> 3863.00s]  Okay.
[3864.00s -> 3866.00s]  All right, that's how you do that.
[3866.00s -> 3869.00s]  There's one hint here that I wanted to just point out
[3869.00s -> 3871.00s]  that may not make much sense right now.
[3872.00s -> 3876.00s]  Once the MapReduce job has gotten to a point
[3876.00s -> 3878.00s]  where it's going to do the reducing,
[3878.00s -> 3884.00s]  you're gonna have to reduce all of those individual files
[3884.00s -> 3886.00s]  that have the same hashes.
[3886.00s -> 3893.00s]  All the ones that end, for instance, in .00001.mapped.
[3894.00s -> 3896.00s]  Okay, I think I might have missed a,
[3897.00s -> 3899.00s]  ending in files, yeah,
[3899.00s -> 3900.00s]  I think I might have missed something there.
[3900.00s -> 3904.00s]  Anyway, all the files that end, in this case, in .00001.mapped,
[3904.00s -> 3906.00s]  you need to get all those files
[3906.00s -> 3909.00s]  and do the collating on them, okay?
[3909.00s -> 3911.00s]  So, you're probably gonna want to have
[3911.00s -> 3913.00s]  some sort of pattern matching
[3913.00s -> 3915.00s]  built into your program so that it does that.
[3915.00s -> 3917.00s]  You basically say, hey, here,
[3917.00s -> 3919.00s]  all the files that you're gonna have
[3919.00s -> 3922.00s]  only use the ones that match this pattern,
[3922.00s -> 3923.00s]  and it's not that hard to do,
[3923.00s -> 3925.00s]  just keep in mind you're gonna have to
[3925.00s -> 3929.00s]  logically figure out how to write that part, okay?
[3929.00s -> 3932.00s]  You are totally allowed to have as many intermediate,
[3932.00s -> 3935.00s]  as many more intermediate files as you want.
[3935.00s -> 3937.00s]  Just remember to delete them
[3937.00s -> 3940.00s]  before you get to the, before you're finally done.
[3940.00s -> 3942.00s]  Create as many intermediate files as you want,
[3942.00s -> 3946.00s]  and then after that, after you get everything into the final,
[3946.00s -> 3948.00s]  the output, delete all the intermediate files
[3948.00s -> 3950.00s]  except for the ones that we wanted you to leave.
[3950.00s -> 3951.00s]  Just make sure you do that.
[3951.00s -> 3953.00s]  So if you want, you can have those.
[3953.00s -> 3954.00s]  And again, I know at this point,
[3954.00s -> 3956.00s]  some of this doesn't make much sense yet
[3956.00s -> 3958.00s]  because you haven't actually dug into the assignment,
[3958.00s -> 3963.00s]  but it will once you get there, okay?
[3963.00s -> 3964.00s]  All right.
[3964.00s -> 3965.00s]  What other questions do you have?
[3965.00s -> 3969.00s]  That is the MapReduce program.
[3969.00s -> 3970.00s]  Don't be scared of it.
[3970.00s -> 3973.00s]  It's just like if you thought at the beginning of proxy,
[3973.00s -> 3974.00s]  you're like, how am I ever gonna do it,
[3974.00s -> 3975.00s]  get through all this?
[3975.00s -> 3976.00s]  It's the same sort of idea.
[3976.00s -> 3977.00s]  There's lots of steps.
[3977.00s -> 3978.00s]  We write out a lot of them for you.
[3978.00s -> 3981.00s]  You will get there one step at a time
[3981.00s -> 3982.00s]  as you go through it.
[3982.00s -> 3983.00s]  Yes.
[3983.00s -> 3987.00s]  So how does this relate to computers going down?
[3987.00s -> 3990.00s]  This doesn't, so a good question.
[3990.00s -> 3991.00s]  The question is, wait, how does this result?
[3991.00s -> 3992.00s]  How does this like,
[3992.00s -> 3995.00s]  how is this robust for computers breaking and so forth?
[3995.00s -> 3996.00s]  This one isn't.
[3996.00s -> 3998.00s]  But you can imagine that if you,
[3998.00s -> 4001.00s]  if you may want to make this more robust,
[4001.00s -> 4003.00s]  you would, in fact, I'm not even,
[4003.00s -> 4005.00s]  I'm not sure that we haven't written some of this in there,
[4005.00s -> 4007.00s]  but if one of the myths, let's say,
[4007.00s -> 4008.00s]  doesn't return your values,
[4008.00s -> 4012.00s]  you're gonna have some timeout in the main map
[4012.00s -> 4014.00s]  or the main program that's doing this goes,
[4014.00s -> 4015.00s]  oh, I better send it to a different,
[4015.00s -> 4017.00s]  I better task a different myth to do this
[4017.00s -> 4019.00s]  because this other one seems to be flaking out on me.
[4019.00s -> 4021.00s]  Yeah, I thought you were saying MapReduce
[4021.00s -> 4024.00s]  is an algorithm to fix that problem.
[4024.00s -> 4026.00s]  That was an example of like a super.
[4026.00s -> 4029.00s]  Yeah, MapReduce in itself doesn't fix the problem,
[4029.00s -> 4031.00s]  but MapReduce makes it relatively easy
[4031.00s -> 4033.00s]  to attack that problem
[4033.00s -> 4035.00s]  because now you've got lots of servers
[4035.00s -> 4037.00s]  and you're getting data back and forth and you go,
[4037.00s -> 4038.00s]  oh, all you need to do is basically say,
[4038.00s -> 4041.00s]  oh, okay, I didn't get anything back from that server.
[4041.00s -> 4043.00s]  I better retarget that exact same job
[4043.00s -> 4044.00s]  to some other server.
[4044.00s -> 4048.00s]  And then that would be how you handle that robust part of it.
[4050.00s -> 4051.00s]  Okay, all right.
[4051.00s -> 4052.00s]  We'll end a few minutes early
[4052.00s -> 4053.00s]  unless there's more questions.
[4053.00s -> 4054.00s]  I'm headed back to my office
[4054.00s -> 4057.00s]  for office hours until about 4 p.m.
[4057.00s -> 4061.00s]  It's 2 19 in Gates and I will see you later.
