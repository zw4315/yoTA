# Detected language: en (p=1.00)

[0.00s -> 8.40s]  Okay, we might as well get started. Welcome. So the midterm is over. I hope
[8.40s -> 11.52s]  everybody did all right. I'll have a couple comments about that. And then
[11.52s -> 17.06s]  Stanford Shell, I hope that's going okay. As I said, there's like, if you
[17.06s -> 21.60s]  haven't really gotten going on it, get going soon. It's, for those of you
[21.60s -> 24.76s]  who did, who have started it, you realize there's just lots of parts to
[24.76s -> 28.08s]  it and lots of things to think about. And there have been lots of piazza
[28.12s -> 33.84s]  questions, good piazza questions, about the assignment. So I hope that's going
[33.84s -> 37.20s]  all right and we will have lots of office hours this week. And when did I
[37.20s -> 41.28s]  say it was due? Wednesday night or Thursday night? Okay, did you say make
[41.28s -> 48.14s]  it Thursday night? So you said? Let's talk in a couple days. We'll see. So the
[48.14s -> 51.56s]  midterm, a couple comments on that. You should have gotten your midterm scores
[51.56s -> 55.24s]  back. If you didn't, please let me know so we can make sure that happens.
[55.60s -> 60.40s]  Overall, I was pretty pleased with it. I think there were a couple
[60.40s -> 63.68s]  questions on there that I knew would be difficult. And there were a couple
[63.68s -> 65.72s]  questions that I thought, hey, everybody should do all right on this.
[65.72s -> 69.36s]  And most people did. The answers to the file system stuff. I mean, I
[69.36s -> 73.48s]  think that was hopefully relatively open ended, but straightforward. Most
[73.48s -> 79.04s]  people did okay. Problem 1D, actually problem 1, I think, was the most
[79.04s -> 83.84s]  challenging problem, which it was kind of meant to be. 1D, let's go
[84.04s -> 88.56s]  in reverse order here. 1D was the question about, hey, how do you
[88.56s -> 92.72s]  deinterleave these outputs? Is it possible to really deinterleave these
[92.72s -> 98.52s]  outputs? The answer is not really. The way we set up the input and
[98.52s -> 103.20s]  output such that they had to track each other directly made it really
[103.20s -> 106.60s]  impossible, no matter what solution you came up with, unless you were
[106.60s -> 110.76s]  allowed to collect all the data first and then pipe it to one, then
[110.76s -> 115.04s]  pipe it to the other, and so forth. And the idea for this problem
[115.04s -> 117.60s]  was, you don't know how much data there is coming in, and you're
[117.60s -> 120.76s]  not allowed to store it all before you start piping it away, and
[120.76s -> 124.16s]  it's not possible. Very few people got that part correct for
[124.16s -> 127.88s]  D, but that's okay. That happens on exams. Definitely go and
[127.88s -> 130.60s]  look at it. If you do have questions about, hey, I don't really
[130.60s -> 133.72s]  understand what the answer is all about. Trust me, we had some
[133.72s -> 136.92s]  TAs during grading who were scratching their heads going, oh,
[136.92s -> 138.32s]  wait a minute, what is this? And they did it all on the
[138.32s -> 141.32s]  board, and they convinced themselves eventually. So it was a
[141.32s -> 146.72s]  difficult, difficult problem. For the actual code for that, two
[146.72s -> 153.24s]  things. First thing, you know how we can use the pipe to, and
[153.24s -> 161.84s]  then you have like FDS, and then OCLOEXEC or whatever it is,
[161.96s -> 163.48s]  you know how to do that, and then you don't have to close
[163.48s -> 165.88s]  some, but you might have to close others and whatever. We
[165.88s -> 169.24s]  didn't even worry about that for the exam. There were too many
[169.24s -> 172.16s]  like corner cases where you could have done one or the other
[172.16s -> 176.76s]  and we just pretended everybody used that pipe to, and we
[176.76s -> 179.00s]  pretended that everyone closed everything inside the
[179.00s -> 182.04s]  children correctly. There were two pipes you had to close
[182.04s -> 184.28s]  correctly or two file descriptors you had to close
[184.28s -> 187.92s]  correctly outside of the children, and that one we
[187.92s -> 191.28s]  cared about. But inside the children, if you said, oh, I'm
[191.28s -> 194.28s]  not sure I got that right, that's okay. We didn't worry
[194.28s -> 197.68s]  about that. The other thing that people tended to miss quite
[197.68s -> 202.64s]  frequently was we didn't say you should wait PID for the
[202.64s -> 207.48s]  children to end the program. But let's just go look at the
[207.48s -> 211.44s]  program, the actual question again, okay? And or I should
[211.44s -> 215.40s]  say, let's look at the actual code that you may or may
[215.40s -> 220.64s]  not have typed up. Hang on, remind me later. Cursor, there
[220.64s -> 228.56s]  we go, and then there we go. Vim to output.cc. Okay. So
[228.56s -> 234.56s]  you wrote all this for the actual pipes and so forth, you
[234.56s -> 237.48s]  did all that. And you were writing where? You were
[237.48s -> 241.32s]  writing in main, right? You were writing the actual main
[241.32s -> 248.28s]  part of this program, which called the, which called the
[249.24s -> 253.12s]  dual echo down here, okay, which called the dual echo down
[253.12s -> 256.88s]  here. And that was that was what you did. And then main
[256.88s -> 262.68s]  ended. And main ended. And if you forgot the wait PID, this
[262.68s -> 265.36s]  is what it should have looked like, by the way. Let's see
[265.36s -> 269.16s]  to output. Let's do the same example to do sort. And then
[269.16s -> 273.16s]  I'll pipe in a little test for test input. Okay, so that
[273.16s -> 276.92s]  was actually relatively nice in that it did sort and WC in
[277.36s -> 280.76s]  the sort of the word count actually did come first, but it
[280.76s -> 282.80s]  didn't have to, it could have come somewhere in the middle,
[282.80s -> 286.08s]  that was the interleaving part. But you'll notice that
[286.12s -> 289.08s]  the prompt didn't come back until after both children
[289.08s -> 292.32s]  finished. That's what you want in programs, you want your
[292.32s -> 295.48s]  programs to end nicely, such that the prompt comes back.
[295.48s -> 300.16s]  Well, if we took out those two wait PIDs, right, let's
[300.16s -> 303.32s]  see what might happen. Okay, it's not guaranteed to
[303.32s -> 307.52s]  happen. But let's see what happens here. output, oops,
[308.04s -> 312.08s]  but there we go to output. And let's do the same thing
[312.08s -> 314.68s]  before. Let's do it up at the top of the screen. There we
[314.68s -> 318.40s]  go. Okay, look. So here's what happened up here, we got
[318.40s -> 321.12s]  the prompt back and then the program went and then it
[321.12s -> 323.88s]  just sits here like that. Is that a nicely behaved program?
[324.20s -> 327.80s]  No, not very nice. So we kind of expected you to go Oh, if
[327.80s -> 330.28s]  I'm writing the main and I want and I'm doing this to
[330.28s -> 332.80s]  up a thing for children, you should wait for the
[332.80s -> 335.56s]  children. So I apologize to people who didn't didn't pick
[335.56s -> 339.28s]  that up. But you kind of should get that, that that's the
[339.32s -> 342.84s]  what you want to do. All right. If you have other
[342.84s -> 346.16s]  there are regrade requests still open. We're relatively
[346.16s -> 348.92s]  strict about regrade requests in that you can't like for
[348.92s -> 351.60s]  the for the pro and con when you go well, I really
[351.60s -> 354.12s]  meant this and try to explain away what you really
[354.12s -> 357.04s]  meant. And if it wasn't on the page, that's it. The
[357.04s -> 359.28s]  other one, there were some people who were saying, ah, I
[359.28s -> 362.08s]  wrote 125 words and you took off points and what
[363.00s -> 366.28s]  I kind of, you know, kind of warned you that the point
[366.32s -> 369.36s]  we thought those examples, those answers could be well
[369.36s -> 373.12s]  within 100 words. And so if you made if you made a few
[373.12s -> 374.84s]  more, we didn't care that much. And if you do want to
[374.84s -> 376.88s]  regrade request, I'll go count your words and make a
[376.88s -> 379.96s]  decision. But like 120, probably too much in that
[379.96s -> 381.20s]  case. Question.
[389.48s -> 391.48s]  Good question. The question is, hey, wait a minute, I
[391.96s -> 393.96s]  didn't know about this pipe filling up business. Is that
[393.96s -> 395.80s]  the way right works or is that or is that the pipe
[395.80s -> 398.28s]  thing? It actually is a pipe. It's a built in Linux
[398.32s -> 401.40s]  issue is that pipes can fill up. They only make so
[401.40s -> 405.36s]  much space for the pipe in Linux. And so what all it
[405.36s -> 407.84s]  does, it generally doesn't break things. Although if
[407.84s -> 410.16s]  you don't understand that, like this code, it broke, it
[410.16s -> 414.52s]  would break our code if we tried to interleave because
[415.12s -> 417.32s]  we never really talked about that. No, we didn't
[417.32s -> 418.84s]  talk about that in the sense that there might have
[418.84s -> 420.72s]  been a Piazza question about it. Maybe it was last
[420.72s -> 425.08s]  quarter. But the said the point is that the pipes
[425.08s -> 427.36s]  can fill up. What do they do? They just block until
[427.36s -> 430.40s]  things lessen up again. And if for some reason
[430.40s -> 433.20s]  you're doing something wonky like that program and
[433.20s -> 435.80s]  trying to collect all the data at once, that can be
[435.80s -> 437.96s]  a problem. So that's kind of why I gave it on the
[437.96s -> 440.64s]  exam was, hey, here's something new. Oh, what do
[440.64s -> 442.80s]  you think about this? This? Oh, now that pipes,
[442.84s -> 444.00s]  you know, the pipes can fill up. What do you
[444.00s -> 445.60s]  think about it? That's kind of why I put it on
[445.60s -> 450.68s]  there. You see what I mean? No, you didn't know
[450.68s -> 452.36s]  that pipes could fill up. No, what I'm saying is
[452.36s -> 453.72s]  you, I didn't. Well, you might have known that,
[453.72s -> 457.04s]  but the midterm said it. Oh, yeah, there was a
[457.04s -> 460.60s]  section. Oh, sorry. Yeah, sorry. Go back and
[460.60s -> 462.24s]  read the midterm. It did say that that was the
[462.24s -> 464.92s]  whole point of Yeah, sorry, didn't read that.
[465.44s -> 471.68s]  Question. No, good question. When the pipes
[471.68s -> 473.00s]  fill up, does it close the file? No, no, it
[473.00s -> 474.72s]  just blocks on it and says, oh, if you want to
[474.72s -> 476.68s]  write more data, I can't accept more data. I'm
[476.68s -> 478.64s]  just going to block you from writing more data
[478.64s -> 481.68s]  until somebody else reads, and then you'll be
[481.68s -> 483.60s]  able to block, undo it. We're going to see an
[483.60s -> 486.00s]  example of something similar to that in
[486.28s -> 489.60s]  threading today, where there's this, there's
[489.60s -> 493.52s]  this reader, writer, kind of dance that has to
[493.52s -> 496.20s]  happen where you've only got so much space, and
[496.20s -> 498.64s]  you need to figure that that part out. So good
[498.64s -> 504.44s]  question on that. Very good question. Yeah. A
[504.44s -> 506.48s]  little more technical question about Maine. Yes.
[508.64s -> 519.56s]  You had a for loop. It's kind of around this
[519.56s -> 520.98s]  within way. Okay, that probably could work.
[520.98s -> 527.44s]  Sure. Oh, put a request in if you think
[527.44s -> 529.60s]  that's right. That's that's doing doing the
[529.60s -> 532.92s]  way PID in a loop where you check for all the
[532.92s -> 535.24s]  children waiting is perfectly legitimate. You
[535.24s -> 537.04s]  absolutely could do that. So put a request in
[537.04s -> 539.96s]  for that. Yeah. Any other questions on the I
[539.96s -> 541.12s]  don't want to get into too many details about
[541.12s -> 542.68s]  the exam. But if you do think we graded it
[542.68s -> 545.88s]  incorrectly, please let us know. As I said,
[545.88s -> 548.32s]  we're we're trying to be fair in the
[548.32s -> 551.96s]  regrade process. But but we're going to be you
[551.96s -> 554.48s]  know, we're going to be not going to just let
[554.48s -> 556.36s]  you kind of redo your test in the regrade
[556.36s -> 559.76s]  process. You've been through that. Okay. All
[559.76s -> 563.40s]  right. And as I said, overall, pretty good on
[563.40s -> 564.92s]  the midterm. It was I think it was a
[564.92s -> 568.32s]  challenging midterm. But overall, people did
[568.32s -> 570.68s]  all right. And if you didn't do so great, feel
[570.68s -> 572.64s]  free to email me and we can chat about
[572.96s -> 574.96s]  going forward and trying to pick things up a
[574.96s -> 578.04s]  little. And you've also got final and these
[578.04s -> 581.32s]  and other assignments and so forth. Okay. All
[581.32s -> 584.52s]  right now. So I know you're all thinking
[584.52s -> 586.48s]  about Stanford shell, which has nothing to do
[586.48s -> 589.16s]  with threading. But I did figure that last
[589.16s -> 590.80s]  week, you were all thinking, Oh, my gosh, I
[590.80s -> 593.92s]  got this midterm coming up. And we went over,
[594.64s -> 598.60s]  we went over mutexes, and then CVS and semaphores.
[598.60s -> 601.08s]  And it was all wicked fast. And what I wanted
[601.08s -> 603.52s]  to do is kind of go back and just kind of
[603.52s -> 605.40s]  review what they are, let you get all the
[605.40s -> 607.08s]  questions out that you might still have about
[607.08s -> 610.32s]  those or new questions or whatever. And then
[610.32s -> 612.84s]  we'll see a couple more small examples. Okay,
[612.88s -> 614.60s]  I'm not going to actually do any like live
[614.60s -> 616.32s]  like stuff today. I just have some examples
[616.32s -> 619.92s]  and we'll go over them as we go. Okay, so
[620.12s -> 622.56s]  in threading, we have to have this ability
[622.56s -> 626.08s]  to to handle race conditions, we have to have
[626.08s -> 630.20s]  the ability for two or more threads to to
[630.20s -> 633.52s]  either act in a similar section of code or
[633.64s -> 636.80s]  act on a data structure in a way that won't
[636.80s -> 639.04s]  corrupt the data structure. And this is just
[639.04s -> 640.84s]  something that you have to deal with. Race
[640.84s -> 642.16s]  conditions happen all the time when you're
[642.16s -> 644.12s]  doing this threads just like just like
[644.12s -> 646.76s]  multi processing. We have a different a few
[646.76s -> 648.24s]  different ways of doing that we kind of
[648.24s -> 651.28s]  walked through them last week. The main one
[651.28s -> 653.96s]  is and this is the the kind of the underlying
[653.96s -> 657.28s]  one for most of these is a mutex. Okay, a mutex
[657.36s -> 659.28s]  and we'll go over the details. I'll just
[659.28s -> 661.60s]  kind of list through here. The mutex is the
[661.60s -> 663.44s]  first one we learned about and we'll we'll
[663.44s -> 666.72s]  see examples of that in a minute. A condition
[666.72s -> 670.72s]  variable any mutex has no ability for two
[670.72s -> 674.32s]  threads to signal another thread that they're
[674.32s -> 678.16s]  done. Right now the signaling can happen by
[678.16s -> 680.60s]  the fact that one thread will actually
[680.64s -> 682.72s]  release the lock and the other thread will
[682.72s -> 685.00s]  gain the lock. So that is in some sense a
[685.00s -> 687.40s]  signal but it's not a distinct like hey
[687.40s -> 689.04s]  anybody who's waiting go ahead and
[689.04s -> 692.24s]  continue. So there has to be some ability
[692.24s -> 694.48s]  to do that if you don't want to busy
[694.48s -> 696.92s]  wait or or if you don't want to just
[696.92s -> 698.80s]  have a regular straight up lock. Okay this
[698.80s -> 700.60s]  is particularly important when you have
[700.60s -> 703.92s]  multiple things trying to access a
[703.92s -> 706.24s]  particular data pick particular like section
[706.24s -> 708.16s]  of code and it could be more than one
[708.20s -> 709.84s]  you can't really handle that directly with a
[709.84s -> 711.32s]  mutex. So that's where a condition
[711.32s -> 714.20s]  variable any comes in. And then there are
[714.20s -> 716.68s]  all sorts of things you can do with a
[716.68s -> 718.32s]  conditional variable any that we happen
[718.32s -> 721.72s]  to do a lot, namely waiting for permits
[721.72s -> 724.84s]  and saying hey here's a whole bunch of
[725.40s -> 727.16s]  thread or a whole bunch of permits that
[727.16s -> 729.24s]  a bunch of threads can work at once. And
[729.24s -> 730.92s]  so what we said was well let's we can
[730.92s -> 733.36s]  use a condition variable any but let's
[733.36s -> 736.76s]  actually let's actually build it up such
[736.76s -> 739.76s]  that we build it into this other
[739.76s -> 742.88s]  thing called a semaphore which is a
[742.88s -> 746.64s]  different type of data structure fairly
[746.64s -> 748.56s]  easy to build has some nuances that
[748.56s -> 750.80s]  we'll talk about later today and it
[750.80s -> 755.08s]  allows you to go ahead
[755.08s -> 758.72s]  and build more structures a little
[758.72s -> 761.00s]  easier than a conditional a condition
[761.00s -> 763.16s]  variable any. Okay so let's review
[763.16s -> 765.16s]  these okay let's review all of them in
[765.16s -> 769.80s]  fact. The let's see there we go maybe
[769.80s -> 775.04s]  not hang on up there okay so the
[775.04s -> 777.64s]  mutex okay and you can use these
[777.64s -> 779.12s]  slides as kind of a reference to if
[779.12s -> 784.44s]  you'd like the mutex is a it's a lock
[784.44s -> 787.08s]  okay and it has two things you can do
[787.08s -> 788.88s]  with it you can say the lock or
[788.88s -> 791.80s]  unlock and what happens is when a
[791.80s -> 796.28s]  thread takes this mutex and locks it if
[796.28s -> 798.40s]  no one else is locked it yet it gets
[798.40s -> 799.92s]  that and it moves on to the next line
[799.92s -> 801.56s]  of code okay and it's that
[801.56s -> 804.24s]  straightforward if another thread comes
[804.24s -> 807.64s]  in and attempts to use the lock but
[807.64s -> 809.64s]  the first the first thread is still
[809.64s -> 813.36s]  using it then what happens is the for
[813.36s -> 816.28s]  the second thread blocks until the
[816.28s -> 818.52s]  other thread unlocks it
[818.52s -> 821.80s]  okay and that's the big details there
[821.80s -> 824.96s]  that you should care about okay you
[824.96s -> 827.52s]  have to pass a mutex by reference or
[827.52s -> 829.68s]  by pointer why because they actually
[829.68s -> 832.56s]  need to share the same mutex it can't
[832.56s -> 834.36s]  be a copy of a mutex because then the
[834.36s -> 836.24s]  data wouldn't be shared and that's how
[836.24s -> 838.00s]  it works and by the way under the
[838.00s -> 840.12s]  hood if you take a parallel processing
[840.12s -> 841.36s]  class or you take maybe an operating
[841.36s -> 843.32s]  systems class they might talk about it
[843.32s -> 846.30s]  uses atomic instructions under the
[846.30s -> 848.54s]  hood to create the mutex so that two
[848.54s -> 850.66s]  threads can't get it at the same time
[850.66s -> 852.54s]  so there's a little more hardware
[852.54s -> 854.74s]  support and operating system support
[854.74s -> 856.70s]  for doing this but that's that's
[856.70s -> 859.02s]  basically how it works okay the thread
[859.02s -> 861.02s]  obtains a lock and then executes the
[861.02s -> 862.86s]  next line of code if it if the
[862.86s -> 864.42s]  other thread can't get it because the
[864.42s -> 867.50s]  lock is already taken the code waits
[867.50s -> 869.58s]  and then until the lock is unlocked
[869.58s -> 872.14s]  the only thread available to the only
[872.14s -> 873.90s]  thread allowed to unlock is the one
[873.90s -> 876.02s]  that locked it okay it's all it's an
[876.02s -> 877.78s]  undefined behavior if another thread
[877.78s -> 880.26s]  tries to unlock a lock thread and it
[880.26s -> 881.38s]  wasn't the one that did it yeah
[881.38s -> 886.54s]  question good I'm listening I'm trying
[886.54s -> 889.02s]  to get this tablet thing working yeah
[889.02s -> 891.66s]  you don't remember your question okay
[891.66s -> 896.46s]  what's that okay all right so let's
[896.46s -> 897.62s]  see I'm gonna try this one more time
[897.62s -> 900.14s]  with the tablet and see if it were go
[900.14s -> 906.54s]  ahead what's your question oh that is
[906.54s -> 908.58s]  okay waiting okay good question the
[908.58s -> 909.58s]  question was a wait is that busy
[909.58s -> 911.02s]  waiting or is it okay waiting that is
[911.02s -> 914.54s]  okay waiting but it is but it doesn't
[914.54s -> 916.26s]  always solve all of our problems right
[916.26s -> 917.78s]  so the permits part can't really do
[917.78s -> 920.38s]  that with one mutex or even just a few
[920.38s -> 922.78s]  new taxes because as we saw with the
[922.78s -> 924.54s]  traveling for the traveling philosopher
[924.54s -> 926.70s]  I'm mixing my my big problems in the
[926.70s -> 929.18s]  world with the with the dining
[929.22s -> 931.54s]  philosophers you can't you have to have
[931.54s -> 933.98s]  the ability to say oh I'm limiting it
[933.98s -> 935.38s]  to so many people being able to do
[935.38s -> 937.26s]  this so many threads doing something
[937.26s -> 938.94s]  with that so it's you have to you
[938.94s -> 942.34s]  have to wait on that okay all right
[942.34s -> 958.38s]  so other question yes it's an
[958.38s -> 959.78s]  interesting question the question is what
[959.78s -> 962.10s]  is going on with when when there's locks
[962.10s -> 965.02s]  and file descriptors remember a lock
[965.02s -> 967.58s]  has no information about the rest of
[967.58s -> 970.34s]  the system okay if a thread if two
[970.34s -> 972.26s]  threads happen to be working on the
[972.26s -> 975.62s]  same file descriptor if one thread reads
[975.62s -> 977.58s]  a bit the other terrible read later in
[977.58s -> 979.38s]  the file descriptor but there's no they
[979.38s -> 982.46s]  they could read at the same time and
[982.46s -> 984.30s]  it would just interleave it as as is
[984.30s -> 986.10s]  necessary but yeah if you want to read
[986.10s -> 987.42s]  only apart from one thread and then
[987.46s -> 988.98s]  something from another thread having a
[988.98s -> 990.82s]  mutex is perfectly fine and you can
[990.82s -> 992.62s]  order it that way if you want to but
[992.62s -> 994.54s]  yeah there's no no other reason
[994.54s -> 997.02s]  remember mutexes are relatively simple
[997.02s -> 998.30s]  you either hold the lock or you don't
[998.30s -> 999.98s]  and anybody any other thread that
[999.98s -> 1001.78s]  tries to get the lock can't while
[1001.78s -> 1003.30s]  you're holding it that's the the
[1003.30s -> 1004.78s]  whole business with that with a mutex
[1004.78s -> 1008.54s]  okay all right let's move on to oh
[1008.54s -> 1010.62s]  let's see a couple other things about
[1010.62s -> 1013.54s]  it oh you should try to hold a mutex
[1013.54s -> 1017.14s]  for as short a time as possible okay
[1017.14s -> 1019.62s]  why because if other threads are trying
[1019.62s -> 1021.86s]  to access that lock and you're still
[1021.86s -> 1022.90s]  holding it because you're doing
[1022.90s -> 1025.34s]  something else if it doesn't matter to
[1025.34s -> 1026.98s]  your if it doesn't matter to your
[1026.98s -> 1028.58s]  logic that the lock is still held
[1028.58s -> 1030.90s]  release it earlier sometimes it's
[1030.90s -> 1032.58s]  inevitable and you have to release it
[1032.58s -> 1034.10s]  you know later on because you're still
[1034.10s -> 1036.22s]  using that data structure but you want
[1036.22s -> 1037.86s]  to really hold them for as short a
[1037.86s -> 1041.34s]  time as possible okay let's see dead
[1041.34s -> 1043.74s]  lock which is when two threads are
[1043.74s -> 1045.66s]  kind of waiting on each other that's
[1045.74s -> 1047.86s]  not really possible with a mutex with a
[1047.86s -> 1051.22s]  single mutex because either one lock or
[1051.22s -> 1052.94s]  one thread has it or not it's not like
[1052.94s -> 1054.54s]  they both can have it if you have
[1054.54s -> 1056.26s]  multiple mutexes that's when we start
[1056.26s -> 1057.54s]  getting into the deadlock problem
[1057.54s -> 1058.82s]  which is why we have to go on to
[1058.82s -> 1061.46s]  figure out other ways of doing this
[1061.46s -> 1067.82s]  okay so one nice very nice helper class
[1067.82s -> 1069.46s]  that's the easiest class in the
[1069.46s -> 1071.66s]  entire world is this thing called a
[1071.66s -> 1074.86s]  lock guard and a lock guard is as
[1075.06s -> 1077.42s]  simple as this it has two methods a
[1077.42s -> 1079.14s]  constructor and a destructor the
[1079.14s -> 1081.90s]  constructor locks the lock the destructor
[1081.90s -> 1083.94s]  unlocks the lock and that's it there
[1083.94s -> 1085.42s]  are no other functions no other
[1085.42s -> 1088.26s]  variables nothing okay just either locks
[1088.26s -> 1091.14s]  it or unlocks it and that's it it
[1091.14s -> 1093.10s]  takes a mutex as its parent so I
[1093.10s -> 1095.06s]  guess that's the one one variable it
[1095.06s -> 1096.66s]  may hold as a reference to the mutex
[1096.66s -> 1100.14s]  and what it what it's nice for is if
[1100.14s -> 1102.86s]  you know that you are going to lock
[1102.86s -> 1104.54s]  use a lock and then like leave a
[1104.54s -> 1106.90s]  function or leave a while the whole
[1106.90s -> 1108.66s]  function you might as well put a lock
[1108.66s -> 1109.78s]  guard around it so you don't have to
[1109.78s -> 1111.86s]  remember to unlock before you leave
[1111.86s -> 1113.66s]  it'll happen automatically for you and
[1113.66s -> 1115.30s]  it's nice in cases where you have
[1115.30s -> 1119.22s]  like conditional behavior where maybe
[1119.22s -> 1120.74s]  you're inside some while loop and you
[1120.74s -> 1122.66s]  return from that while loop great the
[1122.66s -> 1124.02s]  lock gets unlocked for you you don't
[1124.02s -> 1125.86s]  remember to do it or if you're out
[1125.86s -> 1127.46s]  if you break out of the while loop
[1127.46s -> 1130.90s]  and then leave the function the the
[1130.90s -> 1133.02s]  lock the mutex will get unlocked for
[1133.02s -> 1134.34s]  you as well this is a very nice
[1134.34s -> 1137.54s]  convenience class to use if you know
[1137.54s -> 1138.90s]  that you have to do that sometimes you
[1138.90s -> 1139.98s]  can't get away from it because you
[1139.98s -> 1142.46s]  do need to unlock and again don't
[1142.46s -> 1143.78s]  keep don't put a lock guard at the
[1143.78s -> 1145.62s]  top of your function just because it's
[1145.62s -> 1147.30s]  nice to use if you know that there's
[1147.30s -> 1149.54s]  other things you're going to be doing
[1149.54s -> 1152.06s]  in that function that other threads
[1152.06s -> 1153.58s]  might want that lock that would be a
[1153.58s -> 1155.70s]  bad use of it okay but you'll see
[1155.70s -> 1159.70s]  more examples of doing this okay all
[1159.70s -> 1161.50s]  right that's a lock guard now a
[1161.54s -> 1164.02s]  conditional variable any this is the one
[1164.02s -> 1165.74s]  that's a little trickier to understand
[1165.74s -> 1168.90s]  let's review what it does okay it works
[1168.90s -> 1171.86s]  in conjunction with a mutex so you
[1171.86s -> 1174.06s]  have a mutex and then a conditional
[1174.06s -> 1176.70s]  variable any has the ability to wait
[1176.70s -> 1180.94s]  for a signal based on that mutex okay
[1180.94s -> 1183.22s]  so basically what it does is it takes
[1183.22s -> 1185.70s]  the mutex and you lock the mutex and
[1185.70s -> 1189.02s]  then you do a wait on that mutex which
[1189.02s -> 1190.50s]  is this conditional variable any that
[1190.54s -> 1193.42s]  uses the mutex the conditional variable
[1193.42s -> 1197.14s]  any will push you off the processor
[1197.14s -> 1198.34s]  because you're waiting for something to
[1198.34s -> 1200.06s]  happen and then it will unlock the
[1200.06s -> 1202.42s]  lock so it's very similar to SIG
[1202.42s -> 1204.26s]  suspend in that case okay you can
[1204.26s -> 1205.98s]  think of it as analogous to to that
[1205.98s -> 1208.06s]  but the user should always lock the
[1208.06s -> 1210.82s]  mutex first then you're
[1210.82s -> 1212.62s]  generally going to check some condition
[1212.62s -> 1215.90s]  okay and you are going to if the
[1215.90s -> 1218.86s]  condition is met you are going to go
[1218.86s -> 1220.82s]  onto the next bit of code so this is
[1220.82s -> 1222.66s]  this is where conditional variable any
[1222.66s -> 1224.74s]  could be a little bit like easier to
[1224.74s -> 1226.50s]  use we will make it easier to use in
[1226.50s -> 1229.54s]  a minute okay and when you get this
[1229.54s -> 1233.74s]  notification the thread the the wait
[1233.74s -> 1236.30s]  function tries to reacquire that lock
[1236.30s -> 1239.06s]  it may not be possible because two
[1239.06s -> 1241.58s]  threads are waiting and if they both
[1241.58s -> 1243.54s]  get a signal at the same time which
[1243.54s -> 1245.78s]  often happens when we do conditional
[1245.82s -> 1248.90s]  variable any notify all CV notify all
[1248.90s -> 1251.14s]  when those two get that signal same
[1251.14s -> 1253.82s]  time they race to acquire the lock one
[1253.82s -> 1255.10s]  of them gets it the other one just
[1255.10s -> 1257.82s]  continues waiting okay so that's the
[1257.82s -> 1260.38s]  deal with conditional variable any's and
[1260.38s -> 1262.54s]  their their ability to do that and
[1262.54s -> 1264.58s]  when the weight on when the weight
[1264.58s -> 1266.42s]  comes out of the weight that you are
[1266.42s -> 1270.18s]  not you now have the you have the
[1270.18s -> 1271.86s]  lock again so when you get a signal
[1271.86s -> 1274.02s]  once you get the weight then you
[1274.06s -> 1276.18s]  actually acquire the lock again so you
[1276.18s -> 1279.70s]  should unlock it later okay that's how
[1279.70s -> 1281.98s]  the conditional variable any works we
[1281.98s -> 1284.46s]  use this often to do permitting where
[1284.46s -> 1286.98s]  you say I have these X number of
[1286.98s -> 1289.70s]  permits and I have those number of
[1289.70s -> 1291.02s]  through you know Y number of threads
[1291.02s -> 1292.94s]  which is more than X trying to access
[1292.94s -> 1294.62s]  this and I say only that many can do
[1294.62s -> 1299.46s]  it okay and the general idea is you're
[1299.46s -> 1301.14s]  gonna have something you're waiting on
[1301.14s -> 1303.66s]  the permits in this case while it's
[1303.66s -> 1305.58s]  equal to zero you're going to just keep
[1305.58s -> 1309.50s]  waiting and the the other function will
[1309.50s -> 1312.62s]  say increment the number of permits and
[1312.62s -> 1316.66s]  then notify everybody okay that's how
[1316.66s -> 1318.78s]  and then that's when you would check
[1318.78s -> 1320.34s]  you would try to acquire a lock you
[1320.34s -> 1321.74s]  acquire the lock you'd recheck the
[1321.74s -> 1323.58s]  permits see that it's one go out of
[1323.58s -> 1325.14s]  that thing and then you would
[1325.14s -> 1326.90s]  decrement the permits because now
[1326.90s -> 1329.90s]  you've got you're holding one so the
[1329.90s -> 1332.28s]  conditional variable any if you
[1332.32s -> 1334.32s]  understand it you go oh I see what's
[1334.32s -> 1335.92s]  going on here there's lots of you know
[1335.92s -> 1338.04s]  lots of nuance to say or lots of
[1338.04s -> 1341.56s]  incrementing and decrementing because
[1341.56s -> 1343.20s]  you're trying to keep track of this
[1343.20s -> 1345.04s]  one variable which is a permits type
[1345.04s -> 1348.76s]  variable okay so that's that's what
[1348.76s -> 1350.52s]  you have to do that's what the
[1350.52s -> 1352.56s]  conditional variable any does because of
[1352.56s -> 1355.60s]  this weight being a really or because
[1355.60s -> 1359.00s]  of this while loop being really common
[1359.00s -> 1361.60s]  well they built into a conditional
[1361.64s -> 1364.84s]  variable any the weight into another
[1364.84s -> 1366.64s]  type or they built that while loop
[1366.64s -> 1369.92s]  into a second version of weight which
[1369.92s -> 1374.12s]  works like this it takes the mutex just
[1374.12s -> 1376.00s]  like the regular conditional variable
[1376.00s -> 1378.40s]  anyway and then it takes a predicate
[1378.40s -> 1380.68s]  which means a function that returns
[1380.68s -> 1383.44s]  true or false okay that's the while
[1383.44s -> 1385.44s]  condition and it actually does it in
[1385.44s -> 1388.40s]  the opposite way which is you can
[1388.40s -> 1390.36s]  read it like this and this is
[1390.40s -> 1392.24s]  important if you read it it basically
[1392.24s -> 1395.28s]  this down here and often we make that
[1395.28s -> 1396.56s]  function into a lambda function
[1396.56s -> 1398.24s]  because we can otherwise we'd have to
[1398.24s -> 1399.72s]  call it as a separate function which
[1399.72s -> 1401.68s]  sometimes is a little awkward but in
[1401.68s -> 1402.92s]  this case we just call do it as a
[1402.92s -> 1404.64s]  lambda function we say like in this
[1404.64s -> 1407.72s]  case CV wait on the mutex on mutex M
[1407.72s -> 1410.12s]  we pass in the number of permits so
[1410.12s -> 1412.00s]  that we can access it this is in the
[1412.00s -> 1415.68s]  capture clause and then we say return
[1415.68s -> 1417.72s]  permits greater than zero so you can
[1417.72s -> 1421.04s]  say wait until permits is greater than
[1421.04s -> 1422.84s]  zero that's basically what this is
[1422.84s -> 1425.12s]  saying okay I like to use the that
[1425.12s -> 1427.60s]  that like until in this case wait
[1427.60s -> 1429.00s]  until a permit is greater than zero
[1429.00s -> 1432.00s]  because it's really while not permits
[1432.00s -> 1433.84s]  is greater than zero keep waiting
[1433.84s -> 1435.80s]  that's kind of what it really is but
[1435.80s -> 1436.88s]  in this case we just think I just
[1436.88s -> 1438.80s]  think of it as like okay well when
[1438.80s -> 1440.16s]  permits becomes greater than zero that's
[1440.16s -> 1442.72s]  when I can exit this weight okay
[1442.72s -> 1444.04s]  that's what we're looking for the
[1444.04s -> 1447.24s]  until part of that okay so that's how
[1447.24s -> 1449.24s]  conditional variable any's work you'll
[1449.24s -> 1452.32s]  see those in lab this week and you
[1452.32s -> 1454.80s]  will you'll practice using using
[1454.80s -> 1457.88s]  those a bit in lab okay but again you
[1457.88s -> 1460.04s]  still have to with with using these
[1460.04s -> 1461.76s]  conditional variable energy still do the
[1461.76s -> 1464.16s]  things like keep track of the permits
[1464.16s -> 1468.60s]  directly yourself okay and that's maybe
[1468.60s -> 1470.08s]  or maybe not what you want to do if
[1470.08s -> 1471.52s]  you don't want to do that well we
[1471.52s -> 1473.72s]  have another way okay the next thing
[1473.72s -> 1475.84s]  we're going to look at is the semaphore
[1475.84s -> 1480.96s]  class so a semaphore is also relatively
[1480.96s -> 1483.16s]  low level although first for whatever
[1483.16s -> 1486.04s]  reason it's not built into C++ for
[1486.04s -> 1488.64s]  us okay why could be because it's
[1488.64s -> 1490.36s]  actually really easy to build we'll
[1490.36s -> 1492.00s]  we'll take a look at the code again
[1492.00s -> 1495.24s]  in a second but second of all it we
[1495.24s -> 1496.84s]  can we once we build it we can use
[1496.84s -> 1498.44s]  it and we will allow you to use it
[1498.44s -> 1499.72s]  for the rest of the assignments we've
[1499.72s -> 1500.92s]  already built it for you now and
[1500.92s -> 1502.44s]  I'll show you that but here's how it
[1502.44s -> 1504.36s]  works it takes away all of that
[1504.36s -> 1506.16s]  increment and decrement the permits and
[1506.16s -> 1509.08s]  does it for you very nice okay it's
[1509.08s -> 1511.52s]  really easy to set up a semaphore okay
[1511.52s -> 1513.36s]  you basically say semaphore permits
[1513.36s -> 1515.92s]  five and that says there are five
[1515.92s -> 1520.76s]  permits okay and if you do permits dot
[1520.76s -> 1523.00s]  wait what it does is it looks and
[1523.00s -> 1524.52s]  goes oh how many of the five have
[1524.52s -> 1526.56s]  been used oh none of them okay you
[1526.56s -> 1528.24s]  get one and it gives you one and then
[1528.24s -> 1529.96s]  it decrements the permits now four are
[1529.96s -> 1531.72s]  available all the way down to zero
[1531.80s -> 1533.64s]  when there are zero available it just
[1533.64s -> 1538.44s]  waits okay and then when you say
[1538.44s -> 1541.64s]  permits dot signal that is you giving
[1541.64s -> 1543.72s]  up the permit telling anyone else
[1543.72s -> 1546.12s]  waiting for the permit to waiting for
[1546.12s -> 1548.04s]  the semaphore I have released one go
[1548.04s -> 1550.32s]  fight for the one I just released okay
[1550.32s -> 1551.48s]  and the only time that actually
[1551.48s -> 1553.04s]  signal gets sent is when you go from
[1553.04s -> 1554.76s]  zero to one because that's the only
[1554.76s -> 1556.36s]  way at time it matters otherwise it
[1556.36s -> 1558.16s]  will always be able to get the the
[1558.16s -> 1561.92s]  permit okay so that's how that works
[1561.92s -> 1567.48s]  you can think of a mutex as a special
[1567.48s -> 1569.64s]  case of a semaphore with one permit
[1569.64s -> 1572.60s]  kind of okay you shouldn't in fact if
[1572.60s -> 1574.24s]  you go look at this up on like stack
[1574.24s -> 1575.64s]  overflow there's lots of people saying
[1575.64s -> 1576.84s]  don't think of it that way that's not
[1576.84s -> 1578.44s]  a good way it's not exactly the same
[1578.44s -> 1579.36s]  some people have said oh this is
[1579.36s -> 1581.68s]  exactly the same it's not really but
[1581.68s -> 1583.00s]  you can think of it as being one
[1583.00s -> 1584.92s]  permit except that now you can
[1584.92s -> 1586.88s]  actually do a signal when you're done
[1586.92s -> 1589.60s]  with it and the interesting thing
[1589.60s -> 1592.56s]  about a semaphore is you you can
[1592.56s -> 1596.72s]  signal from well you don't have to be
[1596.72s -> 1598.96s]  the one acquiring the lock to signal
[1598.96s -> 1600.36s]  like that's the big difference there
[1600.36s -> 1602.16s]  mutex the only person that the only
[1602.16s -> 1604.36s]  thread that can unlock the mutex is
[1604.36s -> 1606.28s]  the one that locked it that's kind of
[1606.28s -> 1609.60s]  the other difference there okay now a
[1609.60s -> 1610.96s]  couple things we didn't talk about
[1610.96s -> 1614.16s]  semaphores what would a semaphore
[1614.20s -> 1620.16s]  initialized with zero mean what do you
[1620.16s -> 1622.44s]  guys think if I do the semaphore
[1622.44s -> 1623.68s]  initialized to one it would be there's
[1623.68s -> 1625.48s]  one permit and if I do so if I have
[1625.48s -> 1627.44s]  two threads fighting for it and they
[1627.44s -> 1629.88s]  and one they both they both try to
[1629.88s -> 1631.40s]  get it one will get it then when
[1631.40s -> 1632.68s]  that one signals the other one will
[1632.68s -> 1635.04s]  get it what would a semaphore with
[1635.04s -> 1637.12s]  permits of zero mean what do you think
[1637.12s -> 1645.92s]  has enough well so it's a good question
[1645.92s -> 1647.64s]  the question is would it just hang it
[1647.64s -> 1649.00s]  would they would if you had two
[1649.00s -> 1651.08s]  threads trying to get there it would
[1651.08s -> 1654.52s]  they would both wait until what what
[1654.52s -> 1659.84s]  do you think only the parent can
[1659.84s -> 1661.96s]  access the data not quite you're on
[1661.96s -> 1664.04s]  the right track somebody else has to do
[1664.04s -> 1666.12s]  something what do we say locks for
[1666.12s -> 1669.32s]  mutex the only thing that can release
[1669.32s -> 1672.88s]  the mutex is to unlock it is the one
[1672.88s -> 1675.16s]  that locked it is that true for
[1675.16s -> 1678.48s]  semaphores no anybody can signal on a
[1678.48s -> 1681.56s]  semaphore right so this so you're
[1681.56s -> 1682.88s]  getting there anybody else want to take
[1682.88s -> 1684.20s]  a step of what this actually means
[1684.20s -> 1686.76s]  this is actually an interesting case yeah
[1686.76s -> 1692.56s]  good yeah you're waiting for some
[1692.56s -> 1694.84s]  other thread to signal you and it
[1694.84s -> 1696.04s]  doesn't matter that the other thread
[1696.04s -> 1697.48s]  never needed to wait for that permit
[1697.48s -> 1699.72s]  necessarily right it's just a way to
[1699.72s -> 1701.80s]  say hey let some other signal at some
[1701.80s -> 1703.32s]  other threads signal me so you're gonna
[1703.32s -> 1705.52s]  say as well yeah there you go okay
[1705.52s -> 1706.56s]  so that's what that's what it is
[1706.56s -> 1710.88s]  here we don't have any permits
[1710.88s -> 1714.12s]  necessarily okay the permits wait means
[1714.12s -> 1715.48s]  you just have to wait for a signal
[1715.48s -> 1717.52s]  which can come from any other thread
[1717.52s -> 1718.72s]  I'm going to show you an example of
[1718.72s -> 1720.64s]  where this is another case of this
[1720.64s -> 1721.52s]  where it's actually more interesting
[1721.52s -> 1732.32s]  yeah yeah any thread can say permits
[1732.32s -> 1736.00s]  dot signal okay it doesn't matter that
[1736.00s -> 1738.04s]  it didn't have any lock to begin
[1738.04s -> 1740.40s]  with it might be that your logic says
[1740.40s -> 1742.04s]  hey these thread this one thread needs
[1742.04s -> 1743.28s]  to wait for something in fact I'm going
[1743.28s -> 1744.84s]  to show you an example in a second
[1744.84s -> 1748.08s]  where it's it actually is useful but
[1748.08s -> 1749.16s]  it might say this thread needs to
[1749.16s -> 1750.24s]  wait for a whole bunch of stuff to
[1750.24s -> 1751.68s]  happen and it's going to one of them
[1751.68s -> 1753.48s]  it's going to signal it when it finishes
[1753.48s -> 1755.52s]  and just wait doesn't have a permit
[1755.52s -> 1757.00s]  necessarily it doesn't need to lock
[1757.00s -> 1759.12s]  anything until they get it doesn't it
[1759.12s -> 1760.48s]  just needs to get the signal is
[1760.48s -> 1763.08s]  really what it needs to do okay you
[1763.08s -> 1765.22s]  know I'll see that in a second but my
[1765.22s -> 1766.96s]  next question is what if you then
[1766.96s -> 1771.80s]  it said permits negative number does that
[1771.80s -> 1776.04s]  mean let's look at the code to what
[1776.04s -> 1776.76s]  were you gonna say what are you gonna
[1776.76s -> 1784.56s]  say yeah yeah that's exactly where that
[1784.56s -> 1786.80s]  many different threads need to signal
[1786.80s -> 1787.96s]  before it can do you actually do
[1787.96s -> 1790.00s]  anything let's just go look at the
[1790.00s -> 1794.08s]  actual code for semaphore okay I
[1794.08s -> 1796.24s]  gotta remember where it is see slash
[1796.24s -> 1800.18s]  user slash class cs110 I think it's
[1800.18s -> 1803.64s]  local source I believe and then
[1803.64s -> 1807.56s]  threads there it is okay semaphore dot
[1807.56s -> 1809.80s]  CC and you can all go look at this okay
[1809.80s -> 1811.92s]  let's look at how this actually works
[1811.92s -> 1813.28s]  by the way it's got a bunch it's got a
[1813.28s -> 1815.24s]  CV in there it's got a conditional
[1815.24s -> 1816.52s]  variable because that's how we built
[1816.52s -> 1820.76s]  it right let's look at the weight and
[1820.76s -> 1823.60s]  the signal okay weight does the
[1823.60s -> 1827.28s]  following okay weight has this mutex that
[1827.28s -> 1829.04s]  it that it actually tries to acquire
[1829.04s -> 1831.80s]  because it does need to update that
[1831.84s -> 1834.56s]  value okay so you have to have that
[1834.56s -> 1836.80s]  lock in there some case in some sense
[1836.80s -> 1839.36s]  okay then it does a CV weight and it
[1839.36s -> 1842.12s]  does basically wait until the value is
[1842.12s -> 1844.84s]  greater than zero okay and then it
[1844.84s -> 1847.00s]  decrements the value once it actually
[1847.00s -> 1850.08s]  acquires that lock okay that's what
[1850.08s -> 1852.88s]  weight does what does signal do well
[1852.88s -> 1857.12s]  signal acquires the lock okay and then
[1857.12s -> 1861.00s]  increments the value and then if the
[1861.00s -> 1863.56s]  value becomes one it notifies everyone
[1863.56s -> 1870.92s]  all right yeah mutex m is a class
[1870.92s -> 1874.40s]  variable yep it's a class if you look
[1874.40s -> 1877.44s]  at let's see if I can do this
[1877.44s -> 1879.56s]  actually we'll do it here let's see
[1879.56s -> 1883.92s]  it's there include nope include semaphore
[1883.92s -> 1888.00s]  dot H there we go it is a there it is
[1888.00s -> 1890.04s]  it's a class very it's a class
[1890.04s -> 1892.56s]  variable right so when you create this
[1892.56s -> 1894.40s]  when you create the class now you've got
[1894.40s -> 1895.48s]  the mutex in there so it's shared
[1895.48s -> 1898.12s]  between the functions okay all right
[1898.12s -> 1901.36s]  so that's how signal and weight work
[1901.36s -> 1904.72s]  well notice that if the value it's
[1904.72s -> 1907.72s]  only it's really only either incrementing
[1907.72s -> 1909.80s]  or decrementing that value so if you
[1909.80s -> 1912.52s]  start that value off at some negative
[1912.52s -> 1915.04s]  number well it's going to take a whole
[1915.04s -> 1917.00s]  but that number kind of minus one
[1917.04s -> 1919.64s]  number of signals to get or other plus
[1919.64s -> 1921.72s]  one to that number of signals to get up
[1921.72s -> 1925.60s]  to one to actually to actually notify
[1925.60s -> 1928.76s]  the waiting threads that there's that
[1928.76s -> 1931.40s]  it's actually been done okay so what
[1931.40s -> 1933.40s]  might this what what is a an example
[1933.40s -> 1937.12s]  of when when you might need this well
[1937.12s -> 1940.32s]  what if we did the following okay let's
[1940.32s -> 1944.32s]  say we had a program where we had ten
[1944.32s -> 1946.12s]  threads were creating and they each
[1946.20s -> 1948.64s]  need to do something and then one more
[1948.64s -> 1952.44s]  thread needs to wait for it to actually
[1953.28s -> 1956.40s]  proceed with its thing now you could
[1956.40s -> 1959.28s]  do something like join all the ten
[1959.28s -> 1961.32s]  other threads and then do the next
[1961.32s -> 1962.84s]  thing if you wanted to but maybe you
[1962.84s -> 1964.36s]  want to keep those threads going
[1964.36s -> 1965.16s]  maybe you don't want to maybe you
[1965.16s -> 1966.56s]  want to do other logic that's going
[1966.56s -> 1968.16s]  to eventually you know do something
[1968.16s -> 1969.40s]  else in those threads or something
[1969.40s -> 1971.16s]  like that so what you can do in
[1971.16s -> 1973.76s]  this case is you can say let's
[1973.76s -> 1978.76s]  actually go and create these threads
[1979.24s -> 1981.72s]  and then each thread does its thing
[1981.72s -> 1983.36s]  in this case it's just gonna do a
[1983.36s -> 1985.92s]  C out and then it's going to send
[1985.92s -> 1988.36s]  a signal on that semaphore and
[1988.36s -> 1990.64s]  these these thread has no idea which
[1990.64s -> 1992.24s]  like number it's incrementing because
[1992.24s -> 1993.48s]  look I'm done with my stuff I'm
[1993.48s -> 1995.56s]  signaling anybody who cares I'm
[1995.56s -> 1997.76s]  done and it signals it right and
[1997.76s -> 2000.52s]  then the read after ten function
[2000.52s -> 2003.56s]  here well it just waits and because
[2004.08s -> 2005.96s]  we started out this semaphore in this
[2005.96s -> 2008.52s]  case negative nine okay once there's
[2008.52s -> 2010.72s]  ten things that happen it gets
[2010.72s -> 2013.12s]  incremented to one and that's when
[2013.12s -> 2014.52s]  the signal the way it happens and
[2014.52s -> 2017.20s]  that's when the actual semaphore
[2017.20s -> 2019.60s]  will allow the lot to continue by
[2019.60s -> 2021.00s]  the way bring you back down to
[2021.00s -> 2023.04s]  zero as it turns out but that's
[2023.04s -> 2025.08s]  a way to do a signal like that
[2025.08s -> 2027.48s]  through a thread that makes it so
[2027.48s -> 2028.84s]  that you can do ten things in a row
[2028.84s -> 2031.08s]  and the last one gets to work
[2031.40s -> 2035.44s]  like that so let's try this see my
[2035.44s -> 2040.68s]  lecture red CPP I think it is negative
[2040.68s -> 2042.52s]  semaphore okay so let's look at
[2042.52s -> 2044.28s]  negative semaphore which should be
[2044.28s -> 2048.28s]  exactly what I just said it is and
[2048.28s -> 2049.56s]  there's where by the way there's
[2049.56s -> 2051.36s]  where we're creating the semaphore
[2051.36s -> 2053.80s]  negative nine okay and then passing
[2053.80s -> 2055.12s]  that semaphore as reference into all
[2055.12s -> 2057.80s]  the other all the eleven threads we
[2057.80s -> 2060.00s]  happen to have and negative semaphore
[2060.04s -> 2062.32s]  there we go so the threads they all
[2062.32s -> 2063.44s]  did it in their own order which
[2063.44s -> 2065.12s]  they're going to each one signal
[2065.12s -> 2067.60s]  after it got done and then when the
[2067.60s -> 2070.32s]  last one received all those signals it
[2070.32s -> 2073.24s]  proceeded and that's how it worked
[2073.24s -> 2077.44s]  so questions on the new kind of way
[2077.44s -> 2079.04s]  we might use signal we're gonna see
[2079.04s -> 2080.68s]  an example in a second a better a
[2080.68s -> 2084.96s]  bigger example in a minute okay all
[2084.96s -> 2086.96s]  right three different types mutex
[2086.96s -> 2089.80s]  conditional variable any semaphore we
[2089.84s -> 2091.84s]  will use conditional variable any less
[2091.84s -> 2093.64s]  frequently because we've got semaphore
[2093.64s -> 2095.88s]  you will still use mutex is a lot so
[2095.88s -> 2097.64s]  they use those two much more than
[2097.64s -> 2099.68s]  conditional variable any on its own
[2099.68s -> 2101.60s]  although you may have a reason to
[2101.60s -> 2106.20s]  use that at some point okay let us
[2106.20s -> 2110.52s]  talk about another pattern here so
[2110.52s -> 2112.64s]  here's a pattern that's going to come
[2112.64s -> 2115.52s]  up occasionally and this is going to
[2115.52s -> 2117.32s]  leverage the fact that we can use
[2117.32s -> 2119.76s]  like zero not necessarily negative but
[2119.76s -> 2122.56s]  we can use zero for our semaphore to
[2122.56s -> 2127.68s]  go okay it also can be kind of a way
[2127.68s -> 2130.28s]  to not have to use thread join until
[2130.28s -> 2133.84s]  you absolutely need to okay so here's
[2133.84s -> 2135.04s]  what we're going to do we're going to
[2135.04s -> 2137.84s]  look at a program that has two threads
[2137.84s -> 2141.00s]  that are both acting on a particular
[2141.00s -> 2143.04s]  data structure one of the threads is
[2143.04s -> 2145.04s]  writing things to it the other thread
[2145.04s -> 2147.32s]  is going to read from it okay and
[2147.32s -> 2148.92s]  it's in fact going to read the data
[2149.08s -> 2151.16s]  that was just written okay it's very
[2151.16s -> 2153.60s]  similar to a pipe okay in fact pipes
[2153.60s -> 2155.12s]  may use some of this kind of under the
[2155.12s -> 2156.68s]  hood as well but it's very similar to
[2156.68s -> 2158.24s]  the idea of you're writing some data
[2158.24s -> 2159.72s]  and another one's reading the data
[2159.72s -> 2164.16s]  from that that data structure okay it's
[2164.16s -> 2168.32s]  kind of like a web server and a client
[2168.32s -> 2169.92s]  where the client to the web server
[2169.92s -> 2173.12s]  like you typing in www.google.com that
[2173.12s -> 2174.72s]  was that request goes out to the
[2174.72s -> 2176.40s]  Google server and Google gives you
[2176.40s -> 2177.72s]  back the data there's kind of a
[2177.76s -> 2179.84s]  handshake there where you're requesting
[2179.84s -> 2182.04s]  something and then the data has to come
[2182.04s -> 2185.28s]  back it's kind of like that and we will
[2185.28s -> 2187.28s]  do more of that if we get time today
[2187.28s -> 2189.48s]  we'll see another example of that as
[2189.48s -> 2192.28s]  well and as I said it's kind of like
[2192.28s -> 2195.32s]  a pipe okay here's the initial
[2195.32s -> 2197.16s]  program that I will zoom up and we'll
[2197.16s -> 2201.08s]  look at in a little bit of detail okay
[2201.08s -> 2204.28s]  how many people remember while you
[2204.28s -> 2207.84s]  remember cues from cs106b you ever
[2207.84s -> 2209.36s]  talk about like a circular queue or a
[2209.36s -> 2212.76s]  circular buffer remember those okay
[2212.76s -> 2213.92s]  well some people do and if you took
[2213.92s -> 2215.64s]  107e you definitely know those because
[2215.64s -> 2217.52s]  you know it's part of the assignments
[2217.52s -> 2219.84s]  here's what a circular buffer is let
[2219.84s -> 2221.76s]  me actually unzoom and draw a little
[2221.76s -> 2225.36s]  bit here I can hey look at that the
[2225.36s -> 2228.36s]  one from last time okay clear okay my
[2228.36s -> 2229.96s]  horrible drawing skills will come back
[2229.96s -> 2232.92s]  again okay so a circular buffer is
[2232.96s -> 2234.96s]  simply like that you can model it like
[2234.96s -> 2236.28s]  this anyway you can think of it as a
[2236.28s -> 2238.48s]  circle if you want to but a circular
[2238.48s -> 2240.40s]  buffer is like if you start writing
[2240.40s -> 2242.28s]  here the next place you're going to
[2242.28s -> 2243.56s]  write is here then here then here
[2243.56s -> 2245.24s]  then here then here and then you
[2245.24s -> 2246.76s]  just wrap around and continue to write
[2246.76s -> 2248.56s]  here so you need a head and a tail
[2248.56s -> 2251.20s]  more or less okay in fact you can
[2251.20s -> 2252.96s]  keep track of that in your program
[2252.96s -> 2255.56s]  with just a mod operator to keep track
[2255.56s -> 2257.36s]  of where in the actual circular buffer
[2257.36s -> 2258.96s]  is so you can have the buffer
[2258.96s -> 2261.04s]  partially filled or whatever you the
[2261.08s -> 2263.36s]  next place you write is here and let's
[2263.36s -> 2264.48s]  say that one's filled that one's filled
[2264.48s -> 2266.56s]  that one's filled that one's filled I
[2266.56s -> 2268.60s]  guess if your next one you're writing
[2268.60s -> 2270.56s]  is here this was not filled yet it's
[2270.56s -> 2272.76s]  so and so forth but the idea is let
[2272.76s -> 2274.44s]  me erase that like this so let's say
[2274.44s -> 2277.36s]  that everybody else up to here let's
[2277.36s -> 2279.88s]  say it was like this was filling say
[2279.88s -> 2281.04s]  that was filled that we're about to
[2281.04s -> 2283.32s]  write here we would then fill this
[2283.32s -> 2285.88s]  one oops we would then fill this one
[2285.88s -> 2287.52s]  and then come over here and this
[2287.52s -> 2288.72s]  would be the next one then we'd fill
[2288.72s -> 2290.36s]  this one and then we would next one
[2290.36s -> 2291.52s]  would be filled with over here and so
[2291.52s -> 2293.24s]  forth if you ever get to the end where
[2293.24s -> 2294.56s]  it's completely full of you you should
[2294.56s -> 2296.08s]  not continue to write to it because
[2296.08s -> 2298.80s]  it's too it's full that's a circular
[2298.80s -> 2301.00s]  buffer and it makes it nice instead
[2301.00s -> 2303.52s]  of having to like create nodes at each
[2303.52s -> 2305.32s]  time and like walk through them one
[2305.32s -> 2307.36s]  at a time you just have one array and
[2307.36s -> 2309.40s]  go through it in a circular way okay
[2309.40s -> 2312.20s]  anyway that's what a circular buffer is
[2312.20s -> 2314.04s]  so what we're going to do is we're
[2314.04s -> 2315.48s]  going to write a little program look
[2315.48s -> 2317.76s]  at a little program that has this
[2317.76s -> 2320.40s]  circular buffer where one of the threads
[2320.40s -> 2322.80s]  is going to be doing the writing and the
[2322.80s -> 2324.48s]  other thread is going to be doing the
[2324.48s -> 2326.92s]  reading and it's going to hopefully keep
[2326.92s -> 2329.48s]  track of who's writing where such
[2329.48s -> 2331.00s]  that it and reading so that it
[2331.00s -> 2333.08s]  doesn't ever trample on the other one
[2333.08s -> 2334.64s]  or read data that might not be
[2334.64s -> 2337.92s]  available yet okay so what does that
[2337.92s -> 2339.48s]  mean in terms of this program well
[2339.48s -> 2340.68s]  let's let's just look at how the
[2340.68s -> 2345.80s]  program is implemented so far okay we
[2345.80s -> 2348.52s]  have a writer which basically is going
[2348.52s -> 2351.56s]  to write random characters it's going
[2351.56s -> 2352.84s]  to randomly have a character it's going
[2352.84s -> 2354.00s]  to randomly put it's going to put
[2354.00s -> 2357.28s]  that character into the buffer one after
[2357.28s -> 2361.36s]  the other and it's only an eight a
[2361.36s -> 2364.32s]  buffer with eight positions in it but
[2364.32s -> 2367.32s]  we're going to do this 320 times okay
[2367.32s -> 2368.88s]  so it's going to write and then wrap
[2368.88s -> 2371.60s]  around and write right now if
[2371.60s -> 2373.80s]  everything went correct went well the
[2373.80s -> 2375.36s]  reading and writing would happen at the
[2375.40s -> 2378.20s]  exact same rate so that you could do
[2378.20s -> 2379.76s]  that and then the writer might be a
[2379.76s -> 2381.20s]  little bit ahead of a reader and they
[2381.20s -> 2382.60s]  would keep going in that circular
[2382.60s -> 2385.00s]  pattern that would be ideal okay it's
[2385.00s -> 2386.64s]  a very simple like thing that's
[2386.64s -> 2388.28s]  happening here it's just taking that
[2388.28s -> 2390.64s]  random character putting it somewhere in
[2390.64s -> 2393.20s]  the buffer and then when the I
[2393.20s -> 2395.80s]  variable gets bigger than bigger than
[2395.80s -> 2397.20s]  seven it wraps back around at the
[2397.20s -> 2399.52s]  beginning and keeps going it just does
[2399.52s -> 2401.60s]  that 320 times putting the data in
[2401.60s -> 2403.04s]  there okay that's what it doesn't
[2403.04s -> 2405.04s]  then when it's done it says or it
[2405.04s -> 2406.80s]  actually each time it says that it's
[2406.80s -> 2410.20s]  put that data in there and the reader
[2410.20s -> 2413.68s]  does the kind of the reverse it goes
[2413.68s -> 2415.20s]  through and it reads the data one
[2415.20s -> 2416.96s]  character a time and then just wraps
[2416.96s -> 2419.56s]  around and keeps reading data okay so
[2419.56s -> 2421.76s]  in a perfect world the writer might be
[2421.76s -> 2423.08s]  one or two steps ahead of the reader
[2423.08s -> 2424.80s]  and it would everything would work
[2424.80s -> 2427.56s]  perfectly okay and these are in
[2427.56s -> 2429.28s]  different threads so you might think oh
[2429.28s -> 2431.12s]  there's a race condition here ah there
[2431.12s -> 2433.76s]  is let's actually look at it here
[2433.80s -> 2437.12s]  okay this is called confused reader
[2437.12s -> 2439.88s]  writer okay and remember it's taking
[2439.88s -> 2443.12s]  random characters and and then writing
[2443.12s -> 2444.32s]  them and then reading those random
[2444.32s -> 2445.24s]  characters out so it's going to look
[2445.24s -> 2447.24s]  a little funny here at first I will
[2447.24s -> 2449.12s]  actually stop it well because it's
[2449.12s -> 2450.28s]  doing that let's look at what's
[2450.28s -> 2454.68s]  happening here okay so the writer is
[2454.68s -> 2457.00s]  ready to write and the reader is
[2457.00s -> 2459.40s]  ready to the reader is ready to read
[2459.40s -> 2465.04s]  and the writer publishes S okay well the
[2465.04s -> 2467.12s]  reader and then the reader consumes
[2467.12s -> 2470.28s]  space what's going on with that and
[2470.28s -> 2471.84s]  then it says on the reader consumed
[2471.84s -> 2475.60s]  G and then the writer wrote in J and
[2475.60s -> 2478.00s]  the reader consumed at well what's
[2478.00s -> 2479.92s]  happening here is the reader is trying
[2479.92s -> 2481.48s]  to read before the writer has ever
[2481.48s -> 2482.92s]  even written anything and whatever the
[2482.92s -> 2484.56s]  garbage was in there to begin with
[2484.56s -> 2487.52s]  is what gets read out okay and so
[2487.56s -> 2490.04s]  eventually and then it reads consumed
[2490.04s -> 2491.60s]  data with like nothing and blah blah
[2491.60s -> 2493.52s]  can't even write it eventually you
[2493.52s -> 2495.32s]  might see some of the data getting in
[2495.32s -> 2496.56s]  there but it's all garbled and
[2496.56s -> 2498.44s]  there's nothing the writer is writing
[2498.44s -> 2500.84s]  over parts and it's not very it's not
[2500.84s -> 2504.20s]  working the way we want it to yeah
[2506.64s -> 2508.84s]  they're writing to and reading from the
[2508.84s -> 2511.08s]  same buffer which is just a charge
[2511.08s -> 2515.36s]  star buffer yeah you don't worry
[2515.36s -> 2516.72s]  about anything well that's a good
[2516.72s -> 2517.56s]  question you said you don't have to
[2517.56s -> 2519.40s]  worry about any cursor we kind of are
[2519.40s -> 2521.28s]  worrying about the cursor right let me
[2521.28s -> 2522.60s]  go back to the let me go back to the
[2522.60s -> 2524.00s]  drawing again okay let me actually
[2524.00s -> 2527.64s]  redo the the drawing like this okay
[2527.64s -> 2531.48s]  here is the buffer okay let's do it
[2531.48s -> 2533.88s]  in a little more even let's say that
[2533.88s -> 2535.40s]  one two three four or five let's only
[2535.40s -> 2537.44s]  say there's six places okay let's say
[2537.44s -> 2540.96s]  that this is where the first read is
[2540.96s -> 2542.36s]  going to happen but it's also where
[2542.36s -> 2543.76s]  the first right is going to happen
[2543.76s -> 2546.20s]  okay so let's call this the read head
[2546.20s -> 2548.88s]  and the right head there okay well
[2548.88s -> 2551.40s]  where is the last thing that could
[2551.40s -> 2552.88s]  possibly get read it turns out to this
[2552.88s -> 2554.68s]  as well like if you go I'll wrap all
[2554.68s -> 2556.24s]  the way around but that's kind of a
[2556.24s -> 2557.72s]  nuance but for now let's think about
[2557.72s -> 2560.08s]  it let's say that the writer let's say
[2560.08s -> 2562.44s]  the reader tries to read first what's
[2562.44s -> 2564.60s]  gonna read garbage here right so
[2564.60s -> 2566.00s]  that's gonna be garbage if it gets
[2566.00s -> 2567.80s]  ahead well let's say the writer did
[2567.80s -> 2570.32s]  get to write a okay the writer writes
[2570.32s -> 2571.88s]  a and then the writer writes B and then
[2571.88s -> 2573.04s]  the writer writes C and D and let's
[2573.04s -> 2574.72s]  say the reader is nice and starts
[2574.76s -> 2576.76s]  reading now well the reader will read a
[2576.76s -> 2578.36s]  and then be here and the reader will
[2578.36s -> 2579.76s]  read B and be there and then be there
[2579.76s -> 2581.28s]  and the reader will read D etc and
[2581.28s -> 2584.56s]  let's say E F and then it comes
[2584.56s -> 2586.60s]  around here and reads G well good
[2586.60s -> 2588.04s]  let's say the reader some for some
[2588.04s -> 2590.84s]  reason stalls reading right here well
[2590.84s -> 2592.96s]  this is G and then this is going to
[2592.96s -> 2594.88s]  be H and then this is going to be I
[2594.88s -> 2597.56s]  oh it's going to be J before the
[2597.56s -> 2599.80s]  reader ever reads it so that's the
[2599.80s -> 2601.88s]  big issue here okay if they're not in
[2601.88s -> 2603.84s]  perfect sync they're going to be in
[2603.88s -> 2606.60s]  trouble okay now the perfect sync is
[2606.60s -> 2609.72s]  actually a little bit nuanced as well to
[2609.72s -> 2612.08s]  be perfectly synced how many how many
[2612.08s -> 2613.60s]  things can get read before anything's
[2613.60s -> 2616.68s]  written zero right you have to write
[2616.68s -> 2618.12s]  something before you can read any of
[2618.12s -> 2619.56s]  it how many things can be written
[2619.56s -> 2623.88s]  before something must be read the max
[2623.88s -> 2625.88s]  number of things right so you could
[2625.88s -> 2627.48s]  write all the way to the end here
[2627.48s -> 2630.36s]  before going back but if the inch do
[2630.36s -> 2631.88s]  you go back if nothing's been read yet
[2631.88s -> 2634.56s]  you'd better wait okay so that's going
[2634.56s -> 2636.04s]  to be the idea of what we're going to
[2636.04s -> 2640.60s]  do with this with this program here
[2640.60s -> 2642.76s]  okay so anyway we go back and we look
[2642.76s -> 2643.84s]  at it again and we go out so it's
[2643.84s -> 2645.76s]  completely garbled nobody's in the
[2645.76s -> 2647.56s]  right order it should have been it
[2647.56s -> 2651.12s]  should have read SJ CM and let's see
[2651.12s -> 2654.08s]  there's an SJ CM and it did read it
[2654.08s -> 2656.88s]  starting down there but eventually you
[2656.88s -> 2658.48s]  know there's not a not necessarily in
[2658.48s -> 2659.52s]  sync and a bunch of stuff got read
[2659.52s -> 2665.20s]  first and whatever not so good okay how
[2665.20s -> 2667.40s]  can we fix this well there are
[2667.40s -> 2670.40s]  different ways of fixing it okay you
[2670.40s -> 2673.44s]  could you probably could use a couple
[2673.44s -> 2675.20s]  of mutexes maybe if you wanted to
[2675.20s -> 2676.92s]  and try to set it up like that you
[2676.92s -> 2678.76s]  if the that's one way of doing it
[2678.76s -> 2681.36s]  one the way I want to show you is by
[2681.36s -> 2687.28s]  using two semaphores okay what we're
[2687.28s -> 2688.36s]  going to do is work at this is
[2688.40s -> 2689.40s]  actually kind of what we just went
[2689.40s -> 2692.44s]  through why it's broken there's nothing
[2692.44s -> 2694.36s]  basically there's nothing that tells
[2694.36s -> 2696.92s]  the reader that a slot can be read
[2696.92s -> 2698.72s]  from yet and there's nothing to tell
[2698.72s -> 2699.96s]  the writer that all the slots are
[2699.96s -> 2703.00s]  full that's the big problem okay all
[2703.00s -> 2705.76s]  right so what can we do well we can
[2705.76s -> 2708.04s]  have two semaphores okay if we have
[2708.04s -> 2709.56s]  an eight character buffer we can
[2709.56s -> 2714.28s]  initialize an empty buffers to eight
[2714.28s -> 2715.96s]  in other words it starts out with
[2715.96s -> 2718.04s]  eight empty buffers there's eight
[2718.04s -> 2720.28s]  spots that are empty so far so good
[2720.28s -> 2723.68s]  okay and then we can also set up a
[2723.68s -> 2726.80s]  semaphore that says full buffers
[2726.80s -> 2729.80s]  well how many are full initially zero
[2729.80s -> 2731.80s]  so let's do a semaphore starting at
[2731.80s -> 2734.36s]  zero which is that weird case where
[2734.36s -> 2737.96s]  it's always going to require a signal
[2737.96s -> 2739.96s]  to at least get going because it
[2739.96s -> 2741.72s]  started with no permits available and
[2741.72s -> 2744.48s]  it's it's that's what's happening
[2744.48s -> 2747.84s]  there okay so we can do that we can set
[2747.84s -> 2750.60s]  up the semaphore full buffers and
[2750.60s -> 2752.80s]  empty buffers the full buffers if you
[2752.80s -> 2754.92s]  say a semaphore with no parameter it
[2754.92s -> 2757.88s]  starts out at zero okay if you do an
[2757.88s -> 2760.08s]  empty buffer if you do the parameter
[2760.08s -> 2761.36s]  here that's how many permits there
[2761.36s -> 2762.60s]  basically are and this one says
[2762.60s -> 2764.88s]  there's eight empty buffers then you
[2764.88s -> 2766.76s]  have to of course pass both the full
[2766.76s -> 2768.60s]  and empty into both the reader and
[2768.60s -> 2769.88s]  the writer because they're both going
[2769.88s -> 2773.04s]  to be handling both reader and writer
[2773.08s -> 2774.12s]  one's going to be waiting and then
[2774.12s -> 2775.20s]  signaling the other and the other is
[2775.20s -> 2775.96s]  going to be waiting on the other one
[2775.96s -> 2777.88s]  and signaling the first one so that's
[2777.88s -> 2779.80s]  what we're going to have to be
[2779.80s -> 2782.36s]  working on let's see how this works
[2782.36s -> 2786.40s]  in the actual functions so what do we
[2786.40s -> 2789.32s]  have all right we've got the full and
[2789.32s -> 2792.48s]  the empty semaphores here okay we
[2792.48s -> 2793.68s]  are still going to do the same logic
[2793.68s -> 2795.16s]  as before we're just going to do the
[2795.16s -> 2798.30s]  for loop through the entire buffer the
[2798.30s -> 2800.12s]  first thing the writer is going to do
[2800.16s -> 2802.16s]  is it's going to wait on the empty
[2802.16s -> 2805.20s]  buffers but we initialize those to eight
[2805.20s -> 2808.16s]  and for a semaphore if the count is
[2808.16s -> 2811.08s]  eight permits will it wait at all no
[2811.08s -> 2813.12s]  it says great I can start writing and
[2813.12s -> 2814.92s]  so boom it starts writing and then it
[2814.92s -> 2816.28s]  tries to wait again and now there's
[2816.28s -> 2817.52s]  seven available and boom it starts
[2817.52s -> 2819.08s]  writing and that's that and it will
[2819.08s -> 2823.08s]  keep going okay after it writes a
[2823.08s -> 2827.32s]  character it signals the full hey
[2827.32s -> 2829.08s]  there's a character I just wrote and
[2829.32s -> 2833.28s]  so that increments the that increments
[2833.28s -> 2837.00s]  the full counter in the semaphore to
[2837.00s -> 2839.10s]  one and it signals because it
[2839.10s -> 2841.04s]  incremented to one and it signals the
[2841.04s -> 2845.20s]  it signals the other thread the reader
[2845.20s -> 2846.76s]  hey there's something available I just
[2846.76s -> 2849.88s]  put something there all right let's
[2849.88s -> 2851.92s]  look at the reader the reader does
[2851.92s -> 2855.16s]  kind of the opposite it still goes
[2855.16s -> 2857.12s]  through the loop and does it starts by
[2857.16s -> 2860.00s]  waiting for full well nothing's full at
[2860.00s -> 2862.44s]  the beginning so reader has to wait at
[2862.44s -> 2864.24s]  least one iteration of the writer
[2864.24s -> 2866.12s]  putting something in there because the
[2866.12s -> 2867.96s]  the semaphore it's using starts out
[2867.96s -> 2870.96s]  at zero okay but then it immediately
[2870.96s -> 2872.80s]  gets a signal once the first thing
[2872.80s -> 2875.40s]  goes into the writer or once a writer
[2875.40s -> 2876.92s]  writes one it originally immediately get
[2876.92s -> 2878.56s]  signal can read it immediately it
[2878.56s -> 2879.84s]  might be just one step behind
[2879.84s -> 2881.32s]  because maybe the writer hasn't
[2881.32s -> 2882.92s]  written the next one yet and then it
[2882.92s -> 2885.24s]  then it does have to wait again but
[2885.24s -> 2886.96s]  it will do it immediately when there
[2887.80s -> 2889.36s]  is a spot available and there may be
[2889.36s -> 2891.64s]  many depending on how many the writer
[2891.64s -> 2893.52s]  wrote in there might be there might be
[2893.52s -> 2896.16s]  many in there up to eight okay and
[2896.16s -> 2900.16s]  then let's see it then it signals
[2900.16s -> 2902.00s]  empty saying here is emptied one and
[2902.00s -> 2906.64s]  that's when the the empty which the
[2906.64s -> 2909.16s]  writer when it's waiting could end up
[2909.16s -> 2911.72s]  going forward okay so this one by the
[2911.72s -> 2913.92s]  way we'll do this up to eight times
[2913.92s -> 2915.92s]  without the reader doing anything and we
[2915.96s -> 2918.24s]  can test that as we go and then it will
[2918.24s -> 2920.04s]  it should work so this is now how the
[2920.04s -> 2922.56s]  semaphores are going to be useful to
[2922.56s -> 2925.52s]  us to keep everything in order okay
[2925.52s -> 2927.76s]  let's actually look at that one this
[2927.76s -> 2929.84s]  one is just called reader writer the
[2929.84s -> 2931.60s]  correct one so I'll let that go in
[2931.60s -> 2934.56s]  there for a bit and let me just zoom
[2934.56s -> 2938.00s]  up to the top here okay the readers
[2938.00s -> 2939.44s]  are the writers ready to write in the
[2939.44s -> 2941.52s]  readers ready to read great the
[2941.52s -> 2944.36s]  writer published a well guess what the
[2944.40s -> 2946.68s]  reader immediately consumed a and there's
[2946.68s -> 2948.08s]  by the way I shouldn't have said this
[2948.08s -> 2950.12s]  before there's a little bit of random
[2950.12s -> 2952.84s]  sleeping going on here too so that that
[2952.84s -> 2954.28s]  this is you know why it is just one
[2954.28s -> 2955.40s]  after the other because there's some
[2955.40s -> 2957.24s]  random sleeping going on here the
[2957.24s -> 2959.72s]  reader got a in order and then Y goes
[2959.72s -> 2961.76s]  in and then Y comes out and then W IQ
[2961.76s -> 2963.04s]  W well it must have been that the
[2963.04s -> 2964.20s]  reader went to sleep for a while
[2964.20s -> 2966.20s]  because the writer got a chance to
[2966.20s -> 2968.96s]  put four new things into the reader W
[2968.96s -> 2971.52s]  IQ W but what gets read out oh good
[2971.52s -> 2975.08s]  W IQ W gets read out so we know it's
[2975.08s -> 2978.16s]  going to be in order there okay and then
[2978.16s -> 2980.28s]  it continues going through I'm not sure
[2980.28s -> 2982.08s]  we get to a point where we might get
[2982.08s -> 2984.40s]  to a point where eight things go in
[2984.40s -> 2986.68s]  and it waits that long but we can we
[2986.68s -> 2987.60s]  can do that but anyway it is
[2987.60s -> 2990.24s]  definitely going to do it in order
[2990.24s -> 2993.78s]  okay that makes sense everybody out why
[2993.78s -> 2996.36s]  that's the case it doesn't go back and
[2996.36s -> 2998.16s]  look at the code again and remember go
[2998.16s -> 2999.72s]  look at the semaphore code and see
[2999.76s -> 3004.56s]  how that actually works as well all
[3004.56s -> 3011.20s]  right let's look at the code yeah does
[3011.20s -> 3013.76s]  it matter if you join the reader
[3013.76s -> 3023.12s]  writer first yeah good question does it
[3023.12s -> 3024.88s]  matter if you let's actually look at
[3024.88s -> 3026.44s]  the the actual code here exciting put
[3026.44s -> 3029.44s]  that in the main again down here does
[3029.44s -> 3031.12s]  it matter which one you join first I
[3031.12s -> 3034.76s]  don't believe it does why because as
[3034.76s -> 3038.64s]  long as they all get to finish then
[3038.64s -> 3040.48s]  the buffers will be will be filled in
[3040.48s -> 3043.12s]  that case right if you try to
[3043.12s -> 3047.44s]  actually let's see if you try to
[3047.44s -> 3051.96s]  wait on the reader first there it
[3051.96s -> 3053.64s]  might get that the writer ends up
[3053.64s -> 3056.72s]  let's see if you tried to wait on the
[3056.72s -> 3057.84s]  reader it might be it might be that
[3057.84s -> 3059.68s]  you have to do it in order just because
[3059.68s -> 3061.16s]  you have to write before you can read
[3061.16s -> 3063.16s]  and if you wait on the let's see if
[3063.16s -> 3064.96s]  you waited on the reader first you
[3064.96s -> 3067.70s]  might end up not being able to read
[3067.70s -> 3071.52s]  at all and therefore I never think
[3071.52s -> 3073.24s]  about it more yeah I don't think about
[3073.24s -> 3074.92s]  it more but I don't I don't think it's
[3074.92s -> 3076.40s]  actually a racist in that case the
[3076.40s -> 3078.32s]  final waiting it might be I'll get
[3078.32s -> 3079.64s]  back to you on that yeah good
[3079.64s -> 3082.16s]  question yeah yeah so I mean we can
[3082.16s -> 3083.80s]  try it I I don't know that's a good
[3083.80s -> 3085.96s]  we can absolutely try it but I don't
[3085.96s -> 3087.36s]  know that it's going to prove our case
[3087.88s -> 3089.84s]  will prove the negative but let's try it
[3089.84s -> 3093.64s]  reader writer okay and then reader
[3093.64s -> 3095.96s]  writer there we go okay let's just see
[3095.96s -> 3097.84s]  if it goes all the way through it would
[3097.84s -> 3099.24s]  only happen near the end we would care
[3099.24s -> 3101.44s]  because one would end before the other
[3101.44s -> 3103.68s]  but no again and now I think about it
[3103.68s -> 3106.20s]  I don't think it's possible for if one
[3106.20s -> 3107.60s]  ends and it's waiting for the other
[3107.60s -> 3110.08s]  who cares if it's waiting for the
[3110.08s -> 3111.64s]  first one it hasn't ended yet who cares
[3111.64s -> 3114.60s]  so or if the data hasn't come the
[3114.60s -> 3116.08s]  other one wouldn't have ended yet so I
[3116.12s -> 3118.08s]  think it doesn't matter I'm pretty sure
[3118.08s -> 3120.80s]  I'll confirm that but it did finish so
[3120.80s -> 3122.44s]  at least we we know that it can work
[3122.44s -> 3125.20s]  again these sorts of things don't do
[3125.20s -> 3127.52s]  that let it let's do this though let's
[3127.52s -> 3129.16s]  put in on just a little bit more
[3129.16s -> 3133.16s]  waiting we'll put in let's see let's
[3133.16s -> 3137.80s]  put a let's put us let's put a little
[3137.80s -> 3143.04s]  sleep for in here for like three
[3143.04s -> 3146.44s]  seconds right before it even starts to
[3146.44s -> 3148.48s]  try to read this is going to mean that
[3148.48s -> 3149.80s]  the writer is going to try to put it's
[3149.80s -> 3150.84s]  going to put eight things in there and
[3150.84s -> 3152.88s]  then hopefully it will wait to see if
[3152.88s -> 3155.28s]  that works
[3155.28s -> 3159.48s]  all right reader writer okay there we
[3159.48s -> 3161.00s]  go so it's put one two three four five
[3161.00s -> 3162.32s]  six seven eight things in there and
[3162.32s -> 3164.24s]  then it went going after the reader
[3164.24s -> 3166.04s]  finally woke up now I'm going to start
[3166.04s -> 3167.88s]  reading some things that's how that
[3167.88s -> 3170.24s]  worked and the other way around we put
[3170.24s -> 3172.92s]  the if we put it in the writer or in
[3172.96s -> 3174.60s]  rather in the yeah if we put it in the
[3174.60s -> 3176.84s]  before the writer what's going to happen
[3176.84s -> 3183.92s]  here what do you think if I put the
[3183.92s -> 3186.84s]  sleep there what's gonna happen now
[3186.84s -> 3191.64s]  yeah what do you think it should wait
[3191.64s -> 3192.92s]  three seconds for doing almost anything
[3192.92s -> 3194.64s]  right because the real yeah I think
[3194.64s -> 3197.40s]  that's a good good good answer make
[3197.40s -> 3201.60s]  read a writer and then we're going to
[3201.60s -> 3204.56s]  there we go okay there everybody's ready
[3204.56s -> 3206.68s]  then finally the writer starts writing
[3206.68s -> 3207.96s]  up three seconds and then boom it goes
[3207.96s -> 3209.84s]  okay cuz nothing's ever been written
[3209.84s -> 3211.88s]  the reader can't bother to or can't
[3211.88s -> 3225.52s]  do the reading it question good
[3225.52s -> 3226.84s]  question how does it get nine there
[3226.84s -> 3228.16s]  let's actually run in this case and
[3228.16s -> 3229.44s]  see what happens if we get a whole
[3229.44s -> 3231.20s]  bunch of did it do nine or it might
[3231.20s -> 3233.36s]  just be probably just a race condition
[3233.36s -> 3235.20s]  would who writing and reading that's my
[3235.20s -> 3238.36s]  guess it can't read nine without with
[3238.36s -> 3240.52s]  it can't read nine a row because
[3240.52s -> 3242.72s]  there aren't nine spots right but it's
[3242.72s -> 3244.56s]  probably the last right the reeds
[3244.56s -> 3246.76s]  already printing out or isn't printing
[3246.76s -> 3248.52s]  out yet or something like that so it's
[3248.52s -> 3250.16s]  just a race condition there if it were
[3250.16s -> 3252.20s]  like 20 I'd be a little suspect but I
[3252.20s -> 3254.00s]  think eight or nine or ten not a
[3254.00s -> 3255.72s]  one two three four five seven eight
[3255.72s -> 3259.60s]  nine yeah last one and it did do two
[3259.60s -> 3260.92s]  esses at the end so that wasn't a weird
[3260.92s -> 3264.96s]  yeah so I think it's just that the it's
[3264.96s -> 3266.44s]  probably just a race just there it's
[3266.44s -> 3268.68s]  also that maybe the writers got a little
[3268.68s -> 3270.60s]  more is writing a little faster than
[3270.60s -> 3272.08s]  the reader anyway and readers doesn't
[3272.08s -> 3274.28s]  never quite catches up until the last
[3274.28s -> 3275.60s]  part where it goes out finally I can
[3275.60s -> 3277.56s]  read all the rest of the data yeah I
[3277.56s -> 3279.76s]  think that's going on there too do you
[3279.76s -> 3281.88s]  have more questions no are you sure
[3281.88s -> 3289.96s]  okay anybody else all right so that's
[3289.96s -> 3297.72s]  the that reader writer paradigm okay all
[3297.72s -> 3300.84s]  right I think we have time to take a
[3300.84s -> 3302.20s]  look we may not get through the whole
[3302.20s -> 3303.24s]  thing but let's take a look at this
[3303.24s -> 3305.88s]  thing called myth buster okay this is
[3305.88s -> 3308.60s]  a jerry-kane special it's called myth
[3308.60s -> 3310.28s]  buster because what all it does is it
[3310.32s -> 3312.68s]  basically just log on to a myth and you
[3312.68s -> 3314.00s]  go wow there's a thousand other people
[3314.00s -> 3315.52s]  on here it's really slow and it's kind
[3315.52s -> 3317.16s]  of annoying and maybe it'd be kind of
[3317.16s -> 3319.52s]  nice to know which myth has the least
[3319.52s -> 3322.88s]  number of like cs110 people slamming it
[3322.88s -> 3325.84s]  okay well that's what this myth
[3325.84s -> 3328.32s]  busters does okay it basically goes
[3328.32s -> 3331.96s]  to all I guess 10 or 12 myth machines
[3331.96s -> 3335.04s]  and it queries them using a kind of a
[3335.04s -> 3338.92s]  wonky hack to actually see how many
[3339.04s -> 3341.88s]  threads for people in this class are
[3341.88s -> 3343.84s]  using that now I also think it should
[3343.84s -> 3345.76s]  check 107 or just in threads in general
[3345.76s -> 3348.24s]  but whatever it checks this class okay
[3348.24s -> 3349.92s]  and I'll show you it running before we
[3349.92s -> 3353.60s]  do anything else okay myth buster let's
[3353.60s -> 3355.52s]  do it concurrent that's the one we
[3355.52s -> 3359.68s]  don't love but okay okay so holy
[3359.68s -> 3360.88s]  smokes who's using all these
[3360.88s -> 3365.04s]  processes what is this machine and
[3365.04s -> 3366.04s]  there's a little race condition there
[3366.04s -> 3368.32s]  anyway with a number of least oh no
[3368.32s -> 3370.88s]  machine least loaded by CS machine
[3370.88s -> 3372.08s]  number of process at least loaded
[3372.08s -> 3374.08s]  machine 74 so if you were to use it
[3374.08s -> 3375.52s]  you would want to log on a myth 52
[3375.52s -> 3379.24s]  but I'm actually really curious myth 65
[3379.24s -> 3387.52s]  SSH myth 65 myth myth 65 h top let's
[3387.52s -> 3390.84s]  see okay somebody's let's see so
[3390.84s -> 3393.76s]  there's that let's see factor Python
[3393.80s -> 3400.20s]  factor who is this okay so so you you
[3400.20s -> 3402.76s]  left a whole bunch of factors like going
[3402.76s -> 3405.60s]  in your program possibly possibly when
[3405.60s -> 3407.40s]  you when you started I don't mean to
[3407.40s -> 3408.88s]  call him out but she's after the book
[3408.88s -> 3410.64s]  book there were thousands of them so
[3410.64s -> 3412.56s]  you said it's not alone I guarantee you
[3412.56s -> 3414.56s]  that there's some more okay there's
[3414.56s -> 3416.40s]  some more all right let's see if we
[3416.40s -> 3417.92s]  can find a bunch more yeah there's a
[3417.92s -> 3421.36s]  whole bunch more so so yeah so you
[3421.36s -> 3422.64s]  should kill all your process so I
[3422.68s -> 3424.76s]  literally when I when I ran this earlier
[3424.76s -> 3426.56s]  I noticed some of these and I'm gonna
[3426.56s -> 3427.88s]  have to write a little note to next
[3427.88s -> 3430.04s]  quarter make it so that every time you
[3430.04s -> 3431.76s]  submit it just kills all your
[3431.76s -> 3433.56s]  outstanding processes that are still
[3433.56s -> 3435.08s]  running on whatever myth one you have
[3435.08s -> 3437.56s]  because because that's it so anyway
[3437.56s -> 3439.08s]  that's you guys are all doing that in
[3439.08s -> 3440.68s]  those poor 107 students can't use the
[3440.68s -> 3442.32s]  myth machines because you're to neither
[3442.32s -> 3447.60s]  can you so Emma what you can do by
[3447.60s -> 3449.92s]  the way is you can say I think kill
[3449.92s -> 3452.16s]  all Python it will kill all your
[3452.20s -> 3453.96s]  Python things on that myth machine I
[3453.96s -> 3456.00s]  believe you can try that and see if it
[3456.00s -> 3458.08s]  see if it works and maybe it will do
[3458.08s -> 3459.44s]  that and for all nice we can do that
[3459.44s -> 3462.28s]  the good news the good news by the
[3462.28s -> 3466.28s]  way is that all these processes while
[3466.28s -> 3469.40s]  they are taking up memory they should
[3469.40s -> 3471.88s]  all have T under the status which
[3471.88s -> 3473.88s]  actually means stopped so they're not
[3473.88s -> 3476.28s]  actually spinning which is good so
[3476.28s -> 3477.40s]  thank you for not like running
[3477.48s -> 3481.52s]  spins but but yeah the if they're
[3481.52s -> 3483.20s]  generally not good to like have them
[3483.20s -> 3484.48s]  sitting there doing nothing until the
[3484.48s -> 3485.84s]  machine reboots that's kind of what
[3485.84s -> 3487.56s]  was going to happen so anyway but
[3487.56s -> 3489.48s]  anyway that's what myth buster does
[3489.48s -> 3494.56s]  and myth buster runs somewhat slowly in
[3494.56s -> 3497.24s]  that it has to pull each oh that's the
[3497.24s -> 3498.40s]  concurrent ones this is the faster
[3498.40s -> 3500.24s]  the sequential ones the ones gonna be
[3500.24s -> 3501.76s]  slowly that was a nice fast one
[3501.76s -> 3503.40s]  sequential one is going to be slowly
[3503.40s -> 3504.72s]  because it has to do each one in
[3504.76s -> 3507.52s]  order and it's just got to go and do
[3507.52s -> 3509.60s]  this querying thing some of the myth
[3509.60s -> 3513.52s]  machines by the way are down or like
[3513.52s -> 3515.48s]  not available for SSHing into for
[3515.48s -> 3517.16s]  whatever reason and it has a two second
[3517.16s -> 3518.48s]  timeout on that so it has to wait
[3518.48s -> 3521.28s]  for that okay so what does this mean
[3521.28s -> 3523.88s]  well the concurrent one which was much
[3523.88s -> 3528.56s]  faster did it in threads okay just said
[3528.56s -> 3529.48s]  oh I'm going to have a different
[3529.48s -> 3532.16s]  thread asking this myth machine how many
[3532.16s -> 3534.00s]  threads that are how many processes it
[3534.00s -> 3535.28s]  is and if it takes a little while great
[3535.28s -> 3536.56s]  some other ones are still going to be
[3536.56s -> 3537.88s]  running you'll notice it's out of
[3537.88s -> 3540.04s]  order we could figure out how to order
[3540.04s -> 3541.24s]  it a little bit better but you said
[3541.24s -> 3544.44s]  56 52 58 etc this one at least is in
[3544.44s -> 3547.00s]  order and some are missing because it's
[3547.00s -> 3549.56s]  not they're not like myth 57 is down
[3549.56s -> 3551.36s]  or whatever but maybe it should just
[3551.36s -> 3554.00s]  say myth 57 is down but the point is
[3554.00s -> 3556.00s]  that you do it concurrently it's slow
[3556.00s -> 3558.36s]  once you have threading you can wait
[3558.36s -> 3560.56s]  for all those servers to reply to you
[3560.56s -> 3561.92s]  or for a broken down you can do that
[3562.24s -> 3565.28s]  so let's take a look at some of the code
[3565.28s -> 3568.32s]  for this okay here's the various data
[3568.32s -> 3569.48s]  structures we're going to have I
[3569.48s -> 3571.36s]  happen to have made a list of all the
[3571.36s -> 3574.96s]  student soon X in the class okay and
[3574.96s -> 3576.76s]  it and that's what it's asking for
[3576.76s -> 3578.20s]  it so reads that file and then it
[3578.20s -> 3579.72s]  checks each myth machine against all
[3579.72s -> 3581.60s]  those names okay it just looks for
[3581.60s -> 3584.12s]  the process numbers okay it has a set
[3584.12s -> 3586.36s]  of all this that's a set it reads
[3586.36s -> 3587.40s]  that you can read the student files
[3587.40s -> 3589.48s]  it's got a map that counts the
[3589.48s -> 3594.84s]  processes for each for each myth to how
[3594.84s -> 3597.64s]  many process it has okay compile the
[3597.64s -> 3600.32s]  process count map is going to pass in
[3600.32s -> 3602.00s]  those two details and in there we're
[3602.00s -> 3603.08s]  going to do all the threading and
[3603.08s -> 3604.56s]  then it's going to publish the least
[3604.56s -> 3606.60s]  loaded data so that's how the program
[3606.60s -> 3612.24s]  is going to work okay let's see how I
[3612.24s -> 3614.04s]  already mentioned all these things went
[3614.04s -> 3615.92s]  over those things see anything
[3615.92s -> 3617.48s]  important there that we need to know
[3617.48s -> 3621.12s]  nope I think we talked about it all the
[3621.12s -> 3628.48s]  details are in a get numb processes
[3628.48s -> 3630.64s]  okay this is where it actually goes
[3630.64s -> 3635.64s]  and gets the for like myth 54 it gets
[3635.64s -> 3637.64s]  the processes and then it checks them
[3637.64s -> 3640.72s]  all against the the students in the
[3640.72s -> 3644.08s]  class based on their username okay and
[3644.08s -> 3646.44s]  this is how it would work in the
[3646.44s -> 3648.48s]  sequential version okay it's pretty
[3648.48s -> 3651.40s]  straightforward basically goes through
[3651.40s -> 3655.40s]  each myth okay from 51 to 56 and then
[3655.40s -> 3658.64s]  it counts number of processes in each
[3658.64s -> 3660.92s]  one by calling this get numb process
[3660.92s -> 3662.76s]  well that's the slow part because
[3662.76s -> 3664.16s]  you've got 10 different product 12
[3664.16s -> 3666.36s]  different processes 10 different myths
[3666.36s -> 3669.32s]  and each one could be stalling okay
[3669.32s -> 3671.16s]  that's what we're gonna have to try
[3671.16s -> 3674.92s]  to avoid this is what we I showed
[3674.92s -> 3680.16s]  you it working already okay the point
[3680.16s -> 3683.24s]  is that each call spends most of its
[3683.24s -> 3685.96s]  time waiting around for the myth machine
[3685.96s -> 3687.96s]  to respond to it whenever you log on a
[3687.96s -> 3689.20s]  myth and you're waiting well that's
[3689.20s -> 3691.24s]  what your program has to do too right
[3691.24s -> 3692.68s]  it can't go on to anything else if you
[3692.68s -> 3696.08s]  if you do it sequentially so that's the
[3696.08s -> 3698.84s]  that's the big deal okay so when
[3698.84s -> 3700.68s]  you're counting these what you want to
[3700.72s -> 3705.00s]  do instead is do it in threads okay so
[3705.00s -> 3706.80s]  let's see how this might work well
[3706.80s -> 3709.56s]  we're going to have a count cs110
[3709.56s -> 3711.64s]  processes again we're still going to
[3711.64s -> 3712.80s]  pass in the num we're still going to
[3712.80s -> 3714.96s]  pass in the set of students and we're
[3714.96s -> 3716.28s]  still going to set pass in the
[3716.28s -> 3719.16s]  process count map and this or I guess
[3719.16s -> 3720.24s]  this time we're gonna pass it in and
[3720.24s -> 3721.96s]  not just get a return value and then
[3721.96s -> 3724.88s]  we're gonna have a mutex to lock on
[3724.88s -> 3727.92s]  the process count map why because you
[3727.92s -> 3729.76s]  don't want different threads trying to
[3729.80s -> 3732.52s]  update the map at the same time okay you
[3732.52s -> 3734.08s]  might think well why does it matter if
[3734.08s -> 3736.00s]  two threads with two different myths
[3736.00s -> 3738.28s]  updates the map at the same time well
[3738.28s -> 3740.12s]  do you remember how maps are built
[3740.12s -> 3742.92s]  under the hood back to cs110 or
[3742.92s -> 3746.80s]  106b days remember how maps are
[3746.80s -> 3749.00s]  generally some like maps are generally
[3749.00s -> 3753.12s]  built if it's a regular old if it's a
[3753.12s -> 3754.32s]  regular old map you know it's built
[3754.32s -> 3756.64s]  yeah a tree yeah and if you have a
[3756.64s -> 3759.52s]  tree and if it's a balanced tree well
[3759.84s -> 3760.92s]  that means that you have to actually
[3760.92s -> 3763.24s]  move nodes around when you're inserting
[3763.24s -> 3764.60s]  and that would be bad if two things
[3764.60s -> 3766.28s]  try to insert at the same time they'd
[3766.28s -> 3767.44s]  be moving things around they would go
[3767.44s -> 3771.36s]  haywire an unordered set is using a
[3771.36s -> 3774.04s]  hash table which also might cause
[3774.04s -> 3775.36s]  similar issues especially if you have
[3775.36s -> 3777.12s]  hash collisions and so forth so either
[3777.12s -> 3779.44s]  way you don't want two threads to try
[3779.44s -> 3781.36s]  to write to that map at the same
[3781.36s -> 3783.80s]  time so you lock around the map but
[3783.80s -> 3785.32s]  the map writing is very quick
[3785.32s -> 3787.60s]  writing the map or reading from it
[3787.60s -> 3790.04s]  very very quick okay so we can we can
[3790.04s -> 3792.16s]  do that we can not worry too much about
[3792.16s -> 3794.52s]  that okay in fact we're just gonna
[3794.52s -> 3797.48s]  lock do a lock guard around it okay
[3797.48s -> 3800.16s]  we are going to change the up we
[3800.16s -> 3803.84s]  are going to let's see we're going
[3803.84s -> 3807.24s]  to do the actual count process or get
[3807.24s -> 3809.52s]  numb process in here once we get the
[3809.52s -> 3812.24s]  number of processes we are going to if
[3812.24s -> 3813.60s]  the count is greater than zero we're
[3813.60s -> 3815.04s]  going to update the myth count number
[3815.04s -> 3817.20s]  and put it in the map and that's a
[3817.20s -> 3819.28s]  very short this this whole section here
[3819.28s -> 3822.00s]  is very short to update the map this is
[3822.00s -> 3823.88s]  the part that takes a long time you're
[3823.88s -> 3825.76s]  trying to wait that's the part takes
[3825.76s -> 3826.88s]  a long time but if you're doing it in
[3826.88s -> 3828.48s]  12 different threads to 12 different
[3828.48s -> 3831.72s]  myth machines it's actually fine okay
[3831.72s -> 3833.72s]  but you have to lock around updating
[3833.72s -> 3838.24s]  that map for everybody and then we
[3838.24s -> 3841.48s]  have permits in here this is so that
[3841.48s -> 3843.84s]  we don't slam all the myths at once
[3843.84s -> 3845.88s]  I guess it's not a big deal for 12
[3846.00s -> 3847.40s]  different myths having 12 different
[3847.40s -> 3850.16s]  threads but in this case how many did
[3850.16s -> 3852.20s]  we set up here did we did we say how
[3852.20s -> 3853.52s]  many we set up oh we're I guess we're
[3853.52s -> 3854.60s]  gonna we're gonna see how many so
[3854.60s -> 3856.08s]  here we go eight we're gonna say
[3856.08s -> 3857.44s]  we're only allowed eight threads to go
[3857.44s -> 3859.64s]  to time why that's just kind of nice
[3859.64s -> 3861.52s]  when you're doing networking things to
[3861.52s -> 3864.20s]  limit it to some reasonable amount but
[3864.20s -> 3865.52s]  we could get away with thousands if we
[3865.52s -> 3866.64s]  really wanted to in this case but
[3866.64s -> 3868.48s]  there's only 12 minutes or something so
[3868.48s -> 3870.52s]  that's that okay and then we signal
[3870.52s -> 3875.40s]  on the end there we let's see when
[3875.44s -> 3881.60s]  do we actually get the permits I don't
[3881.60s -> 3886.48s]  see a permits wait in there so oh it's
[3886.48s -> 3890.60s]  down here let's see oh right okay when
[3890.60s -> 3892.64s]  we're actually send setting up the
[3892.64s -> 3894.80s]  threads that's when we're doing it we
[3894.80s -> 3896.52s]  will see a different model next week
[3896.52s -> 3898.32s]  for a different model for this in this
[3898.32s -> 3899.76s]  case this is when we're setting up the
[3899.76s -> 3901.56s]  threads down here okay so how are we
[3901.56s -> 3903.04s]  doing that we're saying eight permits
[3903.12s -> 3906.40s]  and we are going through and if we only
[3906.40s -> 3907.88s]  we're going we're only going to launch
[3907.88s -> 3909.68s]  eight threads at a time when one of
[3909.68s -> 3913.08s]  those threads finishes it will signal
[3913.08s -> 3914.76s]  this to start the next thread we are
[3914.76s -> 3917.32s]  not joining on any threads until all
[3917.32s -> 3919.56s]  the way at the end okay those threads
[3919.56s -> 3922.44s]  will end but they were only allowing
[3922.44s -> 3924.52s]  eight to kind of go at the same time
[3924.52s -> 3926.48s]  at some point there will probably be
[3926.48s -> 3928.20s]  nine threads going at this time
[3928.52s -> 3933.84s]  because the signal is going to happen and
[3933.84s -> 3935.28s]  another threads going to get spun up and
[3935.28s -> 3937.24s]  then this one's going to close so in
[3937.24s -> 3938.68s]  this case we could have an off by one
[3938.68s -> 3940.24s]  but it doesn't matter but now there's
[3940.24s -> 3942.12s]  nine threads instead of just eight yeah
[3942.12s -> 3948.44s]  question oh sorry yeah I didn't tell
[3948.44s -> 3950.84s]  you about that one so in this case I
[3950.84s -> 3952.12s]  guess there wouldn't be there would
[3952.12s -> 3953.88s]  probably does it after the thread just
[3953.88s -> 3956.56s]  as a thread ends the the semaphore
[3957.00s -> 3959.84s]  allows you to say on thread exit do the
[3959.84s -> 3963.04s]  actual semaphore releasing I don't know
[3963.04s -> 3964.40s]  the magic that has to go into that we
[3964.40s -> 3966.40s]  could probably look it up in the actual
[3966.40s -> 3967.56s]  let's go let's go look it up real
[3967.56s -> 3969.60s]  quick but yes if you want the if you
[3969.60s -> 3971.20s]  want the signal to happen after the
[3971.20s -> 3972.52s]  thread is when the thread is closing
[3972.52s -> 3975.28s]  down that's what you would use for it
[3975.28s -> 3976.64s]  good good answer on there a good
[3976.64s -> 3981.52s]  question on that user class cs 110 local
[3981.52s -> 3987.24s]  source threads semaphore dot CC okay
[3987.24s -> 3992.04s]  let's look for on thread exit okay here
[3992.04s -> 3996.40s]  we go let's see yeah so it looks like
[3996.40s -> 3998.44s]  there needs to be some P thread magic
[3998.44s -> 4000.84s]  going on there to basically say hey do
[4000.84s -> 4002.84s]  this when the threads exiting and you
[4002.84s -> 4004.12s]  can do that so it's a little bit of a
[4004.12s -> 4005.60s]  little bit of under-the-hood magic
[4005.60s -> 4007.60s]  happening there with leveraging that
[4007.60s -> 4009.08s]  we're using threads to do all this
[4009.08s -> 4011.92s]  yeah you do not need to know that for
[4011.92s -> 4013.48s]  anything specifically just know that if
[4013.48s -> 4016.32s]  you want to exit the thread or if you
[4016.32s -> 4017.80s]  want to send that signal as the
[4017.80s -> 4019.20s]  thread shutting down that's when to do
[4019.20s -> 4024.84s]  it good question the question is that
[4024.84s -> 4026.88s]  thread won't shut down till join it
[4026.88s -> 4028.20s]  will shut down it won't get cleaned
[4028.20s -> 4030.84s]  up until join so in other words it
[4030.84s -> 4033.04s]  still stops and it's no longer taking
[4033.04s -> 4034.84s]  up any cycles on the processor it's
[4034.84s -> 4036.04s]  just waiting at the operating system
[4036.04s -> 4037.76s]  just the thread manager is waiting to
[4037.76s -> 4040.32s]  clean it up until you join it yeah
[4040.32s -> 4044.32s]  other questions on this all right let's
[4044.32s -> 4049.16s]  see think yeah let's see pulling the
[4049.16s -> 4051.24s]  myths concurrently what does that do
[4051.24s -> 4054.48s]  for us that allows us to wait on the
[4054.48s -> 4056.96s]  dumb slow network or the connection to
[4056.96s -> 4059.20s]  happen okay because we've got lots of
[4059.20s -> 4061.80s]  them happening on your computer has the
[4061.80s -> 4063.40s]  ability to send lots of messages to
[4063.40s -> 4065.60s]  different machines all at once that's
[4065.64s -> 4069.80s]  fine it's got its own waiting and D
[4069.80s -> 4072.32s]  interleaving happening with that but but
[4072.32s -> 4073.60s]  as far as you're concerned your
[4073.60s -> 4075.36s]  program can send as many messages it
[4075.36s -> 4077.20s]  wants to different servers in this
[4077.20s -> 4078.74s]  case all the different myths at the
[4078.74s -> 4082.48s]  same time through various threads okay
[4082.48s -> 4085.04s]  they semaphore limits the number of
[4085.04s -> 4089.88s]  threads and yeah here's the on thread
[4089.88s -> 4091.56s]  exit that we talked about an overloaded
[4091.56s -> 4094.56s]  version of signal schedules after the
[4094.60s -> 4096.92s]  entire thread is exited so that's makes
[4096.92s -> 4099.04s]  it so there's not nine threads at once
[4099.04s -> 4100.92s]  going although maybe for a very short
[4100.92s -> 4102.48s]  amount of time but not not long anyway
[4102.48s -> 4106.28s]  and that's it and you can see the
[4106.28s -> 4108.20s]  concurrent one versus let's do this
[4108.20s -> 4111.64s]  let's do it in two different windows so
[4111.64s -> 4117.28s]  let's do it this way all right so I
[4117.28s -> 4119.80s]  guess it's a little it's interesting
[4119.80s -> 4121.48s]  that I'm running this on the myths
[4121.48s -> 4122.88s]  and checking all the myths so it's a
[4122.88s -> 4126.20s]  little okay I think we can do it this
[4126.20s -> 4131.88s]  way here's what I'll do let's do yeah
[4131.88s -> 4133.08s]  I want to make this window a little
[4133.08s -> 4139.80s]  smaller and okay so we're going to
[4139.80s -> 4144.14s]  run myth buster let's do the
[4144.14s -> 4150.20s]  sequential on this side and then see
[4150.52s -> 4157.26s]  let's let's let's CPP let's do the myth
[4157.26s -> 4160.32s]  buster concurrent on this side now try
[4160.32s -> 4162.16s]  to hit return and then really quickly
[4162.16s -> 4163.40s]  hit the other one we could time if we
[4163.40s -> 4165.84s]  wanted to but I said okay ready boom
[4165.84s -> 4169.20s]  boom okay and the miss buster
[4169.20s -> 4171.04s]  sequential one is still going while the
[4171.04s -> 4173.44s]  other one's already done all right did
[4173.44s -> 4175.48s]  it all threads all once this is the
[4175.48s -> 4177.60s]  other one is still one after the
[4177.60s -> 4181.32s]  other after the other after the other all
[4181.32s -> 4182.88s]  right what questions you have about this
[4182.88s -> 4186.16s]  stuff you see how this threading you're
[4186.16s -> 4187.00s]  going to have to think about race
[4187.00s -> 4188.24s]  conditions a lot but there's lots of
[4188.24s -> 4190.80s]  cool models that we can do next week
[4190.80s -> 4192.36s]  we're going to are at the this week
[4192.36s -> 4193.36s]  and then next we're going to talk
[4193.36s -> 4194.60s]  about some other cool problems where
[4194.60s -> 4197.88s]  we're modeling bigger ideas in
[4197.88s -> 4199.68s]  particular one is an ice cream shop
[4199.68s -> 4202.24s]  kind of fun they were going to model
[4202.24s -> 4205.24s]  that allows you to do threads that are
[4205.24s -> 4206.92s]  waiting on other threads and using this
[4206.92s -> 4208.36s]  whole idea of permits and so forth
[4208.36s -> 4216.00s]  question if you don't specify a myth it
[4216.00s -> 4221.16s]  checks all of them in this case oh if
[4221.16s -> 4222.40s]  you just yeah yeah yeah oh good
[4222.40s -> 4224.08s]  question if you have this is just
[4224.08s -> 4226.12s]  about button logging out of the miss
[4226.12s -> 4229.36s]  in general if you just say SSH myth it
[4229.36s -> 4231.32s]  will pick one there is a load balancer
[4231.32s -> 4233.12s]  that's doing exactly what our program
[4233.12s -> 4235.68s]  just did kind of basis as well who's
[4235.72s -> 4237.68s]  busy right now now I think it's kind of
[4237.68s -> 4240.04s]  continually looking at who's busy it's
[4240.04s -> 4241.20s]  kind of got connections are open all
[4241.20s -> 4242.28s]  the time going who's busy who's busy
[4242.28s -> 4244.08s]  and it tries to send you to the one
[4244.08s -> 4246.48s]  that's least busy right it can't
[4246.48s -> 4247.44s]  figure out a family's got all those
[4247.44s -> 4249.00s]  processes stopped though so sometimes
[4249.00s -> 4252.24s]  that work but no it it definitely
[4252.24s -> 4254.24s]  it's doing the exact same thing it's
[4254.24s -> 4255.80s]  really doing more or less the same
[4255.80s -> 4258.52s]  thing for you yeah good question all
[4258.52s -> 4259.76s]  right any other questions think we'll
[4259.76s -> 4260.88s]  get out here a couple minutes early
[4260.88s -> 4265.28s]  all right we'll see you Wednesday
