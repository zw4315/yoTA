# Detected language: en (p=1.00)

[0.00s -> 7.20s]  Okay let's get going even though not a ton of people here but we'll we'll get
[7.20s -> 13.72s]  going so how's the assignment going assignment what is it six how's that
[13.72s -> 18.92s]  going going right yeah it's due tonight I will have office hours today
[18.92s -> 22.60s]  right after class for an hour and 15 minutes or so for anybody who
[22.60s -> 27.48s]  wants to stop by and get some some help with that and hopefully it's it's
[27.56s -> 32.16s]  not too bad hopefully the thread pool is an interesting assignment I mean it kind
[32.16s -> 37.28s]  of has all the different parts to it you got to have mutexes you've got semaphores
[37.28s -> 42.40s]  you do have to probably have a conditional condition variable any in
[42.40s -> 46.44s]  there if you don't maybe you did it some other way but that's likely you'll
[46.44s -> 51.96s]  need that and there's various kind of nuances to that but that's a pretty
[51.96s -> 58.72s]  robust class to be building and so a good job for doing that there are two more
[58.72s -> 63.28s]  assignments we're now going to be on like a Thursday Thursday schedule the
[63.28s -> 66.80s]  next assignment will be out tomorrow although technically you can go look at
[66.80s -> 71.36s]  it right now I'll show you the link in a minute and then it will be due
[71.36s -> 75.08s]  next Thursday the next one will come out Thursday do the following Thursday
[75.08s -> 80.68s]  which I think technically is actually after class ends I'm not sure I'm
[80.80s -> 85.84s]  allowed by school rules to actually have an assignment due after classes end like
[85.84s -> 89.64s]  I think that's like not allowed so I'll have to figure something out maybe I'll
[89.64s -> 92.72s]  make it due Wednesday but then give everybody a free day until Thursday or
[92.72s -> 96.32s]  something like that I was skirting the rules a little bit but I do want to
[96.32s -> 99.68s]  give you enough time but I also understand that you've got finalists to
[99.68s -> 103.52s]  study for and all that so I'll we'll figure something out in that regard
[103.52s -> 111.12s]  but so today so we are mostly done with the new material for assignments in fact
[111.12s -> 115.92s]  we are pretty much all done with new material for assignments we have one
[115.92s -> 122.44s]  more topic which is non blocking IO which is basically IO that doesn't block
[122.44s -> 125.56s]  when you say accept and so forth and there's reasons we might want to use
[125.56s -> 130.56s]  that we will talk about that on the last last day of class maybe the
[130.56s -> 135.28s]  previous day as well after today we actually have three more lectures right
[135.28s -> 141.68s]  next when Monday's a holiday yay Memorial Day next next Wednesday is
[141.68s -> 145.16s]  lecture and then the following Monday Wednesday but really there's no
[145.16s -> 149.44s]  new stuff that's going to be on assignments the eye of the IO non
[149.44s -> 153.48s]  blocking IO I might ask some very like high-level questions about it on
[153.48s -> 155.84s]  the final but that would be about it so we've basically gotten through all
[155.84s -> 160.32s]  the stuff for the quarter we do have next week we will talk a little bit
[160.32s -> 165.60s]  more about what we're gonna start today and then which is about your next
[165.60s -> 171.84s]  assignment actually and then we will also do a little like hey here's the big
[171.84s -> 175.38s]  picture of 110 and all the different things you should have learned in a big
[175.38s -> 180.52s]  picture sense so that's really all we've got going today I wanted to give
[180.52s -> 184.44s]  you a relatively deep dive into the assignment you're gonna start tomorrow
[184.44s -> 188.56s]  why am I doing that I think it's an assignment that you will enjoy but
[188.56s -> 191.48s]  you've got to wrap your head around it and wrapping your head around it takes
[191.48s -> 195.88s]  some time not like the other ones didn't but this one definitely takes some
[195.88s -> 199.40s]  time to get your head wrapped around so we're gonna take most of the class to
[199.40s -> 203.60s]  go over depending on how many questions are I guess about to go over the
[203.60s -> 209.00s]  assignment starting tomorrow and then I will introduce the topic that we will
[209.00s -> 213.66s]  have for the final assignment okay it's called nap reduce and it kind of ties
[213.66s -> 216.88s]  everything together you got to use all the different parts of the things
[216.88s -> 225.44s]  you know to do the final assignment so tomorrow's assignment is a web proxy
[225.44s -> 230.36s]  okay so here's what a web proxy you can go by the way you can go here and
[230.36s -> 235.68s]  download the actual assignment if you go and let's see if I can click on it
[235.68s -> 240.08s]  now let's see if we go here and download it that should be the
[240.08s -> 243.60s]  assignment now you can't we don't have the I will tomorrow morning I will
[243.60s -> 248.56s]  push out the actual repos but feel free if you are not working on the
[248.56s -> 251.96s]  current assignment still to go and read through this it's a relatively long
[251.96s -> 256.68s]  document as you can tell it's not too bad but we're gonna go through it
[256.68s -> 266.20s]  right now okay so hold on I'll go back here and here's what it is all
[266.20s -> 273.20s]  about okay what is a web proxy well a web proxy is a server that sits
[273.20s -> 280.28s]  between your web browser and some web page that you want okay what you can do
[280.28s -> 283.28s]  is you can move I'll show you how to do this today you can set up your web
[283.28s -> 289.84s]  browser to use a proxy server whenever it requests websites so instead
[289.84s -> 293.92s]  of going to the actual website and requesting it it goes to your web
[293.92s -> 298.46s]  server and makes the exact request and or your your web proxy makes the
[298.46s -> 304.58s]  request and then the web proxy forwards that on to the actual web page or web
[304.58s -> 307.74s]  server you're looking for gets the result back and then forwards it back
[307.74s -> 311.16s]  to you now why would we care about doing that well there's a lot of
[311.16s -> 316.26s]  reasons you might want to use a proxy you might want to block access to
[316.26s -> 321.78s]  certain websites okay this this is kind of like a firewall sort of thing
[321.78s -> 324.82s]  if you if you want to think of it that way but basically you know maybe
[324.82s -> 327.90s]  you maybe you want to put a proxy up because you don't want you know your
[328.22s -> 331.38s]  if you run a company you don't want everybody going to Facebook.com during
[331.38s -> 334.86s]  the workday or something draconian like that or whatever but maybe you do
[334.86s -> 337.86s]  that maybe you're a parent and you don't want your kids going to certain
[337.86s -> 342.04s]  websites that will remain unnamed etc but that would be one reason to have
[342.04s -> 345.22s]  a proxy right you set that up the browser goes to that and so forth and by the
[345.22s -> 348.30s]  way if you ever have kids they will be able to get around whatever proxy you
[348.30s -> 353.78s]  put in place so you know don't think it's like some sort of you know full
[353.78s -> 359.54s]  solution this is why only you should own the password to your router that's what
[359.54s -> 364.62s]  but anyway so that's one thing you might do you might want to block access
[364.62s -> 367.46s]  to certain documents I mean let's say you have some giant document like if
[367.46s -> 370.90s]  you're on a plane they always have you go through a web proxy such that you
[370.90s -> 375.22s]  can you can't download like you can't download like YouTube document or you
[375.22s -> 377.66s]  know you can't watch YouTube or whatever on the plane because they have a very
[377.66s -> 381.86s]  limited bandwidth because they're flying around in the sky and then
[382.38s -> 385.50s]  maybe certain types of files I don't know why I put zip files up there but maybe
[385.50s -> 388.86s]  they're too dangerous because they can have viruses or something you want to
[388.86s -> 394.34s]  make those block maybe you say I don't like Liechtenstein and I don't
[394.34s -> 397.86s]  want any web pages coming from there for my whatever my thing is I don't
[397.86s -> 401.62s]  anybody from there sorry if I said okay they're probably not there's only
[401.62s -> 405.90s]  30 40 thousand of them anyway but anyway I don't even know if they have
[405.90s -> 409.76s]  websites there probably do like that are like hosted in elections I bet they
[410.48s -> 415.84s]  you also might want to act here's an actually I think an important reason
[415.84s -> 420.00s]  you might want to use the proxy of sorts you want to act as an anonymizer
[420.00s -> 424.76s]  to strip data from headers to strip what your real IP address is and so
[424.76s -> 430.32s]  forth how many people had heard of the tor browser before or the or onion
[430.32s -> 436.04s]  routing before a few people okay here's what that is that is partially a web
[436.12s -> 441.52s]  proxy partially kind of a thing that wraps everything in high-level encryption
[441.52s -> 447.00s]  what it is the tor network is a network with it was put in place to
[447.00s -> 453.24s]  allow people in countries where they may be discouraged from using the
[453.24s -> 456.96s]  internet or if they use the internet they might be under under like that
[456.96s -> 459.68s]  they might end up getting arrested and so forth and these people are
[459.68s -> 462.40s]  hopefully not breaking the law well they might be breaking the law in their
[462.40s -> 464.64s]  country but hopefully they're doing good things in the world and they
[464.68s -> 469.80s]  might want to use the internet to talk communicate with other people and not
[469.80s -> 473.84s]  necessarily give away their information and so forth now it certainly can be used
[473.84s -> 477.80s]  on the so-called dark web for people who are doing malicious things
[477.80s -> 481.80s]  but let's assume people are doing good things what it does is it has
[481.80s -> 488.48s]  basically you go to a proxy server on this tor network and it takes your your
[488.48s -> 492.24s]  request and it encrypts it when you probably first encrypted but it encrypts it
[492.24s -> 497.36s]  and then sends it on to another proxy server which encrypts it again sends to
[497.36s -> 500.64s]  a next one which encrypted again and all the way along the way it further
[500.64s -> 505.54s]  anonymizes where you came from and it's not a bad way to be able to do
[505.54s -> 510.68s]  like use the internet without fear of somebody being able to figure out who
[510.68s -> 513.56s]  you are and so this is important in countries where there are people
[513.56s -> 516.56s]  fighting the good fight who otherwise might get in trouble with their
[516.56s -> 522.76s]  government or so forth it is not foolproof a couple years ago some
[522.76s -> 530.40s]  student at Harvard of all places actually sent a bomb request a bomb
[530.40s -> 534.40s]  threat into the school and said there there's a bomb in this building
[534.40s -> 537.00s]  and you got it back because he didn't want to take his final exam or
[537.00s -> 541.28s]  whatever and so he put this sent this I know really I mean he probably had
[541.28s -> 545.76s]  some mental illness but he sent the sent this through the tor network which
[545.80s -> 551.16s]  anonymized his thing completely but the police were pretty clever about that
[551.16s -> 554.64s]  what they did was they said well we have the logs of who's using the
[554.64s -> 559.00s]  internet at all on campus at that time who was using the tor network
[559.00s -> 562.28s]  right and they found like two people using the tor network one with some
[562.28s -> 564.76s]  graduate student who's like researching the tor network and like
[564.76s -> 567.52s]  the other one was this kid kid in his dorm room who's the one who did the
[567.52s -> 572.06s]  bomb threat so I mean they figured it out by using external data not knowing
[572.06s -> 575.28s]  exactly you know what his IP address was whatever they just said well who
[575.32s -> 578.88s]  was using this network so be a little more careful than that if you're
[578.88s -> 583.24s]  going to do silly things like that why else might you want to use a
[583.24s -> 587.48s]  proxy maybe you want to take images certain images and do something
[587.48s -> 590.60s]  interesting with them one of my favorite things I found about oh
[590.60s -> 593.52s]  man I was probably 10 years ago at this point is this thing called
[593.52s -> 600.80s]  the upside downturn net which is a web proxy and what it is it's a
[600.80s -> 604.76s]  person who set up a price is a person who had an open wi-fi network
[604.76s -> 607.92s]  now this used to be a thing most most wi-fi networks are now not open they
[607.92s -> 611.48s]  have passwords but usually they had most everybody had an open wi-fi
[611.48s -> 615.52s]  networks and this one guy realized that all his neighbors were like stealing
[615.52s -> 623.00s]  his wi-fi from being open and so what he did was he set up a proxy on
[623.00s -> 627.68s]  his computer he basically set it up on his computer between his computer and
[627.68s -> 631.12s]  the internet through the router at the router and then to his computer event
[631.12s -> 634.76s]  the internet and it basically was a couple little scripts and what it did
[634.76s -> 639.40s]  was it any image that came through that got requested it just took the image
[639.40s -> 643.36s]  flipped it over in an image program and then served it to the user so
[643.36s -> 647.00s]  whoever was browsing using his internet would look and get all these
[647.00s -> 650.92s]  upside-down images which probably is annoying enough that you probably stop
[650.92s -> 655.20s]  using the life right thing and then he said well let's be a little more
[655.20s -> 660.20s]  even a little more diabolical about it besides the upside down when he
[660.68s -> 665.56s]  said you can actually make the blurry internet where instead of flipping it it
[665.56s -> 670.56s]  would just like moderately blur all the images so that it just kind of kind of
[670.56s -> 673.84s]  stare go is something wrong with that image and you do for all the images
[673.84s -> 677.56s]  we're just a little bit blurry and he figured that would be the same have
[677.56s -> 684.48s]  the same same effect you could also you could also use it to and this guy
[684.48s -> 688.08s]  does the exact same thing intercept all traffic and just forward it
[688.08s -> 692.00s]  somewhere else okay this happens when you go to the airport you log on like
[692.00s -> 695.64s]  there's a paywall and you know you log on to any site and it took immediately
[695.64s -> 699.20s]  forward you to some proxy that says please pay for internet or agree to
[699.20s -> 704.08s]  these terms and conditions or whatever this person also had it so that where
[704.08s -> 710.52s]  did it go so that it would just go straight to he switched it every so often
[710.52s -> 717.08s]  it would go straight to where did it go where to go ah maybe it's not
[717.08s -> 721.80s]  there it would go straight to kitten war.com so anytime they were browsing or
[721.80s -> 725.76s]  just go to kitten war.com where I guess you decide between cute kittens pick and
[725.76s -> 728.48s]  choose whatever but that was that's you know that's what he did too so I
[728.48s -> 732.84s]  think you reduced the number of people using his open network in that
[732.84s -> 735.48s]  case many actually got a little note from the guy that owns kitten war
[735.48s -> 739.56s]  saying every so often I get extremely irate emails people claiming that my
[739.56s -> 743.24s]  kitten war site is playing host to some kind of virus and he says I just
[743.24s -> 745.88s]  point them back to you and say it's probably your thing and then he goes
[745.88s -> 750.16s]  yeah prime I think so anyway that's another reason you might want to use a
[750.16s -> 758.00s]  web proxy if you want people to just look at kittens all day okay so oh and
[758.00s -> 760.64s]  the other one this is the big one and this is in fact one that you will
[760.64s -> 766.60s]  be doing for your assignment you may want to cache the actual requests now a
[766.60s -> 772.08s]  cache is we've talked about before is just a local copy of whatever you've
[772.08s -> 778.44s]  requested so in this case the local copy is whatever data comes off the
[778.44s -> 782.96s]  website that allows itself to be cached what kinds of things might be cached the
[782.96s -> 788.58s]  Google logo right the Google logo is the same every single day I mean they
[788.58s -> 791.60s]  change it so when they do the special days or whatever but the actual Google
[791.60s -> 795.12s]  logo itself doesn't change for years and years and years why would you go
[795.12s -> 798.12s]  and request it from the website every single time you go to the
[798.12s -> 802.80s]  website just keep a local copy and that eventually times out like over many
[802.80s -> 805.88s]  days or months or whatever but you don't need to go request it so if you're
[805.88s -> 811.28s]  local if you have it locally you don't need to waste bandwidth going out to
[811.28s -> 814.96s]  the internet as a whole and getting it and that's important now your browser
[814.96s -> 819.36s]  already does a lot of that for you your browser keeps a cache of pages
[819.36s -> 823.02s]  sometimes you'll you know it's it's really bad when they they keep a cache
[823.02s -> 826.32s]  and you're working on a website and then you're changing things and it just
[826.32s -> 830.48s]  never updates and you got to figure out how to manually update it for this
[830.48s -> 835.00s]  assignment you will have a cache both in your browser because this is an
[835.00s -> 839.52s]  assignment you're actually using your browser and for the actual program you
[839.52s -> 843.44s]  should clear the browser data as frequently as you can at least as much
[843.44s -> 847.40s]  as you you know do it frequently enough so that you don't get into the issue
[847.40s -> 851.04s]  of like wait it looks the same something must be wrong so that's that
[851.04s -> 857.66s]  okay so the assignment itself well it requires you to use your browser and it
[857.66s -> 864.32s]  does require you to have your browser pointing to a particular particular
[864.32s -> 868.96s]  computer namely one of the myth machines okay we suggest to use the
[868.96s -> 873.08s]  Firefox browser mainly because we know that most of you don't normally use
[873.08s -> 877.16s]  Firefox it's probably easiest to set up Firefox to do the proxy thing and
[877.16s -> 880.72s]  then just use your other browser do all your regular browsing I happen to
[880.72s -> 884.76s]  using Firefox for this presentation so I'll do a little bit of both right now
[884.76s -> 889.96s]  but what you do is actually we'll do it right now for the assignment I'm
[889.96s -> 900.64s]  going to show you how to do this so first things first I'm going to 1 10
[900.64s -> 910.08s]  spring assignments assignment 7 and then samples actually let's just let's
[910.20s -> 914.88s]  make the original here think this is the starter code right and the starter
[914.88s -> 919.28s]  code has a proxy there's a lot of files we'll talk about those files in a
[919.28s -> 926.20s]  bit starter code has a proxy which is called proxy and it basically chooses a
[926.20s -> 930.84s]  port that's based on a hash of your username so if you do if you do proxy
[930.84s -> 934.64s]  and then somebody else does proxy probably not going to overlap the port
[934.64s -> 937.56s]  numbers and there's enough port numbers to go around so it's probably okay if
[937.56s -> 942.20s]  you find out that it's always if it's always using the same port number
[942.20s -> 946.28s]  somebody else has you can do it you can do a specific port number if you want
[946.28s -> 953.56s]  to anyway this is now on what is this myth 64 listening on port 19 4 1 9
[953.56s -> 960.84s]  so if we go back to Firefox and we go to preferences and in preferences we
[960.84s -> 966.68s]  type in proxy down here and then click on settings it will say a bunch
[966.68s -> 970.16s]  of things it probably says no proxy for you right now it may say use system
[970.16s -> 973.56s]  proxy settings you can set your global ones in your system what you're going to
[973.56s -> 977.44s]  do is set your manual product you see I've done this before you set your
[977.44s -> 981.20s]  manual one to whatever server you have whatever myth you have in this case
[981.20s -> 986.80s]  it's myth 64 and then is it 19 4 1 9 it is because my name didn't hash
[986.80s -> 992.08s]  differently last year or last quarter so anyway it's myth 64 port 19 1 4 9
[992.08s -> 997.40s]  you should also select the use this proxy server for all protocols if you
[997.40s -> 1001.40s]  don't select that you can go to some websites that bypass your proxy and you
[1001.40s -> 1004.60s]  think everything's working great and it's not because it's going past your
[1004.60s -> 1008.96s]  proxy so make sure you click on that and then when you do that if you try
[1008.96s -> 1018.00s]  to go to a website so let's go to let's try example.com it should say
[1018.00s -> 1022.80s]  you're writing a proxy right so now I've gone to example.com it says you're
[1022.80s -> 1027.20s]  writing proxy well that's all it does so far basically intercepts your so if the
[1027.20s -> 1030.96s]  starter code intercepts your request and then feeds back a page that says
[1030.96s -> 1036.08s]  you're writing proxy that's all it does right now okay now it turns out
[1036.08s -> 1042.64s]  that the way we've got this written it only works for HTTP websites the way
[1042.64s -> 1047.00s]  you guys are going to write this it is possible to do it for HTTPS sites
[1047.00s -> 1050.44s]  which is most sites these days so you kind of have to be a little careful that
[1050.44s -> 1056.76s]  you don't go to sites that aren't HD that are HTTPS and you you'll get
[1056.76s -> 1059.00s]  halfway through the assignment go why is this working and you remember oh
[1059.00s -> 1062.88s]  that's an HTTPS site it will work for the starter code because again the
[1062.88s -> 1066.56s]  starter code just completely ignores anything about the request and feeds
[1066.56s -> 1069.88s]  this back so if I go to google.com which is going to be an HTTPS look
[1069.88s -> 1078.44s]  maybe not maybe not that's interesting let's see let's try example.com maybe I
[1078.44s -> 1083.04s]  didn't set it up there okay that one worked let's try let's try stanford.com
[1083.04s -> 1088.68s]  or stanford.edu yeah that one works so HTTPS it maybe if you do HTTPS it
[1088.68s -> 1094.84s]  won't work let's see no that's it so if you go to HTTPS it probably will
[1094.84s -> 1100.20s]  give you an error there so let me do this I'm going to keep the preferences
[1100.20s -> 1105.88s]  up so I can still do the website proxy change this every so often every
[1105.88s -> 1112.56s]  time I do this okay no proxy right now okay so that's what it looks like
[1112.56s -> 1116.84s]  when you run it oh you know what I should do I should just run it with I
[1116.84s -> 1123.08s]  should show you how to do it with the other let's see what show you what
[1123.08s -> 1130.16s]  happens with the regular one so if we go to samples slash proxy solution okay it
[1130.16s -> 1134.96s]  will say the same sort of thing and it'll be set up and then if we go to a
[1134.96s -> 1143.20s]  website like let's do let's do this let me make this let's do well I'll
[1143.20s -> 1147.88s]  just go back and forth between the page if we go to example.com example.com
[1147.88s -> 1153.56s]  happens to be a page that allows it to be allows it to be cached so if you go
[1153.56s -> 1157.28s]  to the page that says allows me to get this is all it looks like their example
[1157.28s -> 1162.08s]  domain your program is going to say okay to cache a response so caching
[1162.08s -> 1166.64s]  response under the hash and there's a big long hash for six hundred and
[1166.64s -> 1170.44s]  four eight hundred seconds so for a while okay so it's going to cache that
[1170.44s -> 1174.52s]  it's going to keep it locally on your myth in the myth machine for you and
[1174.72s -> 1178.48s]  then the next time you go to example.com it's going to come back faster number
[1178.48s -> 1183.48s]  one and it's not going to say anything again there because it's already it's
[1183.48s -> 1188.60s]  already cached it for you so if example.com did change your computer
[1188.60s -> 1193.20s]  wouldn't update that until it timed out sometime later okay many sites
[1193.20s -> 1199.48s]  don't have have that there is one let's see I've got it in me I've got
[1199.48s -> 1205.32s]  it in the actual site let's see if this actually continues to work without it
[1205.32s -> 1211.12s]  seems like it will for right now okay so there's not much going on in the
[1211.12s -> 1217.16s]  starter code but you get to change that you should just leave your settings
[1217.16s -> 1221.60s]  and then use a different browser generally for for doing the other stuff
[1221.60s -> 1226.76s]  okay if you want you can use telnet instead if you want to don't bother
[1227.44s -> 1232.32s]  you want to see more details about what's going on you can do that as well so
[1232.32s -> 1238.00s]  let's try in fact I'm going to do this one it is this is what I want to
[1238.00s -> 1242.44s]  actually send if I want to do the whole get line there oops when I do
[1242.44s -> 1250.04s]  well there we go okay let's see we are on myth 64 right so if I go
[1250.04s -> 1261.08s]  telnet and then myth 64 1 port 19419 it will allow me to connect great and then
[1261.08s -> 1267.24s]  if I type that get line IP if I is just a it tells you your IP address as
[1267.24s -> 1274.48s]  it turns out and then you have to type host IP I guess it's www.ip if y
[1274.48s -> 1284.28s]  dot org and then another another let's see did that actually work no I think it
[1284.28s -> 1287.92s]  didn't don't think it worked maybe it wasn't because we did oh it's just API
[1287.92s -> 1291.92s]  sorry let's try this again telnet and by the way I'm just doing it from my
[1291.92s -> 1295.16s]  Mac I don't doesn't even need to be from another myth machine let's do this
[1295.16s -> 1305.92s]  again and then host API dot IP if y dot org and then another there we go that's
[1305.92s -> 1309.24s]  what we're looking for it just sends back some JSON but you can see all the
[1309.24s -> 1315.80s]  headers and things that it sends back to and your program should be for should
[1315.80s -> 1320.60s]  be capturing all of that data through the through thing and I'll talk about
[1320.60s -> 1323.40s]  some other things that has to be do it has to do as well by the way this
[1323.40s -> 1326.92s]  tells you that it's JSON that's getting sent back and remember we talked about
[1326.92s -> 1330.84s]  what JSON is there it's like that and it basically tells you what your IP
[1330.84s -> 1336.04s]  address is for your computer or your local one is anyway that's how you can
[1336.04s -> 1342.00s]  use telnet to also if you're off campus I mean some people said they're
[1342.00s -> 1345.08s]  gonna be traveling or whatever you're off campus you do need to log on to
[1345.08s -> 1348.92s]  the Stanford VPN to use this is to do this because you're gonna have to go
[1348.92s -> 1353.04s]  directly to one of the myth machines you can't do that from off campus you
[1353.08s -> 1357.16s]  can't go to a specific myth machine off campus okay so you're gonna need to log
[1357.16s -> 1365.52s]  into the VPN for that okay all right like I said you can use telnet you can
[1365.52s -> 1370.80s]  do you can actually do the actual samples one and it tells you it does
[1370.80s -> 1375.48s]  exactly what yours should be doing in the end okay so let's go through what
[1375.48s -> 1379.16s]  the assignments gonna be actually doing you're gonna first there's four
[1379.16s -> 1382.36s]  parts to this assignment the first one you're gonna do is a sequential proxy
[1382.36s -> 1387.68s]  okay eventually you will use thread pool not unless not yours unless you
[1387.68s -> 1391.48s]  really want to we've given you a working version not that yours isn't
[1391.48s -> 1395.64s]  working but we've given you a working version that definitely works so you
[1395.64s -> 1398.52s]  have to do more debugging on thread pool but first you're gonna write a
[1398.52s -> 1403.12s]  sequential version and what it's going to do is you're gonna make first
[1403.12s -> 1406.56s]  thing you're gonna do is just make it into an actual proxy that intercepts the
[1406.56s -> 1409.84s]  request and just passes them on to the intended server and then gets the
[1409.88s -> 1416.20s]  response and passes that back to your browser okay you need to support three
[1416.20s -> 1422.84s]  different types of HTTP requests we have seen get before and get is one
[1422.84s -> 1429.36s]  that basically tell just grabs the web page okay get by the way is not
[1429.36s -> 1433.68s]  supposed to have any side effects on the web server in other words you
[1433.68s -> 1437.08s]  shouldn't pass data that the web server is going to use to update its
[1437.08s -> 1442.04s]  own state that's really not the way get should work because often web browsers
[1442.04s -> 1446.56s]  will make one two or more get requests for the same data for various reasons
[1446.56s -> 1452.36s]  and so in this case you don't want to you don't want to do send any data
[1452.36s -> 1456.52s]  that that server might need to make changes but that normally happens when
[1456.52s -> 1461.36s]  you're doing web pages anyway you also have to do a request called head this
[1461.36s -> 1466.76s]  is a new one this one does exactly the same thing as get except it only
[1466.96s -> 1470.84s]  requests the only thing that you get back is the headers now why might you
[1470.84s -> 1476.28s]  want to do that well sometimes a website or a browser might request the
[1476.28s -> 1480.20s]  head from a particular page knowing that it's about to make an actual get
[1480.20s -> 1484.36s]  request and it may need to set some things up what you get back is how big
[1484.36s -> 1486.88s]  the payload is going to be and if whether it's going to be encrypted or
[1486.88s -> 1490.28s]  not and so forth so sometimes they will do that you should support that the
[1490.28s -> 1494.32s]  difference between get and head is simply a matter of ignoring the payload
[1494.36s -> 1498.28s]  or not or knowing that no payload for the head otherwise you're going to do
[1498.28s -> 1502.72s]  exactly the same thing that's an easy one and then put is one where you
[1502.72s -> 1508.00s]  have to actually send data to the website put is relative to almost the
[1508.00s -> 1512.16s]  same thing except that after all your headers you have payload that
[1512.16s -> 1516.92s]  you're then sending to the to the actual server okay so you have to
[1516.92s -> 1521.12s]  capture the payload from the request and then forward the payload on to the
[1521.12s -> 1525.36s]  next request or to the server that requests it or that you're requesting
[1525.36s -> 1531.24s]  from okay so far so good all right then the request is going to look like this
[1531.24s -> 1535.40s]  it's going to be get and then this is a we've seen this number of times
[1535.40s -> 1538.88s]  let's say you're going to Cornell better to use last research remember you
[1538.88s -> 1544.36s]  need HTTP 1.1 for any web pages you are sending back you can feel free to
[1544.36s -> 1548.76s]  use HTTP 1.0 it's not really gonna make a difference they're basically the
[1548.76s -> 1554.36s]  same format but that's that's that when you do that you forward the request to
[1554.36s -> 1559.92s]  www.cornell.edu okay and the request in that case because you're just for you
[1559.92s -> 1565.24s]  already know you're forwarding it to that server you just need to put the
[1565.24s -> 1568.96s]  slab the actual path in there you don't need the actual full server you
[1568.96s -> 1573.04s]  just say the actual path I don't know that it matters that you have if you
[1573.04s -> 1576.84s]  have a path in there but that's the way it goes we've given you an HTTP
[1577.00s -> 1581.36s]  request class so you don't have to build all of that okay you need to update the
[1581.36s -> 1587.16s]  operator less than less than to do some to do some input for that but it's not
[1587.16s -> 1593.88s]  that much extra work in general HTTP request is all set for you so you just
[1593.88s -> 1597.24s]  basically feed it the information and then you get the request you really
[1597.24s -> 1601.52s]  should understand how request dot CC the file works because it's got a lot of
[1601.52s -> 1603.92s]  functions in there but you're gonna want to use and I know you haven't
[1603.92s -> 1608.40s]  seen these yet but we'll talk about the actual files we're going to need soon
[1608.40s -> 1615.84s]  okay all right so one thing you're gonna have to do in this first one is
[1615.84s -> 1619.80s]  gonna sign it's gonna seem a little weird like what's the point but we want
[1619.80s -> 1624.68s]  you to take the headers that come in okay and we want you to add a header
[1624.68s -> 1631.32s]  called X forwarded proto now remember the headers look like this okay if you
[1631.32s -> 1635.56s]  look here the headers are all of in this case we didn't have any headers but they
[1635.56s -> 1639.68s]  would come after the get I think it actually after the host line I believe
[1639.68s -> 1644.96s]  they're just headers that kind of look like this these are the response
[1644.96s -> 1647.80s]  headers but they look kind of like this where they say they have
[1647.80s -> 1654.92s]  information that is used by the server to like do stuff well the two headers
[1654.92s -> 1662.08s]  that we want you to add or add to are the X forwarded proto which basically
[1662.08s -> 1667.32s]  means that it's saying what protocol are we using here and you're gonna use
[1667.32s -> 1671.08s]  just HTTP as it turns out it's a pretty straightforward you just add that it's
[1671.08s -> 1675.48s]  very easy to do and then you also and if it's already there you just add
[1675.48s -> 1678.64s]  it again no big deal there there's another one you have to do which is
[1678.64s -> 1684.12s]  going to be really important later this is called X forwarded for this is
[1684.16s -> 1690.80s]  basically four proxies to say who they forwarded the request from originally
[1690.80s -> 1695.20s]  right now if you're anonymizing things you're going to leave that blank but
[1695.20s -> 1698.24s]  you're not going to be doing that for this in this case it's basically a
[1698.24s -> 1705.48s]  list of all the various prior places that this request came from okay now why
[1705.48s -> 1709.28s]  do I say there could be many of them eventually and we'll get to this you
[1709.28s -> 1714.32s]  could do it you could have a proxy chain who's to say that your proxy doesn't
[1714.32s -> 1717.36s]  talk to another proxy doesn't talk to another proxy doesn't talk to another
[1717.36s -> 1721.04s]  proxy that's basically what the Tor network is doing incidentally it's
[1721.04s -> 1724.44s]  going one to another and then there's 17 things in between you have no idea
[1724.44s -> 1728.08s]  how to get back to the original one which is kind of the point or there
[1728.08s -> 1732.36s]  might be other reasons to have a proxy talk to another proxy we'll get
[1732.36s -> 1736.20s]  to those in a few minutes what you need to do is if there's a header that
[1736.32s -> 1740.68s]  comes in that says X forwarded for it's going to be a comma separated list of
[1740.68s -> 1745.52s]  all these IP addresses you need to add another comma and add the current IP
[1745.52s -> 1749.28s]  address that you came from and then report like put it back into the
[1749.28s -> 1753.04s]  request okay so you need to do that manually by the way there's no fancy
[1753.04s -> 1757.24s]  function that allows you to do that you have to do that it's really
[1757.24s -> 1761.40s]  pretty easy to to use some of these request functions in this case you
[1761.40s -> 1766.84s]  request the header which we've given you a whole function or a whole class
[1766.84s -> 1772.12s]  that does has this as one of its methods get value or get that sorry
[1772.12s -> 1777.80s]  that's the basically the request the request handler class I believe it is
[1777.80s -> 1781.48s]  and then get value as string and use pass and the exported for it gives you
[1781.48s -> 1784.76s]  back the string it's this comma separated value so don't look at this
[1784.76s -> 1787.24s]  no I have no idea how to get a request header it's it's pretty
[1787.24s -> 1790.36s]  straightforward straight from the actual code you just have to look
[1790.36s -> 1793.88s]  through the code and find out where those are okay like I said you have to
[1793.88s -> 1798.20s]  manually enter that in most of the code for the sequential version is going to
[1798.20s -> 1802.72s]  be in the request handler dot each file so let's look at that for a second
[1802.72s -> 1811.80s]  okay the request handler dot each file let's do it over here in the quest
[1811.80s -> 1818.44s]  handler dot H okay so request handler dot H well it's got a bunch of
[1818.44s -> 1822.20s]  functions into public functions there's a constructor of course and then it has
[1822.20s -> 1827.52s]  service request clear the cache we'll talk about the cache soon and then set
[1827.52s -> 1830.96s]  the maximum cache age that's all that you're the program is going to use and
[1830.96s -> 1835.04s]  then you've got some other functions in here like handle a get request
[1835.04s -> 1839.08s]  you're gonna want to also handle a put request and handle a head request so
[1839.08s -> 1842.92s]  you've got a couple more functions there and then you've got some other
[1842.92s -> 1845.80s]  requests that you're gonna have to handle as well some of those we've
[1845.80s -> 1852.32s]  actually built for you already so let's see there we go handle handle request
[1852.32s -> 1856.64s]  has already got a handle error in it and so forth but otherwise you need to
[1856.64s -> 1862.68s]  actually do most of your work under like let's see where's the get request
[1862.68s -> 1870.20s]  line there we go handle like there's one we're gonna set up again we're
[1870.20s -> 1876.32s]  also gonna set up a point you're also gonna step ahead etc and then see I think
[1876.32s -> 1880.00s]  that's the only there it is down here handle get request is the actual
[1880.00s -> 1883.20s]  function we've done a little bit for you already so you can kind of see
[1883.20s -> 1887.56s]  that it actually look you set you get a risk to create a response you set
[1887.56s -> 1891.88s]  the response code to be whatever you want normally it's going to be 200 you
[1891.88s -> 1897.16s]  set the protocol to be HTTP and in this case slash 1.0 and then the
[1897.16s -> 1900.96s]  payload in this case was your running proxy and that's it and then you push it
[1900.96s -> 1904.72s]  out so pretty straightforward in terms of like the in the connections
[1904.72s -> 1914.72s]  between the the the actual web and your proxy okay and your browser so
[1914.72s -> 1920.60s]  that's that after you've written this one test test test test on lots and
[1920.60s -> 1925.16s]  lots and lots of HTTP sites okay you can also test on HTTPS but most of the
[1925.16s -> 1929.68s]  time you'll get that connection refused or whatever or some other error if you
[1929.68s -> 1935.84s]  can find HTTP sites what are good ones example.com is a good one there's
[1935.84s -> 1940.84s]  that IPFI one there's there's lots of others that are out there but just
[1940.84s -> 1944.00s]  don't don't be surprised like sometimes you'll go to an HTTP site
[1944.00s -> 1948.00s]  and it will quickly turn it into an HTTPS site you won't notice well it's
[1948.00s -> 1950.88s]  broken look for the little lock if there's a lock up in the corner it
[1950.88s -> 1955.60s]  probably means it's HTTPS and you should try a different site so we will
[1955.60s -> 1961.52s]  have well we can put together a list of other sites that are good okay all
[1961.52s -> 1965.12s]  right now that's the first thing the second thing you're gonna do so as I
[1965.12s -> 1970.28s]  said one of the proxy services that it may offer is this thing called
[1970.28s -> 1975.12s]  blacklisting and another one is called caching blacklisting basically
[1975.12s -> 1980.20s]  means to block access to certain websites okay so there is a blocked
[1980.24s -> 1989.12s]  domains.txt file let's look at it it is see already set up for you really
[1989.12s -> 1996.68s]  blocked domains.txt okay so you can't go to any Berkeley sites can't go to any
[1996.68s -> 2000.36s]  Canadian sites can't go any French sites it looks like no government sites
[2000.36s -> 2004.36s]  I guess I can't go to Microsoft.com although I think Microsoft is one of
[2004.36s -> 2007.60s]  those ones that does everything HTTPS anyway the good news is testing the
[2007.60s -> 2011.32s]  blocked sites it doesn't actually have to go to the website so it should block it
[2011.32s -> 2016.56s]  immediately in fact let's test that oh no it hasn't been set up on the starter
[2016.56s -> 2019.92s]  code but anyway these are the ones that you want to do Jerry Cain has one
[2019.92s -> 2023.52s]  set up that should work all the time I'll ask him if it's still set up
[2023.52s -> 2026.80s]  it should be but that's those are sites that you shouldn't be able to go
[2026.80s -> 2031.76s]  to this uses regular expression matching to figure out which sites feel
[2031.76s -> 2035.44s]  free to remember if you took 103 already or go learn about regular
[2035.44s -> 2039.88s]  expressions you do not have to know a thing about it for this for this part
[2039.88s -> 2044.48s]  the blacklist file program blacklist functions are already written for you but
[2044.48s -> 2050.88s]  feel free to look at if you want to see what it looks like okay so if you
[2050.88s -> 2056.00s]  if the browser that's connecting to your proxy does go to a forbidden site
[2056.00s -> 2062.04s]  or block site you actually return a claw of them the client status code are you
[2062.04s -> 2067.28s]  return to the client the status code 403 well let's look up what 403 actually
[2067.28s -> 2075.76s]  is if we go here there we go 403 forbidden okay this means that it it's
[2075.76s -> 2080.08s]  telling the actual browser that that's a forbidden site and most of the time
[2080.08s -> 2083.02s]  your browser just reports whatever the payload is but it knows that it's a
[2083.02s -> 2086.48s]  forbidden site sometimes it may put up some other pages oh my gosh this is
[2086.48s -> 2092.64s]  forbidden but that's the the correct code when the site is not allowed to be
[2092.64s -> 2100.92s]  requested you may have seen that one before for other various things and you
[2100.92s -> 2104.88s]  that means you have to create your own request and send it that response and
[2104.88s -> 2108.24s]  send it back but it's exactly like what the temporary the one I showed you
[2108.24s -> 2111.64s]  already was it's very easy to tell whether a server is allowed using this
[2111.64s -> 2114.72s]  blacklist function I mean I'm giving it to you right here if not blacklist
[2114.92s -> 2119.20s]  server is allowed all right we've written that function for you okay again what I
[2119.20s -> 2122.68s]  don't want you to do is get into the reading this document go oh it sounds
[2122.68s -> 2125.92s]  like I have to write like an entire like in a program would take me months
[2125.92s -> 2131.40s]  not that quite that bad little question no okay all right anything so
[2131.40s -> 2135.76s]  far on this blacklisting pretty straightforward don't let the user go
[2135.76s -> 2153.64s]  to that site yeah let's look up what a put request looks like right so let's
[2153.64s -> 2167.16s]  do it here put put request okay put request versus a post request but here
[2167.16s -> 2172.36s]  we go we'll go to this site here a pull request creates a new resources
[2172.36s -> 2175.60s]  resource on the target the difference between put and post the post is
[2175.60s -> 2179.04s]  identified in calling it once or several times the same effect okay it
[2179.04s -> 2183.36s]  basically says here's a bunch of here's the request here's a bunch of headers
[2183.60s -> 2187.28s]  there's a new line after the headers after that everything until the end of
[2187.28s -> 2191.20s]  the file is data that's all there is to it you generally put how much the
[2191.20s -> 2195.56s]  payload how many bytes the payload is and so forth the good news is you
[2195.56s -> 2198.12s]  don't have to worry about that so much for the assignment you just have
[2198.12s -> 2201.96s]  to know that there will be a payload that you do need to forward otherwise
[2201.96s -> 2205.00s]  you don't even know any details about it you won't have to create any put
[2205.00s -> 2209.28s]  requests yourself but basically it's just a request that sends data to the
[2209.28s -> 2215.48s]  client or to that web server that's it all right any other questions good
[2215.48s -> 2225.16s]  question anybody else okay so that's the web proxy okay caching on the other
[2225.16s -> 2229.18s]  hand is this idea that I mentioned earlier it's keeping a local copy of a
[2229.18s -> 2232.80s]  page so that you don't re-request it from the internet all right that saves
[2232.80s -> 2239.16s]  time it saves bandwidth many times proxies are local to like an
[2239.16s -> 2243.20s]  organization and if lots of people in the organization happen to be going to
[2243.20s -> 2246.48s]  the same web pages and you have a cache of them well it's right there
[2246.48s -> 2249.04s]  locally you don't need to go like lots of people benefit from having
[2249.04s -> 2253.76s]  that having that cache okay in this case you are going to have to do a
[2253.76s -> 2259.32s]  few things for this you're gonna have to update the HTTP request handler to
[2259.32s -> 2262.48s]  check and see if you've already got the cache copy I mean that's basically
[2262.48s -> 2265.36s]  the first thing you do is you're gonna look here's the request do I already
[2265.36s -> 2269.36s]  have it in my cache if I have it in my cache I'm gonna just forward back the
[2269.36s -> 2272.92s]  cache response and be done I never even touch the site that it's trying to
[2272.92s -> 2277.48s]  request from okay and that's kind of nice all right now are you going to do
[2277.48s -> 2280.48s]  that for things like put requests no you can't do that for put because
[2280.48s -> 2283.68s]  you have to send data to the actual website there's no way to cache
[2283.68s -> 2286.48s]  something that's going to be a put so it's absolutely only going to be
[2286.48s -> 2292.42s]  either head or get requests that are cached and we've already built most of
[2292.86s -> 2295.98s]  the logic behind whether it's figuring out whether or not this is cached for
[2295.98s -> 2299.38s]  you so you're not even gonna have to worry too much about that there is an
[2299.38s -> 2303.58s]  HTTP cache class which you should look at and understand you'll have to
[2303.58s -> 2307.00s]  make very minor changes to that when you get to multi-threading but that's
[2307.00s -> 2310.10s]  that's the only real change you're gonna have to make is when you do this as
[2310.10s -> 2315.46s]  a multi-threaded program you're gonna forward as usual if it's not in the
[2315.46s -> 2320.66s]  cache when you get the response the response will tell you whether or not
[2320.66s -> 2325.38s]  it can be cached so in other words you make the request and it comes back and
[2325.38s -> 2331.06s]  the page itself in the headers says oh yeah you can cache this okay let's
[2331.06s -> 2338.78s]  actually test this I have a let's see if I can do this or there we go I have
[2338.78s -> 2341.58s]  a website let me make sure I get it right that I'll let you use to test
[2341.58s -> 2350.62s]  on here as well if we tell that to eco simulation.com 80 and I do get and
[2350.62s -> 2356.86s]  then what is it it is CGI whoops oh no oh no this is really so I forgot my
[2356.86s -> 2359.78s]  browser is really fast I have to write this first and then paste it in
[2359.78s -> 2368.38s]  so see just been it is look because and I forget the name of the pages
[2368.38s -> 2379.30s]  here okay CD public HTML CGI it is called current time dot PHP okay so we
[2379.30s -> 2385.58s]  are going to do a request for we're gonna say get slash CGI bin slash
[2385.58s -> 2396.70s]  current time dot dot PHP and then each and then HTTP one slash one point one
[2397.02s -> 2400.62s]  okay we're gonna put paste that in there and let's see if I can type the
[2400.62s -> 2411.42s]  host thing fast enough let's see telnet let's try that and then host did I get
[2411.42s -> 2422.70s]  it oh no what I forget I forget something else that should get CGI I
[2422.86s -> 2426.74s]  don't know why it's not doing that well we'll look at it in the browser but
[2426.74s -> 2431.42s]  what it's gonna do is it sends back like the ability to be cached okay I'll
[2431.42s -> 2435.66s]  test it in a little bit I'll test it again but basically it's going to say
[2435.66s -> 2438.74s]  that and then you need to determine oh if it's cached I'd better put it in
[2438.74s -> 2443.06s]  the cache okay and then later some of your request the page again you can do
[2443.06s -> 2450.82s]  that let me show you what this looks like for the actual let me show you
[2450.82s -> 2457.02s]  what it looks like for the site that I was just trying to go to let's see
[2457.02s -> 2465.98s]  eco simulation dot-com slash CGI bin slash current time dot PHP there we go
[2465.98s -> 2469.78s]  okay so that's what it looks like what it is I just put up a little page
[2469.78s -> 2476.10s]  that tells you what the current time is now it's got the date and the hour
[2476.10s -> 2481.70s]  minute and seconds if I refresh this right the browser doesn't actually cash
[2481.70s -> 2488.30s]  it as it turns out or rather the the the original proxy server doesn't
[2488.30s -> 2494.22s]  actually cash it let's see if this is still set up I don't think it's
[2494.22s -> 2502.18s]  still set up meaning that hang on preferences maybe it didn't actually set
[2502.34s -> 2510.46s]  up let's see there we go okay so now we've got the proxy server going if we
[2510.46s -> 2520.12s]  do the let's see samples slash proxy solution there we go okay and then now
[2520.12s -> 2524.50s]  we request this from the proxy server there it is now that's it right
[2524.50s -> 2528.22s]  if I were and let's look at what it did it said it cast the response and
[2528.22s -> 2532.86s]  it's gonna cash it for 3,600 seconds so for the next hour it's going to request
[2532.86s -> 2537.02s]  that website and it's always I'm repeating the refreshing here and it's
[2537.02s -> 2541.42s]  always going to the same time because it's been cached okay this is not
[2541.42s -> 2544.78s]  something you want for pages like this because this is a page that's
[2544.78s -> 2550.02s]  generated dynamically okay and many web pages are generated dynamically on the
[2550.02s -> 2553.70s]  web if you go to facebook.com your timeline is updated all the time right
[2553.70s -> 2557.38s]  you got ads flashing up and whatever it's all being regenerated every time
[2557.38s -> 2562.02s]  you refresh or scroll or whatever that's dynamic content the only content that
[2562.02s -> 2567.50s]  became can be cached is static content which should be things like images and
[2567.50s -> 2570.34s]  things that aren't going to change so in this case that's it now what if
[2570.34s -> 2573.38s]  this happens to you and you've cached something that shouldn't be cached okay
[2573.38s -> 2576.62s]  by the way every time I refresh it it says using cached copy because it
[2576.62s -> 2580.12s]  knows to go and use the cached copy there what you can do is you can say
[2580.12s -> 2585.90s]  dash dash clear cache and then it will clear the cache by deleting all
[2585.90s -> 2589.38s]  these files it keeps the files in a hidden directory in your program your
[2589.38s -> 2592.14s]  assignment file I don't know why we hit it but I guess that's the way it
[2592.14s -> 2596.18s]  goes and then now when I refresh it it should go back and there it is now
[2596.18s -> 2599.54s]  it does updated to there of course it's now being cached again so it'll
[2599.54s -> 2605.08s]  update won't won't do that again so that's that's that okay let me go
[2605.08s -> 2608.42s]  back here again so I can do that questions on caching and what you have
[2608.42s -> 2616.50s]  to what the basic idea is no questions on the basic idea for that okay no we
[2616.50s -> 2622.30s]  all right it is that's those are the things you have to do for that and
[2622.30s -> 2625.86s]  feel free to use this test to make sure that your thing is caching right go
[2625.86s -> 2628.54s]  and refresh a bunch of time to go oh it's the same day at time every time
[2628.54s -> 2638.10s]  so we make sure you cache yes so the good question you can cache
[2638.10s -> 2644.94s]  parts of a web site I would say yeah so the here's the thing when you go and
[2644.94s -> 2650.54s]  when you run this and you go to some website it will actually request
[2650.54s -> 2656.42s]  hundreds and hundreds of web pages web actual web pages in some sense if we
[2656.42s -> 2661.04s]  let's see I think if let's do it this way we still have to set up see
[2661.04s -> 2667.70s]  if we set it up for let's make go back to the proxies for a second I'm
[2667.90s -> 2675.30s]  set up there and then let's see how I get oh yeah if I go to okay so now it's
[2675.30s -> 2680.14s]  there's what we have there let me let me make the web page a little smaller so
[2680.14s -> 2683.78s]  you can at least see the scrolling that might happen here okay if I go to
[2683.78s -> 2689.50s]  let's say time.com which I don't think it there we go see all the web
[2689.50s -> 2692.86s]  pages that it's getting and if you can see it's still getting lots and lots
[2692.86s -> 2696.26s]  and lots and lots of web pages right time.com is another derivative test
[2696.26s -> 2700.14s]  because it's not HTTPS except for probably the ads or something some parts
[2700.14s -> 2703.06s]  of it might be but you get lots and lots so look at how many web look at
[2703.06s -> 2708.38s]  how many different pages it requested just from time.com right and it still
[2708.38s -> 2711.24s]  hasn't even finished loading why because it goes and requests the main
[2711.24s -> 2716.78s]  one and the main one says oh here's another image here's a an ad here's
[2716.78s -> 2721.54s]  another sub iframe page and so forth so that's what happens there so good
[2721.54s -> 2724.46s]  question yeah
[2736.30s -> 2741.34s]  yeah so it is loaded so the the question was does the cache persist
[2741.34s -> 2746.30s]  beyond your running it yes it's the files on the actual thing so if we look
[2746.30s -> 2760.58s]  ls-al d.s let's see there we go okay it should be oh you know what I believe
[2760.58s -> 2769.34s]  it's in your it's not in here I think it's in your main see see if it's
[2769.34s -> 2773.54s]  there is there is dot proxy cache myth 64 if we go into that that's in your
[2773.54s -> 2780.06s]  home folder dot proxy cache myth 64 then in there there's all the sites so
[2780.06s -> 2783.94s]  there's all the requests that it saves so all the time.com requests are right in
[2783.94s -> 2787.34s]  there and that hash will become important in a couple minutes okay I
[2787.34s -> 2790.02s]  become really important in a minute I don't know what form this is in let's
[2790.02s -> 2795.66s]  just look seven seven two eight oh that's a directory let's see CD seven
[2795.66s -> 2803.26s]  seven two eight in there created that's binary of some sort or maybe some
[2803.78s -> 2807.94s]  image probably an image so we can do that right so you know how you'd figure
[2807.94s -> 2811.50s]  out if it was an image you'd look at the hex for it you'd go something like
[2811.50s -> 2817.22s]  hex dump and then the name and then you'd oops not hex dump hex what is it
[2817.22s -> 2826.50s]  hex this hex dump oh hex text dumb there we go hex dump and then the
[2826.50s -> 2829.86s]  name and there you go and then you could look and see at the beginning of
[2830.86s -> 2838.14s]  the file many files that are binary actually have like five four four eight
[2838.14s -> 2842.14s]  possibly means like it's a particular type of file like the PNG file or some
[2842.14s -> 2845.14s]  other thing so you can do a little bit of investigation if you want to
[2845.14s -> 2850.66s]  figure that out but anyway that's the point and I'm not sure exactly how
[2850.66s -> 2856.26s]  it's so store but that that's where it is anyway okay all right so let's go
[2856.46s -> 2863.38s]  time.com which is a good one to test because it still remains only HTTP let's
[2863.38s -> 2869.98s]  see did I get rid of the settings here yes I did proxy and then let's make it
[2869.98s -> 2877.50s]  no proxy again and there we go okay all right so you need to do that for
[2877.50s -> 2882.74s]  the caching basically check if it's in the cache if it is for the data on or
[2882.94s -> 2887.46s]  forward it back for your local copy if it's not there request it when it comes
[2887.46s -> 2891.70s]  back say oh this does can this go in the cache put in the cache and a story
[2891.70s -> 2897.74s]  for that okay that is version two version three is now adding
[2897.74s -> 2904.44s]  concurrency you have built a thread pool and using a thread pool as you
[2904.44s -> 2909.22s]  found out is not actually that difficult the hard part is knowing
[2909.22s -> 2913.78s]  when to do all of the mutexes and things when you're using the thread pool
[2913.78s -> 2918.26s]  right because now what we've got we've got multiple threads that are going to
[2918.26s -> 2923.94s]  handle multiple web page requests you're actually going to limit it to 64
[2923.94s -> 2929.02s]  threads your thread pool is going to have 64 threads at once and you'll be
[2929.02s -> 2933.34s]  building this thing called a scheduler to actually handle those now the
[2933.34s -> 2941.34s]  scheduler basically is the first-in first-out kind of basically the
[2941.34s -> 2945.58s]  first-in first-out queue that's going to go into those into the thread pool
[2945.58s -> 2951.46s]  and so you're going to you're gonna have to build that it's not too much
[2951.46s -> 2955.94s]  code actually and as it turns out you're gonna have to do that it will
[2955.94s -> 2961.98s]  be very very simple as turns out when I say it's not much code your scheduler
[2961.98s -> 2968.82s]  class is gonna have like one line that does it calls an HTTP request handler
[2968.82s -> 2973.26s]  which you've already built right and that already has an HTTP blacklist and
[2973.26s -> 2978.62s]  HTTP cache already built for you don't go and try to reinvent things just
[2978.62s -> 2985.38s]  make just say okay I'm gonna use one HTTP request handler but what I'm gonna
[2985.38s -> 2990.94s]  need to do is I'm gonna need to update that handler to be thread safe
[2990.94s -> 2994.94s]  which means that there's certain things like oh maybe the cache needs to be
[2994.94s -> 2999.58s]  thread safe maybe the the blacklist as it turns out doesn't it's already it
[2999.58s -> 3004.22s]  never changes so it doesn't need to be nothing needs to change for that but
[3004.22s -> 3009.90s]  you should you should do that here's the the big thing about this you do
[3009.90s -> 3013.18s]  need to add synchronization directives to the other code that you've written
[3013.18s -> 3018.22s]  this may mean that you have to change like function signatures and
[3018.22s -> 3021.70s]  things that's actually okay you change functions even if they're I don't know
[3021.70s -> 3024.42s]  if any of the public ones will need it but you can change function signatures
[3024.42s -> 3031.66s]  to add functionality for this you're only allowed to have one request open
[3031.66s -> 3036.46s]  for a given request in other words let's say that two thread let's say
[3036.46s -> 3044.22s]  that two threads both requests some some JPEG from time calm at the exact
[3044.22s -> 3049.62s]  same time only one of them is allowed to proceed okay well how might you
[3049.62s -> 3055.02s]  support only one of them proceeding so before or probably a mutex in this
[3055.02s -> 3058.54s]  case just because you're only live one so in this case you need to lock
[3058.54s -> 3062.58s]  around the actual request for that so yeah so you're just gonna have that
[3062.58s -> 3066.74s]  now what you don't want to do is lock around the entire well it's
[3066.74s -> 3069.18s]  basically because of the cache as it turns out you don't want to lock
[3069.18s -> 3075.42s]  around the entire cache that would be really slow in other words while you're
[3075.42s -> 3078.34s]  doing the request or while you're updating the cache or whatever every
[3078.34s -> 3082.14s]  thread is going to say no I can't update the cache here's the nice
[3082.14s -> 3086.66s]  thing about the cache it is thread safe if you are trying to add things
[3086.66s -> 3091.74s]  to the cache from two different sites okay it just does local files that
[3091.74s -> 3094.94s]  have different names associated with them as turns out so you can have two
[3094.94s -> 3099.90s]  different sites doing adding to the cache at the same time it's actually okay
[3099.90s -> 3103.78s]  you can have as many reading from the cache at the same time as you want you
[3103.78s -> 3107.94s]  just can't have two of the exact same site writing to the cache at the same
[3107.94s -> 3110.74s]  time so this is the reason that you're not going that you're not going to
[3110.74s -> 3114.90s]  allow two requests to go out to the same page number one it seems a little
[3114.90s -> 3117.22s]  crazy to do that anyway because you're already requesting it you might as
[3117.22s -> 3120.70s]  well have the cache copy and then sort it for the next one but that's
[3121.42s -> 3134.98s]  yeah so good question the question is wait wait I don't get it how is it not an
[3134.98s -> 3137.66s]  issue if there are multiple threads reading and writing well it turns out
[3137.66s -> 3142.86s]  that the way the cache is built it just it doesn't have any internal
[3142.86s -> 3146.54s]  state it's not like it's updating anything internal it's strictly opening
[3146.54s -> 3151.46s]  closing files in that folder I showed you and those files are distinct so it
[3151.46s -> 3154.62s]  doesn't matter if two things are doing at the same time they both can be two
[3154.62s -> 3157.92s]  different threads can both be calling that function and they will be doing
[3157.92s -> 3161.94s]  different files as long as you aren't requesting doing the same request if
[3161.94s -> 3164.30s]  they're on the same request they're gonna overlap and they're gonna try
[3164.30s -> 3167.58s]  to they're gonna get mucked up in that that way so that's the reason so
[3167.58s -> 3170.62s]  it's mostly thread safe except for the same request so you do need to
[3170.62s -> 3173.54s]  have a mutex around that which again is the reason you don't want to have a
[3173.54s -> 3179.62s]  mutex around the entire cache all time only when you are you only need to do
[3179.62s -> 3184.90s]  it for that that amount of time where you are where you are doing the actual
[3184.90s -> 3189.02s]  let's see I think it's the the I guess it's the actual updating of it
[3189.02s -> 3191.74s]  or rather the reading if it's in there or not I think that's really the
[3191.74s -> 3194.94s]  only thing you're gonna read on you do so it's it's relatively low level but
[3194.94s -> 3201.62s]  you are going to have you do want to have different requests able to go at
[3201.62s -> 3206.34s]  the same time so how are we going to ask you to do that you are going to have an
[3206.34s -> 3212.14s]  array of 997 mutexes and I've already seen some people going they're
[3212.14s -> 3214.62s]  squinting guys going what are you talking about and I put it right here
[3214.62s -> 3219.02s]  what are we talking about why we have 997 mutex okay here's how this is
[3219.02s -> 3224.46s]  going to work every time you request a site you are going to hash the
[3224.46s -> 3229.06s]  actual request okay you're gonna take the request and you're going to hash it
[3229.14s -> 3235.34s]  now it turns out that we built a hash hashing function for you it takes a
[3235.34s -> 3241.70s]  request and returns to you a hash for that request remember how over in the
[3241.70s -> 3250.42s]  other thing here you saw let's see if we do oops if we go back here and do
[3250.42s -> 3255.10s]  that remember how that those numbers there that's the hash that actually
[3255.10s -> 3259.78s]  comes out of so let's see there we go those are all the hashes that come out
[3259.78s -> 3264.82s]  of the hashing function and it uses that hash as the file name as it turns
[3264.82s -> 3268.74s]  out for the folder that the information is going to go into the
[3268.74s -> 3274.18s]  payload so it's going to use that anyway your job is to say okay if we
[3274.18s -> 3279.50s]  have a particular request we're going to call this hash request as string
[3279.50s -> 3289.42s]  function that's all right we're gonna return return that and it's going to
[3289.42s -> 3296.34s]  see if I can do this let's see pages is it now no no no hang on use pen
[3296.34s -> 3302.14s]  pages screen not worth it I guess we're dealing with red right now or black so
[3302.14s -> 3305.74s]  it's going to it's going to get their hash and then you're going to have
[3305.74s -> 3316.02s]  one of those mutexes those 997 mutexes based on that that hash modded by 997
[3316.02s -> 3321.98s]  that's the hash you're going to use for the actual passion or for the mutex
[3321.98s -> 3326.14s]  okay let me explain that in a little more detail here's what you're gonna
[3326.14s -> 3331.42s]  here's what you are going to do you are going to have these 997 mutexes and
[3331.42s -> 3336.58s]  you're going to say okay every time I get another page I'm going to use a
[3336.58s -> 3343.02s]  different mutex for that page the only time they will overlap most of the time
[3343.02s -> 3348.80s]  is if it's the same request because that's the odds are very slim that two
[3348.80s -> 3353.42s]  different requests will have the same hash out of those 997 might be the
[3353.42s -> 3356.50s]  case that's just something you have to do it otherwise you're going to use
[3356.50s -> 3361.86s]  that lock at that point to say I'm locked now based on that hash if you
[3361.86s -> 3364.82s]  have two hash requests coming or requests coming in at the exact same
[3364.82s -> 3368.58s]  time that are for the same site they're going to both have to the same
[3368.58s -> 3371.98s]  value they're going to both end up with the same mutex therefore you're
[3371.98s -> 3376.18s]  going to use the lock for those two identical sites that's what we're
[3376.18s -> 3380.98s]  doing now question is why is it 997 anybody know anything about that
[3380.98s -> 3386.78s]  number it's prime yeah hashing works best when you do mod with a prime number
[3386.78s -> 3390.58s]  so it actually kind of scrambles it up even more than it would otherwise
[3390.58s -> 3401.62s]  that's the way it goes so questions on that no no no the good question you
[3401.62s -> 3404.78s]  have to determine a collision in the same site if it collides you just deal
[3404.78s -> 3407.38s]  with it go well you know what it's gonna be a little slower because that
[3407.38s -> 3411.38s]  collision the collision will happen very infrequently so you don't need to
[3411.38s -> 3414.06s]  worry about that and this is not a you know if you wanted to you could
[3414.06s -> 3418.10s]  pick a bigger prime number and even less likely they would have but the
[3418.10s -> 3420.94s]  odds are pretty good that even if you're making remember you only have
[3420.94s -> 3425.74s]  64 things going at a time so the odds of those 64 have a collision it's a
[3425.74s -> 3428.90s]  little bit of a birthday problem issue but it's not the biggest deal in the
[3428.90s -> 3432.22s]  world and even it happens it's not even you're not gonna notice it I mean
[3432.22s -> 3440.50s]  don't notice it anyway but you won't notice it at all yes oh sure sure you
[3440.50s -> 3443.58s]  could have this a different hash in the same remainder yeah absolutely but
[3443.58s -> 3447.10s]  the hashes are notice how long the hashes are they're like you know 60
[3447.10s -> 3453.26s]  bits or 15 or 20 number 8 digits long right that's a giant number and
[3453.26s -> 3456.42s]  they're gonna hash into the same they're gonna have somewhere in that
[3456.42s -> 3461.94s]  bucket of 997 and that array of 997 buckets sure but the odds are
[3461.98s -> 3466.26s]  slim because you got a 1 out of 90 well you've got a birthday problem number of
[3466.26s -> 3471.46s]  you know percentage wise chance that it actually two very different numbers
[3471.46s -> 3477.36s]  hash to the same bucket basically 1 out of 997 per to two that are going at
[3477.36s -> 3482.26s]  the same time yeah that makes sense don't need to deal with any
[3482.26s -> 3487.54s]  collisions because it will matter anyway it would be the the if you
[3487.54s -> 3490.14s]  still will get an in you still will get an individual hash which is
[3490.14s -> 3494.62s]  different you just will only have 997 mutex is dealing and the mutex is only
[3494.62s -> 3498.30s]  slowing it down it's only saying look you can't go while I'm here and it's
[3498.30s -> 3508.70s]  very short amount of time anyway not not too big of a deal when you're
[3508.70s -> 3513.10s]  accessing the cache they should you should lock around in that case again
[3513.10s -> 3523.70s]  if you if you I guess let's see how should I put this you yeah question is
[3523.70s -> 3526.46s]  why do you need it if it's thread safe to begin with I'm gonna look I'm
[3526.46s -> 3528.82s]  gonna look look into it a little more detail I don't want to give you give
[3528.82s -> 3531.78s]  you the wrong answer on that but the basic idea is yeah just while you're
[3531.78s -> 3535.50s]  accessing that cache for that particular website lock around it and
[3535.50s -> 3539.18s]  it's not really that you're locking because of the access you're simply
[3539.18s -> 3543.26s]  locking because two sites might have the same trying to try to access the
[3543.26s -> 3546.34s]  same files so that's really all you're doing you're not really locking you
[3546.34s -> 3551.74s]  are locking around your cache accesses but it's only it's only when you're
[3551.74s -> 3556.34s]  doing that request that might be the same as some other request that's the
[3556.34s -> 3559.86s]  only reason yeah so it has nothing to do with the cache being thread safe
[3559.86s -> 3563.34s]  or not it has to do with the fact that if you're you are the same web
[3563.34s -> 3566.54s]  if you are doing the same request then it's not safe so you have to lock on
[3566.54s -> 3579.34s]  that case right yeah the question is shouldn't we just be locking around one
[3579.34s -> 3583.26s]  particular thing well remember we've said you're not allowed to make a
[3583.26s -> 3587.30s]  request to the same site at the same time so you do need to lock around the
[3587.30s -> 3590.66s]  entire request in that case like the entire setup for that request because
[3590.66s -> 3595.50s]  you want to make it so that if two browser tabs or whatever go to the same
[3595.50s -> 3599.50s]  ask for the same page at the same time one of them fully completes before the
[3599.50s -> 3602.42s]  other one goes you need to lock around that whole section but again it's one
[3602.42s -> 3607.10s]  997 different locks so it's going to be unlikely to have too much of a
[3607.10s -> 3613.22s]  problem good question okay all right good question and this I think is one
[3613.22s -> 3619.98s]  of the trickier parts of the assignment okay version four there is
[3619.98s -> 3624.36s]  one more thing you're gonna have to do for this assignment the final thing
[3624.36s -> 3626.80s]  you're gonna have to do is this thing called proxy chaining and I mentioned
[3626.80s -> 3632.08s]  that earlier proxy chaining is where you have your proxy goes to another
[3632.08s -> 3635.88s]  proxy goes to another proxy goes to another proxy let me demonstrate for
[3635.88s -> 3644.80s]  that that for you okay if we go and set up our proxy again so we're setting
[3644.80s -> 3652.16s]  up the proxy to be manual proxy for myth 64 let's say that I let's see
[3652.16s -> 3662.52s]  where was I here 110 see spring assignments assignment 7 okay if we do
[3662.52s -> 3669.88s]  let's do this let's do farm or not farm we will use farm in them in a
[3669.88s -> 3674.20s]  little bit again different fun as it turns out in this case we're gonna do
[3674.20s -> 3684.28s]  sample sample proxy solution and we are going to tell it let's see how we do
[3684.28s -> 3692.34s]  this we tell it how to there we go we say dash dash proxy server and let's
[3692.34s -> 3700.52s]  actually do we'll do exactly this one see dash dash proxy server so this is
[3700.52s -> 3707.68s]  what now we've said okay if our browser goes to our proxy and makes a
[3707.68s -> 3712.08s]  request it will not forward it on to the requested website it will forward it
[3712.08s -> 3715.96s]  on to some other proxy that we are about to set up so I have told it that
[3715.96s -> 3721.56s]  I'm setting this up on myth 63 who I probably did this in my office so maybe
[3721.56s -> 3729.88s]  it won't work well we'll see SSH myth 63 okay yes I'm good okay say this one
[3729.88s -> 3738.72s]  10 10 and spring assignments assignments assignments 7 samples slash
[3738.72s -> 3747.40s]  proxy solution and in this case we want port 1 2 3 4 5 here we go it is
[3747.40s -> 3752.84s]  working okay so now it's gonna be 1 2 3 or 5 so when I make a request to my
[3752.84s -> 3763.04s]  other original myth 64 1 it should forward the request on to myth 63 okay
[3763.04s -> 3768.28s]  if all goes well let's try this let's say time calm and let's see what
[3768.28s -> 3773.44s]  happens okay it's loading there we go so notice the original request is going
[3773.44s -> 3776.04s]  here there's some other weirdness going on here the cloth socket it's
[3776.04s -> 3780.36s]  probably time being annoying and over here it's going to the other proxy
[3780.36s -> 3783.40s]  server and then it's forwarding back and forth so there's a little chain of
[3783.40s -> 3791.68s]  proxies okay if we go to let's see if we go to our current time one okay
[3791.68s -> 3795.72s]  there's the current time it actually cached it I think it actually cached it
[3795.72s -> 3799.32s]  in both as it turns out because both proxies wanted to come back as a cache
[3799.32s -> 3804.16s]  that's okay but if we go and do one more time it actually you couldn't see
[3804.16s -> 3807.88s]  let's clear this and let's see if it does it again if we do it there there we
[3807.88s -> 3811.28s]  go it only cached it in the first one because it had it locally it never
[3811.28s -> 3815.44s]  needed to go to the proxy the second proxy there so that's one of the nice
[3815.44s -> 3819.22s]  things about caching you didn't need to go to the other proxy the other
[3819.22s -> 3826.44s]  ones there now what's the trick to doing this well let me show you
[3826.44s -> 3840.20s]  settings no proxy okay all right so you can have as many proxies as you want in
[3840.20s -> 3844.84s]  a row right you should be able to handle as many as happen now each
[3844.84s -> 3850.36s]  individual proxy could really care less how many prior proxies it came
[3850.36s -> 3857.04s]  from or how many it goes to except in one case you don't want to be able to
[3857.04s -> 3862.84s]  create a cycle of proxies what if I was a proxy going to Derek and Derek was
[3862.84s -> 3867.20s]  a proxy coming back to me well we would go back and forth all day and we
[3867.20s -> 3869.84s]  just make millions and millions of requests and that was like we just all
[3869.84s -> 3872.72s]  be waiting for me to start timing out and this and that because there if
[3872.72s -> 3877.40s]  there was no cycle detection right so what we need to do is you need to do
[3877.44s -> 3882.60s]  now remember about ten slides ago when I said there's this thing called X
[3882.60s -> 3888.32s]  forwarded for and where did it say it said where the request came from and you
[3888.32s -> 3892.24s]  add your next request on to it well guess what you're gonna if you come
[3892.24s -> 3897.96s]  from a proxy you're gonna add add that proxies IP address on to this
[3897.96s -> 3902.76s]  list which is going to end up going to the next proxy if you look through
[3902.76s -> 3906.76s]  that list and find out that there's a cycle going on in other words the
[3907.20s -> 3911.12s]  place you're about to send to is one that's already in the list you have to
[3911.12s -> 3914.40s]  return an error message because you don't want to create the cycle the error
[3914.40s -> 3920.40s]  message we happen to want to you to send back is 504 which is gateway
[3920.40s -> 3925.00s]  timeout and it says the server while acting as a gateway practice did not
[3925.00s -> 3928.12s]  receive a timely response that's about the best you can do the error message
[3928.12s -> 3934.68s]  turns out the best you can do for this sort of issue okay didn't work
[3934.84s -> 3948.08s]  because there was this cycle it does go through the proxy again good question
[3948.08s -> 3954.44s]  question is if you if you have a proxy set up here I'll draw it out for you
[3954.44s -> 3965.00s]  no I won't because this isn't gone see of course the if you have a proxy they
[3965.00s -> 3968.32s]  makes a request to another proxy it's expecting the request back from that
[3968.32s -> 3971.56s]  there's a response back from that proxy that proxy might have its own
[3971.56s -> 3975.40s]  proxy that's going to it's expecting your request back so the chain goes
[3975.40s -> 3980.28s]  down the line Bing Bing Bing Bing gets the real website it responds to the
[3980.28s -> 3983.42s]  last proxy respond to the second last proxy respond to the next last proxy
[3983.42s -> 3986.82s]  all the way back to you so that's the whole change it's kind of slow it's not
[3986.82s -> 3994.18s]  fast oh it's not a cycle because there's no request that comes back to the one
[3994.18s -> 3998.50s]  that's already been requested from remember here's the cycle okay I
[3998.50s -> 4003.10s]  request the site from so I'm good so let's say my browser request time
[4003.10s -> 4007.18s]  calm and it comes to me as a proxy as my proxy I go to Elizabeth and
[4007.18s -> 4011.54s]  Elizabeth says she's gonna respond I'm expecting response from her she goes
[4011.54s -> 4016.10s]  to Derek etc and then Derek goes to time okay and then the response comes
[4016.10s -> 4020.26s]  back to Derek from time from Derek goes back to Elizabeth from Elizabeth goes
[4020.26s -> 4024.70s]  back to me no cycle if however Derek had a proxy set up it was going
[4024.70s -> 4028.06s]  to come back to me then it would go browser to me to Elizabeth's a
[4028.06s -> 4032.78s]  Derek to me to Elizabeth's a Derek to me never get to time calm and that
[4032.78s -> 4035.82s]  would be a cycle but you can figure that out because when the request
[4035.82s -> 4040.10s]  comes from time to me I tag on time to the X forwarded for and then I pass
[4040.14s -> 4044.58s]  it on to Elizabeth and Elizabeth tags my IP on to the X forwarded for and then goes to Derek
[4044.58s -> 4049.38s]  and Derek tags hers on to the X forwarded for and then time gets it respond respond respond
[4049.38s -> 4053.78s]  and it comes back that way so it won't the response doesn't need to go I mean can go back
[4053.78s -> 4057.58s]  to the actually goes back to whoever responded but the cycle happens when you're doing
[4057.58s -> 4068.42s]  the request that makes sense if you would you would not check if your own IP is in
[4068.42s -> 4073.02s]  there you would check if the request the the proxy that you're about to send to is in there
[4073.02s -> 4078.34s]  already right because then if it is then you go well I can't I shouldn't be sending to another
[4078.34s -> 4088.46s]  problem good question yeah oh good question I don't know if you notice that both of them
[4088.46s -> 4092.82s]  happen to use the cache because you remember you don't know that there's a proxy and I mean you
[4092.82s -> 4097.70s]  know you're forwarding onto a proxy but you don't necessarily know if it has a cache or not so
[4097.82s -> 4103.14s]  every time you get back a response your local decision is do I make any cash or not and I do
[4103.14s -> 4107.82s]  if it needs to be and then the one previous says oh do I need make it does so it would get
[4107.82s -> 4112.38s]  cached along each each section in real life this is not necessarily going to happen either
[4112.38s -> 4115.06s]  one is going to cache it or there's going to be some other things going on but maybe
[4115.06s -> 4122.82s]  they all locally cache it who knows you know so but good question all right so we
[4122.82s -> 4130.54s]  actually have a program called run proxy farm that you can actually use to to actually check
[4130.54s -> 4137.38s]  and soups to check and run it make a little proxy proxy chain through all the remit machines
[4137.38s -> 4142.30s]  or whatever and it and you can test it out that way what it doesn't test for and this
[4142.30s -> 4145.88s]  is kind of most important thing but it doesn't test for cycles you if you wanted to you could
[4145.88s -> 4149.94s]  dig into the code for the Python program would give you and just write it so that it
[4149.94s -> 4155.14s]  checks for cycles or does some cycle creation is really what it is it should be it's not
[4155.14s -> 4163.18s]  too hard to update but you would have to do that so that's that so that is the assignment
[4163.18s -> 4166.42s]  now I took a while to explain it but I now you should have a good idea when you get to
[4166.42s -> 4171.30s]  it tomorrow or whenever you start doing it I would start doing it sooner than later you
[4171.30s -> 4176.94s]  will get to it one step at a time okay if you do want to support HTTPS it turns out you
[4176.94s -> 4183.48s]  have to support this other header or method called connect we don't expect you to do that
[4183.48s -> 4188.06s]  nor do we we can give you some hints on how to do that so if you wanted to do that you
[4188.06s -> 4193.18s]  had extra time and said oh I'd like to work for HTTPS then feel free to ask and we'll give
[4193.18s -> 4197.10s]  you details about what you need to do make connect work but I would only do that at the
[4197.10s -> 4201.10s]  end and you don't have to test as often as you can clear your caches both in the browser
[4201.34s -> 4208.14s]  and locally in the cache and then that's that the files here's the various files you're gonna
[4208.14s -> 4215.06s]  have to make changes to very minor changes of cache the cache files very minor changes to
[4215.06s -> 4220.94s]  the proxy file somewhat minor but less than like decent changes to request as you see across
[4220.94s -> 4227.14s]  stage this is where you can do most of the work request handler very minor minor in the
[4227.14s -> 4232.90s]  scheduler things as well so again there's a lot of files you have to touch minor changes in most
[4232.90s -> 4245.38s]  of them okay all right question you can't create one more than proxy computer every
[4245.38s -> 4249.22s]  port could have different proxy on it okay yeah and in fact when you guys are all running
[4249.22s -> 4252.64s]  it we might have 25 people on each myth doing 25 different servers
[4257.98s -> 4266.06s]  the cache is locally your own home folder so nobody else's caches yeah there's no oh boy
[4266.06s -> 4269.54s]  that would make it a really hard assignment everybody else gets to cache the stuff too good
[4269.54s -> 4278.22s]  luck doing that kind of debugging but no it's your local right the folder is based off your
[4278.22s -> 4286.62s]  local in your own home folder hidden by hidden folder good question all right and now that we
[4286.66s -> 4289.82s]  talked about that you now know a little more about proxies too and now you're gonna go you're
[4289.82s -> 4295.70s]  gonna go start building one tomorrow or Friday all right so in the last couple minutes I'm gonna
[4295.70s -> 4300.66s]  briefly talk about the next assignment just in this in the big global picture and then next
[4300.66s -> 4306.02s]  Wednesday I will go much more detail about it okay in a similar kind of like here's the
[4306.02s -> 4314.10s]  things you have to think about okay so the last assignment is this algorithm called MapReduce
[4314.10s -> 4323.42s]  and MapReduce is a very cool algorithm that is a distributed algorithm I believe it was first
[4323.42s -> 4333.34s]  it was first invented or at least used widely at Google what it is it's a parallel okay so see
[4333.34s -> 4341.66s]  it's a parallel no I got the brother cursor back but no hang on it's distributed okay it's
[4341.66s -> 4347.74s]  distributed meaning that it is across many myth computers okay so your program will actually run
[4347.74s -> 4356.38s]  on many myth computers it is and it's used to generate and process large data sets okay what
[4356.38s -> 4361.42s]  does that mean it means that you've got this data set that you need to do a lot of analysis
[4361.42s -> 4366.82s]  with and you want to utilize many different servers to do that this is a huge issue for
[4366.82s -> 4371.22s]  companies like Google or Facebook or Apple or companies that have lots and lots of data
[4371.30s -> 4375.30s]  that they're chugging through every day they have billions of things to do and they have
[4375.30s -> 4380.34s]  tens of thousands of servers you have to farm them out across all these servers and do this
[4380.34s -> 4385.42s]  there are two basic parts to MapReduce there's the map stage and there's the reduce stage
[4385.42s -> 4394.30s]  those are the those are the problem specific things okay the map stage says I need to take
[4394.38s -> 4402.30s]  this data farm it out to all these servers and process it in some way okay and it gets
[4402.30s -> 4406.74s]  processed on all those servers and I'll show you an example in a minute or maybe I'm Wednesday
[4406.74s -> 4413.98s]  it processes in a certain way and then it sorts it all and that's not the part of the map part
[4413.98s -> 4417.10s]  but that's that's kind of part of that thing but it's not that happens at all of it you
[4417.10s -> 4421.06s]  always have to do some sorting back down here it shows that you've got a mapper you've got
[4421.06s -> 4425.10s]  some intermediate data you take that intermediate data you always sort it in some way or another
[4425.10s -> 4431.50s]  and you always group it by these keys and I'll show you an example and then you have a reduce
[4431.50s -> 4437.34s]  phase which says okay now that all that data is out there I need to go collect all that data
[4437.34s -> 4444.82s]  in a regulated way so that I can get it back and collate it into one giant result okay so
[4444.82s -> 4448.42s]  you're sending the data out you're mapping it out to all these different servers that are
[4448.42s -> 4452.50s]  going to chug away and do whatever is necessary for it then you're going to sort it and process
[4452.50s -> 4457.78s]  it by these sorting and grouping by the key that will come along with it and then you're going to
[4457.78s -> 4462.82s]  reduce it by bringing it back to the main computer and having the final data set that's
[4462.82s -> 4472.18s]  what MapReduce is all about okay so what is the what are the details yes what's the
[4472.18s -> 4477.34s]  difference between group by key and reduce well you'll see when we do it but group by key
[4477.38s -> 4483.54s]  basically is local you are saying all for my local copy all these keys are the same and you'll
[4483.54s -> 4487.90s]  see the example then you'll go oh I get it and then the reducing is taking all those different
[4487.90s -> 4493.98s]  farmed out versions bringing them all back and further combining them together okay you'll see
[4493.98s -> 4502.58s]  how it works and and that's it and so it requires networking it requires it requires threading
[4502.82s -> 4508.34s]  in terms of getting the the main server has to do the threads to get everything out to all the
[4508.34s -> 4515.38s]  things it requires multi-processing I guess it does and it requires multi-processing and then
[4515.38s -> 4518.78s]  you're going to run multiple programs on there kind of ties everything together that we've been
[4518.78s -> 4523.70s]  doing all quarter okay all right here's the example I'm only going to show this and then
[4523.70s -> 4527.96s]  I'm going to let you go and then we'll finish this up next Wednesday the example is you
[4527.96s -> 4535.92s]  basically have a file let's say a document that's a book and has these words in it and what it's
[4535.92s -> 4541.16s]  going to do is it's going to this script here is going to read in an input file and output it
[4541.16s -> 4546.24s]  for every word it's going to say word and then one meaning there's one word that it's
[4546.24s -> 4549.20s]  associated with it now why do you have to do it you don't necessarily have to have that one
[4549.20s -> 4552.40s]  but we're going to in this case we're going to do that it's going to be generic in this
[4552.40s -> 4556.00s]  way we're going to say it's going to output the word and then it's going to be one so
[4556.00s -> 4560.56s]  at the end of this little script you're going to have all the words in this document there's
[4560.56s -> 4564.28s]  going to be many overlaps and they're all going to say word one the next word one the
[4564.28s -> 4569.88s]  next word one you have lots of duplicates okay after that you are going to then do the
[4569.88s -> 4575.88s]  sorting and collating phase that you'll get to next Wednesday okay all right so we'll get
[4575.88s -> 4580.12s]  back to look to talk a lot more about MapReduce when we get when we come back next Wednesday
[4580.12s -> 4583.48s]  in the meantime I am going to my office now for some office hours if you want to come
[4583.48s -> 4590.20s]  by it's actually 219 I think is where it's going to be and we'll see you guys in lab or next week
