# Detected language: en (p=1.00)

[0.00s -> 5.88s]  Okay, so we are starting out today. Today is one problem. Hopefully you got the
[5.88s -> 11.04s]  handout. If you haven't, it's right up here. I made plenty of them. There is one
[11.04s -> 16.56s]  program we're going to look at today and it is going to model. Where did it
[16.56s -> 25.32s]  go here? That's not it, that's not it, that's not it. It is modeling the ice cream shop. Okay, we're actually
[25.36s -> 33.00s]  going to try something live in person demo with people to demonstrate threading. We
[33.00s -> 37.68s]  have now opened up an ice cream shop. I'm sorry for people watching the video,
[37.68s -> 43.48s]  you're going to not see the chaos that's about to ensue. Okay, here's
[43.48s -> 50.32s]  what I need. I need 11 volunteers or conscripts. Come on up. First three
[50.32s -> 53.68s]  people get to be customers, which means you get ice cream if you actually
[53.88s -> 64.48s]  have real ice cream. Okay, other people, the next people, you get to be a clerk.
[64.48s -> 70.00s]  We get to be a clerk, a clerk, a clerk, a clerk, a clerk. Somebody has to be the manager and
[70.00s -> 73.40s]  somebody has to be the cashier and I think that's it. I think, oh, here's a couple
[73.40s -> 77.56s]  clerks. If you, anybody else who's up here, there we go. Okay, all right, thank
[77.60s -> 84.32s]  you very much. Okay, clerks, clerks, go over in this corner over here. Okay, oh, and by
[84.32s -> 89.32s]  the way, everybody grab one of these too, which is your instruction manual. Okay,
[89.32s -> 92.88s]  there should be enough for everybody. Okay, here's what we're doing. We're
[92.88s -> 96.38s]  going to model an ice cream shop. Now what we're actually doing is we're
[96.38s -> 102.84s]  modeling a problem that was given, believe it or not, a CS107 final exam from many years ago when
[102.88s -> 109.68s]  multi-processing and threading was in CS107. It used to be. We've changed things since then. Okay,
[109.68s -> 117.40s]  but here's what we're doing. All right, we are setting it up. So where's our manager? Okay,
[117.40s -> 119.88s]  you're the manager. You're going to be, you're going to be, people are going to fight over you
[119.88s -> 124.96s]  actually, as it turns out. Okay, and where's our cashier? You're going to kind of come in
[124.96s -> 130.48s]  near the end. Okay, but you have, there's a little number system here. So the one, two,
[130.52s -> 135.00s]  three, they, people will, the customers will take the number in order. So I've got numbers.
[135.00s -> 141.00s]  We have ice cream cones. Okay, and we have lots of, who are the customers? Customers over here.
[141.00s -> 147.84s]  Okay, so here's the way this works. All right, we're modeling this with only three customers.
[147.84s -> 155.16s]  Okay, a customer does the following. A customer comes into our ice cream shop and says, I want
[155.16s -> 161.48s]  X number of cones, and you have how many cones you want on there. Okay, so they're going to come
[161.48s -> 165.08s]  in. They're going to say X number of cones, and what they're going to do is, because they want
[165.08s -> 169.20s]  to get their cones quickly, or at least as quickly as they can, they're going to grab a
[169.20s -> 173.46s]  clerk. For some reason, we have as many clerks as ice cream cones that are going to be
[173.46s -> 178.56s]  delivered that day, and each clerk gets to make one perfect ice cream cone. In fact, each
[178.56s -> 182.28s]  clerk can try to make an ice cream cone perfect, but the manager is going to keep them
[182.28s -> 186.04s]  honest if it turns out to be terrible. I used to have a friend who, he worked in an ice cream
[186.04s -> 191.08s]  shop, and he and a buddy of his used to have a competition to see who could make the smallest
[191.08s -> 198.76s]  scoop without somebody complaining, which is really a mean thing. You have a tiny little scoop and you're like,
[198.76s -> 204.64s]  oh, I'm just too nice not to complain and whatever. Anyway, you don't get to do that. You will actually have a more or less
[204.64s -> 209.76s]  deterministic, it's a random thing, but it's deterministic as far as the ice cream cones go. Okay, so they will
[210.20s -> 218.76s]  grab a clerk. They will grab the number of clerks for each ice cream cone. Each clerk will then, actually, will make the
[218.76s -> 230.76s]  clerks walk all the way over to this table to grab an ice cream cone. This is going to be a time thing. There's going to be ice cream cones over there that you're going to make. When you have made an ice cream cone, you're going to walk back and you're going to present it to the manager.
[230.76s -> 238.76s]  Okay, and by the way, you are milling around at this point waiting for your ice cream cones. You're not getting in the way, you're just kind of waiting for the ice cream cones.
[238.76s -> 253.76s]  When you have created an ice cream cone that you think is perfect, in other words, you have grabbed one, you're going to bring it back to the manager. And if there are two of you who are kind of going towards the manager at the same time, you get to fight over who gives it to the manager.
[253.76s -> 265.76s]  Okay, now you don't really need to participate in this fight. Just basically grab one. And, you know, whoever you want. It's your kind of choice in that case. Okay, and then the manager, you are going to decide whether or not it's a good ice cream cone.
[265.76s -> 282.76s]  Don't tell the clerks it's written on the back. D means bad, G means good. On the ice cream cones. Don't tell the clerks this. Okay, so anyway, and then you are going to either tell them, yes, that was a beautiful ice cream cone, in which case you are going to say, now I have made one of my six ice cream cones that I have to make today.
[282.76s -> 294.76s]  Okay, and you might want to keep track. You can say I need to make six, and you can say five and four. Once you make all six that are good, or that you have approved, you get to go home for the day.
[294.76s -> 306.76s]  Okay, all right. Clerks, if the manager says, no, that wasn't a good cone, you have to throw that cone away, just throw it right on the floor wherever you want, go get another cone, and come back and fight again.
[307.76s -> 319.76s]  Okay, for the manager's attention. Okay, customers, you are just waiting around. Now, if the manager says, this is a great cone, perfectly fine, you can go deliver it to the customer, and then you get to go home.
[320.76s -> 333.76s]  Okay, all right, and now, once you get all three of your cones back, you come take a number, okay, and the cashier is waiting for somebody to take care of.
[333.76s -> 339.76s]  Okay, now, the minute you see somebody take a number, you can go, oh, I'll take number one, and then take as much time as you want checking them out.
[340.76s -> 348.76s]  Make sure they pay you in the right, whatever you want. All right, but you have to check, just check them out. Once you check them out, you get to mark off that you have checked off one customer.
[348.76s -> 358.76s]  You have to check off three customers, then you get to go home. Okay, all right, and then customers, when she's checked you out, you can then take your ice cream and go home.
[358.76s -> 365.76s]  Okay, at the end of the day, you should have however many ice cream cones you get. Now, does everybody, that was a lot of stuff all at once.
[365.76s -> 373.76s]  Okay, you have your own instructions here. Okay, in fact, I will pull up the instructions so that everybody can kind of see what's going on.
[373.76s -> 383.76s]  Let's see, how am I going to do this? I'm going to pull this up here, it should be here, and then ice cream details, there we go.
[383.76s -> 399.76s]  And if this pulls up correctly, we should do that. And there we go, hold on, not now. And here are the instructions, I will make this as big as I can, and there we go.
[399.76s -> 407.76s]  Okay, so I know there's a lot there, but you can kind of see what's happening, right? The customer grabs an ice cream cone, grabs a clerk for ice cream cone, mills around, the clerks do their thing.
[408.76s -> 416.76s]  When the customer gets back the ice cream cones, they go to the cashier, take a number, etc. Everybody get what's going on, more or less? I mean, it might look a little crazy.
[416.76s -> 427.76s]  Let's see if we can make this happen without, no real fights, please. But you can see what happens. Okay, so, customers, come on into the shop, whatever you want.
[427.76s -> 436.76s]  Okay, and go by your business, okay? Clerks over there. Alright, I will narrate for the people listening on the video.
[436.76s -> 450.76s]  We are, the ice cream cone customers are asking the clerks, they're grabbing a clerk, a clerk is going over for the ice cream cone, clerk goes to the manager, and says, is that a good cone?
[451.76s -> 460.76s]  It's a good cone, alright, so we got a good cone, and give it back there, okay, and then, now there's some people milling around, but there's a little, oh, bad cone, we got a bad cone in there.
[460.76s -> 466.76s]  Okay, I thought it was a good cone, okay. So, you can see there might be a little bit of a bottleneck here.
[469.76s -> 475.76s]  Oh no, we got more bad cones. Okay, oh, bad cones. Is that a good cone?
[475.76s -> 477.76s]  That was a good cone, that's good.
[477.76s -> 483.76s]  Okay, so, alright, so then the, has the cashier had anything to do yet? No? Oh, one person, okay.
[483.76s -> 490.76s]  And so you have gotten all your cones, do you have just one cone? Just one cone, okay. Alright, and so you get to take a number, okay.
[490.76s -> 500.76s]  That's a good cone, alright. And, let's see, two, there's number two, okay, so one person is still waiting for the cones, and, have you done all six cones?
[500.76s -> 501.76s]  I've done all six cones.
[502.76s -> 509.76s]  Managed to go home for the day. Clerks, have you taken care of all your cones at this point? Yeah, you're going to all go home, you're great, good to go.
[509.76s -> 515.76s]  Now we have that, and you have now taken care, okay, the cashier is the last one to go home, sadly, but, but that's that.
[515.76s -> 521.76s]  Okay, and we're all done, and you got your cones. Okay, now, that was a bit of a melee up here, right?
[521.76s -> 530.76s]  No fights, I didn't see any real fights, but did you kind of see that this is the thing we're about to try to model, all of that madness in one program.
[530.76s -> 540.76s]  Okay, that's what we're trying to model here, and you have the program, and there's a lot to it, but, we'll go through it one little part at a time.
[540.76s -> 547.76s]  Okay, so, questions on what happened up here? Did anybody see anything that was odd, or didn't get, or whatever?
[547.76s -> 550.76s]  If you didn't quite figure out what was happening, that's okay. Yes?
[550.76s -> 562.76s]  I was confused, so, a customer asks one person, and then they all, like, because like technically only one or three get like a message, and then all of them went through.
[562.76s -> 563.76s]  I was confused on that piece.
[563.76s -> 570.76s]  Yeah, so, okay, okay, well, first, good question. The question was, look, I'm confused on like the mechanics of how this is going to work, like, programming-wise, like, are they all getting it?
[570.76s -> 580.76s]  So, it was all happening kind of in parallel. Each customer was able to ask for however many cones by telling a clerk, one clerk at a time, please make me a cone.
[580.76s -> 585.76s]  And that was what was happening. So, one customer went to a clerk and said, make me a cone.
[585.76s -> 590.76s]  And for some reason, we had a number of the clerks, one per cone, which is a weird model.
[590.76s -> 596.76s]  So, I will grant you that this model of an ice cream store is a little bit weird and probably wouldn't work in real life, and you could certainly make it better.
[596.76s -> 604.76s]  But, that's the model. One person who wants n number of cones goes to n number of clerks and says, make me one cone.
[604.76s -> 613.76s]  And then they go and ask the manager, and the manager is saying, good cone, bad cone, and the clerk has to keep making cones until they get a good cone.
[613.76s -> 617.76s]  Emma, you probably made three cones right before you got a good one, or whatever, right?
[617.76s -> 623.76s]  So, I saw Emma come back and forth a couple of times and scowl on her face with the number of cones she was making.
[624.76s -> 631.76s]  And then the cashier had to get the, now, notice that the clerks were kind of fighting with each other for the manager's attention.
[631.76s -> 638.76s]  Fine. The customers were not fighting for the cashier's attention, and you probably want it that way.
[638.76s -> 645.76s]  Like, in a real ice cream store, you'd rather have the customers go, when they get up to the line, go, oh, I'm next, and then they get handled next.
[645.76s -> 653.76s]  As far as the clerks and the manager go, well, they could kind of all mill around until one gets to decide.
[653.76s -> 656.76s]  Okay, do we see the kind of basic idea, though, of this?
[656.76s -> 666.76s]  Okay, now we're going to try to model it using threading techniques that we, hopefully, kind of understand now, but we will go through them.
[666.76s -> 672.76s]  Okay, we're actually going to go through five different types of things here with this program.
[672.76s -> 677.76s]  It is kind of a meaty program. I can't really imagine how it ended up as a one final exam problem. Maybe it was two.
[677.76s -> 681.76s]  But, anyway, that's the way it goes.
[681.76s -> 685.76s]  We're going to talk about a binary lock, which should be, at this point, hey, do a mutex.
[685.76s -> 686.76s]  This is going to be a binary lock.
[686.76s -> 688.76s]  We're going to do a generalized counter.
[688.76s -> 691.76s]  You should be thinking, maybe, semaphore. You should be thinking about that.
[691.76s -> 693.76s]  A binary rendezvous.
[693.76s -> 700.76s]  A binary rendezvous is when, basically, well, we'll get to it, but it's two threads trying to coordinate between each other.
[700.76s -> 712.76s]  Like, for instance, a clerk and a manager trying to make a decision, like, hey, the clerk has to wait for the manager to tell them whether the cone's good or not, and the manager has to wait for the clerk to come over, and so forth.
[712.76s -> 714.76s]  So that's going to be something we're going to do.
[714.76s -> 719.76s]  A generalized rendezvous is when you have multiple things at once happening.
[719.76s -> 727.76s]  This could be with, let's say, the people who are asking for the ice cream cones have to wait for all their cones to be made.
[727.76s -> 731.76s]  They're generalized, like, I'm waiting for a bunch of things to happen kind of before I can do anything.
[731.76s -> 739.76s]  And then layered construction is more or less, like, how do you do this one thing on top of the other?
[739.76s -> 740.76s]  We'll do that.
[740.76s -> 741.76s]  Okay?
[741.76s -> 742.76s]  And we'll see how that works.
[742.76s -> 744.76s]  You certainly can go download the code.
[744.76s -> 748.76s]  You have the multi-threading, all the code right in front of you.
[748.76s -> 752.76s]  So if you're looking at one piece and you want to go back and go, hey, wait, how did that work with the other part?
[752.76s -> 753.76s]  Feel free.
[753.76s -> 758.76s]  And I know you haven't had a chance to really look through this, but we will go through it one thing at a time.
[758.76s -> 759.76s]  Okay?
[759.76s -> 760.76s]  So, binary lock.
[760.76s -> 761.76s]  What's a binary lock?
[761.76s -> 762.76s]  It's a mutex, basically.
[762.76s -> 763.76s]  Okay?
[763.76s -> 771.76s]  And to remind you, a mutex does nothing else except allow two threads to try to get into some critical region.
[771.76s -> 773.76s]  And it doesn't even have to be the same critical region.
[773.76s -> 782.76s]  They just have to basically both be fighting over some resource, one of only one of which can access that resource at a given time.
[782.76s -> 786.76s]  Many times it's a global variable or some shared variable.
[786.76s -> 789.76s]  They both want to update and you want to do it what we call atomically.
[789.76s -> 790.76s]  Okay?
[790.76s -> 796.76s]  And then, so again, it's all about single thread access.
[796.76s -> 797.76s]  Okay.
[797.76s -> 800.76s]  The generalized counter, this is where we start talking about semaphores.
[800.76s -> 810.76s]  This is where the counter itself, the semaphore itself can do a, can increment a variable atomically.
[810.76s -> 817.76s]  In other words, no other, like only one thread can actually make it do its thing at once, do the incrementing or decrementing.
[817.76s -> 818.76s]  Okay?
[818.76s -> 823.76s]  We talked last time about the various things we can do with a semaphore.
[823.76s -> 833.76s]  If we have a semaphore that has a count of zero, like no permits, it's basically just used as a signaling thing back and forth.
[833.76s -> 834.76s]  Okay?
[834.76s -> 837.76s]  So one thread can signal another thread, which is waiting on that.
[837.76s -> 839.76s]  It's not like there's a permit here.
[839.76s -> 841.76s]  Just one thread goes on waiting around.
[841.76s -> 844.76s]  So we will see those used as we go as well.
[844.76s -> 845.76s]  Okay?
[845.76s -> 852.76s]  And this is where you're coordinating some limited resource that has some number of things in it.
[852.76s -> 861.76s]  Number of columns or one column or one sort of number of things that we're going to, that you might want to limit.
[861.76s -> 862.76s]  Okay?
[862.76s -> 863.76s]  Alright.
[863.76s -> 865.76s]  A binary rendezvous.
[865.76s -> 867.76s]  This is where, again, you use a semaphore.
[867.76s -> 870.76s]  And this is for inter-thread communication.
[870.76s -> 871.76s]  Okay?
[871.76s -> 874.76s]  And the example here is a pretty good one.
[874.76s -> 880.76s]  So suppose we had thread A that needs to know when thread B finishes something.
[880.76s -> 881.76s]  Okay?
[881.76s -> 894.76s]  So, for instance, when the manager has to determine whether or not the cone is good or not, the clerk has to wait around for that to happen and has to wait on that other thread to do their thing.
[894.76s -> 895.76s]  Okay?
[895.76s -> 902.76s]  What we can do is we can have this rendezvous semaphore initialized to zero because all we care about is the signaling part.
[902.76s -> 903.76s]  Okay?
[903.76s -> 909.76s]  And thread A actually waits on that semaphore.
[909.76s -> 910.76s]  Okay?
[910.76s -> 916.76s]  And after thread B finishes, it signals thread A, which continues.
[916.76s -> 917.76s]  Okay?
[917.76s -> 922.76s]  And thread B does not care about anything else that the other thread is doing at that point.
[922.76s -> 925.76s]  It just goes signals and then moves on.
[925.76s -> 926.76s]  Okay?
[926.76s -> 929.76s]  So that's how a binary semaphore works.
[929.76s -> 933.76s]  Or, rather, a binary rendezvous in this case.
[933.76s -> 934.76s]  Okay?
[934.76s -> 938.76s]  There's only one event that needs to happen and that's all we care about.
[938.76s -> 939.76s]  Okay?
[939.76s -> 945.76s]  This is sometimes used to wake up other threads, like a thread just waiting around, and then somebody wakes it up with this signal.
[945.76s -> 947.76s]  That's a good way of thinking about it.
[947.76s -> 951.76s]  You can do a bidirectional rendezvous.
[951.76s -> 953.76s]  This is different than a generalized one.
[953.76s -> 956.76s]  This is like basically one thread waits for the other, which waits for the other.
[956.76s -> 960.76s]  You have to be very careful that you do that so that they're not both waiting at the same time.
[960.76s -> 962.76s]  Because then you'll get deadlock.
[962.76s -> 964.76s]  So you have to be careful there.
[964.76s -> 965.76s]  Okay?
[965.76s -> 968.76s]  So there's some logic that you need to figure out there.
[968.76s -> 969.76s]  Okay?
[969.76s -> 970.76s]  Alright.
[970.76s -> 975.76s]  A generalized rendezvous is where you have a binary rendezvous and a generalized counter.
[975.76s -> 976.76s]  Okay?
[976.76s -> 984.76s]  This could be more or less the ice cream customers are waiting for the clerk to do something.
[984.76s -> 986.76s]  They're actually waiting for a bunch of clerks to do something.
[986.76s -> 989.76s]  And they have to sit around.
[989.76s -> 992.76s]  So in this case, thread A spawned five thread Bs.
[992.76s -> 997.76s]  Ah, that sounds like the ice cream customer asking five different clerks.
[997.76s -> 998.76s]  Okay?
[998.76s -> 1004.76s]  Thread A spawned five thread Bs and needs to wait for all of them to make a certain amount of progress before advancing.
[1004.76s -> 1007.76s]  That's when we would use this technique.
[1007.76s -> 1008.76s]  Okay?
[1008.76s -> 1012.76s]  Again, you have the semaphore initialized to zero.
[1012.76s -> 1019.76s]  When A needs to sync up with the other ones, it will block until they all finish.
[1019.76s -> 1020.76s]  Okay?
[1020.76s -> 1029.76s]  And then when they all finish, thread A will then be able to move forward after that.
[1029.76s -> 1030.76s]  Okay?
[1031.76s -> 1036.76s]  The generalized part of this is you have some task that you're dividing up.
[1036.76s -> 1038.76s]  You're saying I need to make three cones.
[1038.76s -> 1040.76s]  I'm dividing the three different clerks.
[1040.76s -> 1045.76s]  You need to generalize that and then wait for all those tasks to complete.
[1045.76s -> 1048.76s]  That's the generalized rendezvous.
[1048.76s -> 1049.76s]  Okay?
[1049.76s -> 1050.76s]  Alright.
[1050.76s -> 1056.76s]  And then this whole layered construction is basically using all this together to say,
[1056.76s -> 1062.76s]  oh, we've got a mutex, then we can have a semaphore that uses the mutex, and how do you kind of piece them together?
[1062.76s -> 1068.76s]  You've got some global counter that uses this, that's going to have mutex associated with it.
[1068.76s -> 1073.76s]  You've got to wait around as the counter changes value or reaches some value and so forth.
[1073.76s -> 1076.76s]  So that's the big takeaway for that one.
[1076.76s -> 1082.76s]  You need to be able to use these constructs together to suit whatever you're trying to do.
[1082.76s -> 1083.76s]  Okay?
[1083.76s -> 1084.76s]  Alright.
[1084.76s -> 1085.76s]  Alright.
[1085.76s -> 1088.76s]  Let us look at some of the actual code.
[1088.76s -> 1089.76s]  Okay.
[1089.76s -> 1090.76s]  We've already talked about this.
[1090.76s -> 1092.76s]  We modeled it pretty distinctly, okay?
[1092.76s -> 1098.76s]  Ice cream store, clerks, manager, customers, cashier, lots of clerks, one manager, one cashier.
[1098.76s -> 1103.76s]  Customers are in a hurry, so they get lots of clerks per one per ice cream cone.
[1103.76s -> 1107.76s]  And then once they get their cones back, they go to the cashier.
[1107.76s -> 1109.76s]  I mean, it's not a terrible model, all things considered.
[1109.76s -> 1112.76s]  And then each clerk just gets to make one cone.
[1112.76s -> 1115.76s]  Yeah, that's a little weird, but that's the way it works in this world.
[1115.76s -> 1119.76s]  And the manager has to determine whether or not the cone is legitimate or not.
[1119.76s -> 1120.76s]  Okay?
[1120.76s -> 1128.76s]  And the big issue there for the cashier is it has to be a first-in, first-out queue, otherwise it's chaos.
[1128.76s -> 1132.76s]  Because the customers go, I was here first, and why didn't you take care of me, and so forth.
[1132.76s -> 1134.76s]  And Vrinda would not have wanted to do that.
[1134.76s -> 1135.76s]  She could have helped him.
[1135.76s -> 1136.76s]  Okay?
[1136.76s -> 1140.76s]  And then we actually have to, at some point, determine when everybody goes home.
[1140.76s -> 1145.76s]  It's a little wonky, like the manager knows the manager has to make six cones by the end of the day.
[1145.76s -> 1146.76s]  That's a little weird.
[1146.76s -> 1150.76s]  So we could have done it some other way, but in this case we just say, right off the bat we'll do that.
[1150.76s -> 1154.76s]  You will see how the code ends up manifesting itself for that.
[1154.76s -> 1155.76s]  Okay?
[1155.76s -> 1156.76s]  All right.
[1156.76s -> 1159.76s]  Questions before we start looking at the code about the overall picture here?
[1159.76s -> 1163.76s]  You've seen it, now we're going to see some code, you kind of get the idea?
[1163.76s -> 1164.76s]  Okay, good.
[1164.76s -> 1165.76s]  All right.
[1165.76s -> 1168.76s]  So here's the various things we're going to look at.
[1168.76s -> 1169.76s]  Okay?
[1169.76s -> 1172.76s]  We're going to look at all these parts of the code, you have them in here.
[1172.76s -> 1179.76s]  I'll try to tell you which page these are on as we go through them, because they're not necessarily in the order on the code, in the code.
[1179.76s -> 1185.76s]  But the first thing we're going to look at is the random number generation, just to kind of see where it is.
[1185.76s -> 1189.76s]  This is actually on page four of nine in the handout.
[1189.76s -> 1190.76s]  Okay?
[1190.76s -> 1191.76s]  And I've got it right here as well.
[1191.76s -> 1194.76s]  Basically, we have lots of randomness going on here.
[1194.76s -> 1195.76s]  Why?
[1195.76s -> 1201.76s]  Because we want to make it look like it's some sort of actual time constraints, and it's not always the same time.
[1201.76s -> 1202.76s]  Okay?
[1202.76s -> 1203.76s]  We do this often with these sorts of things.
[1203.76s -> 1208.76s]  This makes debugging a little harder, because it is kind of random, but it will definitely test lots of different categories.
[1208.76s -> 1209.76s]  Okay?
[1209.76s -> 1210.76s]  Most of these are times.
[1210.76s -> 1217.76s]  We have get number of, actually a couple of them are get number of cones, like the customer comes in and says,
[1217.76s -> 1219.76s]  I want, you know, however many cones.
[1219.76s -> 1220.76s]  So that's not a time.
[1220.76s -> 1224.76s]  There's get browse time, which is the customer milling around.
[1224.76s -> 1227.76s]  There is, and that's part of it.
[1227.76s -> 1233.76s]  There's get prep time, that's how long it takes the clerks to make an ice cream cone that may or may not be good.
[1233.76s -> 1237.76s]  And then there's get inspection time, how long manager takes.
[1237.76s -> 1244.76s]  And then finally there's get inspection outcome, which is the binary yay or nay as far as the cone goes.
[1244.76s -> 1245.76s]  Okay?
[1245.76s -> 1249.76s]  Relatively straightforward, not anything that you need to particularly concern yourself about.
[1249.76s -> 1253.76s]  It's just using a library function we actually wrote to get these values out.
[1253.76s -> 1254.76s]  Not a good deal.
[1254.76s -> 1255.76s]  Okay.
[1255.76s -> 1256.76s]  Let's look at the structs here.
[1256.76s -> 1264.76s]  So this model is, if you're in 106B or 106A, you would probably cringe if you saw this.
[1264.76s -> 1266.76s]  That there's some global struct here.
[1266.76s -> 1267.76s]  All right?
[1267.76s -> 1268.76s]  Why?
[1268.76s -> 1270.76s]  Because we don't necessarily like global things.
[1270.76s -> 1274.76s]  But with threads, sometimes it just makes it easier to pass around a global variable,
[1274.76s -> 1281.76s]  or to have a global variable than to deal with having a struct that you're passing around.
[1281.76s -> 1282.76s]  Sure.
[1282.76s -> 1287.76s]  For encapsulation reasons, we probably would want to pass it around in a more robust program.
[1287.76s -> 1294.76s]  But for now, we are just making a struct called inspection, and it's got these fields in it.
[1294.76s -> 1295.76s]  Okay?
[1295.76s -> 1297.76s]  It's got a mutex for available.
[1297.76s -> 1306.76s]  This is the handshake basically between, it's the binary rendezvous between the clerk and the manager.
[1306.76s -> 1307.76s]  Okay?
[1307.76s -> 1313.76s]  So there's an available mutex, which is basically saying only one clerk can be dealing with
[1313.76s -> 1314.76s]  the manager at a time.
[1314.76s -> 1317.76s]  The manager can only look at one ice cream cone at a time.
[1317.76s -> 1318.76s]  That's the mutex.
[1318.76s -> 1319.76s]  Okay?
[1319.76s -> 1326.76s]  There is a semaphore for signaling, hey, manager, I've got an ice cream cone for you.
[1326.76s -> 1330.76s]  And there's a semaphore for saying, hey, clerk, here's your ice cream cone.
[1330.76s -> 1331.76s]  It's terrible.
[1331.76s -> 1332.76s]  Or it's great.
[1332.76s -> 1333.76s]  Right?
[1333.76s -> 1334.76s]  That's another one.
[1334.76s -> 1337.76s]  There's actually a boolean in here for whether or not it passed.
[1337.76s -> 1343.76s]  And then, by the way, out here, we create a struct called inspection, and then we immediately
[1343.76s -> 1346.76s]  declare it as a variable inspection.
[1346.76s -> 1349.76s]  Seems like it's overloading the name, but that's the way it goes.
[1349.76s -> 1350.76s]  So this is a global variable.
[1350.76s -> 1354.76s]  Again, we didn't have to do it globally, but just makes it a little easier.
[1354.76s -> 1359.76s]  Now, there are a couple interesting things about this.
[1360.76s -> 1368.76s]  If there's only one value about passed or not, right, how many things can be using this struct
[1368.76s -> 1371.76s]  at any one time?
[1371.76s -> 1372.76s]  One thing, right?
[1372.76s -> 1378.76s]  One manager or one clerk can be inspecting this or using it at one time.
[1378.76s -> 1379.76s]  There's only one manager, which is nice.
[1379.76s -> 1384.76s]  In fact, if we did do many managers, like let's say we had multiple managers or assistant
[1384.76s -> 1387.76s]  managers or whatever, then we would have to rethink this.
[1387.76s -> 1392.76s]  We'd have to have some other either array of these inspection structs or something else,
[1392.76s -> 1396.76s]  because the way it works right now, there's one value at one time which says whether
[1396.76s -> 1398.76s]  or not ice cream cone is good or not.
[1398.76s -> 1400.76s]  That's it.
[1400.76s -> 1401.76s]  Okay?
[1401.76s -> 1404.76s]  All right, so that's how the struct works.
[1404.76s -> 1407.76s]  What questions do you have about that struct at this point?
[1407.76s -> 1410.76s]  Maybe you don't.
[1410.76s -> 1412.76s]  We'll see it in action very soon.
[1412.76s -> 1413.76s]  Okay?
[1413.76s -> 1415.76s]  There's another struct, which is the checkout one.
[1415.76s -> 1418.76s]  So we're kind of jumping ahead to the checkout phase.
[1418.76s -> 1430.76s]  But the checkout has a semaphore for next in place in line, okay, which is a new kind
[1430.76s -> 1431.76s]  of integer here.
[1431.76s -> 1434.76s]  It's an atomic unsigned int.
[1434.76s -> 1440.76s]  What that means is that that variable can be updated by multiple threads at the same
[1440.76s -> 1446.76s]  time, and it will never do that weird double or not double counting.
[1446.76s -> 1451.76s]  It is atomic, such that it makes it so that the ++ works, no matter if 10 threads come
[1451.76s -> 1454.76s]  at it at once, it's what we call thread safe.
[1454.76s -> 1458.76s]  Ten threads can go update that, and you will always get 10 increments if 10 threads
[1458.76s -> 1460.76s]  update or not.
[1460.76s -> 1461.76s]  Yes?
[1461.76s -> 1464.76s]  Ah, good question.
[1464.76s -> 1469.76s]  The question was, hey, is there ever a time you don't want to use the atomic variable?
[1469.76s -> 1473.76s]  Most of the time we don't, because most of the time we're not using threads.
[1473.76s -> 1479.76s]  And the atomic operation is slower, because it's got to do some other things in there,
[1479.76s -> 1483.76s]  and it actually needs the hardware to support it, so it's a different instruction, and
[1483.76s -> 1486.76s]  there's other hardware support, which means it takes a little longer.
[1486.76s -> 1492.76s]  And if you know anything about C and C++, the bottom line is, let the user do things
[1492.76s -> 1497.76s]  as fast as necessary, but give them the tools to be able to do it correctly if that
[1497.76s -> 1498.76s]  has to be an issue.
[1498.76s -> 1501.76s]  So this is one of those ones where, only use an atomic one where you're going to
[1501.76s -> 1502.76s]  need it.
[1502.76s -> 1506.76s]  Otherwise, use the faster ones, because most of the time you don't.
[1506.76s -> 1507.76s]  Very good question.
[1507.76s -> 1508.76s]  Yes?
[1508.76s -> 1514.76s]  So is the other way we talked about updating a variable faster, or that way?
[1514.76s -> 1519.76s]  If you just had a regular unsigned int here, and you did ++, it's going to be
[1519.76s -> 1523.76s]  faster than ++-ing this one, because this one has some more...
[1523.76s -> 1527.76s]  Like, is there a reason you didn't have just, like, permits in general?
[1527.76s -> 1528.76s]  Oh, right, right.
[1528.76s -> 1529.76s]  Well, sure.
[1529.76s -> 1530.76s]  The last time we could have used a...
[1530.76s -> 1533.76s]  Maybe we could have done this with another semaphore.
[1533.76s -> 1535.76s]  We could have done some...
[1535.76s -> 1537.76s]  It would have been a little weird, but maybe you would have used a conditional
[1537.76s -> 1540.76s]  variable a or whatever, but in this case, we're going to see where it gets
[1540.76s -> 1543.76s]  incremented or documented, and then you'll go, oh, okay.
[1543.76s -> 1547.76s]  It makes sense that if we have this atomic thing, we might as well use it.
[1547.76s -> 1548.76s]  We'll get there.
[1548.76s -> 1552.76s]  Ask the question when we see it in action, when you see somebody doing something
[1552.76s -> 1554.76s]  in the next place in line.
[1554.76s -> 1555.76s]  Okay.
[1555.76s -> 1556.76s]  All right.
[1556.76s -> 1561.76s]  So that's the couple of the structs that we're going to have.
[1561.76s -> 1563.76s]  Again, global struct.
[1563.76s -> 1564.76s]  Okay.
[1564.76s -> 1565.76s]  And that's it.
[1565.76s -> 1568.76s]  Now, the other one, again, at this point, it's a global...
[1568.76s -> 1572.76s]  It may be that multiple types of...
[1572.76s -> 1576.76s]  Multiple threads are actually accessing at the same time.
[1576.76s -> 1580.76s]  It turns out it's okay, but the cache here is still going to take the
[1580.76s -> 1586.76s]  customers in order based on this array here when they end up in the array.
[1586.76s -> 1587.76s]  Okay.
[1587.76s -> 1590.76s]  And maybe you'll understand that once you...
[1590.76s -> 1595.76s]  If you can update this next place in line atomically, then you can use that
[1595.76s -> 1600.76s]  as the actual index into the array and make sure that each customer
[1600.76s -> 1603.76s]  gets their own spot in the array.
[1603.76s -> 1605.76s]  You'll see that happening as well.
[1605.76s -> 1606.76s]  Okay.
[1606.76s -> 1611.76s]  The waiting customer semaphore informs the cashier their customer is waiting.
[1611.76s -> 1614.76s]  So the cashier is going to go, start up, and then go,
[1614.76s -> 1616.76s]  I'm waiting for customers to finish.
[1616.76s -> 1617.76s]  And then just wait.
[1617.76s -> 1620.76s]  And then eventually a customer will signal the cashier,
[1620.76s -> 1621.76s]  hey, I'm ready to get checked out.
[1621.76s -> 1623.76s]  Let me check out.
[1623.76s -> 1624.76s]  Okay.
[1624.76s -> 1625.76s]  There are other ways of doing this.
[1625.76s -> 1627.76s]  This just happens to be one of them.
[1627.76s -> 1628.76s]  Okay.
[1628.76s -> 1629.76s]  All right.
[1629.76s -> 1632.76s]  Let's move on to the next thing.
[1632.76s -> 1633.76s]  All right.
[1633.76s -> 1635.76s]  Here's the first real major function here.
[1635.76s -> 1636.76s]  This is the customer function.
[1636.76s -> 1642.76s]  The customer function is page...
[1642.76s -> 1644.76s]  I think it's near the end, actually.
[1644.76s -> 1646.76s]  Yeah, page nine of nine.
[1646.76s -> 1648.76s]  Right near the end, right before main.
[1648.76s -> 1650.76s]  It's the customer one.
[1650.76s -> 1651.76s]  Okay.
[1651.76s -> 1652.76s]  All right.
[1652.76s -> 1654.76s]  So what does the customer have to do?
[1654.76s -> 1657.76s]  Well, the customer goes and figures out...
[1657.76s -> 1660.76s]  The customer already knows by the time they get here
[1660.76s -> 1661.76s]  how many cones they want.
[1661.76s -> 1662.76s]  We will do that.
[1662.76s -> 1664.76s]  We will initialize that in main, as it turns out.
[1664.76s -> 1670.76s]  And the customer will then create a vector of clerks.
[1670.76s -> 1671.76s]  Okay.
[1671.76s -> 1674.76s]  It could have created an array of clerks of the number it's going to do.
[1674.76s -> 1675.76s]  It doesn't matter.
[1675.76s -> 1676.76s]  In this case, we're just making a vector.
[1676.76s -> 1677.76s]  We're in C++.
[1677.76s -> 1678.76s]  We can do vectors.
[1678.76s -> 1679.76s]  Okay.
[1679.76s -> 1686.76s]  And then it is going to call thread on the clerk function
[1686.76s -> 1693.76s]  with its variable i, which is just the...
[1693.76s -> 1695.76s]  It's not really the ID in this case.
[1695.76s -> 1698.76s]  The ID will be passed in based on...
[1698.76s -> 1700.76s]  Because we've got two things going on here.
[1700.76s -> 1703.76s]  We've got the number of the cone, which is i,
[1703.76s -> 1706.76s]  and the ID of the customer as well.
[1706.76s -> 1707.76s]  Okay.
[1707.76s -> 1708.76s]  That's going to get passed into the clerk.
[1708.76s -> 1711.76s]  So the clerk needs to know who to go back to anyway.
[1711.76s -> 1714.76s]  And so the customer is going to ask a particular clerk,
[1714.76s -> 1716.76s]  say, hey, my ID is such and such.
[1716.76s -> 1717.76s]  I want...
[1717.76s -> 1718.76s]  I am...
[1718.76s -> 1719.76s]  This is cone whatever.
[1719.76s -> 1720.76s]  Okay.
[1720.76s -> 1721.76s]  All right.
[1721.76s -> 1725.76s]  And then the customer goes and browses,
[1725.76s -> 1727.76s]  which just is some time.
[1727.76s -> 1728.76s]  It takes up some time.
[1728.76s -> 1729.76s]  Okay.
[1729.76s -> 1732.76s]  And then the customer has to do what?
[1732.76s -> 1733.76s]  The customer has to wait.
[1733.76s -> 1735.76s]  Before the customer checks out,
[1735.76s -> 1739.76s]  all of the customer's cones need to be made.
[1739.76s -> 1741.76s]  Fair enough?
[1741.76s -> 1743.76s]  Which means that they're going to actually join
[1743.76s -> 1745.76s]  on all of their clerks,
[1745.76s -> 1746.76s]  and they're going to wait around
[1746.76s -> 1750.76s]  until the clerks are done making their cones.
[1750.76s -> 1751.76s]  Now, they might still be browsing
[1751.76s -> 1752.76s]  and all the clerks end,
[1752.76s -> 1754.76s]  but either way, that's going to...
[1754.76s -> 1758.76s]  By the time you get past this line on line 8 here,
[1758.76s -> 1760.76s]  you are going to...
[1760.76s -> 1763.76s]  The customer knows that all of the cones have been made.
[1763.76s -> 1764.76s]  Question?
[1764.76s -> 1765.76s]  Yeah.
[1765.76s -> 1767.76s]  So that join doesn't, like, fail?
[1767.76s -> 1770.76s]  It just blocks until the threads are done?
[1770.76s -> 1771.76s]  Yes.
[1771.76s -> 1772.76s]  Good question.
[1772.76s -> 1775.76s]  The join here simply blocks until the threads are done.
[1775.76s -> 1777.76s]  And that's the whole point of join.
[1777.76s -> 1778.76s]  And it cleans up the thread
[1778.76s -> 1780.76s]  because they're done as well.
[1780.76s -> 1781.76s]  Okay?
[1781.76s -> 1784.76s]  So at this point, we know, going forward,
[1784.76s -> 1785.76s]  the customer can check out
[1785.76s -> 1792.76s]  because all of the clerks have finished their cone making.
[1792.76s -> 1793.76s]  Okay?
[1793.76s -> 1794.76s]  Now, there's no, like,
[1794.76s -> 1795.76s]  hey, here's your cone business.
[1795.76s -> 1797.76s]  I mean, that would all have to happen to some other...
[1797.76s -> 1798.76s]  We didn't make that into this thing,
[1798.76s -> 1802.76s]  but you can assume that if we were really doing this
[1802.76s -> 1803.76s]  and there was something else here,
[1803.76s -> 1805.76s]  we would actually have a cone handover sort of thing.
[1805.76s -> 1807.76s]  But in this case, the clerks just know...
[1807.76s -> 1810.76s]  or the customer knows, I have my three cones now.
[1810.76s -> 1811.76s]  Maybe they're waiting at the cashier.
[1811.76s -> 1812.76s]  Who knows?
[1812.76s -> 1813.76s]  Right?
[1813.76s -> 1814.76s]  Okay?
[1814.76s -> 1815.76s]  All right.
[1815.76s -> 1826.76s]  Then the customer has to go and actually find the next place in line.
[1826.76s -> 1827.76s]  Now, take a look at this line.
[1827.76s -> 1829.76s]  This is where your question might come in.
[1829.76s -> 1833.76s]  Check out next place in line ++.
[1833.76s -> 1834.76s]  Okay?
[1834.76s -> 1839.76s]  This is going to assign whatever next place in line is to this customer
[1839.76s -> 1842.76s]  and then atomically increment that variable.
[1842.76s -> 1843.76s]  Okay?
[1843.76s -> 1846.76s]  What this means is that if two threads are coming in...
[1846.76s -> 1848.76s]  if two customers are coming in at the same time,
[1848.76s -> 1851.76s]  boom, one of them will get the next place in line.
[1851.76s -> 1855.76s]  The other one will get the following place in line, guaranteed.
[1855.76s -> 1856.76s]  Okay?
[1856.76s -> 1857.76s]  There is no race condition here
[1857.76s -> 1861.76s]  specifically because we used an atomic variable there.
[1861.76s -> 1864.76s]  Otherwise, we could have a mutex on there
[1864.76s -> 1866.76s]  and then lock it and then update the place in line
[1866.76s -> 1867.76s]  and then unlock it.
[1867.76s -> 1868.76s]  This makes it a little easier.
[1868.76s -> 1871.76s]  If we've got this atomic integer, we might as well use it.
[1871.76s -> 1875.76s]  This kind of negates the necessity of a lock in this case.
[1875.76s -> 1876.76s]  Yeah?
[1876.76s -> 1877.76s]  So then I'm guessing...
[1877.76s -> 1880.76s]  I guess my question is what are the cases when we would need a mutex?
[1880.76s -> 1881.76s]  Yeah, yeah, yeah.
[1881.76s -> 1882.76s]  Good question.
[1882.76s -> 1883.76s]  So what are the cases where you do need a mutex?
[1883.76s -> 1885.76s]  There aren't that many atomic operations.
[1885.76s -> 1887.76s]  Increment happens to be one where we can...
[1887.76s -> 1889.76s]  or an integer that gets incremented and decremented
[1889.76s -> 1892.76s]  happens to be one where we can change it atomically.
[1892.76s -> 1895.76s]  I think you could also add something to it or subtract and multiply, whatever.
[1895.76s -> 1896.76s]  Whatever you want.
[1896.76s -> 1898.76s]  You can do math on that one and it's going to do it atomically.
[1898.76s -> 1902.76s]  But if it was a map, well, there's no atomic map necessarily.
[1902.76s -> 1904.76s]  So you still have to lock and unlock.
[1904.76s -> 1905.76s]  It just makes it a little simpler.
[1905.76s -> 1908.76s]  But you certainly could do this with a lock and unlock if you wanted to.
[1908.76s -> 1909.76s]  Yes?
[1909.76s -> 1912.76s]  Is it something that we can know?
[1912.76s -> 1914.76s]  How is it doing that automatically?
[1914.76s -> 1916.76s]  Or is that just like...
[1916.76s -> 1918.76s]  Do you want to know how it's doing it atomically?
[1918.76s -> 1922.76s]  Yeah, so it's a bit beyond the scope of this class as far as what's happening.
[1922.76s -> 1926.76s]  But there are machine instructions which, when you call them,
[1926.76s -> 1928.76s]  will do this operation atomically.
[1928.76s -> 1931.76s]  And you just have to set it up such that this uses that.
[1931.76s -> 1933.76s]  Like uses that operation.
[1933.76s -> 1935.76s]  It may just be, honestly.
[1935.76s -> 1938.76s]  It may be that that class just puts a lock around it.
[1938.76s -> 1940.76s]  It might just be as easy as that.
[1940.76s -> 1941.76s]  I haven't looked it up.
[1941.76s -> 1946.76s]  But I think in other cases, there are machine instructions where you'll speed things along.
[1946.76s -> 1947.76s]  So that's why you might want to use this.
[1947.76s -> 1948.76s]  You?
[1958.76s -> 1963.76s]  Yeah, so the question was, hey, look, in processes we block and unblock if multiple processes can change one.
[1963.76s -> 1968.76s]  It's not really a global variable because it could be calling a signal handler
[1968.76s -> 1971.76s]  because member processes don't share memory.
[1972.76s -> 1974.76s]  But in this case, yes.
[1974.76s -> 1979.76s]  If you're using the atomic variable, you don't need the lock if that's all you're really doing to it
[1979.76s -> 1981.76s]  is updating the variable itself.
[1981.76s -> 1986.76s]  You don't need to worry about it because it will be done in such a way that you don't need to do the lock on it.
[1986.76s -> 1988.76s]  It's just another thing to show you.
[1988.76s -> 1991.76s]  You can use this if it's a case where you have something like this.
[1991.76s -> 1993.76s]  Don't overuse it because it is a little slower.
[1993.76s -> 1995.76s]  But use it when you can if you want to.
[1995.76s -> 1997.76s]  Or you can just lock. Nobody's going to take off points for that.
[1997.76s -> 2000.76s]  If you do both. Or do one or the other.
[2001.76s -> 2005.76s]  Okay, so then what happens after the customer gets in line?
[2005.76s -> 2015.76s]  Well, the customer tells the checkout, signals the checkout person to or the cashier to actually keep going.
[2015.76s -> 2017.76s]  So the checkout waiting customer signal.
[2017.76s -> 2021.76s]  So the cashier is going, I'm waiting around, waiting around and goes, oh, there's a signal.
[2021.76s -> 2025.76s]  Let's start processing this, the next customer.
[2025.76s -> 2031.76s]  And the checkout, the cashier will go and look up who the next customer is based on the same variable.
[2031.76s -> 2036.76s]  You'll see how that works as well when we get to the cashier.
[2036.76s -> 2042.76s]  And while the cashier is checking the customer out, the customer has to wait.
[2042.76s -> 2052.76s]  So the customer says, check our customer's place, wait, and remember this is a semaphore per each one of those.
[2053.76s -> 2060.76s]  It is what? It is a semaphore per customer in that case.
[2060.76s -> 2072.76s]  And let's see, the semaphore again, it's just a single zero value semaphore.
[2072.76s -> 2075.76s]  Just signaling. Doesn't need any like permits or anything like that.
[2075.76s -> 2077.76s]  Could you have done this with permits? Maybe.
[2077.76s -> 2087.76s]  Like with permits, the thing about permits though is that there's still a bit of a race condition there as far as who gets handled next with a permit.
[2087.76s -> 2092.76s]  Like there might be some permit thing. If you signal everybody, it won't go necessarily in line.
[2092.76s -> 2093.76s]  That's going to be an issue.
[2093.76s -> 2100.76s]  Okay, we need the customers based on our model to be handled in the order they arrived at the cashier.
[2100.76s -> 2101.76s]  That's the important part.
[2102.76s -> 2103.76s]  Alright.
[2106.76s -> 2113.76s]  Once the signal comes back from the cashier, the customer has checked out and leaves.
[2115.76s -> 2116.76s]  Question?
[2119.76s -> 2121.76s]  Okay, this wait right here.
[2122.76s -> 2125.76s]  You tell me what that's waiting. What did the customer just do?
[2125.76s -> 2128.76s]  The customer just signaled the cashier.
[2128.76s -> 2130.76s]  So what's the customer have to do?
[2131.76s -> 2135.76s]  Wait for the cashier to check them out. That's what's happening here.
[2135.76s -> 2137.76s]  Okay, so there's a double signal going on here.
[2137.76s -> 2141.76s]  They're signaling the cashier to say, hey, can you check me out?
[2141.76s -> 2144.76s]  And then waiting for the cashier to signal back.
[2144.76s -> 2149.76s]  Now, the cashier has to signal back in the proper order, right?
[2149.76s -> 2154.76s]  The cashier, because this signal, there is no waiting associated with a signal.
[2154.76s -> 2156.76s]  Like you signal and then you go on.
[2156.76s -> 2159.76s]  So it might be that all the customers are sitting here waiting.
[2159.76s -> 2165.76s]  The cashier needs to go to signal the correct next kind of customer.
[2165.76s -> 2167.76s]  We'll get to see how that works in a little bit.
[2168.76s -> 2169.76s]  Okay.
[2169.76s -> 2170.76s]  Question?
[2176.76s -> 2178.76s]  Cashier will signal in order. We'll see how that happens.
[2186.76s -> 2193.76s]  Could have their ice cream cones completed before or will they not have sent the signal to the cashier?
[2194.76s -> 2195.76s]  Right, so your second part.
[2195.76s -> 2202.76s]  So basically the question was, wait, could somebody in line not have their cones made before somebody further up in line?
[2203.76s -> 2208.76s]  Remember, the customer is just milling around until they get all their cones back, then they get in line.
[2209.76s -> 2213.76s]  This isn't a case where you go stand in line while everybody goes and gets the whatever.
[2213.76s -> 2216.76s]  You're one person standing, you only stand in line when you get your cones.
[2216.76s -> 2218.76s]  So that's the order you'll be taking.
[2219.76s -> 2225.76s]  And now, it could be, certainly, that two customers get their cones at the same time and then fight over who gets to be in place first.
[2226.76s -> 2231.76s]  That's fine, but whoever ends up in first place gets handled by the cashier first.
[2232.76s -> 2234.76s]  And we'll see how that happens in a minute or two.
[2235.76s -> 2236.76s]  Other questions on this one?
[2237.76s -> 2238.76s]  Yes?
[2238.76s -> 2242.76s]  I want to make clear, it just looks a little weird though.
[2243.76s -> 2250.76s]  So the whole checkout.customers place, that's because you literally have an array of semaphores?
[2251.76s -> 2255.76s]  One for each customer, or is it one semaphore that he can track up all the time?
[2256.76s -> 2257.76s]  No, let's take a look.
[2258.76s -> 2261.76s]  There is a customers array, which is a semaphore per customer.
[2262.76s -> 2264.76s]  So each customer gets their own semaphore, which they're waiting on.
[2264.76s -> 2267.76s]  How do they know where they are in line?
[2268.76s -> 2277.76s]  They do right here, they get their place in line by getting the next place in line variable, which is updated per customer that comes in,
[2278.76s -> 2280.76s]  and then incrementing it so the next customer gets the next place in line.
[2281.76s -> 2282.76s]  That's what we're doing right there.
[2285.76s -> 2290.76s]  Yep, the cashier is just going to go through a loop and go, you, you, you, you, and know which one to actually get next.
[2291.76s -> 2295.76s]  And the only way the cashier is going to know to get anybody is because the cashier could signal.
[2296.76s -> 2298.76s]  So that's the signaling part there.
[2300.76s -> 2303.76s]  Is this starting to gel a little bit? How this stuff works? Good.
[2304.76s -> 2306.76s]  If you're like, oh, I get it all and I'm bored, awesome.
[2307.76s -> 2308.76s]  I would love it if that was the case.
[2309.76s -> 2311.76s]  So great, if that's what's going through your head.
[2312.76s -> 2314.76s]  How does the customer browse? Pretty straightforward.
[2315.76s -> 2320.76s]  The customer just gets a browse time and then sleeps for that amount of browse time.
[2321.76s -> 2325.76s]  Alright, sleep for is the way threads sleep for a particular amount of time.
[2326.76s -> 2330.76s]  They call sleep for and then the amount of time in milliseconds.
[2331.76s -> 2336.76s]  And then they do that and then the customer just said, the customer just killed so many seconds.
[2339.76s -> 2340.76s]  Alright, that's that.
[2341.76s -> 2343.76s]  Alright, let's look at the clerk function.
[2344.76s -> 2350.76s]  Remember one, oh, by the way, what happened? We didn't, we kind of went right over this part.
[2351.76s -> 2354.76s]  Here is where the clerk threads get started.
[2355.76s -> 2356.76s]  This is back in the, in the customer function.
[2357.76s -> 2358.76s]  This is an interesting point.
[2359.76s -> 2370.76s]  We are going to see when we get to main that both the manager and the customers and the cashier are all created in main.
[2371.76s -> 2377.76s]  And then the cashier and the manager immediately go to sleep, basically, because they don't have anything to do yet.
[2378.76s -> 2379.76s]  But have their threads started?
[2380.76s -> 2385.76s]  Yes, their threads have started, which means that it's actually less time to wake them up.
[2386.76s -> 2389.76s]  This is going to actually follow directly into the next thing.
[2390.76s -> 2392.76s]  In fact, not this next assignment, which I'll have out by tonight at some point.
[2392.76s -> 2400.76s]  Or by the next assignment, you'll learn about these things called thread pools, which are ready, waiting threads to go do their thing.
[2401.76s -> 2403.76s]  Does that sound like any other assignment you've seen?
[2404.76s -> 2408.76s]  Farm, maybe? Right, farm was processes waiting to go.
[2409.76s -> 2411.76s]  They're already ready, they're what we call spun up, ready to go.
[2412.76s -> 2413.76s]  That's the same sort of thing.
[2414.76s -> 2419.76s]  We are spinning up the customers, the manager, and the cashier.
[2420.76s -> 2425.76s]  But we are not spinning up the clerks until the customer actually does that.
[2426.76s -> 2428.76s]  So it's kind of like the customer goes and hires a clerk.
[2429.76s -> 2431.76s]  You can think of it that way, which would be weird.
[2432.76s -> 2435.76s]  Now, we go into the clerk and we see what happens with the clerk.
[2436.76s -> 2441.76s]  The clerk needs to do what?
[2442.76s -> 2444.76s]  Make a cone that's perfect.
[2444.76s -> 2451.76s]  And if it's not perfect, then it needs to make another cone until the manager says you have made a perfect cone.
[2452.76s -> 2456.76s]  So there's a little while loop in here that says while not success.
[2457.76s -> 2458.76s]  This success is a local variable.
[2459.76s -> 2460.76s]  It does not need to be locked or anything.
[2461.76s -> 2463.76s]  It's for the clerk itself and that's the way it goes, which is kind of nice.
[2464.76s -> 2466.76s]  Every clerk has its own success variable.
[2467.76s -> 2471.76s]  No need to block on that or have any reason to lock on those.
[2471.76s -> 2475.76s]  What does the clerk do? The clerk makes a cone.
[2476.76s -> 2483.76s]  The clerk locks the available lock.
[2484.76s -> 2489.76s]  The available lock is whether or not the manager is available.
[2490.76s -> 2493.76s]  So the clerk says, I need to lock this manager lock.
[2494.76s -> 2497.76s]  What happens if a thread tries to lock and somebody else holds the lock?
[2498.76s -> 2499.76s]  Just flocks.
[2499.76s -> 2505.76s]  So all the clerks could come and this is where they're fighting over the manager.
[2506.76s -> 2514.76s]  One of the managers is looking at a cone and says the manager unlocks the other clerk that holds this lock,
[2515.76s -> 2517.76s]  unlocks it, and then the manager is a free for all.
[2518.76s -> 2520.76s]  All the other clerks try to grab that manager right there.
[2520.76s -> 2531.76s]  Then once the lock is gathered, then the clerk says,
[2532.76s -> 2537.76s]  I'm going to signal the manager, go please inspect my cone.
[2538.76s -> 2540.76s]  And then what does it do? It waits.
[2541.76s -> 2542.76s]  This looks exactly like what it did before.
[2543.76s -> 2546.76s]  First you signal, then you wait because you're telling the other thread,
[2547.76s -> 2549.76s]  do something and now I'm going to wait for you to finish it.
[2550.76s -> 2553.76s]  Question?
[2554.76s -> 2560.76s]  So the requested and finished parts of the inspection stress are both semaphores?
[2561.76s -> 2564.76s]  They are both semaphores with zero permits.
[2565.76s -> 2567.76s]  It's just a signaling semaphore in that case.
[2568.76s -> 2574.76s]  The requested is requesting the manager.
[2575.76s -> 2577.76s]  And by the way, what do you think the manager is doing at this point?
[2577.76s -> 2581.76s]  If the manager is waiting for the requested signal, it is waiting.
[2582.76s -> 2583.76s]  So that's what it's doing right there.
[2584.76s -> 2587.76s]  And then the manager has to then signal back to the thread,
[2588.76s -> 2590.76s]  Oh, now you can go again.
[2591.76s -> 2596.76s]  So there's only one requested and one finished.
[2597.76s -> 2604.76s]  What does that mean again about how many things can be dealing with this struct at one time?
[2605.76s -> 2610.76s]  Actually, it turns out there's two, the manager and the clerk,
[2611.76s -> 2614.76s]  but no other clerks because they're all going to be stuck on this lock
[2615.76s -> 2616.76s]  before they could go and change anything.
[2617.76s -> 2621.76s]  That's why there's only one need for a zero one there.
[2622.76s -> 2626.76s]  So there's always one waiting and one's doing something and I'm signaling back?
[2627.76s -> 2631.76s]  There could be always one waiting and then the manager signals.
[2631.76s -> 2633.76s]  Maybe, maybe not, depending on how much time these things take.
[2634.76s -> 2638.76s]  The manager could be sleeping, which means the manager is going to just wait until it gets a signal.
[2639.76s -> 2640.76s]  Or it could happen immediately.
[2641.76s -> 2642.76s]  Here's the nice thing about all of this.
[2643.76s -> 2647.76s]  The way we set this up, as long as things are progressing okay,
[2648.76s -> 2649.76s]  it's as efficient as it can be.
[2650.76s -> 2653.76s]  There may be some wait time, but that wait time is out of our control.
[2654.76s -> 2656.76s]  We're going to make it as efficient as possible so there's no extra wait time.
[2657.76s -> 2658.76s]  And there's certainly no busy waiting here.
[2658.76s -> 2660.76s]  We're not spinning, we're not doing any process.
[2661.76s -> 2663.76s]  We're just kind of going, look, I know I'm waiting for some other threat.
[2664.76s -> 2665.76s]  I'm just going to sleep until it happens. The instant it happens, I move on.
[2666.76s -> 2667.76s]  That's the way it goes.
[2668.76s -> 2671.76s]  Why do we need both requested and the traditional support?
[2672.76s -> 2674.76s]  Why couldn't we signal requested and then wait on requested?
[2675.76s -> 2680.76s]  Yeah, very good question. Why couldn't we signal on requested and wait on requested?
[2681.76s -> 2683.76s]  I was thinking about this. I think there's a race condition there.
[2683.76s -> 2689.76s]  If you signal and then try to wait, you might actually be the one getting your own signal.
[2690.76s -> 2692.76s]  If things happen in an order where you don't...
[2693.76s -> 2698.76s]  It could happen in an order where you send a signal, go to sleep and wait,
[2699.76s -> 2700.76s]  and then by the time that signal propagates through the operating system,
[2701.76s -> 2704.76s]  it comes back to you instead of the other thing waiting.
[2705.76s -> 2710.76s]  And not only that, the semaphore would drop down again,
[2711.76s -> 2712.76s]  and then it would take two signals actually.
[2713.76s -> 2718.76s]  It would be an even better one. It would take two signals to actually make one of them go,
[2719.76s -> 2721.76s]  unless it happened to be exactly ordered.
[2722.76s -> 2724.76s]  So you want to just avoid that kind of ordering nightmare.
[2725.76s -> 2729.76s]  In this case, just use two because you know that one threat is going to wait on the request
[2730.76s -> 2731.76s]  and the other is going to wait on finished and you're okay.
[2732.76s -> 2736.76s]  You can try it. In fact, go try to build it with one and see if you can get it to do a deadlock or not.
[2737.76s -> 2738.76s]  But I imagine you might be able to.
[2739.76s -> 2740.76s]  Good questions.
[2741.76s -> 2744.76s]  All right. Anything else on the clerk? What the clerk's doing?
[2745.76s -> 2747.76s]  Oh, by the way, the clerk does what here?
[2748.76s -> 2750.76s]  The clerk says, waits for the manager to come back,
[2751.76s -> 2754.76s]  and then the clerk checks success and says,
[2755.76s -> 2757.76s]  oh, either it passed or not, right?
[2758.76s -> 2761.76s]  And if it didn't pass, well, first of all, it unlocks.
[2762.76s -> 2765.76s]  And if it didn't pass, well, it makes another cone, right?
[2766.76s -> 2767.76s]  Otherwise it would leave if it didn't do that.
[2767.76s -> 2771.76s]  And so it may stay in this loop as long as it keeps making bad cones.
[2772.76s -> 2773.76s]  It's just going to stay in that loop.
[2774.76s -> 2776.76s]  Really understand what's going on there?
[2778.76s -> 2780.76s]  All right, good. All right.
[2782.76s -> 2784.76s]  All right, the make a cone, pretty straightforward.
[2785.76s -> 2786.76s]  It's just going to wait again.
[2787.76s -> 2789.76s]  It's going to say, I'm about to make a cone and it's going to get some time
[2790.76s -> 2794.76s]  and then sleep for that amount of time and then tell how much time it was.
[2795.76s -> 2796.76s]  I'm going to run this program at the end.
[2797.76s -> 2798.76s]  And it's like, oh, my gosh, what's going on?
[2799.76s -> 2800.76s]  But you'll see when it happens.
[2801.76s -> 2803.76s]  Okay. All right.
[2804.76s -> 2805.76s]  Let's look at the manager function.
[2806.76s -> 2809.76s]  So the manager, remember, the manager starts out knowing
[2810.76s -> 2811.76s]  how many cones it's going to make that day.
[2812.76s -> 2813.76s]  It's a little weird.
[2814.76s -> 2816.76s]  We could have done something else where there's a Boolean flag
[2817.76s -> 2818.76s]  that says all cones, like all customers have been handled,
[2819.76s -> 2821.76s]  signal to Boolean, you know, or not even signal,
[2822.76s -> 2823.76s]  just you could have another signal if you wanted to.
[2824.76s -> 2826.76s]  Or you could just say, yeah, signal would probably work pretty well.
[2827.76s -> 2830.76s]  Have another semaphore for being done for the manager.
[2831.76s -> 2832.76s]  It says go home. You're done.
[2833.76s -> 2838.76s]  And maybe you could link it together with one for the cashier as well
[2839.76s -> 2840.76s]  or something like that.
[2841.76s -> 2842.76s]  Although the manager can actually go home,
[2843.76s -> 2844.76s]  although not the best business practice, before the cashier does.
[2845.76s -> 2848.76s]  Because the cashier might still be taking care of all the other customers.
[2849.76s -> 2850.76s]  But that's what it does.
[2851.76s -> 2852.76s]  So it knows how many cones it needs to make.
[2853.76s -> 2854.76s]  The manager knows how many cones they need to make.
[2854.76s -> 2857.76s]  And then they are going to attempt a bunch.
[2858.76s -> 2859.76s]  We're just doing this to log it, as it turns out.
[2860.76s -> 2863.76s]  And then they're going to approve a bunch of cones as well.
[2864.76s -> 2866.76s]  Until they approve the total number of cones they need to,
[2867.76s -> 2868.76s]  they can't leave.
[2869.76s -> 2870.76s]  They are going to, first things first,
[2871.76s -> 2873.76s]  well, find out if they can leave, which they can't immediately.
[2874.76s -> 2875.76s]  And then they're going to wait on requested.
[2876.76s -> 2877.76s]  Because they're waiting for a clerk to come
[2878.76s -> 2879.76s]  and hand them an ice cream cone and say please investigate there.
[2880.76s -> 2881.76s]  Please inspect this.
[2882.76s -> 2883.76s]  Then they inspect the cone.
[2884.76s -> 2885.76s]  And it's going to be some time.
[2886.76s -> 2887.76s]  And it's going to be some time.
[2888.76s -> 2890.76s]  And it's going to actually update the struct
[2891.76s -> 2892.76s]  to say whether or not the cone passed.
[2893.76s -> 2895.76s]  And then after it inspects it,
[2896.76s -> 2899.76s]  it's going to send a signal back to the waiting clerk
[2900.76s -> 2901.76s]  to say go check your cone.
[2902.76s -> 2903.76s]  I just inspected it.
[2904.76s -> 2908.76s]  And then it does the num cones attempted plus plus.
[2910.76s -> 2912.76s]  And if inspection passed,
[2912.76s -> 2914.76s]  it's going to say the number of crew.
[2915.76s -> 2921.76s]  Now, can this is going to happen at the same time
[2922.76s -> 2925.76s]  as possibly the clerk is looking at inspection pass?
[2926.76s -> 2927.76s]  Is that okay if they both look at the same variable
[2928.76s -> 2929.76s]  at the same time?
[2930.76s -> 2931.76s]  That's actually okay.
[2932.76s -> 2934.76s]  As long as no thread is able to update
[2935.76s -> 2936.76s]  while the other thread is looking at it,
[2937.76s -> 2939.76s]  many threads can look at that one variable at the same time
[2940.76s -> 2941.76s]  because it's not going to change.
[2942.76s -> 2943.76s]  So that's perfectly fine.
[2944.76s -> 2945.76s]  They might do it in some weird order
[2946.76s -> 2947.76s]  in with the assembly language, but it doesn't matter.
[2948.76s -> 2949.76s]  It doesn't matter.
[2950.76s -> 2951.76s]  All right.
[2952.76s -> 2955.76s]  So what's the manager do after they inspect a cone?
[2956.76s -> 2958.76s]  They update number of cones approved, possibly.
[2959.76s -> 2960.76s]  And then they go back in the while loop.
[2961.76s -> 2963.76s]  If they have reached the number of cones they need,
[2964.76s -> 2965.76s]  exit the while loop, go home for the day.
[2966.76s -> 2967.76s]  That's that.
[2968.76s -> 2969.76s]  Question?
[2970.76s -> 2971.76s]  Say again?
[2974.76s -> 2975.76s]  Oh, such a good question.
[2976.76s -> 2977.76s]  Okay, yes.
[2978.76s -> 2979.76s]  So he's saying, look, the lock happening here,
[2980.76s -> 2981.76s]  is this the one here?
[2982.76s -> 2983.76s]  Yeah.
[2984.76s -> 2985.76s]  So the lock happening right here.
[2986.76s -> 2987.76s]  Okay.
[2988.76s -> 2989.76s]  You just have to remember that a lock
[2990.76s -> 2991.76s]  has nothing to do with the lock.
[2992.76s -> 2993.76s]  It has nothing to do with the lock.
[2994.76s -> 2995.76s]  It has nothing to do with the lock.
[2996.76s -> 2997.76s]  Okay.
[2997.76s -> 2998.76s]  You've got to remember that a lock has no care
[2999.76s -> 3000.76s]  about what data structures there are.
[3001.76s -> 3002.76s]  It doesn't know, it's not saying
[3003.76s -> 3004.76s]  you can't touch this data structure.
[3005.76s -> 3006.76s]  It's saying anyone else who tries to get this lock
[3007.76s -> 3008.76s]  is going to be denied.
[3009.76s -> 3010.76s]  Right?
[3011.76s -> 3012.76s]  That's all it's doing.
[3013.76s -> 3014.76s]  It's not like packaging up a data structure
[3015.76s -> 3016.76s]  and saying, nope, nobody else can touch it.
[3017.76s -> 3018.76s]  It's just saying, hey, if you're going to try
[3019.76s -> 3020.76s]  to get my lock, you're not going to be able to.
[3021.76s -> 3022.76s]  So it's very abstract in that case.
[3023.76s -> 3024.76s]  Right?
[3025.76s -> 3026.76s]  It's just saying nobody goes past this line
[3027.76s -> 3028.76s]  of the story there.
[3029.76s -> 3030.76s]  Okay?
[3031.76s -> 3032.76s]  All right.
[3033.76s -> 3034.76s]  Good question.
[3035.76s -> 3036.76s]  Does that answer it for you there?
[3037.76s -> 3038.76s]  It doesn't affect the actual,
[3039.76s -> 3040.76s]  so the manager can go and do whatever it wants
[3041.76s -> 3042.76s]  with that data structure at that point
[3043.76s -> 3044.76s]  because it doesn't need to lock.
[3045.76s -> 3046.76s]  Now, if two threads were trying to update
[3047.76s -> 3048.76s]  that data structure, then you would need a lock
[3049.76s -> 3050.76s]  and then only one would be able to do it
[3051.76s -> 3052.76s]  based on your logic around locking.
[3052.76s -> 3054.76s]  So if I don't call lock and the manager
[3055.76s -> 3056.76s]  tries to modify it, am I going to get a zero?
[3057.76s -> 3058.76s]  No.
[3059.76s -> 3060.76s]  Very good question.
[3061.76s -> 3062.76s]  If the manager tried to update something here,
[3063.76s -> 3064.76s]  in fact it does, it actually updates the,
[3065.76s -> 3066.76s]  it actually updates the,
[3067.76s -> 3069.76s]  in Inspect-A-Comb, we'll see that in a minute,
[3070.76s -> 3072.76s]  it updates the Boolean about whether or not
[3073.76s -> 3074.76s]  it passed or not.
[3075.76s -> 3076.76s]  Perfectly able to do that.
[3077.76s -> 3078.76s]  The clerk is not going to look at that
[3078.76s -> 3079.76s]  until after it gets its signal,
[3080.76s -> 3081.76s]  which in that case it will be fine.
[3082.76s -> 3083.76s]  Everything will be updated and it will be fine.
[3084.76s -> 3085.76s]  Good.
[3086.76s -> 3087.76s]  All right.
[3088.76s -> 3089.76s]  Other questions on this?
[3090.76s -> 3091.76s]  Sounds like you guys are starting to get this.
[3092.76s -> 3093.76s]  This is great.
[3094.76s -> 3095.76s]  Okay.
[3096.76s -> 3097.76s]  All right.
[3098.76s -> 3099.76s]  Let's now, let's see.
[3100.76s -> 3101.76s]  Why can there only be one waiting clerk?
[3102.76s -> 3103.76s]  Because of that lock.
[3104.76s -> 3105.76s]  That's the whole point of this,
[3106.76s -> 3107.76s]  that lock before.
[3108.76s -> 3109.76s]  All the clerks will get there and go,
[3110.76s -> 3111.76s]  ah, I can't do anything yet.
[3112.76s -> 3113.76s]  Okay.
[3114.76s -> 3115.76s]  So let's look at the,
[3116.76s -> 3117.76s]  this is the Inspect-A-Comb.
[3118.76s -> 3119.76s]  This is not too interesting,
[3120.76s -> 3121.76s]  except so it basically sleeps for a while
[3122.76s -> 3123.76s]  while it's inspecting the cone
[3124.76s -> 3125.76s]  and then updating inspection passed
[3126.76s -> 3127.76s]  based on whatever the random number
[3128.76s -> 3130.76s]  that comes back from get inspection outcome is.
[3131.76s -> 3133.76s]  And then it reports on whether it's approved or not
[3134.76s -> 3135.76s]  and then ends.
[3136.76s -> 3137.76s]  That's all the Inspect-A-Comb does.
[3138.76s -> 3141.76s]  It does update the inspection passed struct
[3142.76s -> 3143.76s]  but that's perfectly fine
[3144.76s -> 3145.76s]  because we know logically
[3146.76s -> 3147.76s]  that no other threat is even looking at that right now.
[3148.76s -> 3149.76s]  Okay.
[3150.76s -> 3151.76s]  What it can't do, by the way,
[3152.76s -> 3153.76s]  is you can't go to the customer,
[3154.76s -> 3155.76s]  like the customer can't,
[3156.76s -> 3157.76s]  what if the clerk went and said,
[3158.76s -> 3159.76s]  oh, I didn't get this to pass.
[3160.76s -> 3161.76s]  I'm going to give it back to the customer anyway
[3162.76s -> 3163.76s]  even though it's not a good inspection.
[3164.76s -> 3165.76s]  It's not like the customer can go check this
[3166.76s -> 3167.76s]  because the customer should not have access to this
[3168.76s -> 3169.76s]  I might be stretching the analogy a bit
[3170.76s -> 3172.76s]  but that's the way that you wouldn't want the customer
[3173.76s -> 3174.76s]  to have access to this
[3175.76s -> 3176.76s]  because this number is going to change
[3177.76s -> 3178.76s]  for every inspection passed
[3179.76s -> 3180.76s]  is going to change for every cone that comes through
[3181.76s -> 3182.76s]  and it's only one value
[3183.76s -> 3184.76s]  and it's not like it's stored anywhere
[3185.76s -> 3189.76s]  except while the clerk and the manager care.
[3190.76s -> 3191.76s]  Then it's updated again
[3192.76s -> 3193.76s]  for the next one that comes through.
[3194.76s -> 3195.76s]  Single struct in this case.
[3196.76s -> 3197.76s]  Okay.
[3198.76s -> 3199.76s]  That's updated here
[3200.76s -> 3201.76s]  because we've already locked what we need to.
[3202.76s -> 3204.76s]  We logically know the only update
[3205.76s -> 3206.76s]  is going to happen from right here
[3207.76s -> 3210.76s]  and the clerk is not reading this value at all right now.
[3211.76s -> 3212.76s]  We know that based on our logic
[3213.76s -> 3214.76s]  and that's sometimes the hardest thing
[3215.76s -> 3217.76s]  to remember to figure out.
[3218.76s -> 3219.76s]  Other questions on this one?
[3220.76s -> 3221.76s]  Okay.
[3222.76s -> 3223.76s]  All right.
[3224.76s -> 3225.76s]  Now we're finally to the cashier.
[3226.76s -> 3227.76s]  Okay.
[3228.76s -> 3229.76s]  Let's see how many customers there will be during the day.
[3230.76s -> 3231.76s]  A little weird in that sense.
[3232.76s -> 3233.76s]  We could have again done something
[3234.76s -> 3235.76s]  where we had a queue that kept
[3236.76s -> 3237.76s]  or this vector queue, probably a queue
[3238.76s -> 3242.76s]  that eventually the cashier would get a signal
[3243.76s -> 3244.76s]  that says there's no more people
[3245.76s -> 3246.76s]  that are going to enter the queue
[3247.76s -> 3248.76s]  and then when the queue is empty
[3249.76s -> 3250.76s]  the cashier can go home.
[3251.76s -> 3252.76s]  We didn't do it quite this way.
[3253.76s -> 3254.76s]  Remember it's a final exam problem.
[3255.76s -> 3256.76s]  It's not like this was an assignment problem
[3256.76s -> 3257.76s]  but it starts to get interesting for the cashier.
[3258.76s -> 3260.76s]  Okay, the cashier does go in order.
[3261.76s -> 3262.76s]  Right?
[3263.76s -> 3264.76s]  The cashier goes from zero to the number of customers.
[3265.76s -> 3266.76s]  Okay?
[3267.76s -> 3268.76s]  And the first thing the cashier does
[3269.76s -> 3273.76s]  is wait on the waiting customers set it for.
[3274.76s -> 3275.76s]  In other words, if nobody's there yet
[3276.76s -> 3277.76s]  don't do anything but just sit there and wait.
[3278.76s -> 3279.76s]  Okay?
[3280.76s -> 3281.76s]  Wait for that thing.
[3282.76s -> 3283.76s]  Could you have maybe done it
[3284.76s -> 3285.76s]  where they wait on the first one
[3286.76s -> 3287.76s]  and a signal comes in?
[3288.76s -> 3289.76s]  Maybe.
[3290.76s -> 3291.76s]  That might have been another way of doing it
[3292.76s -> 3293.76s]  but in this case we just had that sum of four
[3294.76s -> 3295.76s]  and it says waiting on the first one.
[3296.76s -> 3297.76s]  Then what does it do?
[3298.76s -> 3299.76s]  It rings up the customer i
[3300.76s -> 3301.76s]  because when it gets that first signal
[3302.76s -> 3303.76s]  it knows that signal had to have
[3304.76s -> 3305.76s]  the first one anyway has to come
[3306.76s -> 3307.76s]  from that first customer.
[3308.76s -> 3309.76s]  Okay?
[3310.76s -> 3311.76s]  And so it rings up the customer
[3312.76s -> 3313.76s]  and then what does it do?
[3314.76s -> 3315.76s]  Well it knows that that was the customer
[3316.76s -> 3317.76s]  through that customer's semaphore
[3318.76s -> 3319.76s]  to say you're done.
[3320.76s -> 3321.76s]  I've checked you out.
[3322.76s -> 3323.76s]  Go eat your ice cream.
[3324.76s -> 3325.76s]  Okay?
[3326.76s -> 3327.76s]  And then it goes and does the next one.
[3328.76s -> 3329.76s]  Now what could happen in the meantime?
[3330.76s -> 3331.76s]  If another customer has come in
[3332.76s -> 3333.76s]  and is waiting in the queue
[3334.76s -> 3335.76s]  well this wait right here
[3336.76s -> 3337.76s]  this wait right here
[3338.76s -> 3339.76s]  will blast right through.
[3340.76s -> 3341.76s]  It'll blast right through that
[3342.76s -> 3343.76s]  because another customer has already signaled
[3344.76s -> 3345.76s]  and this is a difference between semaphores
[3346.76s -> 3347.76s]  and signaling in processes.
[3348.76s -> 3349.76s]  The signal remember does what?
[3350.76s -> 3351.76s]  It's on a semaphore.
[3352.76s -> 3353.76s]  It just decrements or increments a counter.
[3354.76s -> 3355.76s]  So there's some counter there
[3356.76s -> 3357.76s]  that has been in case of the signaling
[3358.76s -> 3359.76s]  has incremented that counter
[3360.76s -> 3361.76s]  and so by the time this wait happens
[3362.76s -> 3363.76s]  if another customer is already there
[3364.76s -> 3365.76s]  right through and handle
[3366.76s -> 3367.76s]  the next customer immediately.
[3368.76s -> 3369.76s]  That's an important part right there.
[3370.76s -> 3371.76s]  Okay?
[3372.76s -> 3373.76s]  And then it signals that customer
[3374.76s -> 3375.76s]  goes to the next customer
[3376.76s -> 3377.76s]  and that wait if the customer's not ready yet.
[3378.76s -> 3379.76s]  If the customer is ready
[3380.76s -> 3381.76s]  then it will just go
[3382.76s -> 3383.76s]  this will go right up and ring up
[3384.76s -> 3385.76s]  the next customer.
[3386.76s -> 3387.76s]  But it's doing it in order
[3388.76s -> 3389.76s]  and that's the important part here
[3390.76s -> 3391.76s]  because this is kind of a queued up
[3392.76s -> 3393.76s]  sort of system.
[3394.76s -> 3395.76s]  Once all it goes through
[3396.76s -> 3397.76s]  all the customers it needs to
[3398.76s -> 3399.76s]  goes home.
[3400.76s -> 3401.76s]  Okay?
[3402.76s -> 3403.76s]  Question?
[3404.76s -> 3405.76s]  Yeah, good question.
[3406.76s -> 3407.76s]  How is it that it's doing it
[3408.76s -> 3409.76s]  in order of the customer?
[3410.76s -> 3411.76s]  It's not when they arrive.
[3412.76s -> 3413.76s]  It's when they arrive to check out.
[3414.76s -> 3415.76s]  In other words the customer
[3416.76s -> 3417.76s]  has gotten her ice cream cones
[3418.76s -> 3419.76s]  and then she goes up to the cashier
[3420.76s -> 3421.76s]  or goes up to the line
[3422.76s -> 3423.76s]  which may have other customers in it
[3424.76s -> 3425.76s]  and stands there.
[3426.76s -> 3427.76s]  At that point let's go back quickly
[3428.76s -> 3429.76s]  and look at what the customer
[3430.76s -> 3431.76s]  what the let's see
[3432.76s -> 3433.76s]  this is what the customer was doing.
[3434.76s -> 3435.76s]  Here's where the customer is doing this.
[3436.76s -> 3437.76s]  It's checking the next place in line
[3438.76s -> 3439.76s]  by checking the next place in line
[3440.76s -> 3441.76s]  variable
[3442.76s -> 3443.76s]  and then that's the line
[3444.76s -> 3445.76s]  that's the signal it will end up
[3446.76s -> 3447.76s]  waiting for.
[3448.76s -> 3449.76s]  Remember here's where it does it.
[3450.76s -> 3451.76s]  It waits in its place in line.
[3452.76s -> 3453.76s]  And so the only way you can get in line
[3454.76s -> 3455.76s]  is to go and get the next place in line
[3456.76s -> 3457.76s]  and then update the counter
[3458.76s -> 3459.76s]  so the next person in line
[3460.76s -> 3461.76s]  gets the next place.
[3462.76s -> 3463.76s]  It's kind of like taking that little bar
[3464.76s -> 3465.76s]  at the supermarket and moving it
[3466.76s -> 3467.76s]  behind that and that's what you're doing.
[3468.76s -> 3469.76s]  You're like oh here's my place
[3470.76s -> 3471.76s]  and then I'm going to put the bar
[3472.76s -> 3473.76s]  behind the next one.
[3474.76s -> 3475.76s]  That's kind of what's going on
[3476.76s -> 3477.76s]  with that update right here.
[3478.76s -> 3479.76s]  Other questions on that?
[3480.76s -> 3481.76s]  Good.
[3482.76s -> 3483.76s]  Let's go back and look at
[3484.76s -> 3485.76s]  let's see we did the manager,
[3486.76s -> 3487.76s]  spec con, cashier, okay.
[3488.76s -> 3489.76s]  So the cashier, yeah, the cashier
[3490.76s -> 3491.76s]  is done when they've checked
[3492.76s -> 3493.76s]  every out in order.
[3494.76s -> 3495.76s]  Yeah.
[3496.76s -> 3497.76s]  Okay, you got it.
[3498.76s -> 3499.76s]  What was it?
[3500.76s -> 3501.76s]  Is it something interesting?
[3502.76s -> 3503.76s]  How does it know to wait in order?
[3504.76s -> 3505.76s]  Yeah, the customer gets the ordering.
[3506.76s -> 3507.76s]  Because we're updating the customer's
[3508.76s -> 3509.76s]  array with their order
[3510.76s -> 3511.76s]  and then we're just looping through
[3512.76s -> 3513.76s]  that array in signal.
[3514.76s -> 3515.76s]  Yeah, so this is an interesting
[3516.76s -> 3517.76s]  way of doing this.
[3518.76s -> 3519.76s]  This function has no real idea
[3520.76s -> 3521.76s]  which customer is where
[3522.76s -> 3523.76s]  except for the fact that it's
[3524.76s -> 3525.76s]  going through this loop
[3526.76s -> 3527.76s]  and the only reason it gets through
[3528.76s -> 3529.76s]  the loop is because it first
[3530.76s -> 3531.76s]  has to wait for that semaphore
[3532.76s -> 3533.76s]  for the waiting semaphore
[3534.76s -> 3535.76s]  which is are there any customers
[3536.76s -> 3537.76s]  is really what it is.
[3538.76s -> 3539.76s]  And then as a customer comes through
[3540.76s -> 3541.76s]  the customer, when that signal
[3542.76s -> 3543.76s]  happens that gets decremented again
[3544.76s -> 3545.76s]  but if another customer comes in
[3546.76s -> 3547.76s]  it gets incremented.
[3548.76s -> 3549.76s]  And so if two customers come in
[3550.76s -> 3551.76s]  it will be high enough that
[3552.76s -> 3553.76s]  you know there's two people in line
[3554.76s -> 3555.76s]  and then that will go right through.
[3556.76s -> 3557.76s]  Which one is it actually signaling?
[3558.76s -> 3559.76s]  It's signaling zero, one, and then two
[3560.76s -> 3561.76s]  based on that.
[3562.76s -> 3563.76s]  And remember this program
[3564.76s -> 3565.76s]  there is actually very little
[3566.76s -> 3567.76s]  actual communication between the threads.
[3568.76s -> 3569.76s]  I mean it's really only
[3570.76s -> 3574.76s]  the customer is just waiting for the signal
[3575.76s -> 3576.76s]  and then that signal comes out of nowhere
[3577.76s -> 3578.76s]  and it moves on.
[3579.76s -> 3580.76s]  It doesn't know what place
[3581.76s -> 3582.76s]  it knows what place in line it is
[3583.76s -> 3584.76s]  but it doesn't really care at that point.
[3584.76s -> 3585.76s]  It just gets a signal and goes
[3586.76s -> 3587.76s]  I'm done, I can leave the store.
[3588.76s -> 3590.76s]  So yeah, good question on that.
[3591.76s -> 3592.76s]  Okay, could we have handled
[3593.76s -> 3594.76s]  the customer and cashier
[3595.76s -> 3596.76s]  if we handled the clerk's manager
[3597.76s -> 3598.76s]  without the array?
[3599.76s -> 3600.76s]  Not really, right?
[3601.76s -> 3602.76s]  The problem is that we needed
[3603.76s -> 3604.76s]  to do this in order
[3605.76s -> 3606.76s]  so we need to have enough semaphores
[3607.76s -> 3608.76s]  for each one to wait in their place.
[3609.76s -> 3610.76s]  Otherwise if there was one semaphore
[3611.76s -> 3612.76s]  there would be fighting going on
[3612.76s -> 3613.76s]  and then that signal came through
[3614.76s -> 3616.76s]  and the person who came in last in line
[3617.76s -> 3618.76s]  could all of a sudden be jumping up in front
[3619.76s -> 3620.76s]  and that wouldn't be so good.
[3621.76s -> 3622.76s]  We wouldn't like that at all.
[3623.76s -> 3624.76s]  Kind of like that one where
[3625.76s -> 3626.76s]  a line at his grocery store ends up
[3627.76s -> 3628.76s]  somebody opens it up
[3629.76s -> 3630.76s]  and the person in the back of the line
[3631.76s -> 3632.76s]  goes straight to the other cashier
[3633.76s -> 3634.76s]  and everybody else is like
[3635.76s -> 3636.76s]  it's not the right order.
[3637.76s -> 3638.76s]  Chaos.
[3639.76s -> 3640.76s]  Any other questions on what the cashier is doing?
[3640.76s -> 3645.76s]  We finally made it to the main function here.
[3646.76s -> 3647.76s]  So the main function
[3648.76s -> 3649.76s]  sets things up
[3650.76s -> 3652.76s]  and let's see how it actually sets things up.
[3653.76s -> 3657.76s]  It sets up the customers, the manager and the cashier.
[3658.76s -> 3660.76s]  Remember it does not do anything with the clerks
[3661.76s -> 3663.76s]  because the clerks happen in the customer.
[3664.76s -> 3665.76s]  The customer somehow magically
[3666.76s -> 3667.76s]  creates a clerk thread.
[3668.76s -> 3669.76s]  That's how that one works.
[3670.76s -> 3674.76s]  So the customers, the total cones order,
[3675.76s -> 3676.76s]  this is just for logging basically,
[3677.76s -> 3678.76s]  it sets up here.
[3679.76s -> 3681.76s]  And then the customers,
[3682.76s -> 3683.76s]  we know how many customers are going to come in
[3684.76s -> 3685.76s]  because we're writing this program.
[3686.76s -> 3687.76s]  Maybe that could be some other random number
[3688.76s -> 3689.76s]  but we did it as a constant.
[3690.76s -> 3691.76s]  For each customer what do we do?
[3692.76s -> 3693.76s]  We get however many cones they want.
[3694.76s -> 3695.76s]  That's where we determine how many cones
[3696.76s -> 3697.76s]  each customer wants.
[3698.76s -> 3699.76s]  And then we set up a thread
[3700.76s -> 3701.76s]  for each customer
[3702.76s -> 3705.76s]  with the customer ID basically
[3706.76s -> 3708.76s]  and with the number of cones they want.
[3709.76s -> 3710.76s]  And that's how each customer
[3711.76s -> 3713.76s]  knows to go and get so many clerks,
[3714.76s -> 3715.76s]  one for each cone
[3716.76s -> 3717.76s]  and then it passes on its own ID
[3718.76s -> 3719.76s]  to the clerks
[3720.76s -> 3722.76s]  and to the cashier.
[3723.76s -> 3725.76s]  And then we actually just keep track
[3726.76s -> 3727.76s]  of the total cones order
[3728.76s -> 3729.76s]  because we want to report on that.
[3730.76s -> 3731.76s]  We're going to have to join these at some point
[3732.76s -> 3733.76s]  because they're all threads
[3734.76s -> 3735.76s]  and when they end we need to join them,
[3736.76s -> 3737.76s]  we'll get there.
[3738.76s -> 3739.76s]  Then we need one thread for the manager
[3740.76s -> 3741.76s]  and one thread for the cashier
[3742.76s -> 3744.76s]  and we don't need to tell them anything
[3745.76s -> 3746.76s]  at this point.
[3747.76s -> 3748.76s]  We need to tell the manager
[3749.76s -> 3750.76s]  the total number of cones ordered.
[3751.76s -> 3752.76s]  The cashier will use the global constant
[3753.76s -> 3756.76s]  to tell how many customers there are.
[3757.76s -> 3758.76s]  So it doesn't need to be passed in.
[3758.76s -> 3759.76s]  It probably should have been
[3760.76s -> 3761.76s]  in terms of an encapsulation question.
[3762.76s -> 3764.76s]  So I noticed that the cashier
[3765.76s -> 3767.76s]  gets joined for the manager.
[3768.76s -> 3769.76s]  What's the idea there?
[3770.76s -> 3771.76s]  Is that on purpose?
[3772.76s -> 3773.76s]  Cashier gets joined for the manager,
[3774.76s -> 3775.76s]  I don't think it matters.
[3776.76s -> 3777.76s]  I think these are irrelevant
[3778.76s -> 3779.76s]  because they're both ending
[3780.76s -> 3781.76s]  and they're ending
[3782.76s -> 3783.76s]  and they're not coordinating
[3784.76s -> 3785.76s]  and they don't really need to worry about it.
[3785.76s -> 3789.76s]  Is the total number of total cones ordered?
[3790.76s -> 3791.76s]  The max number of clerks
[3792.76s -> 3794.76s]  is the total total cones ordered, yes.
[3795.76s -> 3796.76s]  That's because we know
[3797.76s -> 3798.76s]  that each clerk only makes one cone.
[3799.76s -> 3800.76s]  No, that's not true.
[3801.76s -> 3802.76s]  Each clerk could make
[3803.76s -> 3804.76s]  infinite number of cones
[3805.76s -> 3806.76s]  but it only makes one good cone.
[3807.76s -> 3808.76s]  It only makes one past inspection cone.
[3809.76s -> 3810.76s]  Question?
[3811.76s -> 3812.76s]  Is it possible that the clerk signals
[3813.76s -> 3814.76s]  before the manager is gone?
[3815.76s -> 3816.76s]  Sure.
[3817.76s -> 3818.76s]  Nothing happens then
[3819.76s -> 3820.76s]  because all that's happening
[3821.76s -> 3822.76s]  when you signal.
[3823.76s -> 3824.76s]  Remember, this is not the same
[3825.76s -> 3826.76s]  as signaling in a process.
[3827.76s -> 3828.76s]  This is just updating that semaphore.
[3829.76s -> 3830.76s]  And so the semaphore
[3831.76s -> 3832.76s]  is going to get updated no matter what.
[3833.76s -> 3834.76s]  Who cares if there's a manager thread yet?
[3835.76s -> 3836.76s]  Once the manager thread gets ready
[3837.76s -> 3838.76s]  and checks that signal,
[3839.76s -> 3840.76s]  does a wait on that signal,
[3841.76s -> 3842.76s]  it will move right on.
[3843.76s -> 3844.76s]  Very good question.
[3845.76s -> 3846.76s]  It will move the same
[3847.76s -> 3848.76s]  like you're signaling the semaphore
[3849.76s -> 3850.76s]  and then somebody else
[3851.76s -> 3852.76s]  might be waiting on that semaphore.
[3853.76s -> 3854.76s]  And so that's where
[3855.76s -> 3856.76s]  the abstract signaling part comes in.
[3857.76s -> 3858.76s]  Good question.
[3859.76s -> 3860.76s]  Anybody else on this one?
[3861.76s -> 3862.76s]  So then what do we do
[3863.76s -> 3864.76s]  after we, oh, now,
[3865.76s -> 3866.76s]  here's the most interesting part here
[3867.76s -> 3868.76s]  and I already mentioned this
[3869.76s -> 3870.76s]  a little bit.
[3871.76s -> 3872.76s]  So the customers are just all spinning up
[3873.76s -> 3874.76s]  and going about their business.
[3875.76s -> 3876.76s]  What they're likely to do
[3877.76s -> 3878.76s]  is just wait.
[3879.76s -> 3880.76s]  But they are already running
[3881.76s -> 3882.76s]  and ready to go
[3883.76s -> 3884.76s]  and they're just waiting
[3885.76s -> 3886.76s]  for that one signal to happen
[3887.76s -> 3888.76s]  through the condition variable any
[3889.76s -> 3890.76s]  and when that happens, boom,
[3891.76s -> 3892.76s]  they go and they start inspecting.
[3893.76s -> 3894.76s]  You don't have to spin up a thread
[3895.76s -> 3896.76s]  and spinning up a thread
[3897.76s -> 3898.76s]  takes a little time.
[3899.76s -> 3900.76s]  This is a good way.
[3901.76s -> 3902.76s]  This is going to set us up
[3903.76s -> 3904.76s]  for that thread pool stuff
[3905.76s -> 3906.76s]  as we go.
[3907.76s -> 3908.76s]  And thread pools are a good way
[3909.76s -> 3910.76s]  to make it so that you reduce
[3911.76s -> 3912.76s]  the lag that comes
[3913.76s -> 3914.76s]  with creating a thread.
[3915.76s -> 3916.76s]  There is some.
[3917.76s -> 3918.76s]  Okay, then what do we do?
[3919.76s -> 3920.76s]  We join all of the customers,
[3921.76s -> 3922.76s]  then we join the clerk
[3923.76s -> 3924.76s]  and we join the manager
[3925.76s -> 3926.76s]  and I don't believe that matters,
[3927.76s -> 3928.76s]  whatever that's happening,
[3929.76s -> 3930.76s]  because we're just waiting
[3931.76s -> 3932.76s]  for them all to end.
[3933.76s -> 3934.76s]  And that will mean that
[3935.76s -> 3936.76s]  we're just waiting for whatever,
[3937.76s -> 3938.76s]  what they all did.
[3939.76s -> 3940.76s]  And it was much better
[3941.76s -> 3942.76s]  than me typing it all live.
[3943.76s -> 3944.76s]  That would have been a nightmare.
[3945.76s -> 3946.76s]  Any questions on the code so far?
[3947.76s -> 3948.76s]  What are the takeaways from this?
[3949.76s -> 3950.76s]  There's a lot going on here.
[3951.76s -> 3952.76s]  We made a big model,
[3953.76s -> 3954.76s]  not even that big really,
[3955.76s -> 3956.76s]  but it's a big enough model
[3957.76s -> 3958.76s]  that there's lots of moving parts.
[3959.76s -> 3960.76s]  Managing all the threads, waiting,
[3961.76s -> 3962.76s]  you do have to plan this out.
[3963.76s -> 3964.76s]  This is not something you can
[3965.76s -> 3966.76s]  you have to sit there and plan.
[3967.76s -> 3968.76s]  Trust me, Julie Zielinski,
[3969.76s -> 3970.76s]  when she created this,
[3971.76s -> 3972.76s]  must have spent some time going,
[3973.76s -> 3974.76s]  okay, what do I really need here?
[3975.76s -> 3976.76s]  I want all these things to happen.
[3977.76s -> 3978.76s]  I need some managers out there.
[3979.76s -> 3980.76s]  They're going to need a semaphore
[3981.76s -> 3982.76s]  and there's going to be another semaphore
[3983.76s -> 3984.76s]  for the clerk and all I need too.
[3985.76s -> 3986.76s]  It's not like she just started writing code.
[3987.76s -> 3988.76s]  She certainly planned this out
[3989.76s -> 3990.76s]  to some extent.
[3991.76s -> 3992.76s]  Although I guess I know Julie enough
[3993.76s -> 3994.76s]  to know she probably just did start it,
[3995.76s -> 3996.76s]  but you could modify this model
[3997.76s -> 3998.76s]  in a zillion different ways.
[3999.76s -> 4000.76s]  You could make it so that the clerks,
[4001.76s -> 4002.76s]  there's multiple clerks
[4003.76s -> 4004.76s]  that already spun up
[4005.76s -> 4006.76s]  and then you get one in time.
[4007.76s -> 4008.76s]  That'd be a thread pool sort of thing
[4009.76s -> 4010.76s]  where a clerk, once they make a good ice cream,
[4011.76s -> 4012.76s]  goes back in the pool and gets another one.
[4013.76s -> 4014.76s]  Maybe you'd want a semaphore,
[4015.76s -> 4016.76s]  some number of permits with the number of clerks
[4017.76s -> 4018.76s]  that can do it at a time or something.
[4019.76s -> 4020.76s]  Who knows?
[4021.76s -> 4022.76s]  But you would do that.
[4023.76s -> 4024.76s]  If we had more than one manager,
[4025.76s -> 4026.76s]  it's not a force,
[4027.76s -> 4028.76s]  and then could create multiple clerks in Maine,
[4029.76s -> 4030.76s]  you could have done them in Maine,
[4031.76s -> 4032.76s]  and then spun them up and that would have worked too.
[4033.76s -> 4037.76s]  Yeah, so I keep throwing around this thread pool thing.
[4038.76s -> 4039.76s]  A thread pool is basically
[4040.76s -> 4041.76s]  a number of threads that are all waiting to do a job.
[4042.76s -> 4043.76s]  It's exactly like the farm
[4044.76s -> 4045.76s]  where you have all those Python processes
[4046.76s -> 4047.76s]  that are still running on myth machines around the world.
[4048.76s -> 4049.76s]  You've got all those processes
[4050.76s -> 4051.76s]  that are all ready to go,
[4052.76s -> 4053.76s]  waiting for something to do,
[4053.76s -> 4054.76s]  and then, boom, you make do with them.
[4055.76s -> 4056.76s]  You don't need to start anything else up.
[4057.76s -> 4058.76s]  You will see that in two assignments.
[4059.76s -> 4060.76s]  You'll actually build a thread pool
[4061.76s -> 4062.76s]  and see how it works,
[4063.76s -> 4064.76s]  but it's not really that complicated.
[4065.76s -> 4066.76s]  You have a whole bunch of threads
[4067.76s -> 4068.76s]  and then you say, go,
[4069.76s -> 4070.76s]  but just do a wait and then I'll eventually signal you.
[4071.76s -> 4072.76s]  That's really all there is to it.
[4073.76s -> 4074.76s]  All right.
[4075.76s -> 4076.76s]  And then, yeah, that's the thread pool,
[4077.76s -> 4078.76s]  waiting around.
[4079.76s -> 4080.76s]  We want to avoid spinning up a thread,
[4081.76s -> 4082.76s]  taking the time to do that if we can,
[4083.76s -> 4084.76s]  but we did it for the clerks,
[4085.76s -> 4086.76s]  we did it for the manager and the cashier.
[4087.76s -> 4088.76s]  All right.
[4089.76s -> 4090.76s]  So, that is the program.
[4091.76s -> 4092.76s]  Let me actually show it to you in action.
[4093.76s -> 4095.76s]  Let's go find a terminal here.
[4096.76s -> 4097.76s]  Whoops.
[4098.76s -> 4099.76s]  Skip this version.
[4100.76s -> 4101.76s]  I need to go back to the cursor.
[4102.76s -> 4103.76s]  Skip this version.
[4104.76s -> 4105.76s]  Hang on.
[4106.76s -> 4107.76s]  There we go.
[4108.76s -> 4109.76s]  Okay.
[4110.76s -> 4111.76s]  All right.
[4111.76s -> 4114.76s]  We need to go to 110
[4115.76s -> 4116.76s]  and spring,
[4117.76s -> 4119.76s]  live, lecture, thread, CPP.
[4120.76s -> 4121.76s]  Okay.
[4122.76s -> 4123.76s]  In here, I have already created the ice cream parlor.
[4124.76s -> 4125.76s]  Let's see it go.
[4126.76s -> 4127.76s]  Boom.
[4128.76s -> 4129.76s]  Now, this is going to go on, right?
[4130.76s -> 4131.76s]  It goes on and on and on and on
[4132.76s -> 4133.76s]  and if we kind of go up and see what's going on here,
[4134.76s -> 4135.76s]  clerk starts to make ice cream cone zero
[4136.76s -> 4137.76s]  for customer number seven.
[4138.76s -> 4139.76s]  Manager is presented with an ice cream cone.
[4139.76s -> 4140.76s]  Right, et cetera, et cetera.
[4141.76s -> 4142.76s]  And it keeps going, keeps going, keeps going,
[4143.76s -> 4144.76s]  and you can kind of see,
[4145.76s -> 4146.76s]  eventually, it's going to keep going.
[4147.76s -> 4148.76s]  I don't know how many, there it is.
[4149.76s -> 4150.76s]  Okay.
[4151.76s -> 4152.76s]  So, at the end here, what happens?
[4153.76s -> 4154.76s]  Well, it says the manager is presented with an ice cream cone,
[4155.76s -> 4156.76s]  manager spent some time,
[4157.76s -> 4158.76s]  and then the manager is done.
[4159.76s -> 4160.76s]  Manager inspected a total of 333 ice cream cones
[4161.76s -> 4163.76s]  before approving a total of 27.
[4164.76s -> 4165.76s]  Terrible clerks, it turns out.
[4166.76s -> 4167.76s]  Right?
[4167.76s -> 4168.76s]  Wasting a whole bunch of ice cream.
[4169.76s -> 4170.76s]  90% of the ice cream is wasted.
[4171.76s -> 4172.76s]  Not good.
[4173.76s -> 4174.76s]  Not going to be in business very long.
[4175.76s -> 4176.76s]  And then the manager leaves, right?
[4177.76s -> 4178.76s]  And then the last customer here
[4179.76s -> 4180.76s]  takes up position, let's see,
[4181.76s -> 4182.76s]  14 at the counter.
[4183.76s -> 4184.76s]  Why would that happen?
[4185.76s -> 4186.76s]  Why would we have customer 10, I don't know,
[4187.76s -> 4188.76s]  I'd have to look into that,
[4189.76s -> 4191.76s]  why it's not position 10.
[4192.76s -> 4193.76s]  I'll flip that up, I'll have to see.
[4194.76s -> 4195.76s]  Oh, I know why.
[4195.76s -> 4196.76s]  Well, because 12, 11, 5, whatever,
[4197.76s -> 4198.76s]  they all happened before.
[4199.76s -> 4200.76s]  Turns out that it took the most time
[4201.76s -> 4202.76s]  to make customer 10s,
[4203.76s -> 4204.76s]  which is not the order customer 10 gets in line.
[4205.76s -> 4206.76s]  The order customer 10 was the 14th,
[4207.76s -> 4208.76s]  the final customer to get their cones made,
[4209.76s -> 4210.76s]  is what happened there.
[4211.76s -> 4212.76s]  Okay?
[4213.76s -> 4214.76s]  And then the cashier has already rung everybody up,
[4215.76s -> 4216.76s]  it took less time to ring them up.
[4217.76s -> 4218.76s]  And then the cashier goes home.
[4219.76s -> 4220.76s]  Yeah?
[4220.76s -> 4221.76s]  Close, the question was,
[4222.76s -> 4223.76s]  technically the cashier,
[4224.76s -> 4225.76s]  the manager thread ends before the cashier.
[4226.76s -> 4227.76s]  The manager thread is joined
[4228.76s -> 4229.76s]  after the cashier thread.
[4230.76s -> 4231.76s]  So if you want to think about it,
[4232.76s -> 4233.76s]  the cashier has to wait at the door
[4234.76s -> 4235.76s]  before leaving, yes.
[4236.76s -> 4237.76s]  Although the thread is actually gone,
[4238.76s -> 4239.76s]  but all the cleanup for the thread
[4240.76s -> 4241.76s]  has not happened yet.
[4242.76s -> 4243.76s]  Let's say the manager left their coffee cup
[4244.76s -> 4245.76s]  on the table and somebody has to go clean it up.
[4246.76s -> 4247.76s]  That's still there,
[4248.76s -> 4249.76s]  but the manager's long gone.
[4250.76s -> 4251.76s]  Okay.
[4252.76s -> 4253.76s]  All right.
[4254.76s -> 4255.76s]  Feel free to look at this code,
[4256.76s -> 4257.76s]  modify it, check it out,
[4258.76s -> 4259.76s]  try to make some other semaphore changes,
[4260.76s -> 4261.76s]  see what happens.
[4262.76s -> 4263.76s]  This is not a bad problem
[4264.76s -> 4265.76s]  for a final exam.
[4266.76s -> 4267.76s]  Like if you want to,
[4268.76s -> 4269.76s]  if this is the kind of,
[4270.76s -> 4271.76s]  now, coming up with making it work
[4272.76s -> 4273.76s]  is the hard part,
[4274.76s -> 4275.76s]  like for like designing the problem,
[4276.76s -> 4277.76s]  so it's unambiguous.
[4278.76s -> 4279.76s]  But this is a pretty good problem.
[4280.76s -> 4281.76s]  And you may see something similar
[4282.76s -> 4283.76s]  on the final exam.
[4284.76s -> 4285.76s]  We'll see you guys Thursday.
