# Detected language: en (p=1.00)

[0.00s -> 4.10s]  Okay, all right, so we've made it to the last day
[4.70s -> 6.42s]  whoo-hoo
[6.42s -> 9.58s]  I'll have more comments right at the end of class about about
[10.10s -> 15.66s]  What this class where you should like feel that you are after taking this class and so forth
[16.08s -> 20.22s]  Without it without raising your hands unless you like absolutely want to
[20.82s -> 24.42s]  How many people in here came into cs110 and went?
[25.08s -> 31.48s]  Man cs110 I've heard that it's like so much work and it's gonna be like yeah, I see a couple people going
[31.48s -> 36.54s]  I don't mind telling you it's gonna work, but it's been okay, right like you've made it and you you did very well
[37.16s -> 40.46s]  Overall, I think I'm very happy with the way
[40.90s -> 47.00s]  Students have done and how people have like gone through the class as I think I might have said before
[48.34s -> 53.00s]  It's not me speaking up here. That's teaching you all this stuff as much as I'd love to say
[53.00s -> 55.04s]  Well, I'm the one, you know teaching you all this stuff
[55.04s -> 59.38s]  It's you doing the assignments really is where where you get the the learning out of this, right?
[59.70s -> 64.46s]  You don't learn about six to spend from me telling you what six to spend is you learn about it from like wait
[64.46s -> 68.98s]  How does this work and how do I program? What's this weird race condition? And why is my code?
[70.10s -> 76.06s]  Stalling and why is there this deadlock and whatever you learn that from actually doing it and putting in the hard work
[76.06s -> 81.22s]  So good job there. I'll have a couple more comments about about that later
[81.24s -> 85.24s]  So, how's the assignment going not produce getting there
[86.20s -> 90.54s]  Okay, some people are like I haven't started it yet. You should probably start it soon if you haven't yet
[92.20s -> 95.30s]  Technically, it's due today. I put something on Piazza that said look no
[95.80s -> 102.12s]  Alright, somebody else answered this on Piazza that said that you won't have any late days until starting Friday
[102.12s -> 106.72s]  So you still have until tomorrow without any late credit for the assignment if you're still working on it
[106.72s -> 110.76s]  I will have office hours both today right after class for about an hour
[110.94s -> 116.14s]  And then tomorrow morning my normal regular office hours. I will hold those as well
[116.22s -> 120.86s]  You are welcome to stop by and chat about the assignment or about the final exam
[121.62s -> 123.62s]  and so forth and
[124.32s -> 130.70s]  The exam is Monday. So it's coming up pretty quickly. There's not actually that much time before the exam but
[131.50s -> 137.62s]  It's Monday if you do have extenuating circumstances and need to take the later exam and so forth
[137.62s -> 140.18s]  Please let me know before too long if you have
[141.12s -> 147.00s]  Other accommodations I will email you in the next day or two about timings and so forth
[147.76s -> 149.76s]  Okay. Yes question
[152.12s -> 156.72s]  Yeah there well that's good question the question was are there gonna be any office hours over the weekend
[156.72s -> 163.48s]  We will definitely have something on Sunday. I haven't talked to the I haven't talked to the CAs yet about what other plans
[163.54s -> 166.20s]  They do we'll have some there's also gonna be a review session
[166.20s -> 170.64s]  I think that see as we're talking about like Saturday at some point or something like that
[170.64s -> 176.30s]  But we'll let you know as soon as we can about that. Yeah, that's that
[176.98s -> 182.38s]  And then let's see. What else we will have everything graded midweek next week
[182.70s -> 188.44s]  As best we can before before that as far as one of their logistical thing
[189.90s -> 191.90s]  for the
[192.16s -> 193.90s]  End of term
[193.90s -> 197.28s]  Evaluations, please do that if you get the chance. I
[198.26s -> 200.98s]  Will gladly take any constructive feedback
[201.50s -> 204.08s]  And constructive feedback is like oh, you know what?
[204.08s -> 207.36s]  There was too much material or this material didn't make much sense when you covered it
[207.36s -> 210.50s]  And I mean, I'm not upset about good constructive feedback
[210.50s -> 215.76s]  It's feedback like the class sucked is not gonna help you much right but like feedback like hey
[215.76s -> 220.40s]  I wish you Chris would have done this or this was good, but this could have been better that sort of stuff
[220.40s -> 226.12s]  Fine with me. I'm always trying to make the class better. So we will appreciate if you did this
[227.38s -> 231.52s]  Let's see. Okay. So today we're gonna talk about a topic that's not on the final
[232.34s -> 237.84s]  And in fact, I was looking at it. I was going over it this morning going it's way too much for one lecture
[238.34s -> 243.00s]  This is actually too much though. So I'm gonna skip some things in here and basically give you the
[243.94s -> 247.58s]  Kind of the overview with a couple of examples of this
[248.56s -> 254.16s]  Non-blocking. I oh so so far we have been talking about I
[254.84s -> 257.72s]  oh in other words reads and writes that when you
[258.16s -> 263.00s]  Send the when you do the system call for read or write with a file descriptor
[263.00s -> 270.84s]  It actually blocks until it gets a response or and the response is some amount of data
[270.84s -> 273.84s]  now, it's not always all the data you're either sending or
[274.62s -> 278.06s]  Requesting but it's some of the data or at least it
[278.42s -> 283.40s]  It's going to be some data and it waits until that some data is actually processed
[284.10s -> 289.54s]  Be it over the network or reading or writing a file and today and the way we get around
[290.18s -> 298.18s]  Those limitations is we have just been doing multi-threading or multi-processing. We're generally multi-threading where we say oh great
[298.86s -> 302.62s]  Let's run like we're gonna have this read or write but it's going to block
[302.64s -> 308.64s]  So we're gonna have we're gonna have the ability for other threads to accept connections or to be also doing work
[308.72s -> 311.20s]  That's how we're getting around it. It's not the only way
[311.76s -> 318.88s]  There is this idea of having a non-blocking situation where you say I'm gonna read some data
[318.88s -> 320.88s]  And it might come back with zero data
[320.88s -> 325.36s]  But it comes back instantly either it does it comes back with some amount of data
[325.68s -> 328.96s]  And we're gonna see why that might be an interesting idea
[329.74s -> 333.22s]  And of course you can't do it just on your own in your own program
[333.22s -> 338.82s]  There's gonna be some other things we need to have support from the kernel and from the operating system about yeah
[350.66s -> 353.06s]  Yeah, good question, so this just came up on Piazza
[353.88s -> 361.16s]  There was a question on a recent file maybe last quarter actually that mentioned the term IO bound and
[361.68s -> 364.90s]  We can contrast that with CPU bound
[365.96s -> 368.68s]  Okay, and I made a comment in the Piazza post
[368.68s -> 372.44s]  You should know what IO bound means and maybe we haven't talked about it explicitly
[372.68s -> 376.72s]  but here's what IO bound actually means it means that your
[377.62s -> 381.56s]  Processor is not chugging away doing calculations
[381.56s -> 385.78s]  It's just waiting for some input or output to happen
[385.78s -> 392.38s]  And that's this idea of this this weighted this blocking sort of idea is it takes time for?
[392.90s -> 398.82s]  Data to be processed now. I've mentioned on Monday that when you're reading and writing from a hard drive
[398.82s -> 402.42s]  It's like millions of times slower than reading and writing from memory
[402.56s -> 409.62s]  And so there is some what we call latency that is involved with actually doing a read or write
[409.88s -> 415.28s]  So something that's IO bound means your CPU is sitting there go twiddling its thumbs going
[415.28s -> 419.94s]  I don't know what I don't know what to do right now because I I can't go on until I get some data
[420.04s -> 424.92s]  So that's what it means to be IO bound CPU bound is kind of the exact opposite
[425.20s -> 431.04s]  It means that your computer is chugging away doing something and it can't finish some function
[431.28s -> 434.94s]  Until it finishes all of the calculations
[434.94s -> 439.86s]  It needs to do or something that is taking the processors time, right?
[439.86s -> 447.62s]  If it's if something's IO bound if you can use that processor, which by the way is really fast to do some other work
[447.90s -> 453.46s]  Let's do that. And that's where we have multi-threading and that's that's why having this question came up the other day, too
[453.86s -> 458.54s]  About oh what happened when we had one processor. How did we get this idea of?
[459.20s -> 460.80s]  Multi-processing like
[460.80s -> 465.92s]  Multi-threading how did that actually work? It was because your processor is so fast that it can switch between
[466.60s -> 472.32s]  Processes faster than you can notice so that when you move your mouse around the screen guess what?
[472.32s -> 475.60s]  That's a different process taking care of the mouse movement
[475.60s -> 480.84s]  But you don't you can't tell because it's it happens so fast and it does such a small amount of work
[481.04s -> 487.24s]  That it looks like it's just happening at the exact same time as something else and on a multi-processor
[487.50s -> 492.54s]  Process or a computer like the ones we have these days. It probably is but on a single processor
[492.54s -> 495.70s]  it was just that your mouse would move around and
[496.38s -> 500.66s]  Part of the time that it was would have been working on your program is now spent actually
[500.94s -> 504.10s]  Moving the mouse and updating the screen and so forth and this goes back
[504.78s -> 506.78s]  All the way back to the mid-1980s
[507.26s -> 511.38s]  When you bought the original of the original Macintosh computer
[511.38s -> 515.14s]  It had mouse routines that it would look just like, you know
[515.14s -> 520.48s]  Something would be happening in the mouse would take over for a second and you couldn't tell that it was time from the processor do
[520.48s -> 522.48s]  To take the time. Yeah
[525.84s -> 528.96s]  I mean saying something is IO blocked is similar. Yes
[528.96s -> 533.00s]  I mean the term IO bound is well known as oh
[533.28s -> 540.40s]  You've got a processor that's doing some input output and it's bound by the fact that that's low part is the input output
[540.52s -> 544.36s]  That's really what IO bound generally means and if you can
[544.54s -> 547.14s]  If you can make something CPU pound bound
[547.78s -> 550.46s]  That's not a not necessarily a bad thing
[550.54s -> 552.70s]  It's not neither one of these is a bad thing
[552.78s -> 558.10s]  But being CPU bound is actually harder because it's much because your computer is so fast at doing things
[558.42s -> 561.36s]  Right now if you were trying to factor large numbers
[561.54s -> 562.06s]  Yeah
[562.06s -> 567.66s]  That's gonna be a CPU bound sort of thing because you takes a lot of processing to do that
[567.74s -> 572.86s]  Right and it might be that you have to factor some large number and then spit it out to the processor
[572.88s -> 580.00s]  So in fact, I guess the farm program that we did with multi-processing had elements of it that were CPU bound on the
[581.00s -> 586.80s]  Python side, right because it had to do all that factoring and then it never got back to you with a response until after
[586.80s -> 588.32s]  The CPU part was done
[588.32s -> 594.32s]  So so you can do that but knowing the difference between these two terms is going to be helpful long term anyway
[594.32s -> 596.32s]  So, yeah question
[601.82s -> 608.02s]  Who would a program always be one of them a program could at certain times be CPU bound and at certain times being IO bound
[608.02s -> 611.70s]  But it's it's going to be it's going to be one of the other generally. Yeah
[612.62s -> 615.26s]  It's all well, it's generally gonna fit into one of those
[615.26s -> 621.44s]  Although you could if you if let's say you had you knew you were gonna have a whole bunch of IO bound threads
[621.50s -> 628.58s]  Just keep doing more threads until it becomes CPU bound or the trade-off is not, you know, then that's perfect, right?
[628.58s -> 633.34s]  You've got all these outstanding connections and you're you're chugging away creating all your ass
[634.66s -> 640.82s]  Processing all these outstanding connections and you've got so many that it actually is taking your process of time until you get something back
[640.82s -> 643.66s]  So yeah, I mean the the trade-off would be
[644.66s -> 649.54s]  Or the the idea would be yeah, keep doing seek more CPU stuff while you can
[649.84s -> 651.84s]  You know, so now
[651.94s -> 656.32s]  Sometimes you don't want to do that because it takes more energy and there's other you know things going on your fans
[656.32s -> 657.68s]  So come out on your computer and whatever
[657.68s -> 661.80s]  But if you really wanted to eke out every processor cycle from your computer
[661.80s -> 664.96s]  You would keep doing more threads to be able to do that
[670.24s -> 673.92s]  Yeah, I mean I could ask you, you know, I could ask you I could say why is
[674.90s -> 680.78s]  Networking going to be IO bound and you'd probably you would have to say oh it's because it's the slower part of the connection
[680.78s -> 686.02s]  It's got to talk between two computers and it's not your and your processor has to wait and we use six suspend and we use
[686.02s -> 687.14s]  You know
[687.14s -> 688.98s]  we use
[688.98s -> 690.98s]  other
[690.98s -> 693.78s]  Blocking sort of reads and writes and so forth. So yeah
[694.82s -> 697.06s]  Other questions on that good questions
[697.94s -> 699.94s]  Okay, so let's talk about
[700.24s -> 702.00s]  IO
[702.00s -> 707.08s]  In general and system calls we have this idea that we have fast system calls
[707.32s -> 712.20s]  Okay, those are the ones that return immediately, which means all they need to do is
[712.72s -> 715.76s]  do some process that doesn't really involve a
[716.52s -> 720.84s]  connection or file reading or writing and so forth so
[721.48s -> 724.12s]  There are lots of examples of system calls that might do that
[724.12s -> 727.40s]  But let's say get hostname or something like that
[727.42s -> 732.46s]  That system call doesn't need to go outside the network and needs to just query something that the that the
[733.18s -> 736.74s]  Kernel already knows about it just returns immediately and and that's the way it goes
[737.34s -> 739.34s]  There's no real limit on
[741.06s -> 742.06s]  Immediately
[742.06s -> 747.38s]  As long as it needs to do stuff as long as the processor needs to be doing things
[747.38s -> 752.06s]  There's a kernel needs to be actually doing something to do that that still can be considered fast
[752.18s -> 756.22s]  Even if it takes 60 seconds, it still might be fast because it has to do something
[756.24s -> 759.52s]  So you're factoring a whole bunch of numbers or you're factoring one number
[759.52s -> 764.32s]  it might be still fast in the sense that it's not waiting around but the idea of
[764.92s -> 765.96s]  a
[765.96s -> 772.00s]  Slow system call is when it actually has to say I can't do anything right now until something else
[772.60s -> 774.60s]  responds to me or
[774.80s -> 778.92s]  You know gets back with some data and so forth. Okay, so
[780.88s -> 784.44s]  Slow system calls are the ones where we don't know how long they're gonna wait
[784.50s -> 790.58s]  It depends on some other resource right reading from a client might depend on some other computer getting back to you
[791.18s -> 792.78s]  and
[792.78s -> 797.58s]  The and we want to minimize that kind of behavior if we can help it
[797.76s -> 804.02s]  Okay, so calls to read are fast if they're from a local file because it's not that much
[804.02s -> 806.02s]  But you still depends on what your definition is
[806.02s -> 810.18s]  You could still consider that slow because file reading is slower than memory access and so forth
[810.18s -> 812.18s]  But in general it's relatively fast
[812.36s -> 819.28s]  Right calls are slow if it's going to a socket or if there's some internal congestion
[819.28s -> 825.56s]  Like the socket is filled with lots of ingoing and outgoing connections and that can happen when you have one port
[825.96s -> 832.44s]  Responding to all these connections like a web server often has its port like it's really on the edge of oh my gosh
[832.44s -> 837.92s]  I'm almost gonna not have enough time to respond to these because just the port itself is getting lots and lots of requests
[837.92s -> 843.58s]  This is what happens when you go online to like reddit and somebody puts a web page and they're not ready for all the connections
[843.58s -> 847.54s]  And it like suddenly goes down. It's because well, I just couldn't handle all the connections
[848.18s -> 851.32s]  So we want to avoid that if we can, okay
[852.18s -> 854.76s]  And then slow system calls in general can block
[856.10s -> 862.10s]  Indefinitely, in other words, you have to wait for them. And in that case, they're considered slow. We've
[862.62s -> 864.82s]  done some of this before where we've we've
[865.56s -> 867.92s]  Made it so that slow system calls don't matter
[868.42s -> 871.56s]  Wait PID is a good one where we have that double, you know
[871.56s -> 877.96s]  Hang remember before when we said oh if we don't if we do wait PID without W no hang and the negative one
[878.72s -> 880.72s]  We or not even that I want just the W
[880.72s -> 880.92s]  No
[880.92s -> 887.46s]  Hang it will wait until the child ends and that's a slow system call because it's waiting for the child to end and it
[887.46s -> 890.80s]  Just goes on just gonna be off the processor until the child finishes
[890.80s -> 894.80s]  So once we start using W no hang you have some more logic you have to fuse
[894.94s -> 900.78s]  But it means that you can get control back and just do call it again at some other time
[900.90s -> 904.98s]  after you've done some other work and then it won't and then you get the benefit of
[905.42s -> 912.04s]  Not having to hold up until that ends. Okay, so let's see read and write with IO sock stream
[912.58s -> 917.28s]  We've generally done it with multi threading to say great do the accept call
[917.38s -> 922.70s]  But do it on in another thread so you can go back and do another except immediately now
[922.70s -> 928.14s]  We're gonna do it in a slightly different way. Okay, accept and read slow the way we've been doing
[928.14s -> 932.18s]  So we'll see we're gonna have to work up to this by the way about how this how this works
[932.22s -> 937.82s]  So, how do we actually make these slow system calls fast? Well, we can tell the
[938.52s -> 943.74s]  We can tell the system don't wait on an accept call. What does that mean?
[943.80s -> 949.52s]  It means you call accept and then it returns immediately and you're responsible for doing it again
[949.68s -> 954.24s]  If you need to actually get it in a connection, we'll see how this works
[954.24s -> 958.76s]  It's gonna be a lot of wild true loops with some extra help from the
[959.46s -> 964.32s]  From the operating system. Okay, as we'll see and we've done some of this before in other forms
[964.32s -> 966.32s]  So it will look very similar in the big picture
[966.76s -> 972.48s]  So generally if you do accept if you set it to non blocking it can return with negative one
[972.58s -> 976.26s]  Which generally means an error and often it sets remember it sets error
[976.26s -> 983.06s]  No, if you get an error in this case, it sets it to E would block which basically says, okay
[983.06s -> 987.86s]  It's the error is that it would block except there's no connection to block on so that's the error
[987.86s -> 992.60s]  So it's not really an error, but that's how you handle it. We've seen that before as well
[993.66s -> 995.30s]  Okay
[995.30s -> 999.22s]  Same thing with read and write you can set those to be non blocking
[999.24s -> 1003.96s]  But then it becomes your responsibility to call them again when you want to send more data
[1004.04s -> 1004.56s]  Okay
[1004.56s -> 1009.54s]  Now you already have to do that because all the data might not get sent from your buffer anyway
[1009.72s -> 1012.34s]  But in this case, it could be zero bytes get sent
[1012.68s -> 1015.96s]  Just because you it's not even ready to take your request at all
[1016.00s -> 1021.88s]  So it just returns immediately and at some further time in the future. It will send the data
[1022.60s -> 1028.56s]  Okay, so if it does if there's no more if it would block
[1029.24s -> 1032.96s]  And there is data to be sent still you'll get this negative one business back
[1033.18s -> 1037.12s]  Okay, if there's no more data, you'll still just get zero as always
[1037.80s -> 1042.70s]  Okay, so that's how it's gonna work. Let's see a couple examples of this
[1043.60s -> 1047.88s]  Let's do talk about this little program called slow alphabet server
[1047.88s -> 1052.32s]  I'm not going to type it up because of the time but here's what it's going to do. We're going to
[1053.20s -> 1058.24s]  artificially put some delay in here of a point one second delay and
[1059.02s -> 1061.22s]  Tenth of a second delay, which is noticeable
[1061.62s -> 1066.74s]  you can actually notice that and what we're gonna do is we are basically going to set up a
[1068.46s -> 1071.10s]  Client here too. We're gonna have a thread pool like we've done before
[1071.50s -> 1074.70s]  Right and when we get a connection request
[1074.70s -> 1080.56s]  All we're gonna do is set up a little output sock buffer and then feed the alphabet one letter at a time
[1081.22s -> 1085.34s]  With a delay in there after each letter, okay
[1085.36s -> 1089.48s]  So what that's gonna mean it's gonna mean 26 it's gonna take 26 letters
[1089.48s -> 1096.16s]  It's gonna take 2.6 seconds to actually push out which is really slow to push 26 letters out, but we're artificially doing this
[1096.68s -> 1102.16s]  To see why it might be a good idea to use this non blocking things
[1102.44s -> 1106.64s]  Okay, so here's what it does, but it waits for a connection
[1106.64s -> 1113.52s]  It has a thread pool to actually handle the connection so it can request it can respond to many connections
[1113.86s -> 1118.34s]  The worker is slow because we put that artificial delay in there and then it closes the connection
[1119.54s -> 1125.18s]  Nothing here is actually non blocking but it's definitely slow because we put that delay in there
[1125.66s -> 1132.38s]  Okay, you will see this often servers in general if they're trying to serve many many web pages
[1132.38s -> 1135.80s]  we'll give a little bit of data to you and a little bit of data the next one a little bit of
[1135.80s -> 1137.80s]  Data the next one so that it
[1137.98s -> 1140.70s]  Doesn't block one for two too long
[1140.92s -> 1147.48s]  Okay, and you'll notice this sometimes if you're loading a web page it loads partial data and it loads a little bit of the
[1147.92s -> 1150.68s]  Image you're trying to download or it loads, you know, this this
[1151.32s -> 1156.28s]  Add and then miss add and whatever it takes a little bit of time and that's you know, what happens
[1156.28s -> 1157.52s]  So you've seen this before?
[1157.52s -> 1163.84s]  Okay, you've seen these you've also seen buffering like on YouTube, which is more or less the same thing where there's just not enough data
[1163.84s -> 1168.88s]  That's gotten to you yet to actually give you an image or give you the the video
[1168.98s -> 1171.70s]  So that's what happens there, okay
[1172.22s -> 1176.90s]  So here's a client that we're going to actually test. Okay, and the client here
[1177.30s -> 1178.62s]  has a
[1178.62s -> 1180.62s]  while loop and basically
[1180.74s -> 1184.78s]  It goes and it tries to connect to the server
[1184.78s -> 1188.96s]  Which is going to be on localhost here at the same machine here, and then it is going to
[1189.82s -> 1196.58s]  Read one byte at a time and then print out that byte but we have yet to do this non blocking thing
[1196.64s -> 1201.76s]  So the read it's going to read it pretty fast print it out pretty fast then go back here and read it again
[1202.20s -> 1208.28s]  The delay though, it's going to come from the server doing really slow pushing out of the data
[1208.44s -> 1211.36s]  Okay, and that's all it's doing. It's printing out this out. So let's actually see this
[1212.88s -> 1214.88s]  If we
[1215.30s -> 1217.30s]  Let's see
[1218.76s -> 1221.20s]  There we go, okay, so we have
[1222.56s -> 1226.00s]  What was the name of this file? This one was slow alphabet
[1226.64s -> 1231.88s]  If we do slow alphabet server like this in the background and then we do
[1232.96s -> 1234.96s]  Let's see. This one was
[1235.12s -> 1239.92s]  This one was blocking alphabet client. Okay, watch what happens. There's your
[1240.80s -> 1242.64s]  amount of
[1242.64s -> 1246.56s]  Like reading the 26 bytes you could tell it was slow. Let's actually time it
[1247.12s -> 1252.08s]  Okay, if you time it then it will take in this case 2.6 seconds, which makes sense
[1252.08s -> 1255.60s]  We've delayed for 0.1 second for letter and it's 26 letters and so forth
[1255.94s -> 1257.94s]  Okay, that shouldn't be
[1258.18s -> 1264.66s]  Too strange notice something in here. We did put a little we counted how many times we called the read, right?
[1264.70s -> 1266.70s]  We called it 26 times
[1267.06s -> 1271.14s]  Mainly because we asked for one character at a time. Okay, is there a question over here? Oh
[1273.54s -> 1275.26s]  Good question
[1275.26s -> 1277.88s]  Yeah, good question. So I used a little bash
[1278.78s -> 1283.04s]  Shortcut if you do time exclamation X or do something with two exclamations
[1283.04s -> 1285.28s]  It does the previous command
[1286.14s -> 1291.20s]  After like it does the previous command with time for instance, so it just does the last thing
[1291.26s -> 1297.82s]  This would probably do it twice time time. Yeah, it does the last thing with it with the current command. Good question
[1298.28s -> 1304.18s]  Okay. So anyway, that's what's happening with the server. Okay. Nothing is new yet. Okay
[1304.18s -> 1306.76s]  We basically done exactly what we've done before now
[1306.76s -> 1312.68s]  I can do this up to 128 times before anyone would actually not get 0.2 seconds because I wouldn't even
[1313.06s -> 1319.78s]  I'd be able to keep doing this as many times as we wanted to in fact, I'm going to cancel the server for right now
[1320.58s -> 1326.50s]  But that's uh, so that's where we kind of are already. Nothing should be new yet
[1326.62s -> 1331.58s]  everything's blocking in the kind of the way it is we put this strange delay in there to kind of show that it
[1331.58s -> 1335.68s]  Takes some time and and it could be a network connection that takes some time. Okay question
[1335.68s -> 1337.68s]  Oh
[1341.84s -> 1342.86s]  Good question
[1342.86s -> 1346.72s]  Why did they use the while of I kind of wanted to show you that you have to do one if you want to do
[1346.72s -> 1351.10s]  It one byte at a time if you wanted to do a stream you could but that's all hidden from you
[1351.10s -> 1354.54s]  And in this case, and by the way, it would ask for a big buffers worth
[1354.54s -> 1359.22s]  So it would still wait 26 are probably 2.6 seconds, but not
[1360.02s -> 1365.54s]  It probably wouldn't you wouldn't be able to see each letter. It would probably ask for the letter and then go, okay
[1365.58s -> 1368.40s]  I asked for the whole 26 at once. So in this case you want to go
[1368.40s -> 1370.68s]  Let's just see it one character at a time
[1372.36s -> 1376.90s]  All right, so this is what we just ran and we saw that took 2.6 seconds and
[1377.84s -> 1379.08s]  in
[1379.08s -> 1381.60s]  Our case we're only reading one character at a time
[1381.60s -> 1386.36s]  So you can see each character and you can kind of perceive that it's going to be relatively slow
[1386.96s -> 1388.28s]  Okay
[1388.28s -> 1392.00s]  So if we want to change to a non blocking
[1392.78s -> 1399.82s]  Equivalent of this we're going to use a function that we are going to see in a few minutes and it's pretty low level
[1399.82s -> 1403.94s]  But it's just called set as non blocking. So after you set up the client
[1404.46s -> 1408.66s]  Okay, you get you call this function that plays some magic
[1409.62s -> 1415.98s]  System calls itself and says if you will when you're reading from this socket don't block on it. That's all it's doing
[1415.98s -> 1421.76s]  We'll see that in a little bit. Okay, but you're gonna do basically the same thing here when you read those
[1422.30s -> 1424.30s]  okay, it is going to
[1425.34s -> 1429.30s]  Not block so you could get a negative one back
[1429.50s -> 1434.30s]  Okay, meaning that it would there was some error but the error could be that it would just block
[1434.58s -> 1437.62s]  Okay, so you could do that if you do get zero back
[1437.62s -> 1442.40s]  It means that there you're still getting no or you don't have any data left. So that's fine
[1442.40s -> 1446.06s]  Just like normal, but in this case we want to if we had
[1446.70s -> 1451.70s]  Greater than zero we would handle it and it should be just one byte because we're still only asking for one byte
[1451.96s -> 1452.92s]  and
[1452.92s -> 1458.68s]  That's it. But the other option could be what if it's negative one, so it's not zero. It's not zero. It's not greater than zero
[1458.68s -> 1459.96s]  So it's negative one
[1459.96s -> 1461.96s]  Check to see that it's not
[1462.36s -> 1468.64s]  The oh it would block because that means there's some other error that the connection died or there's some other error, but if it is
[1469.44s -> 1472.82s]  He would block then you just go. All right in this case
[1472.82s -> 1476.52s]  We're gonna log that we had an unsuccessful read and we just go and try again
[1477.18s -> 1482.18s]  Okay, this is going to do boom boom boom and try to read very fast
[1486.50s -> 1493.14s]  E again is a sim, I think E again and E would block are actually the same thing as it turns out
[1493.22s -> 1499.34s]  I'm not sure they could be different on different systems. But here's how you would figure that out. By the way, you would say
[1499.76s -> 1504.84s]  Error no dash L and that lists them all let's look at E
[1505.88s -> 1507.88s]  would block
[1507.96s -> 1514.78s]  Oops, you would lock her up. He would there it is. It's number 11 and in this case E again
[1515.40s -> 1519.92s]  Also 11 so it's actually redundant in this case, although on different systems
[1519.92s -> 1522.44s]  It might not be but either one of those could get
[1523.20s -> 1529.02s]  Could be the error number if it's going to block E again means try again, basically
[1529.44s -> 1534.42s]  In this case, it happens with the same number. So I guess it's redundant on our system. Good question. Yeah
[1535.12s -> 1538.40s]  Good question. All right, so question
[1545.72s -> 1547.72s]  This is the client
[1547.80s -> 1553.92s]  Right. This is now the this is now the client they're doing so the client now is setting it unblocking now
[1553.92s -> 1558.60s]  We we don't we could set the server to also be non-blocking and we'll see a little bit of that later
[1558.66s -> 1563.34s]  But we don't care right now that the server is blocking because it's still fast and we've done it with a thread and whatever
[1563.34s -> 1565.34s]  But yeah, good question
[1569.26s -> 1574.26s]  Yeah, we have to get there so this is a good question good question wait, is there is there any advantage to this
[1574.78s -> 1576.34s]  We'll see an example later
[1576.34s -> 1580.42s]  unfortunately because at the time I have to skip over some of the part that you can go look at the details but
[1580.42s -> 1583.30s]  We'll see why this why we could use
[1584.34s -> 1587.74s]  We could see we'll see why this is just another way to do a similar thing
[1587.80s -> 1589.80s]  We've already done. Is it better or not?
[1590.20s -> 1593.04s]  Threads take a little time to spin up and threads take you know
[1593.04s -> 1599.94s]  multi-threading things letting the operating letting the operating system handle the waiting is sometimes a better like the not the waiting but the
[1600.88s -> 1605.74s]  The alerting us that there's data and so forth. Sometimes it's just a little more efficient. So
[1606.88s -> 1608.88s]  new servers generally
[1609.36s -> 1615.00s]  Handle it the way we're going to talk about just because they've decided that it's a little faster than doing that multi-threading
[1615.10s -> 1620.66s]  So there's just this is really just another way of doing similar things we've already done the way we've already done it
[1621.22s -> 1624.22s]  Generally fine, but if you're gonna serve billions of web pages
[1624.22s -> 1627.62s]  Maybe you want to get a little more efficient. This might be a better way to the way
[1627.62s -> 1631.62s]  We're going to show you a little more efficient. So long answer for why are we doing it?
[1631.62s -> 1633.62s]  It's another way to do it
[1634.68s -> 1638.78s]  Okay, so anyway now if we run this this is the
[1640.58s -> 1643.94s]  Non-blocking equivalent. Okay, if we run this and we do the
[1645.06s -> 1652.06s]  Let's see. We still need to set up the server. There's the server and if we call non blocking alphabet client
[1652.14s -> 1654.14s]  Okay, it looks exactly the same
[1654.74s -> 1656.82s]  Okay, but take a look at what just happened
[1657.54s -> 1662.50s]  We now got 26 bytes back, but we did. What is that? Let's see
[1663.54s -> 1669.90s]  16 million reads in that 2.6 seconds, right? Well, why is that?
[1670.30s -> 1672.30s]  Why is that a good or a bad thing?
[1673.04s -> 1678.12s]  During the time when we weren't doing those reads we could have been doing other things
[1678.72s -> 1681.88s]  So let's say our program needed to do something else
[1682.38s -> 1686.24s]  Right, we could have done that something else and then gone back and read again later
[1686.24s -> 1689.20s]  So otherwise we would have had to block right?
[1689.20s -> 1692.96s]  This is a dumb way to do it because we're just chugging away and doing all we're doing is reads
[1693.04s -> 1698.88s]  But you'll argue that maybe you want to accept input from the user or something during that time instead of just blocking
[1702.52s -> 1710.00s]  This frees up time on the main thread in this case, right now could you
[1710.40s -> 1714.88s]  Have a thread could you have called that read in a thread? Sure
[1715.32s -> 1716.88s]  So it seems a little odd to do that
[1716.88s -> 1719.06s]  But you might do that and then it's the same sort of thing
[1719.06s -> 1723.06s]  You might need a you might need to figure out when that thread ends and so forth in this case
[1723.06s -> 1727.28s]  We're just saying you know what? We're trying to read 26 bytes. Oh, it's gonna take a while
[1727.36s -> 1731.70s]  Maybe we want to do something else in the meantime, right? I mean, what are the things could we do?
[1733.28s -> 1740.34s]  Non-blocking alphabet clients, not that one. How about non-blocking alphabet client dot CC, right?
[1740.76s -> 1745.92s]  If we do the read, this is the non-blocking read. Okay, let's say that
[1746.88s -> 1754.32s]  Let's say that we get to here where it was unsuccessful. Maybe we did something else like I'm doing
[1755.32s -> 1756.76s]  other work
[1756.76s -> 1758.16s]  right
[1758.16s -> 1760.16s]  like that and
[1762.64s -> 1764.44s]  There we go
[1764.44s -> 1766.16s]  make and
[1766.16s -> 1771.16s]  Let's see. I don't think I killed the server yet. So that's that. There we go. It's doing other work doing other work
[1771.16s -> 1773.28s]  Right, it's you'll see there were letters in there
[1773.28s -> 1776.00s]  I don't you saw but there were some letters spinners perched in there
[1776.00s -> 1777.48s]  But look at how much work we did, you know
[1777.48s -> 1781.24s]  So we could you could have your one thread doing more work and this is the way to do it
[1781.50s -> 1788.48s]  So that's the benefit, you know, no threads necessary in here. No thread pool. No threads necessary. We got the work done
[1788.48s -> 1792.50s]  We did have to re-ask a lot of times but we were able to do more work. That's probably the bottom line
[1793.14s -> 1795.14s]  Yeah other questions on that
[1796.74s -> 1798.14s]  Okay
[1798.14s -> 1801.22s]  So where does that get us now? Well now we've seen that we can actually
[1802.14s -> 1803.74s]  do this
[1803.74s -> 1809.94s]  Okay, and we see that we get millions and millions of reads and we got lots of extra time because 0.1 seconds to a
[1809.94s -> 1816.38s]  Computer is super duper fast. Okay. I mean it's after anybody in here read the book super intelligence by Nick Bostrom
[1816.86s -> 1820.24s]  One of my favorite books although it scares me to death it's a book about
[1820.80s -> 1827.20s]  One what happens when we end up creating a super intelligent AI it's actually smarter than humans and
[1827.80s -> 1833.44s]  there's lots of ramifications of that and we have to maybe be a little careful about that if we want humans to actually persist but
[1834.44s -> 1836.86s]  one of the interesting things about that they mentioned this that
[1837.56s -> 1839.48s]  Computers are so fast that you know
[1839.48s -> 1843.56s]  If you're holding and I think this is the example to use in the book if you're holding a glass of water and you
[1843.56s -> 1850.68s]  Drop it, right? Well because your neurons are relatively slow and the processing of your the seeing things as slow
[1850.82s -> 1856.26s]  You don't get that much time to like move your hand down here and pick it up because you only see so many different data
[1856.26s -> 1860.54s]  Points now the nice thing about your brain is it's very good. It's very good at integrating
[1860.54s -> 1865.66s]  so if I throw a ball to you your brain actually can see the path and put your hand in the right place and
[1865.66s -> 1871.54s]  You're very good at that two billion years of evolution has done a good job of that right but a computer
[1872.20s -> 1874.20s]  Your brain sees, you know
[1874.72s -> 1880.02s]  100 or a thousand different data points in the point one seconds that it takes for something to drop a computer will see
[1880.36s -> 1887.82s]  You know billions or millions of data points and so really to a computer dropping a glass is like the glass is like
[1889.44s -> 1894.28s]  The computers doing like oh I can do it I can do tons of calculations while doing that I can you know
[1894.28s -> 1899.86s]  It's so it's I mean, that's the scary part is that computers are just super duper fast, right?
[1900.52s -> 1902.52s]  But you know, but they can't love
[1903.00s -> 1904.40s]  Not yet
[1904.40s -> 1905.76s]  Not yet
[1905.76s -> 1907.56s]  so anyway
[1907.56s -> 1911.46s]  Read the read the book if you want like it's a little bit of a it's a little bit of a
[1913.52s -> 1918.34s]  Scary book to read but but really it's good because it talks about some of the things and especially if you're doing AI
[1918.56s -> 1920.56s]  It's a just a great book to understand
[1920.56s -> 1922.68s]  Oh, we might have to face this someone in the future
[1922.68s -> 1927.52s]  But my point is during the time when this is reading waiting for that slow thing to happen
[1927.52s -> 1931.66s]  The computer gets to do zillions of other things, which is the point here, okay?
[1931.66s -> 1935.80s]  We could handle that in a thread or we could do something but now it's just one thread doing all the work
[1936.74s -> 1940.70s]  Okay. Now here's the part that I'm actually going to skip over a little bit
[1942.22s -> 1948.34s]  There is this class that we are going to that is used in the other example that basically is
[1949.02s -> 1954.70s]  Going to be used to show you how you can take do file reading or writing in this case
[1955.68s -> 1957.40s]  Piecemeal, okay
[1957.40s -> 1963.88s]  and so it's basically a it's just a little class that has an initialization that takes a
[1964.84s -> 1967.44s]  file descriptor and it takes the
[1968.24s -> 1976.20s]  It takes the actual like data itself in a string format and it's going to push that data to that file descriptor
[1977.28s -> 1979.76s]  Piecemeal like some amount of data at a time
[1980.10s -> 1984.62s]  It's going to do that and it's going to do that through this function called send more data
[1984.62s -> 1988.86s]  And if the send more data cover comes back with false, it means you're done sending data
[1988.86s -> 1994.26s]  But the whole reason for setting this up and and it's like many slides here showing you the nuances of this
[1994.66s -> 1999.10s]  this outbound file class, but the big the big idea is
[2000.06s -> 2000.82s]  Set it up
[2000.82s -> 2008.46s]  So that you say I need to send this string to this file and send some and then it just continually can say send
[2008.46s -> 2013.12s]  More data and it will do that kind of on its own and the whole point of this is doing it
[2013.12s -> 2017.16s]  So there are lots of slides here where it talks about the details here
[2017.16s -> 2022.12s]  Here would be a little test program for that which basically sets up an outbound file
[2022.92s -> 2024.92s]  initializes it with a
[2025.64s -> 2030.52s]  Sorry, it's actually a file name that gets ready and not the actual string, but it's the file name
[2030.52s -> 2036.28s]  It opens that file name up and then in this case, it's going to print it out to standard out whenever you call
[2037.18s -> 2041.98s]  Send more data and in this case, it's going to do that now it does this in a non-blocking way
[2042.28s -> 2046.46s]  Okay, so it will send some data and then it'll send some more and send some more but it will try to return
[2046.90s -> 2048.42s]  Immediately won't try to send all of it
[2048.42s -> 2052.06s]  It might send one byte at a time or it might send a hundred bytes at a time
[2052.06s -> 2053.46s]  But it's some amount of data
[2053.46s -> 2058.94s]  So this is just kind of abstracting that away so that we can use it to show what happens when we do this
[2058.94s -> 2060.30s]  with a server
[2060.30s -> 2063.44s]  So I'm going to skip over all the all the details about this
[2063.90s -> 2066.02s]  The the basic idea or the
[2067.58s -> 2070.10s]  Example here takes a file and
[2070.74s -> 2074.82s]  shoots it out to standard out so I can actually show you what the what the
[2075.50s -> 2080.26s]  The end part of it is here if we let's see. This one is
[2083.34s -> 2087.22s]  It is outbound file test, right and it just prints it out to the file
[2087.22s -> 2090.86s]  But it did it in piecemeal and you can't tell because there's no delays in this one
[2090.86s -> 2096.00s]  Just looks like cat but in this case it does it you just send one bit of it one piece of the data at a
[2096.00s -> 2099.92s]  Time that's all that's about know the details of this. You can go look at it
[2099.92s -> 2104.64s]  I don't think they're particularly important for getting through what we want to cover for the rest of the day here
[2104.64s -> 2111.08s]  So lots of this again, you have to deal with accept and so forth as part of this because you're trying to send to
[2111.52s -> 2113.44s]  that outbound
[2113.44s -> 2115.44s]  server and
[2115.56s -> 2119.52s]  Let's see. We're gonna just skip past this and get past this. Here's the by the way
[2119.52s -> 2126.56s]  Here's the set as non blocking function. Okay. I said that it was I said that it was low level
[2126.56s -> 2128.26s]  It's another one of these system calls
[2128.26s -> 2134.12s]  It's got lots of stuff in it that you if you want to actually use it then you go do it
[2134.12s -> 2138.66s]  But the important part is here is that you call this function called FCN TL
[2138.70s -> 2144.62s]  It takes in the descriptor and some other information and you you give it a parameter that says hey
[2144.62s -> 2149.58s]  Don't block on that descriptor when you're reading or writing from it. So that's all that's doing
[2149.88s -> 2152.60s]  There is set as blocking which does the exact opposite
[2153.20s -> 2157.84s]  And then you can check to see if something is blocking or unblock or non blocking as well
[2158.20s -> 2160.72s]  Low level functions don't need to worry about those details
[2161.40s -> 2165.16s]  Unless you care about creating them. You can always just use that. Okay
[2166.44s -> 2167.72s]  so
[2167.72s -> 2172.78s]  Again, we're not going to worry about the outbound file abstraction. The idea is read a file
[2173.40s -> 2176.16s]  Every time you say send more data send a little bit of chunk of data
[2176.16s -> 2180.60s]  That's all I care that you really know about this is all blasting through that because of the time
[2180.60s -> 2182.60s]  but what I want to spend a little bit of time on is
[2183.52s -> 2188.08s]  Two servers that are going to utilize this outbound file
[2188.76s -> 2194.96s]  Class to actually enable you to serve data quickly without threads
[2195.36s -> 2200.66s]  Okay, so the same ideas we did before are the same idea now is oh no more threads necessary. Let's do it
[2201.24s -> 2203.60s]  Okay, we're gonna use non blocking IO
[2204.40s -> 2206.60s]  for a single threaded web server
[2207.40s -> 2212.30s]  Again, not necessarily the best way to do it, but probably a little more efficient than using threads
[2213.00s -> 2215.00s]  Because we can't do that. Okay
[2215.84s -> 2219.48s]  It's going to be responsive because there's nothing blocking here
[2219.48s -> 2224.80s]  And it's also hopefully not going to miss any connections. Okay, that's because again
[2225.20s -> 2227.76s]  It's got it's going to respond quickly
[2227.82s -> 2229.82s]  But then you're gonna check many times
[2229.82s -> 2233.30s]  To be able to check and make sure that you you don't have a connection yet
[2233.30s -> 2235.30s]  And when you do you get it and you handle it very quickly
[2235.66s -> 2239.28s]  Okay, so let's see some of the details here of this
[2239.94s -> 2244.50s]  Function we are going to create a list of outbound files
[2244.50s -> 2249.72s]  In other words what this server is going to do is you have a web page and this is actually one that we can
[2249.94s -> 2251.50s]  You can use from a web browser
[2251.50s -> 2253.54s]  I'll show it show it to you in action in a few minutes
[2253.60s -> 2259.80s]  But you're gonna have a web page that basically is keeping a list of the files that you want to send out
[2259.92s -> 2264.40s]  So think of it like a web server saying I'm gonna go to google.com or I'm gonna go to
[2264.84s -> 2267.24s]  www.stanford.com and request a bunch of web pages
[2267.48s -> 2272.86s]  Each web page that gets sent back is going to be held in one of these outbound files that can get sent back piece
[2272.86s -> 2277.72s]  By piece by piece. Okay, and we're gonna keep a list of those in this in this program
[2277.72s -> 2279.72s]  Okay, so what's happening here?
[2280.16s -> 2281.74s]  We are
[2281.76s -> 2285.04s]  Setting up a circuit. Okay, our socket rather we are
[2285.70s -> 2292.78s]  Then making it non-blocking now. This is the this is now the server is now doing the non-blocking part
[2293.00s -> 2293.48s]  Okay
[2293.48s -> 2297.70s]  It's going to set up this list of files that we're going to the connect the connection files
[2297.70s -> 2301.32s]  The ones we want to send back turns out they're all the same file in this case
[2301.44s -> 2306.68s]  But we just because we're always just going to request the same file. We didn't say so do a certain file specific file
[2307.38s -> 2313.42s]  Remember in lab a couple weeks ago. You did a file server. You remember that example. Hopefully you covered in lab
[2313.42s -> 2315.74s]  We looked it over. This is the same sort of thing
[2315.74s -> 2319.86s]  Except now the file is all just one file basically the same same basic idea
[2319.98s -> 2326.42s]  Okay, and then we've got a little bit of either logging or some other data capture thing. Okay?
[2326.42s -> 2332.22s]  There's a while true loop in here. Okay, the while true loop will do an except which will not block
[2332.92s -> 2334.92s]  Okay, and it will
[2335.08s -> 2340.20s]  Calculate it'll just do the kind of the logging again of how many times it had to go through this while loop
[2340.64s -> 2344.88s]  Okay, if you don't have a connection it basically just goes it
[2344.88s -> 2347.80s]  Well, if you don't have a connection what we want to do is
[2348.48s -> 2350.36s]  Use the time
[2350.36s -> 2353.36s]  Now to send some data to all those files
[2353.52s -> 2355.96s]  So basically we're gonna go. Hey, does anybody want to talk to me?
[2355.96s -> 2360.32s]  If not, I'm gonna send a bunch of data to the files that have already been set up. That's all that's going on here
[2360.42s -> 2366.90s]  Okay, so we set up the we we send them out and in here we are going to
[2367.76s -> 2374.02s]  Push on to the list of if we do have a connection here. Okay, then we are going to
[2374.78s -> 2376.78s]  I'm sorry, if we don't have a connection here. We're going to
[2378.10s -> 2381.86s]  Initialize this one that looks like we're actually doing we are doing it when we do have that
[2381.86s -> 2387.50s]  We're going to just get a connection set it up pushing on the data and deal with it if we don't
[2387.92s -> 2392.68s]  This is where we are going to send more data, okay, so basically
[2393.50s -> 2397.72s]  You go and after you've tried to do a connection if you set the connection up great
[2397.72s -> 2399.32s]  You don't set the connection up
[2399.32s -> 2403.64s]  Then you push some more data to all your files and just a little bit at a time and that's all that we're doing
[2403.64s -> 2405.64s]  Yeah
[2405.74s -> 2407.74s]  Yeah
[2407.74s -> 2409.74s]  This
[2414.28s -> 2419.68s]  Is a server remember this is the server going on here, right? So in this case, we're accepting a
[2420.32s -> 2425.84s]  Somebody's requesting us. So we have to do the accept. This is basically where in every other program we've ever written
[2425.92s -> 2432.52s]  We've said accept and it's just stayed right there until it gets a come until it gets connection, right now
[2432.52s -> 2433.80s]  It's going. Oh great
[2433.80s -> 2437.52s]  I have more time to do something because nobody wants to talk to me and I'm gonna do what am I gonna do?
[2437.54s -> 2439.54s]  If I get a connection, I will set it up
[2439.82s -> 2445.58s]  Right if I don't get a connection then or if I even if I do the next thing I'm going to do
[2445.58s -> 2448.82s]  I'm going to take some time to push a bit to push out to all those files
[2448.82s -> 2452.44s]  They're requesting this data. And this is where it's come down. Is this gonna take some time?
[2452.88s -> 2453.38s]  Yes
[2453.38s -> 2457.36s]  Now if you have a thousand files here that are being served it is gonna take some time
[2458.02s -> 2462.96s]  Now by the way, we're getting into CPU bound things if your list has
[2463.86s -> 2467.88s]  Ten or a hundred thousand different connections now
[2467.88s -> 2471.50s]  It's got to go whipping through this while loop a hundred thousand times
[2471.74s -> 2475.54s]  That's going to be CPU bound because none of those calls are blocking
[2475.54s -> 2479.44s]  It's just I got all this stuff to do I have to do it in this case
[2479.50s -> 2485.98s]  So this is this is where it would become CPU bound. That's that's what's going on there. Okay. All right
[2485.98s -> 2488.94s]  Let's actually run this if we run this
[2489.54s -> 2491.54s]  Let's do it this way
[2491.84s -> 2495.84s]  If we run this but this one is called oh
[2496.72s -> 2499.80s]  Let's see. Hang on for I want to cancel the server before
[2500.96s -> 2505.48s]  This one's called the expensive server. Okay, let me just run it and
[2506.36s -> 2512.44s]  It's saying statics file server listening on port one two, three, four five and this is myth 61
[2512.92s -> 2515.20s]  By the way, I did restart all the myths today
[2515.20s -> 2518.92s]  I had to go and like literally start half of them and they were all just sitting there dead. I don't know why
[2519.78s -> 2525.30s]  107 probably not because of you guys. Let's do this. Let us go to
[2526.70s -> 2528.50s]  myth
[2528.50s -> 2535.98s]  When I say it was myth 61 and it is port one three four five one three four five and hopefully there there is
[2536.62s -> 2540.74s]  The file so we are serving just this one file a million times and happens to be that
[2540.74s -> 2545.06s]  So if we go there and serve this file, we'll do that now what's happening in here?
[2545.06s -> 2546.20s]  And by the way, that was where it was
[2546.20s -> 2550.72s]  It was doing that if other people also wanted to connect that might go up if two people are connecting at the same time
[2550.72s -> 2558.16s]  But it's gonna go through pretty fast. Okay, what's happening right now? This is myth 61. Let's check something
[2559.40s -> 2561.88s]  Let's see SSH myth
[2565.40s -> 2566.68s]  61
[2566.68s -> 2571.64s]  Yes, oops. Yes, and each top we should say there we go
[2571.92s -> 2574.72s]  Take a look at what expensive server is doing right there
[2575.32s -> 2579.04s]  That one hundred percent is my expensive server. Why?
[2581.00s -> 2583.92s]  Why is my expensive server expensive
[2585.84s -> 2592.92s]  Okay, nobody's really requesting much data and what's it doing it is
[2594.76s -> 2598.00s]  Sitting here. Let's go back one slide. There we go
[2598.00s -> 2602.32s]  It's sitting here in this while loop not blocking on accept
[2602.32s -> 2606.18s]  So it's doing this while loop again and again and again and again and there's no data to serve
[2606.18s -> 2608.06s]  So this while loop is just going nuts
[2608.06s -> 2609.46s]  Okay, if we put a C out in there
[2609.46s -> 2611.78s]  We would see a whole bunch of C out statements just like we did before
[2611.94s -> 2617.14s]  But what it means is that it's that if we do a top we are getting there
[2617.14s -> 2622.52s]  It is a hundred percent of the work is on one core and some myth machine myth 60
[2622.60s -> 2624.86s]  Whatever this is is right now
[2624.86s -> 2631.56s]  The fans are starting to come on and whatever and some poor 107 student doesn't get their their heap allocator gun or whatever
[2632.42s -> 2638.30s]  So, so that's what that's what's happening there. So what do we want to do? We've got this feature
[2639.62s -> 2644.50s]  What did we do in the past when we wanted when we had to deal with this?
[2645.18s -> 2650.18s]  What did we do when we want to wait for something? Oh
[2652.58s -> 2659.50s]  We moved it off the processor, right so we have to have this is the same thing there we have to have
[2659.64s -> 2661.64s]  Another
[2661.64s -> 2666.12s]  Operating system support for this. Okay, and this is a thing called e-poll and
[2666.80s -> 2670.00s]  the e-poll family of system calls are basically
[2671.24s -> 2675.64s]  Waiting for file descriptors. Okay, so it's basically saying
[2676.80s -> 2678.80s]  instead of
[2679.16s -> 2683.92s]  Doing that while loop again and again and again and instead of blocking on it. We are going to
[2684.70s -> 2686.70s]  be able to
[2686.88s -> 2688.88s]  we're basically going to
[2688.94s -> 2690.50s]  go and
[2690.50s -> 2693.38s]  Call the function we want when something happens
[2693.62s -> 2699.70s]  So in other words we can we're going to do some sort of waiting if we have no data to send and we have nothing
[2699.70s -> 2704.86s]  Else going on. We are going to shut the processor down or at least our process down and we're going to do that
[2704.86s -> 2706.86s]  Okay, so there's a whole bunch of functions here. There's a
[2707.18s -> 2712.42s]  Create function that returns a file descriptor and it has this
[2713.10s -> 2715.10s]  Cloe exec thing which we've used before
[2715.78s -> 2718.18s]  and it sets sets up a
[2719.06s -> 2725.86s]  File descriptor that we won't that won't that will we will get alerted on as it turns out it has this watching
[2726.18s -> 2730.18s]  Facility which basically says what's happening whenever something changes
[2730.18s -> 2736.28s]  So if you're watching a network connection if data comes in it will get the waiting will stop
[2736.62s -> 2742.66s]  Okay, and you actually can call e-poll wait to do the waiting around. Okay, and
[2743.28s -> 2745.08s]  It's waiting
[2745.08s -> 2750.72s]  Until there's some timeout which the timeout you can set so that you can go do more work and whatever
[2751.12s -> 2753.00s]  Okay, so it's basically the same sort of idea
[2753.00s -> 2760.80s]  You've just now have more control over it than you would have from a blocking sort of server. Okay, there's a struct in here
[2761.28s -> 2766.44s]  There's this interesting C thing called a union anybody know what a union is
[2766.44s -> 2770.24s]  You probably never used unions in C before it's a pretty old
[2770.74s -> 2776.22s]  Concept and it goes back to when data was scarce like when you had to data was scarce
[2776.34s -> 2783.58s]  Here's what this is. By the way, a union says this data structure can hold either
[2784.18s -> 2790.78s]  something a void star or an int or a UN 32 T or a UN 64 T and
[2791.24s -> 2798.26s]  Whichever one you happen to have in there. It will be able to get out that data based on which which one of these
[2798.26s -> 2802.72s]  Which one of these variables that you use in there
[2802.72s -> 2808.28s]  So why does it do that so that you can store different types of data in the same amount of space, right?
[2808.28s -> 2815.08s]  It's going to allocate enough for the entire the biggest thing even though you might only be using a 4-byte
[2815.32s -> 2820.36s]  Int right you can have it'll have enough space for a 64 byte int
[2821.04s -> 2825.32s]  But it won't but it's but it doesn't need to have a different one for each one
[2825.32s -> 2827.32s]  So doesn't have to have four in there. It's just got one
[2827.46s -> 2830.66s]  Go look up unions and why they're used you don't see them too often
[2830.66s -> 2833.44s]  But when you do you have to kind of understand what they what they do
[2834.22s -> 2841.26s]  Okay, we'll hold a single type of data out of a data types. Okay, what kind of events can we listen for?
[2841.42s -> 2846.46s]  Okay, and this by the way goes but this is now event based things and this is we've seen events before
[2847.06s -> 2851.52s]  When we have when we have signal handlers, though, that's an event based model
[2851.52s -> 2857.22s]  But in this case we can say for a file the a file is available for reading or it's available for writing
[2857.86s -> 2861.66s]  and we can also have it what's called edge triggered and if you
[2862.06s -> 2867.92s]  Saw us if you took cs107e you would have heard of edge triggered before but that means that you actually
[2868.54s -> 2869.82s]  get
[2869.82s -> 2877.50s]  Like an event on a change in the descriptor. Okay versus what like what type of data you're looking for
[2877.50s -> 2881.94s]  This is saying hey, I want to do it when I get the data. Okay, so
[2882.50s -> 2886.46s]  What are we gonna do? We are going to set this up now
[2887.28s -> 2889.68s]  Where we have the
[2890.88s -> 2897.76s]  The server itself main is not really going to change. Okay for this server. It's going to set up the socket and
[2899.00s -> 2904.20s]  With create software server socket in this case, and then it is going to run this server
[2904.20s -> 2911.32s]  So this is just kind of abstracting in a way decomposing it a little bit. Okay run server is going to set things as non blocking
[2912.02s -> 2916.46s]  Okay, and then it sets this watch set of what we're blocking
[2917.42s -> 2923.58s]  It's going to build the watch set which I will see in a second based on that server socket that we have
[2923.98s -> 2927.14s]  Okay, what's happening with the build initial watch set?
[2927.14s -> 2934.82s]  We are setting up some e-poll in other words to watch for that thing changing. Okay, and then there's some other
[2935.70s -> 2940.86s]  it's basically setting up the the union and the struct there in this case the struct and
[2941.34s -> 2944.10s]  Then it's calling this e-poll control to set it up
[2944.34s -> 2949.40s]  think of it in a very similar way to SIG suspend how you have to do the six the
[2950.22s -> 2954.94s]  Set just have to set up the signals that you want to block and so forth same idea
[2955.50s -> 2959.02s]  Different topic but basically same exact idea and again
[2959.02s -> 2962.08s]  I'm not asking you to memorize this stuff right now or know how to use it
[2962.08s -> 2964.08s]  But just know that it's possible to do this
[2964.66s -> 2966.66s]  Okay. All right
[2967.64s -> 2974.76s]  The next thing we're going to do is we're actually going to still do our while true we're going to have these events we are going to
[2975.60s -> 2977.60s]  have the number of events
[2977.84s -> 2982.16s]  Get triggered by this weight thing here
[2982.16s -> 2986.52s]  Okay, we might have a timeout on there to say just wait until there's a timeout so that we can go do data
[2986.80s -> 2992.84s]  As well, you don't want to time it out, but it could timeout and if it does well
[2992.86s -> 2996.22s]  It'll just go on and do the next next part, okay
[2996.34s -> 3002.98s]  you can actually get many events triggered at exactly the same time think of it as the same thing as the child process getting a
[3004.34s -> 3010.74s]  Weight PID where it returns multiple things. So you should have you should handle all the events here. Okay, and
[3012.58s -> 3018.22s]  When you get them triggered we handle the events one at a time using a for loop
[3018.22s -> 3021.70s]  so basically the events get triggered we find those events and then we go and
[3022.32s -> 3024.32s]  And deal with them
[3024.36s -> 3026.04s]  okay, and
[3026.04s -> 3033.08s]  If you get an event, then you can actually in this case like consume the data read from the file descriptor
[3033.08s -> 3036.22s]  You're saying hey, what did you want to tell me right and then it will do that
[3036.22s -> 3042.46s]  And then you can publish the response if you don't have things to read in if you're just trying to to write it out
[3042.76s -> 3045.48s]  Okay, so what else is this and there's a lot of code here
[3045.48s -> 3050.16s]  I know this is a lot of code that you have to do, but you have to see but basically we are
[3051.10s -> 3054.30s]  Setting up the except there's a new except call by the way
[3054.94s -> 3060.98s]  Called except for which has this non-block parameter thing on there. Yeah mark, of course. Oh, sorry. Good
[3065.14s -> 3070.22s]  Yeah, well you'll see in a second why this is still non blocking it's not waiting in the same sense
[3070.22s -> 3071.86s]  it's basically you're
[3071.86s -> 3073.86s]  You're doing it so that it's allowing
[3074.46s -> 3080.14s]  How should I put it? It's it's not it's if you it's not going and
[3081.06s -> 3083.10s]  Blocking on the except call you're still doing that
[3083.10s -> 3086.42s]  It's just not going to have to call as many it's not gonna have to go through this loop as many times
[3086.74s -> 3090.66s]  You'll see when we get a little bit farther along good. Good question on this, okay
[3092.02s -> 3097.70s]  We again we do this is all set up and setting up the watch list and and setting up the
[3098.50s -> 3101.24s]  The except and so forth. Okay, so
[3103.90s -> 3108.78s]  The consumer available data part is where it's going to basically do the
[3109.48s -> 3112.84s]  Get the connection. Okay, and we're going to set the connection up
[3113.48s -> 3115.54s]  And we're going to set the connection up
[3116.04s -> 3118.28s]  at that point, okay, and
[3119.20s -> 3125.68s]  It is going to and then we're also going to be able to do that's just setting up the connection and getting the the request
[3125.68s -> 3127.86s]  and then we are going to
[3129.12s -> 3131.12s]  let's see do the
[3132.60s -> 3136.36s]  Where's here we're going to yeah still take care of the requests
[3136.54s -> 3139.26s]  Okay, and we may have a whole bunch of active connections
[3139.62s -> 3142.90s]  Okay that we have to do and we kept that in a map and and so forth
[3144.02s -> 3146.02s]  okay, and then
[3146.06s -> 3148.38s]  we will actually change the
[3149.18s -> 3155.10s]  Event based on whether or not we've already have connections again these details go look at the slides
[3155.10s -> 3160.30s]  I don't want to go into all the details about the the how this this works under the hood
[3161.10s -> 3163.86s]  But we basically are going to get
[3164.84s -> 3170.96s]  Requests or get the events happening and the kernel is going to handle this for us. Okay, so
[3171.60s -> 3174.96s]  Where do we get here publish response? This is where we're going to actually in this case
[3174.96s -> 3179.36s]  we're going to take do an actual website that we're going to respond with instead of the
[3179.80s -> 3184.90s]  Instead of that file in this case and the publishing the response is going to
[3185.56s -> 3190.90s]  For all the different places that we need to send data send a little bit of data at a time using the right
[3191.84s -> 3193.84s]  Man okay, and it's only going to send
[3194.96s -> 3200.08s]  Let's see. I believe it might act. Let's see. It's going to try to send
[3200.08s -> 3204.40s]  I think it actually tries to send all of it at once here, but but that's that
[3204.96s -> 3212.44s]  And then after it sends all the data it needs to close the client. Okay, where does that like? What's the whole point?
[3212.44s -> 3214.44s]  What's the whole point here? Okay
[3215.26s -> 3217.26s]  In this case
[3217.30s -> 3223.82s]  Let's see. It's not blocking in the same. So we've left it. We've let the kernel handle the
[3224.38s -> 3226.94s]  events for us and in our case
[3226.94s -> 3230.14s]  We are still able to do the extra work that we want to
[3230.28s -> 3236.58s]  While the kernels waiting around for data to either come in or whatever or not. Okay, so it's not stopping us
[3237.22s -> 3243.02s]  From handling this but when there isn't any data to send or receive we just that we do shut down
[3243.16s -> 3244.80s]  We don't need to go back to that while loop
[3244.80s -> 3250.94s]  So in some sense, it's it's blocking in the sense that if there's nothing to be done our process turns off
[3251.48s -> 3255.52s]  Right, but if we have anything to do either sending or receiving data
[3255.76s -> 3261.00s]  It will be triggered by the fact that there is the kernel waiting telling us going
[3261.00s -> 3263.64s]  Oh, you've got more stuff to send go send it
[3263.64s -> 3266.72s]  You've got more stuff to receive got a client connection coming in do that
[3266.72s -> 3270.04s]  So the the while loop will not just continue spinning like that
[3270.06s -> 3275.10s]  It will actually block in the same block on more than one thing and that's really the big idea
[3275.10s -> 3279.34s]  Is that it's kind of blocking on both sending the data to all our different things
[3279.34s -> 3284.86s]  If there's no data to send it will just wait around or if there's no accepting connections to accept
[3284.86s -> 3288.02s]  Does that make sense Amy to your to your why is it not blocking anymore?
[3288.02s -> 3294.14s]  It's kind of blocking in the sense that it's it's not blocking but it's basically saying now we can wait for two things at
[3294.14s -> 3299.98s]  Once whether we have to send or receive not just wait and check again and again and again to see if we have
[3300.46s -> 3303.38s]  So we're setting up these events to say we've got two events
[3303.38s -> 3309.14s]  Well, we've got at least one event which is accepting clients and depending on how many clients request the data
[3309.42s -> 3312.94s]  Then we've got many more we've got other things to do as well
[3313.42s -> 3316.30s]  every time we are able to send that the
[3317.02s -> 3320.98s]  The e-poll will actually call the right function to do that the work for us
[3320.98s -> 3325.42s]  so our our main function can just sit there and
[3325.96s -> 3330.68s]  The we let the kernel tell us when to send and receive data, that's the big difference
[3330.96s -> 3333.08s]  So that's why it's not not blocking anymore
[3333.08s -> 3338.68s]  We've leveraged the fact that the kernel will handle that waiting for us and our main thread doesn't need to do anything
[3338.76s -> 3340.48s]  Could we do more work? Yeah, sure
[3340.48s -> 3343.56s]  We can continue to do more work and now we're still waiting for two things at once
[3343.68s -> 3348.88s]  But it's just abstracting it away a little bit. That's all and I know there's a lot a lot going on here
[3349.44s -> 3353.08s]  To see that and the day that the code you can go and read through the code to do that
[3353.86s -> 3355.86s]  Here's the bottom line
[3355.86s -> 3360.54s]  Okay, the bottom line here is there are lots of ways to build a server
[3361.22s -> 3366.80s]  Okay, we've seen a a number of different ways to do this. Okay, we can build a
[3367.54s -> 3371.02s]  Threaded server we can build a non threaded server and just kind of hope for the best
[3371.14s -> 3375.46s]  We can build a threaded server that uses threads or uses thread pool to do that
[3375.90s -> 3381.82s]  Which does we do know that they're going to be some blocking calls and it's fine to do that again
[3381.84s -> 3384.48s]  It's just maybe it's a different strategy to do that
[3385.28s -> 3391.96s]  but we've now seen another one where you let the kernel tell you when data needs to be sent or received and
[3392.64s -> 3396.52s]  Then it will that'll work in a different way before I go on to more details
[3396.52s -> 3399.68s]  Let me show you what this actually looks like
[3400.48s -> 3403.00s]  in this case, this is the
[3403.90s -> 3405.90s]  Let's see. We've got the
[3406.84s -> 3407.84s]  a
[3407.84s -> 3412.88s]  Efficient server I believe is what it is. It's going to listen on port 3 3 3 3 3 and if we go to
[3413.04s -> 3415.04s]  What was it myth 61 again?
[3415.80s -> 3417.80s]  myth Smith
[3418.44s -> 3424.72s]  Myth there we go. 61 3 3 3 3 3 it's going to serve us this website, right?
[3424.72s -> 3428.54s]  It happened to be a website where it tells that and went and pulled the the image from somewhere and whatever
[3428.56s -> 3433.86s]  But you would be able to do that many times and for every browser window that's open
[3433.88s -> 3437.98s]  It will just feed a bit at a time and I think even if all of us in here
[3438.04s -> 3440.84s]  Tried to load that one page at the exact same time in our browsers
[3440.84s -> 3445.08s]  You probably wouldn't see much of a slowdown because it's just sending one or two bytes of time
[3445.08s -> 3449.70s]  But I'm doing it very fast to all of you. So that's how that that's that's what's going on there
[3450.48s -> 3452.48s]  Okay, so where?
[3453.24s -> 3455.24s]  Where does that leave us in the big picture?
[3455.88s -> 3460.74s]  When you're building a server when you're doing anything and this is hopefully one of the big takeaways of this class
[3461.00s -> 3465.88s]  It depends on your own system setup what operating system are using
[3465.88s -> 3472.30s]  Maybe you're using an operating system doesn't support this event driven model. Well, too bad. All right Linux happens to support it, right?
[3472.32s -> 3476.68s]  Maybe you have a computer that has a really fast network card and there's less waiting
[3476.68s -> 3479.20s]  You're gonna have to do on that or maybe it's got multiple network cards or whatever
[3479.72s -> 3485.92s]  What about the network itself? What if you are trying to serve a website through like your phone's data plan, right?
[3485.92s -> 3491.62s]  You might have a totally different idea of the best way to do that based on the actual platform
[3491.62s -> 3496.44s]  So it's all about trade-offs and it's all about how you could do that the big idea with the server
[3496.90s -> 3500.18s]  Accept is and respond to as many connections as you can
[3500.78s -> 3509.02s]  That's the big idea and respond as quickly as you can to client requests. Okay, don't block the accept and don't
[3510.00s -> 3511.64s]  Serve too slowly
[3511.64s -> 3517.00s]  That's those are the big ideas and that's the the basic idea of any server when you're setting it up
[3517.00s -> 3522.76s]  Okay, you want to respond quickly and you want to accept and you don't want to block the the user, okay
[3525.56s -> 3531.00s]  Don't write a server that busy waits because we don't like busy waiting because it makes the fans on our computer turn on
[3531.20s -> 3535.26s]  Right. We don't like that and we're gonna just wasted CPU time and energy and so forth
[3535.48s -> 3540.14s]  Okay, but you have to understand some of these low-level ideas when you're making this choice
[3540.56s -> 3545.28s]  Some of you will undoubtedly go to companies that do networking as their core business, right?
[3545.28s -> 3550.00s]  Some of you might end up in Cisco or some other company that has lots of networking, right?
[3550.00s -> 3556.44s]  That's happening at our Amazon Web Services or something like that and you'll have to understand some of this low-level stuff, right?
[3556.44s -> 3559.28s]  why do you avoid busy waiting and so forth and
[3560.46s -> 3563.08s]  Do you need to know all the details like all that stuff? I just flew through
[3563.14s -> 3569.74s]  Well, it depends but you will if you get into that take CS 144 if you if you want to do that
[3569.96s -> 3574.66s]  Okay, and you have to be smart about this too, by the way, right? This is a great comic
[3574.66s -> 3576.66s]  I love this comic because
[3576.66s -> 3582.50s]  It it's one of the xkcd comics that basically it's this server that says hi
[3582.50s -> 3586.50s]  I'm a server have you ever done this where you go to a web page on your web on your phone and
[3586.78s -> 3591.26s]  The server basically gives you tries to give you the mobile version of the website
[3591.26s -> 3595.10s]  But it doesn't take you to the right page takes you to like it's the main website
[3595.10s -> 3598.48s]  Then you're like this is exactly what's going on here, right? Oh boy. Can I help? Let me get it
[3598.48s -> 3602.18s]  Oh, you're a smartphone browser your browser tells the web server
[3602.18s -> 3605.38s]  What kind of browser it is, by the way, and you can spoof it in some cases, too
[3605.38s -> 3610.90s]  You can pretend that you're a regular computer browser, even though you're on your phone. Sometimes that's a good way to do it
[3610.90s -> 3614.74s]  I don't know if the main browsers let you do that now, but they might
[3616.38s -> 3619.82s]  You have to do sometimes you have to delete the end but it's more than that
[3619.82s -> 3627.38s]  Actually, the reason the M shows up is because the browser that your phone's browser says, oh, I'm a web. I'm a phone
[3628.10s -> 3630.74s]  Right and the and the client or the server goes
[3630.74s -> 3635.56s]  Oh, I better give you the paired down version even though your phones have regular full browsers on them
[3635.56s -> 3641.26s]  So anyway in this case this server says hey, I've got this new mobile version and
[3641.96s -> 3643.52s]  The phone goes wait a minute
[3643.52s -> 3648.62s]  You're giving me the main page and then the server just resets because it has no it's kind of dumb like that
[3648.62s -> 3654.10s]  So build your servers smart if you're gonna build servers, right? Don't try to be too fancy with them
[3654.10s -> 3661.38s]  Even though you've got new things like browsers and your watch browsers and so forth and it's it's their trade-offs
[3661.38s -> 3665.78s]  But be smart about that. Okay. All right, so we are a little early which is great
[3667.74s -> 3671.66s]  As I said at the beginning of class you guys made it through a difficult class
[3671.98s -> 3672.98s]  You
[3672.98s -> 3678.78s]  Can argue whether this class is more or less difficult than cs107 or cs103 or whatever
[3678.78s -> 3682.14s]  But it if you weren't challenged by this class
[3682.34s -> 3687.54s]  You're a smarter person than me because this is I think a challenging class. You should give yourself a pat on the back for
[3688.14s -> 3691.46s]  Doing well and making it through all these crazy long
[3691.66s -> 3696.26s]  Assignments with 15 pages of reading and a hundred files to look through and so forth
[3696.78s -> 3698.78s]  If you want to take more
[3699.08s -> 3703.24s]  Systems classes there are tons of them. If this was the last systems class you ever did
[3703.24s -> 3709.22s]  Well, you shouldn't congratulate yourself on being done with that too. Um, and and go do your AI stuff and whatever
[3710.18s -> 3711.62s]  but
[3711.62s -> 3716.48s]  And did I tell you about Chris peach telling me that how important systems is to AI these days?
[3716.50s -> 3723.28s]  And so Chris peach who you many of you know does AI research and CS education AI research
[3723.52s -> 3730.84s]  And he was talking about with me the other day about the fact that all of the AI that's done now uses
[3731.12s -> 3733.52s]  GPUs and tensorflow and all these kind of
[3734.56s -> 3741.66s]  Systems II things to do AI and he says I wish I paid more attention in 110 in those systems classes
[3741.66s -> 3744.68s]  Or maybe I wish I'd I wish I'd taken a parallel processing course
[3744.68s -> 3748.04s]  So I I could dig in a little bit more to figure out what's going on
[3748.04s -> 3751.84s]  Or at least I understood a little bit more about how this works. So systems is not
[3752.44s -> 3756.12s]  Something that you necessarily you can do a lot of stuff without knowing much systems at all
[3756.20s -> 3761.02s]  But you can definitely inform what you're doing in almost any field by understanding a little bit more about
[3761.32s -> 3768.56s]  Some of the decisions that are made and so forth. So so let's I'll leave you with with that thought you guys are great
[3768.56s -> 3771.88s]  Thank you for beer bearing with me during my first quarter teaching this all alone
[3771.88s -> 3775.46s]  I apologize if there were mistakes along the way, but you guys are great
[3775.46s -> 3781.72s]  I will see you on Monday at the final or during the office hours today and tomorrow and thank you
[3781.84s -> 3783.84s]  very much
