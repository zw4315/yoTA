# Detected language: en (p=1.00)

[0.00s -> 4.58s]  When the internet was first designed, it was based on a controversial and revolutionary
[4.58s -> 6.68s]  idea – packet switching.
[6.68s -> 10.24s]  Nowadays, it seems straightforward and the obvious way to build networks.
[10.24s -> 11.72s]  But that wasn't always the case.
[11.72s -> 16.04s]  It's a very simple idea, but of course as it is with simple ideas, there are many
[16.04s -> 18.76s]  interesting implications that arise once you put it into practice.
[18.76s -> 22.56s]  We'll spend an entire week of the course on packet switching and its implications,
[22.56s -> 28.92s]  but in this video we present the high-level idea and its immediate benefits.
[28.96s -> 33.12s]  A packet is a self-contained unit of data that carries information necessary for it to reach
[33.12s -> 35.68s]  its destination.
[35.68s -> 40.28s]  Packet switching is the idea that we break our data up into discrete, self-contained
[40.28s -> 41.72s]  chunks of data.
[41.72s -> 45.14s]  Each chunk called a packet carries sufficient information that a network can deliver the
[45.14s -> 48.12s]  packet all the way to its destination.
[48.12s -> 51.60s]  So let's say we have a source and a destination, and a network of packet switches A, B and
[51.60s -> 53.52s]  C between them.
[53.52s -> 57.92s]  When A receives a packet for the destination, it sends it along the link to B.
[57.92s -> 61.64s]  When B receives a packet for the destination, it sends along to C.
[61.64s -> 67.16s]  When C receives a packet for the destination, it sends it to the destination directly.
[67.16s -> 71.24s]  In the simplest form of packet switching, each packet is routed separately and independently.
[71.24s -> 75.40s]  For example, let's say there is another switch connected to B called D.
[75.40s -> 80.00s]  Immediately after sending a packet to C, B can send the next packet to D.
[80.00s -> 84.00s]  Or if the next packet were also to the destination, it would send two packets back
[84.00s -> 84.96s]  to back to C.
[84.96s -> 89.48s]  Here's a simple definition of packet switching.
[89.48s -> 95.44s]  It means that independently, for each arriving packet, we pick its outgoing link.
[95.44s -> 97.60s]  If the link is free, we send it.
[97.60s -> 101.64s]  Else we hold the packet for later.
[101.64s -> 104.36s]  Here's one example of how packet switching can work.
[104.36s -> 108.62s]  Each packet contains an explicit route, specifying the IDs of each packet switch along the
[108.62s -> 110.48s]  way all the way to the destination.
[110.48s -> 115.76s]  We call this self-routing, or source routing, because the source specifies the route.
[115.76s -> 122.72s]  When the source sends a packet, it puts in the packets A, B and C, and then the destination.
[122.72s -> 126.74s]  It forwards the packet to A. A looks inside the header and sees the next hop is B, so
[126.74s -> 132.20s]  it forwards the packet to B. B sees the next hop is C, and C sees the last hop is
[132.20s -> 133.20s]  the destination.
[133.20s -> 138.44s]  Turns out the Internet supports this source routing, but it's generally turned off because
[138.44s -> 140.84s]  it raises big security issues.
[140.84s -> 145.56s]  One simple optimization, and what the Internet mostly does today, is to place a small amount
[145.56s -> 150.04s]  of state in each switch, which tells it which next hop to send packets to.
[150.04s -> 154.60s]  For example, a switch can have a table of destination addresses and the next hop.
[154.60s -> 158.92s]  When it receives a packet, it looks up the address in the table and sends the packet
[158.92s -> 161.16s]  to the appropriate next hop.
[161.16s -> 166.32s]  In this model, all the packets need to carry is the destination address.
[166.32s -> 169.36s]  Using the address, each switch along the way can make the right decision.
[169.36s -> 173.66s]  For example, in our network here, A's table says that packets to destination should go
[173.66s -> 178.80s]  to switch B. Switch B's table says packets to destination should go to switch C, and
[178.80s -> 181.60s]  so on.
[181.60s -> 183.80s]  Packet switching has two really nice properties.
[183.80s -> 187.94s]  The first is that a switch can make individual, local decisions for each packet.
[187.94s -> 190.86s]  It doesn't need to keep extra state on the packets it's seen, or whether two packets
[190.86s -> 192.88s]  go to the same destination.
[192.88s -> 196.76s]  Even if many packets are part of some larger transfer or protocol, the switch doesn't
[196.76s -> 198.04s]  need to know or care.
[198.04s -> 201.08s]  The switch doesn't need to know that some packets are a Skype call, others are a web
[201.08s -> 203.92s]  request, and others still are a firmware update for your computer.
[203.92s -> 205.56s]  It just forwards packets.
[205.56s -> 208.94s]  This greatly simplifies the switch.
[208.94s -> 213.98s]  The second is that it lets a switch efficiently share a link between many parties.
[213.98s -> 217.44s]  For example, consider a wireless router in a home with two people browsing the Internet
[217.44s -> 219.32s]  on their laptops.
[219.32s -> 222.96s]  If one person is reading a page, then the other person can download a file at the full
[222.96s -> 224.68s]  speed of the link.
[224.68s -> 227.88s]  If the first person starts loading a web page, the link can be shared between two
[227.88s -> 228.88s]  of them.
[228.88s -> 233.24s]  Once the download completes, the first person can use the full speed of the link.
[233.24s -> 236.40s]  These two points are really important, so I'll go into some greater detail on both
[236.40s -> 238.14s]  of them.
[238.14s -> 241.56s]  Of course, when we communicate, we don't usually send only one packet.
[241.56s -> 242.56s]  We send many.
[242.56s -> 246.20s]  For example, a voice call consists of many consecutive packets, all part of the same
[246.20s -> 247.50s]  communication.
[247.50s -> 250.34s]  We call this sequence of packets a flow.
[250.34s -> 254.82s]  More specifically, a flow is a collection of datagrams belonging to the same end-to-end
[254.82s -> 261.46s]  communication – for example, a TCP connection.
[261.46s -> 268.18s]  Let's first of all look at how each packet is routed independently.
[268.18s -> 271.42s]  Because each packet is self-contained, a switch doesn't need to know about groups of packets
[271.42s -> 272.92s]  or flows.
[272.92s -> 276.62s]  Imagine if every switch had to keep track of every single web connection passing through
[276.62s -> 277.62s]  it.
[277.62s -> 281.14s]  This would require a huge amount of state that would be really hard to manage.
[281.14s -> 285.26s]  Instead, treating each packet independently means the switch can be much simpler to build,
[285.26s -> 287.54s]  manage and troubleshoot.
[287.54s -> 291.34s]  The switch doesn't need to worry about adding or removing the per-flow state.
[291.34s -> 294.12s]  Imagine if every time you wanted to load a web page, you had to communicate with
[294.12s -> 297.88s]  every switch along the path just to set up the state so that your request could
[297.88s -> 299.66s]  get through.
[299.66s -> 301.54s]  This could make things much, much slower.
[301.54s -> 307.54s]  Instead, you can just send packets and the switches forward them appropriately.
[307.54s -> 310.46s]  The switches also don't need to store this state.
[310.46s -> 313.98s]  Because switches have to be really fast, they need to store this state in very fast
[313.98s -> 316.98s]  memory, which would be expensive.
[316.98s -> 322.94s]  This lets switches focus on doing just one thing – forwarding packets quickly and efficiently.
[322.94s -> 327.06s]  Finally, it means switches don't have to worry about failures.
[327.06s -> 331.14s]  Imagine, for example, what happens when you start a web request, but then your tablet
[331.14s -> 333.60s]  runs out of energy.
[333.60s -> 336.66s]  The switch is going to keep the per-flow state for the request, but if one of the
[336.66s -> 340.34s]  nodes that created the state fails, the switch needs to know how to clean up after
[340.34s -> 341.34s]  it.
[341.34s -> 345.30s]  Otherwise, you could have millions, billions, or however many of dead flows eating up
[345.30s -> 346.42s]  your memory.
[346.42s -> 349.22s]  With packet switching, a switch has no per-end point state.
[349.22s -> 351.90s]  If your tablet dies, the switch doesn't care.
[351.90s -> 354.90s]  It just means that it stops receiving packets from it.
[354.90s -> 358.22s]  In this way, the switch is more functionally independent of the computers sending traffic
[358.22s -> 360.62s]  through it.
[360.62s -> 362.68s]  Think about how you typically use the internet.
[362.68s -> 364.66s]  Your use is bursty.
[364.66s -> 367.58s]  You load a web page, then read it, then load another one.
[367.58s -> 370.18s]  You download a few songs from iTunes, then listen to them.
[370.18s -> 373.58s]  You stream a show from Netflix for 45 minutes, then stop.
[373.58s -> 375.10s]  Data traffic is bursty.
[375.10s -> 379.22s]  Rather than always sending and receiving data at a fixed rate, usage jumps and drops
[379.22s -> 382.34s]  goes up and down over time.
[382.34s -> 386.02s]  While there are large-scale changes in peaks in data traffic – 3 pm in the afternoon
[386.02s -> 390.26s]  is typically high, as is 8 pm, while 2 in the morning is low – on a smaller
[390.30s -> 393.78s]  scale, it is very bursty, and these bursts are often independent.
[393.78s -> 397.46s]  Let's say you and your friend are both browsing the web in a coffee shop.
[397.46s -> 401.26s]  When you load a new page, and when your friend loads a new page, are mostly independent.
[401.26s -> 403.70s]  Sometimes you might overlap, but often they won't.
[403.70s -> 408.46s]  By treating all of your traffic as just packets, the wireless router can very effectively
[408.46s -> 411.18s]  and simply share its capacity between you.
[411.18s -> 414.10s]  If you're loading a page when your friend is reading, the wireless router can give
[414.10s -> 415.98s]  all of its capacity to your packets.
[415.98s -> 419.30s]  Similarly, if your friend is loading a page and you're reading, the router can give
[419.34s -> 421.50s]  all of its capacity to your friend's packets.
[421.50s -> 424.26s]  The link doesn't need to go partially idle because one of you isn't using it,
[424.26s -> 428.50s]  and if you're both using it, then the link can be shared between you.
[428.50s -> 433.26s]  This idea of taking a single resource and sharing it across multiple users in a probabilistic
[433.26s -> 436.34s]  or statistical way is called statistical multiplexing.
[436.34s -> 441.38s]  It's statistical in that each user receives a statistical share of the resource based
[441.38s -> 442.90s]  on how others are using it.
[442.90s -> 445.90s]  For example, if your friend is reading, you can use all of the link.
[445.90s -> 450.62s]  If both of you are loading a page, you receive half of the link capacity.
[450.62s -> 453.90s]  So there are two major benefits of packet switching.
[453.90s -> 458.60s]  First it makes the switches simple, because they don't need to know about flows of packets.
[458.60s -> 465.74s]  And second, it lets us efficiently share the capacity among many flows sharing a link.
[465.74s -> 469.42s]  This simple building block was revolutionary at the time, but it's now accepted as
[469.42s -> 471.70s]  the common way to build networks.
