# Detected language: en (p=1.00)

[0.00s -> 5.76s]  So why does this matter? If two computers are going to communicate, they need to agree
[5.76s -> 11.18s]  on whether they represent numbers using big-endian or little-endian formats. This is complicated
[11.18s -> 16.96s]  by the fact that different processors use different endianness. For example, x86
[16.96s -> 21.76s]  processors from Intel and AMD are little-endian, the least significant byte comes first.
[21.76s -> 25.36s]  ARM processors, in contrast such as those used in the iPhone, are big-endian, where
[25.36s -> 28.40s]  the most significant byte comes first.
[28.40s -> 33.56s]  We don't want two computers to care or know whether the other side is big-endian or little-endian.
[33.56s -> 37.68s]  So protocol specification bodies typically pick one and stick with it. For the internet,
[37.68s -> 42.52s]  this means big-endian. All protocols that are internet specifications use a big-endian
[42.52s -> 43.52s]  format.
[43.52s -> 48.04s]  Here's an example snippet of C code that will tell you whether your computer is big-endian
[48.04s -> 52.12s]  or little-endian. It tastes like 16-byte value and casts a pointer to it that lets
[52.12s -> 57.92s]  the code look at the bytes individually. If the byte at index 0 is 0x40, this means
[57.96s -> 62.80s]  the most significant byte comes first and the computer is big-endian. If the byte at
[62.80s -> 66.04s]  index 1 is 0x40, then it's little-endian.
[66.04s -> 71.56s]  But wait, this creates a complication. You need an internet packet to be in big-endian
[71.56s -> 75.60s]  format, but what if your processor is little-endian? Let's say, for example, that you want to
[75.60s -> 80.40s]  set the port number of TCP segment to be 80, the HTTP port. A simple way to do this
[80.40s -> 84.92s]  might be to create a C struct that has a fueled port at the right offset. But if you
[84.92s -> 90.88s]  use a value 80 to compare with the port field, that 80 will be stored little-endian with
[90.88s -> 96.92s]  0x50 as the first byte. Big-endian needs 0x50 stored in the second byte, so although
[96.92s -> 102.68s]  the port field in the segment is 80 and you have 80 as your value, this test will
[102.68s -> 104.08s]  fail.
[104.08s -> 108.04s]  To make this easier, C networking libraries provide utility functions that convert between
[108.04s -> 114.32s]  host and network order. The function h2ns, for example, takes a host short, a 16-bit
[114.32s -> 120.20s]  value, as a parameter and returns a value in network order. There's also functions
[120.20s -> 125.72s]  for converting a network short to a host short and functions for longs, 32-bit values.
[125.72s -> 130.20s]  So the right way to test whether the packet port is 80 is to read the port field with
[130.20s -> 136.44s]  packet structure and call n2hs to convert it from network order to host order. You
[136.44s -> 141.40s]  can then compare it with 80 and get the correct result. In the case of a little-endian
[141.40s -> 146.68s]  architecture, n2hs and h10s reverse the order of the two bytes. In the case of a big-endian
[146.68s -> 151.12s]  architecture, they just return the value unchanged.
[151.12s -> 154.60s]  These functions provide you the mechanisms by which you can write networking code that's
[154.60s -> 160.12s]  independent of your processor architecture. But be careful. I can't stress this enough.
[160.12s -> 165.08s]  Be careful whenever you handle network data. If you aren't principled and rigorous about
[165.08s -> 168.88s]  when you translate between host and network order, you'll give yourself a tremendous
[168.88s -> 173.72s]  headache because you've forgotten to convert or inadvertently converted twice and suddenly
[173.72s -> 177.92s]  your protocol is behaving wrongly or triggering all kinds of weird bugs. I've certainly
[177.92s -> 182.84s]  done this many times and so you won't want to avoid it as much as you can.
[182.84s -> 187.00s]  Now that we know how internet specifications lay out multibyte values in network order
[187.00s -> 191.96s]  or big-endian, we can look at how internet specifications describe their packet formats.
[192.00s -> 197.68s]  For historical reasons, internet specifications are written in plain ASCII text. The block
[197.68s -> 204.00s]  text on the left is taken verbatim from Request for Commons RFC 791, which specifies
[204.00s -> 210.56s]  the Internet Protocol Version 4, or IPv4. The top shows the bits from 0 to 31. Packets
[210.56s -> 216.24s]  are written four bytes wide. Since IPv4 has five rows of required fields, this means
[216.24s -> 221.16s]  that an IPv4 header is at least 20 bytes long. Nick and I often use a simpler visual
[221.16s -> 224.60s]  format when we show packets, like the one on the right.
[224.60s -> 230.12s]  To use this as an example, the total length field of an IPv4 packet is 2 bytes or 16
[230.12s -> 234.56s]  bits long, as you can see in the upper right. This means that an IPv4 packet can't
[234.56s -> 241.36s]  be longer than 65,535 bytes. That field in the packet is stored big-endian. A packet
[241.36s -> 247.32s]  length of 1400 bytes is stored as 0x578, so the third byte of an IP packet of that
[247.32s -> 250.12s]  length is 0x05.
[250.12s -> 255.56s]  Let's see this in Wireshark. I'm just going to start Wireshark and listen for packets.
[255.56s -> 259.48s]  This first packet is for something called TLS, or Transport Layer Security. It's what
[259.48s -> 264.92s]  web browsers use for secure connections, HTTPS. TLS hides the data of the packet
[264.92s -> 270.36s]  from us, but we can still see its headers. Using Wireshark, we can see that a TLS payload
[270.36s -> 276.60s]  is inside a TCP segment to port 443, the standard TLS port. This TCP segment is inside
[276.60s -> 281.96s]  an IPv4 header. Looking in detail at the IPv4 header, we can see that the packet's
[281.96s -> 292.96s]  total length field is 1230. The hexadecimal for 1230 is 0x04ce, 1024, or 4 times 256,
[292.96s -> 299.52s]  plus 106, or 0xce. At the bottom, Wireshark shows us the actual bytes of the packet,
[299.52s -> 305.48s]  and there it is, 04ce, in big-endian, or network order.
[305.48s -> 309.28s]  We've seen how different processors lay out numbers differently. But since network particles
[309.28s -> 313.92s]  need to agree, protocol specifications decide how the numbers are laid out in their packets,
[313.92s -> 317.76s]  which can differ from your processor. To help you with this, see networking libraries
[317.76s -> 323.08s]  provide helper functions that convert between hosts and network order. But use them carefully.
[323.08s -> 326.64s]  Using them haphazardly can easily lead you to many lost hours of debugging, which
[326.64s -> 330.36s]  can be prevented by being careful when you start and deciding on a principled approach
[330.36s -> 331.56s]  to converting in your code.
