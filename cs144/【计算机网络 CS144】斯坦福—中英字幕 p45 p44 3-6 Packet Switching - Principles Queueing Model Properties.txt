# Detected language: en (p=1.00)

[0.00s -> 4.58s]  Continuing with our theme of packet switching, in this video I'm going to tell you about
[4.58s -> 6.62s]  some useful probabilities of queues.
[6.62s -> 10.28s]  These are going to come in handy whenever we're thinking about how a queue evolves,
[10.28s -> 17.40s]  how a packet buffer changes to affect the queuing delay of packets through a network.
[17.40s -> 21.80s]  As we've seen before, we can think of a network as a set of queues interconnected
[21.80s -> 26.22s]  by some links, and those links are carrying the traffic or the packets from many, many
[26.22s -> 27.86s]  different users.
[27.86s -> 32.38s]  And when multiplexed together, when statistically multiplexed together, that whole process of
[32.38s -> 35.18s]  packet arrivals is very, very complicated.
[35.18s -> 39.38s]  So we usually think of the arrival processes as being random events.
[39.38s -> 43.46s]  Each one was of course deterministically generated, but the aggregate we can think
[43.46s -> 46.06s]  of as a random process.
[46.06s -> 53.06s]  So it's going to be good for us to understand how queues with random arrival processes work.
[53.06s -> 56.32s]  And so that's going to be the topic that I'm going to be discussing today.
[56.32s -> 61.14s]  So usually arrival processes are complicated in systems like networks, so we often model
[61.14s -> 63.62s]  them using random processes.
[63.62s -> 68.18s]  And this study of queues with random arrival processes is called queuing theory.
[68.18s -> 71.58s]  And queuing theory you've probably heard of before has a reputation for having very
[71.58s -> 73.62s]  hairy mathematics.
[73.62s -> 77.98s]  But despite that hairy mathematics, queues with random arrival processes have some really
[77.98s -> 80.78s]  interesting properties that's going to be good for us to understand.
[80.78s -> 86.82s]  They're going to really help us understand the dynamics of networks.
[86.82s -> 88.26s]  So I'm going to go through a set of properties.
[88.26s -> 93.10s]  I'm going to be starting with this one here that burstiness tends to increase delay.
[93.10s -> 98.02s]  And it's at this level that I want you to remember these properties.
[98.02s -> 100.90s]  The details of mathematics we're not going to worry about so much.
[100.90s -> 106.30s]  I want you to understand these basic intuitive properties of queuing systems.
[106.30s -> 109.22s]  So it all comes down to the way that the queue evolves.
[109.94s -> 113.66s]  So I'm going to just sketch here my queue again.
[113.66s -> 116.78s]  This is the arrivals to the queue of our packets.
[116.78s -> 120.66s]  You'll hear people call customers as well because queuing theory applies to many other
[120.66s -> 121.66s]  systems.
[121.66s -> 124.70s]  So if I say customers I mean packets in this context.
[124.70s -> 127.68s]  And so this is our arrivals, these are our departures, and we're going to be thinking
[127.68s -> 134.46s]  about the evolution of the queue occupancy, queue of t, queue as a function of time.
[134.46s -> 139.62s]  On this timeline down here I've drawn a sequence of arrivals and departures.
[139.62s -> 143.90s]  Packet arrivals happening at these blue downward arrows representing the time or the epoch of
[143.90s -> 148.38s]  the arrival, and then these red upward arrows being the departures, the times at
[148.38s -> 150.42s]  which the queue was serviced.
[150.42s -> 156.26s]  And just like in many queues for networks, we're going to think of this as representing
[156.26s -> 163.26s]  a link of a fixed rate r, which means that the interdeparture opportunities are at
[163.30s -> 166.18s]  one over r apart.
[166.18s -> 168.70s]  Now let's look at the evolution of the queue.
[168.70s -> 173.30s]  The queue here has the first arrival, the blue one, which takes it up to one.
[173.30s -> 176.42s]  And then we have the service, the upward red arrow, which is going to take us to
[176.42s -> 177.42s]  zero.
[177.42s -> 179.98s]  There's a new arrival, which is going to take us back to one again.
[179.98s -> 182.82s]  Then there's this departure here, which is going to take us to zero, then back up
[182.82s -> 185.48s]  to one again, then zero, et cetera.
[185.48s -> 188.98s]  At this point here we've had two arrivals in a row, which is going to take us back
[188.98s -> 192.94s]  to a queue occupancy of two, and so on.
[192.94s -> 197.26s]  So this is going to be the evolution of the queue.
[197.26s -> 201.22s]  Now let's look at this one here, this departure opportunity.
[201.22s -> 204.62s]  The reason I've drawn this is a dotted line.
[204.62s -> 206.62s]  Sometimes people call this a shadow departure.
[206.62s -> 210.38s]  It was a departure opportunity when we could have sent a packet, but the queue was empty
[210.38s -> 214.70s]  so that we never actually sent the packet, because we can't actually go down to a negative
[214.70s -> 216.08s]  queue occupancy.
[216.08s -> 218.40s]  That wouldn't be possible.
[218.40s -> 221.56s]  And so the queue sticks at zero even though we missed this opportunity.
[221.56s -> 226.16s]  It's going to turn out that these missed opportunities are quite important.
[226.16s -> 230.60s]  You can't have a negative queue occupancy, so some people say you don't get credit
[230.60s -> 231.76s]  for good behavior.
[231.76s -> 236.92s]  By not having an arrival during this interval here, it meant that the queue occupancy stuck
[236.92s -> 237.92s]  at zero.
[237.92s -> 239.98s]  But we don't get any credit for it.
[239.98s -> 246.88s]  And so if we have random arrivals with arrivals that are spread out, if we miss an opportunity
[246.88s -> 247.88s]  to send, it's tough.
[247.88s -> 250.40s]  We never get that back again.
[250.40s -> 254.72s]  Let's now take a look at the first property I wanted to explain.
[254.72s -> 259.16s]  And that is that bursty arrivals tend to increase delay.
[259.16s -> 265.04s]  I'm going to start with a very simple example where there is no burstiness, where
[265.04s -> 270.12s]  we have the simplest arrival process, which is a sequence of arrivals all exactly one
[270.12s -> 271.96s]  second apart.
[271.96s -> 275.48s]  So this is one packet per second.
[275.48s -> 278.12s]  And in fact it's one packet exactly every second.
[278.12s -> 280.24s]  Nothing random about this at all.
[280.24s -> 282.12s]  Let's look at the sequence of departures.
[282.12s -> 286.44s]  I'm going to assume that there is one departure every second.
[286.44s -> 291.08s]  So if we were to sketch the queue occupancy here, I won't sketch the graph, I'll
[291.08s -> 292.08s]  just put the numbers in.
[292.08s -> 297.56s]  If we were to sample the occupancy here, there'd be an arrival but no departure.
[297.56s -> 303.60s]  So we'd have one, and then zero, and then it's one again, and then zero, one, zero.
[303.60s -> 308.72s]  So in the way I've drawn it here, there are long periods of zero and then these short
[308.72s -> 312.04s]  periods of one when there's been arrival but no departure.
[312.04s -> 316.72s]  But of course I could shift either the arrivals or departures and make those zeros and ones
[316.72s -> 319.64s]  be of different durations.
[319.64s -> 323.04s]  So that'll just carry on because everything's nice and periodic.
[323.04s -> 327.88s]  The interesting thing to note here is Q of t, the queue occupancy, is either zero or
[327.88s -> 328.88s]  one.
[328.88s -> 332.40s]  So we can say it's always less than or equal to one.
[332.40s -> 335.56s]  And the average queue occupancy is going to be somewhere between zero and one.
[335.56s -> 338.90s]  We know that for sure just because of the structure of the problem.
[338.90s -> 344.28s]  So periodic arrivals make for a nice simple understanding of that queue evolution.
[344.28s -> 348.56s]  Now let's look at a different example when things are more bursty.
[348.56s -> 354.08s]  So just as before, the arrivals are going to be at the rate of one per second, but they're
[354.08s -> 355.28s]  going to arrive in bursts.
[355.28s -> 360.88s]  And in fact we're going to have n arrivals, we're going to have n arrivals, n arrivals
[360.88s -> 363.98s]  every n seconds.
[363.98s -> 367.08s]  So n packets every n seconds, but they're going to come in these bursts of n.
[367.08s -> 373.56s]  In this particular case, it's five packets every five seconds.
[373.56s -> 377.24s]  The service opportunities or the departures are going to be the same as before.
[377.24s -> 379.64s]  We're going to have one per second.
[379.64s -> 384.18s]  So in terms of the rates, the arrival rate and the departure rate, everything is exactly
[384.18s -> 385.32s]  the same as before.
[385.32s -> 387.12s]  It's one packet per second.
[387.12s -> 390.40s]  It's just that the burstiness of the arrivals is going to change things.
[390.40s -> 394.08s]  And let's look at the way in which they change.
[394.08s -> 397.68s]  So here we've got a sudden burst of arrivals of five.
[397.68s -> 402.20s]  So depending on when we sample it, sample the queue occupancy, we're going to have
[402.20s -> 409.20s]  q of t equals zero all the way through to five, depending on when we sample.
[409.20s -> 413.92s]  During this time here, it's four, then three, then two, then one, then zero.
[413.92s -> 417.64s]  And then it's going to go up to five again sometime in here, and four, and so
[417.64s -> 421.02s]  on, and so on, and so on.
[421.02s -> 426.04s]  So before our queue occupancy was zero or one, but now even with the same arrival rate
[426.04s -> 430.68s]  and even with the same departure rate, our queue occupancy can go between zero and five.
[430.68s -> 434.92s]  So our arrival, our average queue occupancy is higher.
[434.92s -> 438.60s]  And the variance of the queue occupancy is higher too, because it's varying all the way
[438.60s -> 439.90s]  across zero to five.
[439.90s -> 445.56s]  So average and the variance have both increased, even though the rate hasn't changed.
[445.56s -> 448.80s]  So clearly the burstiness is going to make a big difference.
[448.80s -> 452.44s]  And in general we say burstiness increases delay.
[452.44s -> 455.76s]  And that simple example, it illustrates it, it doesn't prove it, but hopefully it gives
[455.76s -> 460.48s]  you intuition as to why burstiness will increase delay.
[460.48s -> 464.94s]  The second property, which is very similar to the first, it's almost the counterbalance
[464.94s -> 469.84s]  of the first, is that determinism tends to minimize delay.
[469.84s -> 473.80s]  But it's enough for us to know that, in general, determinism minimizes delay.
[473.80s -> 480.00s]  In other words, random arrivals wait longer on average than simple periodic arrivals.
[480.00s -> 483.54s]  Let me move on to the third property I'd like you to know about.
[483.54s -> 488.24s]  And that is a well-known result called Little's result.
[488.24s -> 489.88s]  Queues are very complicated.
[489.88s -> 495.64s]  And as I've already given you an indication, the mathematics tends to get very hairy.
[495.64s -> 499.28s]  But there are some simple results that you really need to know, and it's important for
[499.28s -> 500.28s]  us to understand.
[500.28s -> 505.04s]  Because they're going to come in handy when we're understanding the basic properties
[505.04s -> 506.04s]  of queues.
[506.04s -> 509.68s]  And this one, Little's result, is deceptively simple.
[509.68s -> 516.04s]  So in any queuing system, like the one shown here, there's a following property,
[516.04s -> 519.88s]  which is a little surprising.
[519.88s -> 529.28s]  If I've got a well-defined arrival rate, let's call that lambda, and I've got an
[529.28s -> 537.48s]  average number of queues in the system, L, and I want to know what the average delay
[537.48s -> 545.76s]  is, and I'm going to call this D equals average delay of a customer or a packet through
[545.76s -> 549.54s]  the queue.
[549.54s -> 554.12s]  Then Little's result tells us that there is, in general, the number of customers in
[554.12s -> 561.40s]  the system equals the average arrival rate times the average delay of a customer through
[561.40s -> 562.84s]  the queue.
[562.84s -> 564.96s]  That's it.
[564.96s -> 570.18s]  This deceptively simple result applies for any queuing system for which there are
[570.18s -> 573.20s]  no customers that are lost or dropped.
[573.20s -> 585.52s]  So it doesn't matter what the arrival process is, it doesn't matter how bursty,
[585.52s -> 590.76s]  how non-bursty, so long as it has a well-defined arrival rate lambda, then we can make this
[590.76s -> 591.76s]  calculation.
[591.76s -> 597.84s]  So you can go to any queue, and we'll look at some examples in a moment, and you can
[597.84s -> 601.40s]  calculate the average number in the queue as a function of the arrival rate and the
[601.40s -> 602.40s]  average delay.
[602.56s -> 606.24s]  Or of course, if you know L and lambda, then you can figure out the average delay that's
[606.24s -> 609.60s]  going to be seen by a customer through this queue.
[609.60s -> 616.60s]  Now L is the average number that are in the queue plus currently being serviced,
[616.60s -> 621.58s]  so long as D is the average delay of customers that arrive until they've completed
[621.58s -> 622.58s]  service.
[622.58s -> 629.96s]  Turns out this result also holds if we say L is the average number of customers in just
[629.96s -> 635.64s]  the queue but not yet entering service, so long as D also equals the average delay
[635.64s -> 638.32s]  through the queue prior to entering service.
[638.32s -> 642.04s]  So both of those are true.
[642.04s -> 647.92s]  We're going to be using this result quite a lot throughout the quarter.
[647.92s -> 652.80s]  Having told you about those three properties of queues, something I need to tell you
[652.80s -> 656.92s]  before we get on to the fourth property, and that is the Poisson process.
[656.92s -> 662.84s]  You're going to hear a lot about the Poisson process whenever you study queues or any complicated
[662.84s -> 665.48s]  system that we model probabilistically.
[665.48s -> 669.28s]  First of all, I'm going to tell you what the Poisson process is, then I'm going to
[669.28s -> 673.80s]  tell you why it's interesting and some caveats about using it.
[673.80s -> 679.04s]  The Poisson process is an arrival process in our case, and an arrival process we say
[679.04s -> 685.68s]  is Poisson if, and in fact, and only if, the probability of there being k arrivals
[685.68s -> 690.20s]  in an interval of t seconds is given by this expression here, kind of a hairy expression,
[690.20s -> 697.36s]  but the important thing is that we can express this as the expected number of arrivals within
[697.36s -> 704.84s]  an interval t is simply lambda t, where lambda is the arrival rate.
[704.84s -> 707.96s]  Also successive inter-arrival times are independent.
[707.96s -> 713.96s]  What this means is that once we've picked one arrival from this expression here, this
[713.96s -> 716.84s]  will lead to an arrival event happening.
[716.84s -> 720.76s]  Then the next arrival is independent of the first one, and in fact if we take a sliding
[720.76s -> 726.84s]  window and move that over the arrival process within any period, the inter-arrival times
[726.84s -> 728.88s]  within one period are independent of the next.
[728.88s -> 733.04s]  That means that there's no burstiness or coupling of one arrival to another.
[733.04s -> 735.48s]  Okay, that's what the Poisson process is.
[735.48s -> 740.72s]  If you pick up any book on probability, then you can find a more detailed description
[740.72s -> 743.40s]  if that's something that's new to you.
[743.40s -> 745.16s]  So why the Poisson process?
[745.16s -> 746.96s]  Why are we interested in the Poisson process?
[746.96s -> 752.26s]  Well, the Poisson process happens to model an aggregation of many independent random
[752.26s -> 754.86s]  events very well.
[754.86s -> 760.56s]  For example, it's used in models of new phone calls arriving to a switch.
[760.56s -> 764.72s]  So when we have a telephone switch, and we say we want to model the arrival of
[764.72s -> 769.44s]  a new phone call that is being placed through the day, then a Poisson process is a very
[769.44s -> 771.48s]  good model of this.
[771.48s -> 777.56s]  Or the decay of many independent nuclear particles, where we have a huge number of particles all
[777.56s -> 781.60s]  operating independently of each other, they will decay at certain times.
[781.60s -> 787.12s]  That decay, as an aggregation of many random events, tends to a Poisson process, as we
[787.12s -> 789.56s]  have a large number of particles.
[789.56s -> 793.84s]  And you may also be familiar with shot noise in an electrical circuit, which is also modeled
[793.84s -> 795.68s]  as a Poisson process.
[795.68s -> 800.16s]  The final thing, despite the complexity of the equation on the previous slide, it actually
[800.16s -> 801.96s]  makes the math very easy.
[801.96s -> 806.96s]  And this is a big reason that it gets used very widely as well.
[806.96s -> 812.08s]  At this point, I should give you some warnings.
[812.08s -> 813.64s]  Network traffic is very bursty.
[813.64s -> 818.32s]  There's nothing independent about one packet arrival after another.
[818.32s -> 822.92s]  As we will see later, packets tend very frequently to arrive in bursts.
[822.92s -> 826.52s]  And many things in the network help actually to keep them that way and make them very
[826.52s -> 827.52s]  bursty.
[827.52s -> 832.56s]  So packet arrivals are not, and I can't overemphasize this, they are not Poisson.
[832.56s -> 836.60s]  There's been some classic papers, research papers that have shown this.
[836.60s -> 842.88s]  However, it does model quite well the arrival of new flows, of new communications.
[842.88s -> 848.64s]  For example, the inter-arrival times of web requests or sending emails.
[848.64s -> 852.16s]  For any one individual, they may be somewhat Poisson, but when you take the aggregation
[852.16s -> 857.00s]  of many users putting their network traffic into the network, that is actually modeled
[857.00s -> 860.24s]  quite well by a Poisson process.
[860.24s -> 865.24s]  And sometimes, sometimes we can use some of the results that apply to queues with
[865.24s -> 869.76s]  Poisson arrivals to give us an intuition, an understanding of maybe what's happening,
[869.76s -> 871.20s]  even at the packet level.
[871.20s -> 876.88s]  But we must do that very, very carefully.
[876.88s -> 880.26s]  Let's look at a very common example of why we use the Poisson process.
[880.26s -> 882.96s]  This is something called the MM1 queue.
[882.96s -> 887.80s]  The MM1 queue is about the simplest type of queue that is commonly analyzed.
[887.80s -> 895.76s]  The notation is that the M stands for a Markovian arrival process, which in our case is Poisson,
[895.76s -> 902.52s]  Markovian service process, which is exponential in our case, which means that the time that
[902.52s -> 908.84s]  it takes to service a packet is exponentially distributed, and each one has a service time
[908.84s -> 913.40s]  independent of all of the others, and that there is one server, in other words that
[913.40s -> 916.24s]  there's one outgoing line servicing this queue.
[916.24s -> 923.04s]  This is very widely used because it assumes a nice simple Poisson arrival with independent
[923.04s -> 927.22s]  arrivals from one packet to the next.
[927.22s -> 933.12s]  But it's also used because the math is nice and simple, and the result is very intuitive.
[933.12s -> 940.64s]  So if we were to analyze this, and we can analyze it using continuous-time Markov chains,
[940.64s -> 946.40s]  we will discover that the average delay of a packet going through this queue is given
[946.40s -> 951.92s]  by the simple expression 1 over mu minus lambda.
[951.92s -> 958.32s]  What this tells us is that it's 1 over the difference between the service rate and
[958.32s -> 959.58s]  the arrival rate.
[959.58s -> 963.68s]  So as the load increases, and the load gets closer and closer to the service rate, then
[963.68s -> 965.68s]  this number will grow very rapidly.
[965.68s -> 975.86s]  And if we plot this on a graph, so as a function of lambda over mu, as we get closer
[975.86s -> 981.86s]  and closer to 1, in other words where they're equal, the average delay of a packet through
[981.86s -> 987.42s]  this queue will increase very, very steeply.
[987.42s -> 991.78s]  And this is the case for almost any queuing system, not just the MM1 queue.
[991.78s -> 997.22s]  The reason that we use the MM1 queue sometimes as a placeholder for a more complicated system
[997.22s -> 1000.32s]  is only that the math is simpler and this expression is simple.
[1000.32s -> 1005.30s]  But you see a very similar shape for almost any queuing system.
[1005.30s -> 1009.42s]  We can use Little's result to figure out what the average queue occupancy is, and we
[1009.42s -> 1017.34s]  know that L equals lambda times D, which in this case is simply going to be lambda
[1017.34s -> 1022.98s]  over mu divided by 1 minus lambda over mu.
[1022.98s -> 1027.82s]  The reason for writing it in terms of lambda over mu is simply that lambda over mu represents
[1027.82s -> 1031.46s]  the intensity, just as I sketched on the graph here.
[1031.46s -> 1037.30s]  As lambda approaches mu, lambda over mu approaches 1, and the denominator turns to 0, and the
[1037.30s -> 1042.68s]  queue occupancy and the average delay will blow up and turn towards infinity.
[1042.68s -> 1045.22s]  So the MM1 queue provides us a good intuition.
[1045.22s -> 1051.26s]  Don't ever assume that this is the actual representative measure of the queue occupancy
[1051.26s -> 1055.54s]  or the average delay, but it can often help to give it an intuitive sense of what's
[1055.54s -> 1060.04s]  going on in a network.
[1060.04s -> 1063.70s]  So in summary, the main queue properties I want you to take away from this video are
[1063.70s -> 1067.06s]  that burstiness tends to increase delay.
[1067.06s -> 1070.70s]  So bursty arrivals tend to make queuing delays longer.
[1070.70s -> 1075.30s]  Little's result gives us a nice relationship between the average occupancy of a queue,
[1075.30s -> 1081.26s]  L, lambda the arrival rate, and D, the average delay of a customer through that queue.
[1081.26s -> 1086.30s]  While packet arrivals are not Poisson, some events are, such as web requests and new
[1086.30s -> 1087.82s]  flow arrivals.
[1087.82s -> 1092.06s]  And Poisson process also forms the basis of the MM1 queue, which is a simple queuing
[1092.06s -> 1097.02s]  model that often can give us some intuition about the delay properties of a network.
[1097.02s -> 1098.06s]  That's the end of this video.
