# Detected language: en (p=1.00)

[0.00s -> 4.48s]  For two parties to communicate, they need to agree on the message they exchange.
[4.48s -> 8.22s]  If one party assumes messages are in Spanish, and the other assumes they are in Cambodian,
[8.22s -> 10.08s]  they will not be able to communicate.
[10.08s -> 14.32s]  For computers, this means agreeing on what fields messages have, how they are arranged
[14.32s -> 16.72s]  and formatted, and how they are represented.
[16.72s -> 20.78s]  To generate a message to send, software typically has to create a copy of it in memory,
[20.78s -> 22.68s]  which then passes to the networking card.
[22.68s -> 26.32s]  Similarly, when a computer receives a message, the networking card puts that message in
[26.32s -> 29.20s]  memory, which the software can then access.
[29.20s -> 32.56s]  Understanding how this works and some of the pitfalls you can encounter is important if
[32.56s -> 37.36s]  you want to understand network protocols and write network protocol software.
[37.36s -> 40.20s]  So let's start with a simple model of computer memory.
[40.20s -> 45.28s]  In most computers today, memory is organized in terms of bytes, 8-bit chunks of memory.
[45.28s -> 48.48s]  A program has an address space, starting at address 0.
[48.48s -> 50.18s]  Most computers today are 64 bits.
[50.18s -> 53.96s]  This means that memory addresses are 64 bits long, so a computer is up to 2 to the
[53.96s -> 56.88s]  64 bytes, or 18 sextillion bytes.
[57.24s -> 59.56s]  In practice, computers today do not have this much memory.
[59.56s -> 62.44s]  They have gigabytes, which is 2 to the 30th.
[62.44s -> 68.20s]  In this example, our computer has 8 gigabytes of memory shown on the left, so its largest
[68.20s -> 75.86s]  address is the hexadecimal value shown of 0x020000.
[75.86s -> 79.48s]  Software can access each byte of this memory, or access byte in groups, such as loading
[79.48s -> 85.28s]  a 64-bit integer from 8 contiguous byte cells of memory in a single instruction.
[85.28s -> 88.26s]  But how does a computer represent a multibyte value?
[88.26s -> 94.28s]  Let's say we want to represent the number 1024, which in hexadecimal is 0x0400, or
[94.28s -> 96.28s]  4 times 256.
[96.28s -> 99.24s]  This value requires 16 bits, or 2 bytes.
[99.24s -> 103.14s]  Which byte comes first, 0x00 or 0x04?
[103.14s -> 107.56s]  How you lay out a multibyte value in memory is called endianness, and there are two
[107.56s -> 108.72s]  options.
[108.72s -> 114.12s]  In little endian, the least significant byte is at the lowest address, so the least significant
[114.12s -> 116.64s]  byte comes first in memory.
[116.64s -> 121.62s]  It turns out that from a computational or architectural standpoint, this can make the most sense.
[121.62s -> 126.32s]  The other option is big endian, where the most significant byte is the lowest address.
[126.32s -> 130.12s]  Big endian makes more sense to a human reader reading left to right, because it's
[130.12s -> 133.04s]  how we write numbers with the most significant digits first.
