# Detected language: en (p=1.00)

[0.00s -> 6.64s]  This video is a continuation about packet switching, and in this video I'm going to
[6.64s -> 11.36s]  be talking about a number of different Q-models.
[11.36s -> 15.18s]  I'm going to start out by describing a simple, deterministic Q-model.
[15.18s -> 18.96s]  This is something that's going to help us understand the dynamics of many simple
[18.96s -> 19.96s]  Q-systems.
[19.96s -> 25.64s]  It often works as a good way of understanding what's going on in the network.
[26.64s -> 28.24s]  Here's a router.
[28.24s -> 34.20s]  As we know already, routers have to have queues in the interface to hold packets during times
[34.20s -> 35.40s]  of congestion.
[35.40s -> 38.32s]  This is where the variability in queuing delay takes place.
[38.32s -> 43.54s]  If we can understand the dynamics, even just having a rough sense of the dynamics
[43.54s -> 47.84s]  of that queue, it really helps us understand the end-to-end queuing delay and the dynamics
[47.84s -> 48.84s]  of the network.
[48.84s -> 53.96s]  We're going to take a closer look at this, and we're going to create a simple model.
[53.96s -> 55.96s]  Here are the main characteristics of this queue.
[55.96s -> 56.96s]  I'm going to draw a queue like this.
[56.96s -> 62.88s]  This is the standard way to draw a queue, showing where the packets will be stored.
[62.88s -> 68.06s]  In that router queue, this is a four-port router, so packets could be coming in from
[68.06s -> 73.40s]  any of the interfaces into that queue, and then they will depart under the outgoing
[73.40s -> 74.40s]  link.
[74.40s -> 79.48s]  We're going to say that that queue has an occupancy of Q of T, so at time T it has
[79.48s -> 82.44s]  Q packets or bytes in it.
[82.92s -> 90.64s]  It's going to be useful to think about the aggregate or the cumulative departure process,
[90.64s -> 95.36s]  that is, all of the packets or all of the bytes that have departed up until some time
[95.36s -> 96.36s]  T.
[96.36s -> 100.52s]  Similarly, it's going to be useful to think of the cumulative arrivals, the total
[100.52s -> 103.80s]  number of packets that have arrived up until time T.
[103.80s -> 109.68s]  Finally, because the outgoing link typically has a deterministic and fixed rate, we're
[109.68s -> 111.56s]  just going to say it has a fixed rate of R.
[111.68s -> 118.00s]  So they're going to be the main parameters of our model.
[118.00s -> 123.64s]  We can also think of a queue as being like a bucket full of water, and here's a simple
[123.64s -> 124.64s]  example here.
[124.64s -> 130.60s]  A of T is the cumulative number of bytes that have arrived up until time T.
[130.60s -> 136.56s]  D of T is the cumulative number of bytes that have departed up until time T, and
[136.56s -> 140.40s]  in this example, they're going to depart at a fixed link rate of R.
[140.40s -> 145.92s]  At any one time, there may be some bytes that have arrived but haven't yet departed.
[145.92s -> 152.08s]  They're the ones sitting in the bucket here, and the occupancy of that bucket is
[152.08s -> 153.20s]  going to be Q of T.
[153.20s -> 155.28s]  So this is like a simple model of our queue.
[155.28s -> 158.36s]  It's just another way of thinking about it.
[158.36s -> 163.36s]  We can draw the evolution of this as a function of time, and I'm going to try and sketch
[163.36s -> 165.00s]  how this might look.
[165.00s -> 168.72s]  So here are going to be the axes of my graph.
[168.72s -> 173.08s]  As a function of time, we're going to look at the cumulative number of bytes.
[173.08s -> 176.68s]  So remember this is cumulative.
[176.68s -> 183.72s]  I'm going to first look at the arrival process, A of T.
[183.72s -> 187.80s]  Bytes tend to arrive as part of a packet, and they're going to arrive at some particular
[187.80s -> 189.60s]  link arrival rate.
[189.60s -> 193.06s]  So I'm going to draw what that cumulative arrival process might look like.
[193.06s -> 197.22s]  It could look like anything, but here are the bytes arriving a packet.
[197.22s -> 200.06s]  This is the gap between the first packet and the second packet.
[200.06s -> 204.82s]  Here's a bunch more bytes arriving, a gap, maybe it's a long gap this time, and then
[204.82s -> 207.30s]  a new packet arriving.
[207.30s -> 213.06s]  So this is supposed to be a straight line, and this would be the arrival rate of the
[213.06s -> 216.98s]  packet on the incoming link, and this is the number of bytes.
[216.98s -> 222.98s]  So let's say the packet is of length P, the number of bytes of that first packet.
[222.98s -> 225.46s]  Now let's look at what the departure process might look like.
[225.46s -> 232.38s]  I'm going to try and label this as A of T, the cumulative arrival process.
[232.38s -> 235.18s]  And then in yellow I'm going to try and draw the, I'm going to sketch out what
[235.18s -> 237.50s]  the departure process might look like.
[237.50s -> 244.72s]  We know that the departure process is going to work at an operate at rate R. So at some
[244.72s -> 248.70s]  point after that first packet has arrived, let's assume that it's a store and forward
[248.70s -> 249.70s]  model.
[249.70s -> 250.70s]  It doesn't matter.
[250.70s -> 251.70s]  That's just for the sake of my example.
[251.70s -> 256.78s]  So at this time here, the packet has arrived, and then we'll say, OK, it's going to depart
[256.78s -> 261.42s]  at rate R. So that's going to be my gradient there.
[261.42s -> 266.00s]  So that's rate R, that packet departing.
[266.00s -> 271.76s]  At this point, there's nothing left, so we're going to wait until there's a whole
[271.76s -> 274.06s]  new packet in the queue.
[274.06s -> 280.18s]  And then we're going to depart again at rate R. That's going to be rate R, and
[280.18s -> 281.18s]  so on.
[281.66s -> 285.50s]  So this might be one way in which it evolves.
[285.50s -> 289.26s]  The point here is not the particular shape of this graph, but just to say you can easily
[289.26s -> 293.22s]  sketch the arrival and departure process.
[293.22s -> 297.28s]  And what this, kind of a cool property of this is that we can immediately from this
[297.28s -> 301.18s]  tell some nice characteristics of the system.
[301.18s -> 306.56s]  First of all, we can immediately tell how, what the value of Q of T is.
[306.56s -> 311.76s]  Because at any one time, so if we were to pick a particular time, Q of T is the number
[311.76s -> 315.16s]  of bytes that have arrived, but not yet departed.
[315.16s -> 321.20s]  So it's simply D of T minus A of T. I'm sorry, A of T minus D of T. So it's the
[321.20s -> 324.10s]  number that have arrived minus those that have departed.
[324.10s -> 329.16s]  So for example, if we were to take a line here, down to here, so a vertical, it's
[329.16s -> 334.52s]  supposed to be a vertical line, that value, that distance between the two of those is
[334.52s -> 338.68s]  Q of T. So at any one time it's the occupancy of that Q.
[338.68s -> 346.36s]  Similarly, if we look at a particular byte that arrives, say at this time here, if we
[346.36s -> 352.40s]  assume that all bytes arrive and then depart in the same order, then this byte,
[352.40s -> 356.60s]  because it's this particular cumulative byte, we know that it departs here.
[356.60s -> 361.56s]  So if we take the horizontal distance between these two lines, this is going to tell us
[361.60s -> 368.48s]  the D of T, I'll call it little d of T, the delay through the Q.
[368.48s -> 370.76s]  So this is a very useful model giving us an intuition.
[370.76s -> 376.28s]  I often sketch graphs like this when I'm trying to understand the dynamics of a Q,
[376.28s -> 380.52s]  or the dynamics of a system.
[380.52s -> 388.08s]  Okay, then to summarize, we can say that the Q occupancy, so Q occupancy,
[388.08s -> 395.52s]  Q of T equals, it's the ones that have arrived minus the ones that have departed.
[395.52s -> 397.52s]  So a nice simple expression for that.
[397.52s -> 404.36s]  And that D of T is the time spent in the Q by a byte that arrived at time T.
[404.36s -> 421.52s]  So it's the time spent in the Q by a byte arriving at time T.
[421.52s -> 427.48s]  And that's simply the horizontal distance between those two lines.
[427.48s -> 432.60s]  Now, the assumption of this is always that it's first come, first serve, or FIFO.
[432.64s -> 434.64s]  We also say first in, first out.
[434.64s -> 436.64s]  In this context, those have the same meaning.
[436.64s -> 437.28s]  So that's true.
[437.28s -> 441.20s]  If the bytes didn't arrive and depart in the same order, then we couldn't make this statement
[441.20s -> 445.88s]  here about D of T, because we don't know that we're referring to the same byte.
[445.88s -> 450.04s]  Let's go on and look at an example now of how we might use this.
[450.04s -> 452.44s]  So I'm going to work through an example.
[452.44s -> 458.72s]  We're going to assume that every second, a 100-bit packet is going to arrive to a Q
[458.72s -> 460.52s]  at rate 1,000 bits per second.
[460.56s -> 465.08s]  In other words, this packet is going to arrive at a rate of 1,000 bits per second.
[465.08s -> 468.00s]  And it's 100 bits long.
[468.00s -> 474.12s]  We're going to assume the maximum departure rate, that was our R, is 500 bits per second.
[474.12s -> 477.32s]  And the question is, what is the average occupancy of the Q?
[477.32s -> 479.56s]  So just reading the question, it's not so obvious.
[479.56s -> 486.84s]  But if we plot this in the way that I did before, I'm not going to try and sketch it,
[486.84s -> 490.76s]  because I want these numbers to be very clear.
[490.76s -> 495.00s]  A of T, shown in red here, is the arrival process.
[495.00s -> 497.68s]  This here is the packet arriving.
[497.68s -> 502.52s]  It's the 100-bit packet arriving at rate 1,000 bits per second.
[502.52s -> 507.32s]  So therefore, it takes a tenth of a second, 0.1 of a second to arrive.
[507.32s -> 509.56s]  The maximum departure rate is 500 bits per second.
[509.56s -> 510.56s]  It's slower.
[510.60s -> 517.96s]  So our departure rate, departure d of T, the rate here is that the gradient of that is
[517.96s -> 519.44s]  500 bits per second.
[519.44s -> 526.04s]  So that 100-bit packet is going to take 0.2 of a second in order to depart.
[526.04s -> 531.72s]  In the previous example, I showed it as a store and forward of each packet.
[531.72s -> 532.88s]  Here, I didn't.
[532.88s -> 533.96s]  And that's just a choice.
[533.96s -> 536.12s]  And I just made that choice when answering the question.
[536.12s -> 540.32s]  The question isn't clear as to which way it is.
[540.40s -> 546.48s]  So we can now see the time evolution of Q of T, which is the vertical difference between
[546.48s -> 549.88s]  those two lines, and the delay of an individual packet.
[549.88s -> 554.44s]  But the question is, what is the average occupancy of the queue?
[554.44s -> 556.76s]  Well, let's look at how we might solve that.
[556.76s -> 561.04s]  I'm going to write this out just so that you have a clear record of this.
[561.04s -> 562.88s]  So the solution is this.
[562.88s -> 566.70s]  During each repeating one-second cycle, the queue is going to fill at rate 500 bits
[566.70s -> 569.20s]  per second for a tenth of a second.
[569.24s -> 572.24s]  So that was my arrival process here.
[572.24s -> 582.88s]  Then it drains at 500 bits per second for 0.1 of a second.
[582.88s -> 589.24s]  Over the first two tenths of a second, the average occupancy is therefore 0.5 times
[589.24s -> 597.08s]  0.1 times 500 equals 25 bits.
[597.08s -> 600.36s]  The queue is empty for eight tenths of a second every cycle.
[600.36s -> 602.04s]  That's from here to here.
[602.04s -> 611.24s]  And so the average queue occupancy, Q-bar of T, is 0.2 of a second when it's 25 bits,
[611.24s -> 613.12s]  and 0.8 of a second when it's 0.
[613.12s -> 619.60s]  So the average queue occupancy is 5 bits.
[619.60s -> 624.46s]  Continuing with our theme of simple deterministic queue models, I want to explain why it is
[624.46s -> 630.38s]  that small packets can reduce end-to-end delay.
[630.38s -> 635.62s]  You may have been wondering why we can't simply send an entire message in one packet.
[635.62s -> 639.22s]  Why is it that we have to break messages down into smaller packets?
[639.22s -> 644.22s]  There's a very good reason for this, and I want to explain this in terms of the end-to-end
[644.22s -> 645.34s]  delay.
[645.34s -> 652.98s]  So on the left, I've got an example of a message of length R that's being delivered
[652.98s -> 655.46s]  from end-to-end.
[655.46s -> 660.62s]  And this is going through three routers, R1, R2, and R3.
[660.62s -> 664.54s]  And I'm just showing, as we did before, the delay across each link in terms of the
[664.54s -> 669.30s]  packetization delay and the propagation delay over the links as it makes its way across
[669.30s -> 670.30s]  the network.
[670.30s -> 672.66s]  We already know the expression for the end-to-end delay for this.
[672.66s -> 677.42s]  It's simply made up of the sum of all the M over Ri's.
[677.42s -> 679.34s]  This is the packetization delay.
[679.34s -> 684.28s]  And then the sum of all of the propagation delays over the links.
[684.28s -> 685.98s]  So we've seen this before.
[685.98s -> 693.50s]  If you look at the one on the right, we can see that the message is being broken
[693.50s -> 697.26s]  down into packets of length P. So I've broken that same message.
[697.26s -> 699.54s]  It's the same length as before overall.
[699.54s -> 700.54s]  This is the message.
[700.54s -> 702.50s]  But I've just broken down into packets of length P.
[702.50s -> 706.70s]  So the packetization delay over the first link is P over R1.
[706.82s -> 712.06s]  And so now the end-to-end delay is this expression here, P over Ri for the packetization delay
[712.06s -> 718.26s]  on each link, and then Li over C for the propagation delay.
[718.26s -> 724.62s]  M over P is simply the additional time for the ones that arrive at the end.
[724.62s -> 728.58s]  Strictly speaking, this should be M minus 1 over P, because it's the remaining packets.
[728.58s -> 732.02s]  I'm going to assume that M is much bigger than P, so that's basically the same.
[732.02s -> 741.70s]  M over P times R3, the packetization delay of that set of packets over the last link.
[741.70s -> 744.58s]  But the most important thing here is that you can see what's going on.
[744.58s -> 749.02s]  In this case on the left, the whole message has to be transferred over the first link
[749.02s -> 751.42s]  before it can start on the second link.
[751.42s -> 756.42s]  Whereas over here, the first packet goes and then is transferred onto the second link
[756.42s -> 759.82s]  while the first link is carrying the second packet.
[759.82s -> 761.10s]  So we've got a pipelining effect.
[761.10s -> 763.14s]  We've got parallelism over the links.
[763.14s -> 766.18s]  And so therefore the end-to-end delay is going to be reduced.
[766.18s -> 770.74s]  Over a long network with very big messages, this will make a very significant difference.
[770.74s -> 775.42s]  And so the end-to-end delay can be reduced by making the packets smaller.
[775.42s -> 779.58s]  Let's look at this simple example here.
[779.58s -> 785.10s]  I've got a number of flows, n flows, or n packets coming in on n external links, all
[785.10s -> 786.58s]  running at rate R.
[786.58s -> 791.66s]  I've got a packet buffer corresponding to the output queue of the router.
[791.66s -> 794.98s]  And then an outgoing link that's running at rate R as well.
[794.98s -> 799.10s]  Clearly if all of those ingress links were running at the full rate R, then the
[799.10s -> 805.54s]  output link would be overwhelmed, and we'd start dropping packets very quickly.
[805.54s -> 810.78s]  And in fact there would be a rate of n times R coming in, and a rate of 1R going out.
[810.78s -> 815.86s]  So we'd be dropping them at a rate of n minus 1 times R.
[815.86s -> 820.62s]  But because of the statistical multiplexing and the burstiness of the arrivals, we can
[820.62s -> 826.22s]  potentially get away with this if the average rates are sufficiently low.
[826.22s -> 833.18s]  So in general we say the reduction in rate that we need at the egress compared to the
[833.18s -> 838.18s]  ingress is because of that statistical multiplexing, and we call that benefit the statistical
[838.18s -> 839.82s]  multiplexing gain.
[839.82s -> 842.66s]  We never know what it's going to be precisely, because it's going to depend on the particular
[842.66s -> 845.62s]  arrival process of packets.
[845.62s -> 851.38s]  And temporarily, if there are temporary oversubscription to the output link, the buffer can absorb
[851.38s -> 853.22s]  those brief periods.
[853.22s -> 857.22s]  And so a bigger buffer is going to absorb bigger and longer periods when the aggregate
[857.22s -> 859.54s]  rate happens to exceed R.
[859.54s -> 864.10s]  But because the buffer has a finite size, there's always losses that can occur.
[864.10s -> 866.30s]  And that's just a fact of life in packet switching.
[866.30s -> 869.18s]  Nothing that we can do about that.
[869.18s -> 875.82s]  Let's look at a couple of specific examples here.
[875.82s -> 876.82s]  See the top part?
[876.82s -> 887.30s]  At the top here, I've got an arrival process A into this router buffer that's being drained
[887.30s -> 889.62s]  at rate C.
[889.62s -> 894.42s]  And a separate one that is going through a router that's arriving at rate B and being
[894.42s -> 896.62s]  drained at rate C.
[896.86s -> 901.82s]  And I'm showing over here on the left-hand side the rates as a function of time.
[901.82s -> 906.06s]  And you can see here that the peaks and troughs don't exactly line up, so that if we take
[906.06s -> 912.18s]  the sum of the two flows, then we can expect there to be some statistical multiplexing
[912.18s -> 913.18s]  gain.
[913.18s -> 914.18s]  Let's have a look at what that might be.
[914.18s -> 919.82s]  Of course I made up these numbers, these are just to give us an example.
[919.82s -> 925.54s]  But if we take A plus B here, that was the rate of A plus B, and that's the line
[925.54s -> 926.54s]  in pink.
[926.54s -> 928.22s]  That's this one here.
[928.22s -> 936.38s]  You can see that the rate of the combined flows, R, is quite a bit less than 2C, in
[936.38s -> 939.40s]  other words, less than the sum of the two peaks.
[939.40s -> 944.34s]  So in this case we would say the statistical multiplexing gain equals 2C over R. It's
[944.34s -> 948.12s]  the benefit that we're getting from summing the two of them.
[948.12s -> 952.04s]  We can actually come up with a different definition, and some people use a different
[952.04s -> 956.52s]  definition for statistical multiplexing gain, because in this case you can see we didn't
[956.52s -> 959.32s]  actually take advantage of the fact that there is a buffer.
[959.32s -> 968.80s]  We're not using that to buffer any temporary rate that exceeds R.
[968.80s -> 976.36s]  One definition could be that for a given buffer size B, the ratio of the rates that
[976.36s -> 979.92s]  we need in order to prevent packet loss is the statistical multiplexing gain, and
[979.92s -> 983.32s]  that generally will be a lower rate, because we can absorb the change.
[983.32s -> 992.08s]  For example, in this case, imagine that we were to serve it at this rate, R', instead.
[992.08s -> 997.12s]  So we'll call that R', where R' is a little bit less than R.
[997.12s -> 1003.32s]  So long as the amount that we need to buffer here and here when the rate exceeds R', can
[1003.32s -> 1006.48s]  be accommodated by the buffer, then we're okay.
[1006.48s -> 1011.94s]  And so in this case, for the buffer of size B, we might say that instead the multiplexing
[1011.94s -> 1016.26s]  gain is 2C over R', which is a slightly larger number.
[1016.26s -> 1019.66s]  Okay, so two definitions of statistical multiplexing gain.
[1019.66s -> 1026.00s]  One where we don't consider the buffer, and one where we do.
[1026.00s -> 1030.54s]  So in summary, often we can use a simple deterministic model of a queue to understand
[1030.54s -> 1032.22s]  the packet dynamics in a network.
[1032.22s -> 1033.38s]  And I'd encourage you to do this.
[1033.38s -> 1037.06s]  It gives a very good intuitive understanding of what's happening in the network.
[1037.06s -> 1039.38s]  I often use this myself.
[1039.54s -> 1044.02s]  Second, we learned that we can break messages into packets, or rather the reason that we
[1044.02s -> 1048.06s]  break messages into packets is because it lets us pipeline the transfer of packets
[1048.06s -> 1051.70s]  from one end to another, and reduces the end-to-end delay.
[1051.70s -> 1056.86s]  Finally, statistical multiplexing lets us carry many flows efficiently on a single link.
[1056.86s -> 1061.14s]  And this is one of the prime reasons that we use packet switching.
[1061.14s -> 1063.58s]  Okay, that's the end of this video.
