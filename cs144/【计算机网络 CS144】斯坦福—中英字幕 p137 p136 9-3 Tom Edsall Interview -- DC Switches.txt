# Detected language: en (p=1.00)

[0.00s -> 6.04s]  So, I'm here today with Tom Edsel, who I've known for a number of years.
[6.04s -> 10.84s]  Tom has been involved in the design of switches and routers for a long time now.
[10.84s -> 16.12s]  He was a master's student at Stanford, and after that has worked for a number of companies,
[16.12s -> 22.00s]  most notably at Cisco, where he's arguably responsible for the design and deployment
[22.00s -> 25.88s]  of more Ethernet switches and routers than anybody else on the planet.
[25.88s -> 31.60s]  So, he is extremely well qualified to talk to us today about the design of switches and routers.
[31.60s -> 32.60s]  Hi Tom.
[32.60s -> 33.60s]  Hey Nick.
[33.60s -> 41.56s]  So, the first question I had for you Tom is, so in CS144 we learn about Ethernet switches
[41.56s -> 45.48s]  and IP routers and their basic functionality.
[45.48s -> 49.06s]  Can you tell us a little bit about the history of routers and Ethernet switches and
[49.06s -> 54.56s]  when they were first built and sold, and were they based on CPUs or specialized hardware?
[55.24s -> 56.24s]  Okay.
[56.24s -> 64.56s]  So, I think the first Ethernet switch, or maybe not the first, but certainly the first
[64.56s -> 69.08s]  very, very successful one was a product that we designed here at Cisco called the
[69.08s -> 71.16s]  Catalyst 5000.
[71.16s -> 79.72s]  And the Catalyst 5000 initially was a simple layer 2 switch, a multi-port bridge, if you will.
[79.72s -> 87.88s]  And it was based upon some custom silicon that we designed, and there was one ASIC,
[87.88s -> 91.72s]  one application specific integrated circuit, if you don't know what an ASIC is, one piece
[91.72s -> 98.84s]  of custom silicon, and that was repeated for every port in the system, and we had
[98.84s -> 105.44s]  a line card that was 12 ports, so it had 12 of these ASICs on it, and then there
[105.44s -> 108.08s]  were several of these line cards in a chat-seat.
[108.08s -> 114.72s]  And all of those devices were connected with a common bus across the backplane.
[114.72s -> 123.32s]  And that was built shortly after we came into Cisco in 19, well, that product came
[123.32s -> 130.56s]  out in 1995, and we were immediately trying to figure out how to add layer 3 capability,
[130.56s -> 132.92s]  how to add routing to that.
[132.92s -> 138.88s]  Cisco, meanwhile, had a router, and we were a part of Cisco, so the main part of Cisco
[138.88s -> 148.00s]  had a router, but it was based on a microprocessor, it was a MIPS processor, all done in software.
[148.00s -> 156.72s]  And we began to investigate what it would take to do routing in hardware, and the
[156.72s -> 162.60s]  initial response was that it couldn't be done, and then talking to people was like,
[162.60s -> 167.16s]  yeah, but it's way too complicated, it would take too long to explain, and we couldn't
[167.16s -> 171.84s]  quite understand what the problem was, and we kept on asking and asking and asking.
[171.84s -> 178.44s]  And eventually, we really came to a conclusion that it could be done, and it was just people
[178.44s -> 181.64s]  hadn't thought about doing it in hardware.
[181.68s -> 190.56s]  The initial product, what it did was it allowed the first packet of a flow to be bridged to
[190.56s -> 197.04s]  a router blade in the system, a router on a line card, in hardware.
[197.04s -> 202.40s]  That router was running in software on this MIPS processor, it would route the packet
[202.40s -> 204.68s]  as it always has.
[204.68s -> 210.84s]  But when that initial packet was sent to the software router, we learned in hardware
[210.88s -> 216.04s]  or cached in hardware the flow information about that packet.
[216.04s -> 221.20s]  And then when it returned from the software router, we compared the return flow with the
[221.20s -> 225.40s]  one that went to the software router, and we could see what was different about the
[225.40s -> 225.96s]  packets.
[225.96s -> 230.12s]  And the thing that was different, of course, was it was a new layer 2 header.
[230.12s -> 235.64s]  So then we would remember that layer 2 header, and then all subsequent packets, we would
[235.64s -> 240.36s]  just do the rewrite to the layer 2 header that we had learned from the software.
[240.40s -> 244.52s]  So the hardware and software were actually running almost completely independently, and
[244.52s -> 248.20s]  the hardware was essentially caching the layer 3 routes.
[248.20s -> 257.96s]  So is caching still used today, as far as you know?
[257.96s -> 265.84s]  Yes, it's used and it depends on the product.
[265.84s -> 271.24s]  In general, we think about a fast path and a slow path.
[271.24s -> 275.76s]  And you can think of a fast path as a cache.
[275.76s -> 281.64s]  Sometimes that cache may be done in hardware, sometimes it may be done in software.
[281.64s -> 288.16s]  Quite often, the first packet will go to the slow path, or alternatively, a packet
[288.16s -> 295.08s]  that has a set of options would go to this slow path, and sort of the normal packet
[295.12s -> 297.12s]  could go through a fast path.
[297.12s -> 306.92s]  But the technique of caching comes and goes over the years, and sort of depends on the
[306.92s -> 311.00s]  set of problems we're trying to solve and the constraints that we're solving those
[311.00s -> 311.64s]  under.
[311.64s -> 312.40s]  I see.
[312.40s -> 316.20s]  So in class, we learn about the sort of the basic forwarding.
[316.20s -> 321.60s]  So learning for layer 2 addresses and then forwarding or broadcasting if you don't know
[321.60s -> 327.12s]  the address, and then for layer 3, checking the version number, decrementing the TTL,
[327.12s -> 330.92s]  updating the checksum and forwarding to the correct egress.
[330.92s -> 334.80s]  Presumably, Ethernet switches and routers have more features and functions than that,
[334.80s -> 335.88s]  and they do other things.
[335.88s -> 345.12s]  What would be the sort of the main ticket items that really make that box more
[345.12s -> 350.08s]  complex or differentiate one box from another?
[350.16s -> 355.64s]  So the list of things that they do is a daunting list.
[355.64s -> 362.24s]  That basic function that you just mentioned is essentially what we did in that very first
[362.24s -> 367.36s]  hardware router that we were caching the information.
[367.36s -> 376.20s]  The other things that we do, there's a lot of work done around security features.
[376.20s -> 384.60s]  Sometimes, it's just simple things like checking to be sure that you don't have zero
[384.60s -> 394.16s]  offset fragments, just simple security checks in addition to checking the version number.
[394.16s -> 399.96s]  Of course, when you decrement a TTL, you have to make sure that you redirect the packet
[399.96s -> 406.76s]  to the local CPU if the TTL goes to a zero.
[406.76s -> 413.32s]  You need to provide all sorts of protections of the internal CPU.
[413.32s -> 419.60s]  You don't want to be susceptible to denial of service attacks, and so there's all sorts
[419.60s -> 427.20s]  of filtering and pasting that occurs on the control plane packets that go to the local CPU.
[427.20s -> 436.64s]  There's, you know, monthly cast is a complete nightmare to implement and has 100 different
[436.64s -> 438.40s]  features to make it work right.
[438.40s -> 442.40s]  It's the most difficult thing that we do.
[442.40s -> 447.28s]  There are a number of monitoring functions that have to occur in these switches.
[447.28s -> 451.92s]  Probably the most basic and arguably the most useful is something we call a switch port
[451.92s -> 458.48s]  analyzer where we can mirror all of the traffic going to a particular port on some other port
[458.48s -> 462.80s]  or all the traffic coming in from a port to another port where it would be sent to
[462.80s -> 465.68s]  some sort of analyzer.
[465.68s -> 471.36s]  And then, of course, you want to have multiple of these analyzers running simultaneously,
[471.36s -> 476.00s]  and then you want to have an analyzer on a remote switch that can monitor the traffic
[476.00s -> 479.60s]  on the local switch, and so then you have to figure out how to tunnel that information
[479.60s -> 481.84s]  across the network.
[481.84s -> 488.32s]  You know, quality of service, active queue management, the list goes on and on with
[488.32s -> 491.68s]  these routers, switches and routers do.
[491.68s -> 495.84s]  Yeah, so they're really complex pieces, and I guess they're used in all sorts of different
[495.84s -> 504.24s]  places as well, in the home, the enterprise, wide area networks, data centers, access networks, edge.
[504.24s -> 507.12s]  Are they substantially different?
[507.12s -> 511.28s]  Are the boxes, the systems and the way that they're built substantially different for those
[511.28s -> 515.60s]  different contexts?
[515.60s -> 517.36s]  Yes, they are.
[517.36s -> 525.76s]  If you look at the router in your home, the feature set isn't particularly sophisticated.
[525.76s -> 530.40s]  The bandwidths are low, extremely low.
[530.40s -> 534.80s]  Of course, you know, quite often they have wireless built into them.
[534.88s -> 542.88s]  And so you can, those are usually built using some sort of merchant silicon and running an
[542.88s -> 546.56s]  operating system there, perhaps based upon Linux.
[546.56s -> 553.36s]  The bigger boxes, they come in either fixed form factors, meaning that the number of
[553.36s -> 558.56s]  ports is fixed, you can't change out line cards, and then there's the big chassis,
[558.56s -> 563.68s]  modular chassis where you have multiple line cards and multiple different kinds of interfaces
[563.68s -> 568.64s]  that can go in on each one of those line cards.
[568.64s -> 576.00s]  And the architectures internally for the small switches, it would typically be a switch on
[576.00s -> 577.20s]  a chip.
[577.20s -> 581.84s]  On the bigger systems, of course, that doesn't work because there's more ports than you
[581.84s -> 587.84s]  can fit on a single chip, or the entire system is spread across multiple line cards
[587.84s -> 592.64s]  and sometimes even multiple chassis and multiple racks of chassis.
[592.64s -> 602.24s]  And those systems tend to be based upon crossbars or some sort of centralized relatively
[602.24s -> 607.84s]  simple high-performance switching element that switches the traffic between the line
[607.84s -> 609.84s]  cards or between the port devices.
[611.04s -> 618.96s]  The port devices themselves, or line cards, are generally, the silicon used there looks
[618.96s -> 625.52s]  a lot like the single switch on a chip in that one device may support 48 ports of
[625.52s -> 628.96s]  10 gigabit Ethernet or 48 ports of 40 gigabit Ethernet.
[631.44s -> 637.68s]  And the emphasis in the data center will be on bandwidth and low cost.
[638.88s -> 645.36s]  The emphasis on the campus will be not as much on bandwidth, but it certainly will
[645.36s -> 653.12s]  be based upon cost and a number of access features around authentication and the
[653.12s -> 654.48s]  identification of the endpoints.
[656.56s -> 663.04s]  In the WAN, it's going to be a lot of emphasis around bandwidth and buffering and
[663.04s -> 667.84s]  different kinds of interfaces, as well as quality of service becomes an important
[667.84s -> 668.56s]  factor.
[668.56s -> 671.44s]  So yeah, they're all different flavors.
[671.44s -> 676.48s]  So over the years, as these switches and routers have evolved and developed, what have been
[676.48s -> 681.68s]  the main advances in technology or architecture that have allowed them to scale?
[683.36s -> 687.76s]  Have they been primarily coming from the underlying technology like Moore's Law?
[687.76s -> 691.92s]  Have there been specific technologies that have helped networking switches and routers
[691.92s -> 693.76s]  or specific architectures?
[693.76s -> 696.48s]  What's allowed them to keep up with the performance demands?
[697.20s -> 703.04s]  Well, yeah, you know, if we followed Moore's Law strictly, probably the fastest link in
[703.04s -> 704.48s]  the world would be 10 gigabits.
[704.48s -> 708.64s]  And of course, you know, we're switching orders of magnitude faster than that today.
[709.20s -> 716.24s]  So networks have had to go through, and network boxes have had to go through
[716.24s -> 720.80s]  architectural changes to overcome the limitations of Moore's Law.
[720.80s -> 724.48s]  So absolutely, we take advantage of Moore's Law as much as we can.
[724.96s -> 729.12s]  But if I look at some of the switches that I've been involved in designing, and bear
[729.12s -> 738.40s]  in mind that these switches account for 60% to 70% of the entire switching market.
[738.40s -> 740.64s]  So these are significant platforms.
[742.16s -> 748.00s]  The original Catalyst 5000 product line was based upon a bus.
[748.00s -> 749.52s]  It was a common shared bus.
[749.52s -> 753.20s]  The entire bandwidth of that switch was one gigabit per second.
[753.20s -> 758.56s]  And it was an aggregation of 10 megabit links with some 100 megabit links involved.
[759.68s -> 762.16s]  But that bus quickly ran out of speed.
[762.16s -> 767.92s]  It was the performance of the bus was based upon how fast you could signal on a single
[767.92s -> 771.28s]  wire and how many of those wires you could put in parallel.
[771.28s -> 773.28s]  And that was the limit of the entire chassis.
[774.72s -> 778.08s]  The next generation of that platform, the Catalyst 6000,
[778.08s -> 783.20s]  which is still a, I think it's still maybe a billion dollar product for Cisco.
[783.20s -> 788.40s]  It was delivered in 1998, I believe, 98, 99.
[790.40s -> 794.56s]  It moved to a crossbar architecture.
[794.56s -> 800.40s]  And the crossbar architecture allowed us to have much faster signaling on each wire and
[800.40s -> 805.04s]  to have signaling between ports independent of one another.
[805.04s -> 807.12s]  So it wasn't a bus-based architecture.
[808.00s -> 810.48s]  However, that was not an arbitrated fabric.
[810.48s -> 814.08s]  I know that Nick, you've done a lot of work on arbitration and the importance of
[814.08s -> 820.96s]  arbitration, but we actually, you know, most networks in the world in the 2000,
[820.96s -> 823.36s]  2010 actually did not have arbitration in them.
[824.48s -> 829.44s]  It was basically, you send the packets into the crossbar and hope for the best luck that
[829.44s -> 831.28s]  it's delivered to the other end with no problems.
[831.76s -> 836.00s]  Much less expensive and much less complicated.
[837.68s -> 843.76s]  In the 2010 timeframe, maybe 2008 timeframe, we were really starting to feel the
[843.76s -> 848.56s]  pressure on that crossbar and we added arbitration to it to improve the
[848.56s -> 849.68s]  performance of that crossbar.
[851.28s -> 857.76s]  And also allowed packets to be sprayed across the crossbars to get better
[857.76s -> 864.24s]  performance, so that we had to do packet reordering on the egress side to
[864.24s -> 866.24s]  guarantee a packet order.
[867.44s -> 869.84s]  So those are some of the architectural changes.
[870.72s -> 878.72s]  We've moved from external memories to on-chip memories, use of embedded DRAM was
[878.72s -> 879.92s]  popular for a while.
[879.92s -> 883.68s]  Now we're moving more back to embedded static RAM.
[883.68s -> 888.24s]  That's just following the technologies that are available to us from the silicon
[888.24s -> 889.12s]  perspective.
[889.12s -> 897.52s]  But generally, packaging on custom ASICs has not advanced nearly as much as the
[897.52s -> 903.04s]  silicon itself, and so it's, you know, cheaper to build a bigger die than to have
[903.04s -> 906.16s]  multiple smaller devices that are connected together.
[907.12s -> 908.08s]  Great, thank you.
[908.08s -> 914.08s]  So in class, we have one speaker that was talking about SDN, software-defined networking.
[914.08s -> 921.76s]  And the basic idea is that opening up more programmatic control to the switching
[921.76s -> 926.16s]  sort of forwarding plane from either from the customer, the owner operator of the
[926.16s -> 930.00s]  network, or at least software that's under their control.
[930.00s -> 937.04s]  So if this change, or as this change happens, we'll switch to SDN, software-defined
[937.04s -> 937.68s]  networking.
[937.68s -> 939.36s]  Will switches need to change?
[939.36s -> 940.56s]  How will they change, do you think?
[945.04s -> 950.08s]  You know, that's a big point of some debate.
[950.80s -> 958.16s]  I ultimately don't think that the underlying hardware is going to change in ways that
[958.16s -> 959.76s]  a lot of people think it might change.
[960.64s -> 973.52s]  One part of what we hear about this SDN is around open flow, and open flow would
[973.52s -> 977.04s]  indicate that maybe there should be some architectural changes to the underlying
[977.04s -> 978.00s]  silicon.
[978.00s -> 981.52s]  And I'm not convinced that that's going to be what happens.
[981.52s -> 986.80s]  I think that the underlying silicon and the fields that it uses and how it's
[986.80s -> 990.56s]  structured actually works quite well for us.
[990.56s -> 996.24s]  And whether that's being controlled through a centralized controller or not, I think
[996.24s -> 1003.52s]  is completely orthogonal to whether you use open flow or don't use open flow.
[1003.52s -> 1008.96s]  However, there is another thing that's happening, which is I would characterize
[1008.96s -> 1013.28s]  more than SDN as a virtualization of the network.
[1013.28s -> 1016.56s]  And that virtualization is done through overlay technologies.
[1017.60s -> 1020.88s]  There are a lot of different overlay technologies.
[1022.16s -> 1030.48s]  VXLAN is one, NVJerry is another, STT is one, LISP is one, FabricPath, Trill.
[1031.52s -> 1034.08s]  There's a proliferation of these technologies.
[1034.08s -> 1037.36s]  I do believe that the industry will settle on a small number of them.
[1038.64s -> 1043.92s]  I have my bets, but we won't go into exactly what I'm betting on right now.
[1044.64s -> 1053.20s]  But this overlay technology, I think, really does provide a fundamental value
[1053.20s -> 1054.08s]  in the network.
[1054.08s -> 1061.60s]  And a switch built four years ago probably can't do it or can't do it at scale
[1061.60s -> 1071.04s]  or can't do it in performance and scale.
[1071.04s -> 1078.72s]  So I think new hardware will enable these overlay technologies
[1078.72s -> 1083.04s]  and will continue to improve on what you can do with that overlay technology.
[1084.88s -> 1085.36s]  Great, thank you.
[1085.36s -> 1086.48s]  Do you want to call that SDN?
[1087.44s -> 1087.94s]  Sure.
[1088.48s -> 1089.60s]  One last question.
[1089.60s -> 1094.96s]  So if students want to learn more about design of switches and routers,
[1096.48s -> 1100.16s]  I mean, are there still lots of job opportunities?
[1100.16s -> 1103.36s]  Is it still a growing and expanding field?
[1103.36s -> 1107.76s]  We hear all sorts of talk of the hardware side of switching routers
[1109.12s -> 1110.80s]  becoming a sort of a smaller field.
[1111.60s -> 1115.92s]  And we see everybody going off to work for Google and Facebook and the like.
[1117.60s -> 1121.44s]  Is it still an exciting and growing field to be working in?
[1124.96s -> 1127.76s]  You know, it's an interesting question.
[1127.84s -> 1132.48s]  I've been doing this since 1985.
[1132.48s -> 1134.40s]  So it's been quite a long time.
[1135.12s -> 1140.80s]  And there have been, you know, periods of great excitement.
[1141.44s -> 1146.48s]  We first came up with, you know, switching technologies.
[1146.48s -> 1152.32s]  And the industry was happening and the internet was starting to become a big deal
[1152.32s -> 1153.84s]  and networks came into their own.
[1153.84s -> 1155.52s]  That was a very exciting period of time.
[1156.16s -> 1162.96s]  And I would say that there was a period where there wasn't a lot happening.
[1162.96s -> 1165.84s]  That it was, yes, we're going to build a faster switch.
[1165.84s -> 1167.76s]  We're going to add a couple of knobs here and there.
[1169.44s -> 1175.52s]  And that was sort of the 2000 to 2010 time period.
[1176.96s -> 1180.72s]  I think we are experiencing a bit of a revolution now.
[1181.52s -> 1183.76s]  A lot of it actually has,
[1186.32s -> 1190.16s]  I think that the catalyst for it has been some of the work that you have done.
[1191.28s -> 1194.88s]  And with the open flow and this whole idea of SDN networks and,
[1194.88s -> 1198.16s]  oh, let's do some virtualization.
[1198.16s -> 1205.04s]  And it's not that that technology, you know, came from one source necessarily,
[1205.04s -> 1209.76s]  but was sort of being thought about and baking in a lot of the labs.
[1210.56s -> 1215.76s]  And now it's really burst onto the scene.
[1216.40s -> 1222.16s]  And it really has been intellectually challenging for me
[1222.16s -> 1229.04s]  and very interesting doing ethernet switch design again.
[1230.64s -> 1235.28s]  And that technology will mature and will slow down
[1235.28s -> 1237.76s]  and presumably something else will come along after that.
[1238.64s -> 1240.16s]  Is it a growing industry?
[1241.12s -> 1247.20s]  There are fewer and fewer companies developing their own hardware.
[1249.44s -> 1250.64s]  Cisco of course does it.
[1252.96s -> 1255.12s]  Juniper develops some of their own hardware.
[1255.12s -> 1260.08s]  It's very difficult for a startup to get the funding to develop new hardware.
[1260.08s -> 1262.24s]  So they tend to use merchant silicon.
[1262.24s -> 1266.48s]  And so if you are looking to design switch hardware,
[1268.64s -> 1271.44s]  I think there are fewer opportunities in that space.
[1272.88s -> 1277.52s]  However, I do think there are some pretty interesting things to do in that area.
[1277.52s -> 1281.84s]  And in my own case, I was lucky enough to be in a startup
[1281.84s -> 1287.44s]  and currently am in a startup that does do hardware development of switches.
[1287.44s -> 1294.72s]  And I've got a list so long of things that I want to do,
[1294.72s -> 1296.48s]  and I can't do all of them.
[1296.48s -> 1299.76s]  And I'm sure other people have a list of ideas
[1299.76s -> 1303.60s]  and pretty cool things that can be done in those switches in the hardware.
[1304.64s -> 1308.80s]  So it's not that all of the great ideas have been thought of.
[1309.60s -> 1317.36s]  It's not that bad, but it's not as it was in the late 90s.
[1318.16s -> 1320.80s]  And if you have some internship opportunities come out,
[1320.80s -> 1323.44s]  send me some details and I'll forward them to the class.
[1323.44s -> 1328.80s]  I absolutely would love to hire interns.
[1329.44s -> 1331.76s]  I would bring on many interns.
[1333.36s -> 1335.52s]  OK, wonderful. Let's chat about that.
[1335.52s -> 1337.68s]  So thanks ever so much, Tom. Really appreciate it.
[1337.68s -> 1340.48s]  This is really interesting, provided the kind of insight
[1340.48s -> 1343.68s]  that we can't get in the classroom or from textbooks normally.
[1343.68s -> 1345.76s]  So it's extremely useful. Thank you.
[1345.76s -> 1348.08s]  OK, thank you.
