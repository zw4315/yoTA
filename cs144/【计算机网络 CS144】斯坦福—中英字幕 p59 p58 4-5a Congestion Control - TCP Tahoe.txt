# Detected language: en (p=1.00)

[0.00s -> 4.00s]  So in this video, I'll talk about congestion control, particularly the basic
[4.00s -> 8.00s]  motivation for, for congestion control and transport protocols and protocols in
[8.00s -> 12.00s]  general, and then walk through the first example of a protocol that really
[12.00s -> 17.00s]  identified and tackled this problem, TCP, particular version of TCP called TCP
[17.00s -> 21.00s]  Tahoe. And I'll talk about the first mechanism that TCP Tahoe uses to try
[21.00s -> 25.00s]  and deal with congestion, something called slow start. So the basic
[25.00s -> 31.00s]  motivation for congestion control is that flow control tells an end point, say,
[31.00s -> 37.00s]  Boston's going to tell San Francisco the amount of data they can accept. And so
[37.00s -> 43.00s]  flow control specifies the limitations of the end point. However, it can very
[43.00s -> 49.00s]  well be that this node in Boston is able to receive data much, much faster
[49.00s -> 54.00s]  than the network can support it. So for example, while this node in Boston
[54.00s -> 60.00s]  might have, you know, a buffer that allows it to receive 100 packets per RTT,
[60.00s -> 66.00s]  per RTT, it could be that some bottleneck link on the path from San
[66.00s -> 72.00s]  Francisco to Boston can really only support about five packets per RTT. And
[72.00s -> 78.00s]  so the idea is that if San Francisco communicates with Boston, this node in San
[78.00s -> 82.00s]  Francisco communicates with the node in Boston at a rate which flow control
[82.00s -> 86.00s]  doesn't allow, then it's going to send packets much faster than it can support.
[86.00s -> 89.00s]  Most of these packets are going to be dropped, and it's going to spend a lot
[89.00s -> 92.00s]  of its time doing retransmissions to recover from these heavy errors. You
[92.00s -> 95.00s]  don't want to saturate the network because everything will work less
[95.00s -> 99.00s]  efficiently than if most packets arrive. You'll require less control
[99.00s -> 104.00s]  overhead. The rule would generally work better. And so the basic idea of
[104.00s -> 108.00s]  congestion control is that endpoints should control their data rate so that
[108.00s -> 112.00s]  they do not overload the network. This will generally increase the performance
[112.00s -> 117.00s]  of the network. So if we just take a step back, in terms of congestion
[117.00s -> 121.00s]  control, what really led to it as this very important area of study and
[121.00s -> 126.00s]  of engineering in the Internet, it all comes from TCP. So, basic history of
[126.00s -> 130.00s]  TCP in 1974, established it through a handshake, you know, sin, sin ack,
[130.00s -> 135.00s]  ack. In 1978, TCP and IP were split, were split. It used to be that the
[135.00s -> 139.00s]  Internet just, at that point, the ARPANET just supported TCP, but they realized, oh,
[139.00s -> 143.00s]  we need to split them because we need stuff like UDP. Then January 1, 1983,
[143.00s -> 147.00s]  that was, you know, the switch day when suddenly the entire ARPANET switched
[147.00s -> 151.00s]  over to TCP IP, IPv4. Three years after that,
[151.00s -> 155.00s]  the Internet began to suffer congestion collapse, where links were
[155.00s -> 159.00s]  saturated, they were sending, you know, operating at line speed, yet no
[159.00s -> 164.00s]  worse useful work was being done. Instead, all the packets being
[164.00s -> 169.00s]  transmitted were unnecessary retransmissions or acknowledgements. So
[169.00s -> 175.00s]  you're seeing full utilization of links while simultaneously no application
[175.00s -> 181.00s]  level throughput. So then Van Jacobsen in the seminal paper fixed TCP, figured
[181.00s -> 187.00s]  out what was going on. And he published the seminal TCP paper which described
[187.00s -> 193.00s]  TCP Tahoe. So these names, Tahoe and Reno, come from the versions of hardware
[193.00s -> 198.00s]  for Berkeley Unix that these TCP implementations occurred on. And so you
[198.00s -> 203.00s]  read about Tahoe, Reno, and then after you start getting names like New Reno,
[203.00s -> 208.00s]  Vegas, Daytona, just to follow that theme. But Tahoe and Reno were denoted
[208.00s -> 213.00s]  sort of by versions of the Berkeley, of Berkeley Unix that were distributed in
[213.00s -> 217.00s]  the hardware they were for. So then about, you know, a couple years after
[217.00s -> 221.00s]  this first TCP Tahoe, fast recovery and fast retransmit, something that's in
[221.00s -> 226.00s]  a later video, TCP Reno, which are common today, but the time there are new ideas
[226.00s -> 231.00s]  were added. And so if you look, basically all TCP implementations today
[231.00s -> 236.00s]  have the mechanisms that are in TCP Tahoe and TCP Reno. And so we're gonna go
[236.00s -> 243.00s]  through them in this series of videos. So there are basically three questions
[243.00s -> 249.00s]  that a transport protocol needs to answer if it's gonna provide reliable
[249.00s -> 254.00s]  transport, right? The first is, when should it send new data? That is, when
[254.00s -> 258.00s]  should it send data which it has never put out on the network before? Second
[258.00s -> 261.00s]  is, when should it send a retransmission? When should it try to
[261.00s -> 264.00s]  retransmit data it has sent before? And finally, when should it send
[264.00s -> 267.00s]  acknowledgements for data that it successfully received? These are these
[267.00s -> 271.00s]  basic things of when is it going to generate packets, right? Whether they're
[271.00s -> 275.00s]  data packets, retransmissions of data packets, or acknowledgement packets.
[276.00s -> 279.00s]  Now of course, often we talk about data acknowledgement packets as being
[279.00s -> 283.00s]  independent, but in TCP they're not. The acknowledgements are simply a field
[283.00s -> 286.00s]  in the header, and you can of course piggyback data and acknowledgement. But
[286.00s -> 289.00s]  often we just talk about data acknowledgement separately, just pretending
[289.00s -> 293.00s]  that the flow is unidirectional, though often it might not be. It might be
[293.00s -> 297.00s]  bidirectional. The point being that it can be that you have no data to
[297.00s -> 302.00s]  send, but you do need to send an acknowledgement. So what did TCP look
[302.00s -> 307.00s]  like before TCP Tahoe? So essentially what happens is you set up a connection
[307.00s -> 312.00s]  through a handshake, and at end point now has the flow control window size,
[312.00s -> 317.00s]  denoted by the window field of a TCP header. And so what, pre-Tahoe, what
[317.00s -> 321.00s]  TCP would do is this seemed like a simple thing. It would just send the
[321.00s -> 325.00s]  full window of packets. So if the window said, aha, I'm 30 kilobytes, it
[325.00s -> 329.00s]  would send 30 kilobytes worth of packets. So this is obeying the flow
[329.00s -> 334.00s]  control. It would then start a retransmit timer for each packet. And then if it
[334.00s -> 338.00s]  didn't receive an acknowledgement for that packet by the time the retransmit
[338.00s -> 343.00s]  timer fired, it would then retransmit that packet. And so the basic problem
[343.00s -> 347.00s]  with this encounter is what happens if the flow control window is much larger
[347.00s -> 351.00s]  than what the network can support? It might be that your end point has space
[351.00s -> 355.00s]  for 30 kilobytes, but, you know, the link is already saturated. You can't
[355.00s -> 359.00s]  suddenly just dump another 30 kilobytes on it. I mean, these numbers might seem
[359.00s -> 363.00s]  small now, but back then these were, you know, you had 50, you had relatively slow
[363.00s -> 366.00s]  links in comparison to today's speed. So think of this more of like your
[366.00s -> 370.00s]  window suddenly advertised 30 megabytes. You don't necessarily want to dump 30
[370.00s -> 375.00s]  megabytes onto your DSL or your cable modem link immediately. So if you
[375.00s -> 379.00s]  implement that algorithm, you just send a window of packets, what happens? Well,
[379.00s -> 383.00s]  so here's a picture. So here it's showing on the x-axis is time in seconds
[383.00s -> 388.00s]  and the y-axis is the packet sequence number the, in terms of kilobytes, so the
[388.00s -> 393.00s]  sequence number of the byte that TCPS sent. And so what you see is on
[393.00s -> 397.00s]  connection establishment, it immediately sends a full buffer of
[397.00s -> 401.00s]  packets, about 20 kilobytes worth. And then it's getting some
[401.00s -> 406.00s]  acknowledgement, so it's sending some more data, but then suddenly its window
[406.00s -> 411.00s]  is a certain size, the flow control window, and it hasn't received an
[411.00s -> 416.00s]  acknowledgement for this, this segment here. And so at this point, TCP is
[416.00s -> 420.00s]  blocked, right? Here's the, these dots are showing the packets that are
[420.00s -> 424.00s]  transmitted, so at this point it's blocked in that it is sent up to the
[424.00s -> 428.00s]  last acknowledged byte plus the window size, and it can't send anymore. And
[428.00s -> 433.00s]  the reason is that this packet probably was lost. So then here is the,
[433.00s -> 440.00s]  basically here's the timeout. And it retransmits that packet. Then,
[440.00s -> 445.00s]  as you can see, it's able to send a whole bunch more packets, it gets a whole bunch
[445.00s -> 449.00s]  of acknowledgements, or it gets a cumulative acknowledgement allowing the
[449.00s -> 453.00s]  window to move forward, et cetera, et cetera. But the basic point to see
[453.00s -> 458.00s]  here is that there are these huge sawtooths that you see big bursts of
[458.00s -> 463.00s]  packets followed by idle timeouts. Big bursts of packets followed by idle
[463.00s -> 467.00s]  timeouts. And that many of these packets are redundant, like this
[467.00s -> 472.00s]  packet here is sent three times. And this one is also sent three times.
[472.00s -> 477.00s]  So you're seeing lots of additional retransmissions. And overall, the
[477.00s -> 482.00s]  protocol's not performing very well. It's sending all these packets, but if
[482.00s -> 487.00s]  you look at the actual slope of this line, in the sense of the data
[487.00s -> 492.00s]  outstanding, the slope isn't very high. If TCP were operating at line speed,
[492.00s -> 496.00s]  operating at the correct speed, it should be following this line here. But
[496.00s -> 500.00s]  instead, it's following a line with a much lower slope. It's actually sending
[500.00s -> 504.00s]  data much slower than it should be able to. So this is what was observed,
[504.00s -> 509.00s]  that TCP is very slow because it's sending lots of retransmissions
[509.00s -> 514.00s]  unnecessarily, and there are lots of timeouts. So based on this,
[514.00s -> 521.00s]  Van Jacobsen proposed three improvements. The first is the idea of a congestion
[521.00s -> 525.00s]  window. The second is better timeout estimation, and the last is self-clocking.
[525.00s -> 529.00s]  I'm going to walk through each of those. The congestion window, I'm going to
[529.00s -> 533.00s]  talk about in this video. In future videos, I'll talk about timeout
[533.00s -> 539.00s]  estimation and self-clocking. So the congestion window.
[539.00s -> 545.00s]  So the basic insight is that the flow control window is only about the end
[545.00s -> 550.00s]  point. And so what you want to do is have TCP estimate a congestion window
[550.00s -> 554.00s]  that is, how much can the network support? When I, in the sense of how
[554.00s -> 557.00s]  quickly can I send data and have the network deliver it reliably? And then
[557.00s -> 560.00s]  the sender window is going to be the minimum of these two. In the sense of
[560.00s -> 563.00s]  there's no point sending data faster than the network can support, nor is
[563.00s -> 567.00s]  there any point sending data faster than the end host can support. And then
[567.00s -> 571.00s]  what you do is, based on this idea of a congestion window, you separate how
[571.00s -> 575.00s]  you behave in terms of sending packets and the size of this congestion
[575.00s -> 581.00s]  window into two states. The first is something called slow start. The second
[581.00s -> 585.00s]  is congestion avoidance. You slow start when you're doing connection
[585.00s -> 589.00s]  startup or when there's a packet timeout. When something has gone very
[589.00s -> 593.00s]  wrong and you want to just back off completely and then figure out what it
[593.00s -> 597.00s]  is that the network can support. Congestion avoidance, in contrast, is
[597.00s -> 601.00s]  when the network, when you're behaving pretty well. That is, you're operating
[601.00s -> 605.00s]  close to the network capacity, and so you don't want to start sending things
[605.00s -> 610.00s]  much faster, nor much slower. You're operating close to what you think the
[610.00s -> 617.00s]  congestion window of the network is. So the idea of slow start is that what
[617.00s -> 623.00s]  the node does is rather than start its window at the flow control window
[623.00s -> 628.00s]  size, it starts its window at a size of a minimum, maximum segment, segment
[628.00s -> 633.00s]  size. So basically one segment, one packet's worth of data. Today, nodes
[633.00s -> 637.00s]  might start with two or four. There's some rules about that, two,
[637.00s -> 643.00s]  three, or four, but the original version started at one. And then every
[643.00s -> 648.00s]  time a packet's acknowledged, every time you receive a new acknowledgement, you
[648.00s -> 652.00s]  increase this window by the maximum segment size. And what this means in
[652.00s -> 656.00s]  terms of practice is that in the first round trip time, you're gonna send a
[656.00s -> 660.00s]  single packet, it'll be acknowledged. Now your segment size, now your window size
[660.00s -> 663.00s]  is two, so you'll send two packets, they'll both be acknowledged. You
[663.00s -> 666.00s]  increase by two, now you'll send four packets, they'll be acknowledged.
[666.00s -> 669.00s]  You'll then send eight packets, there's this exponential growth. And so that's
[669.00s -> 673.00s]  what you're seeing here. See, here's one packet, two packets, or there's
[673.00s -> 677.00s]  one, two, four, you know, eight, et cetera. This exponential growth,
[677.00s -> 681.00s]  scaling up, so in a large, logarithmic number of steps, you can
[681.00s -> 685.00s]  hopefully discover what is the con, the congestion window size of the network.
[685.00s -> 689.00s]  So this might seem, I mean, exponential growth is not slow, and so the name is, it
[689.00s -> 693.00s]  can be a little confusing. The reason it's called slow is that it's slow compared to
[693.00s -> 696.00s]  the prior approach. It's actually the much faster mode of TCP today, but
[696.00s -> 700.00s]  compared to sending an entire flow control window of packets, doing this
[700.00s -> 704.00s]  exponential scale up through a logarithmic number of steps was
[704.00s -> 708.00s]  comparatively so. So it's an interesting sort of historic compared to modern
[709.00s -> 716.00s]  modern idea. And so we can see in this figure, this is also from Van
[716.00s -> 722.00s]  Jacobsen's paper, that the packet sequence number, you know, is increasing
[722.00s -> 726.00s]  this way, and you see this exponential growth, and then using slow start, you
[726.00s -> 730.00s]  end up, plus then the congestion avoidance state that I'll talk about in
[730.00s -> 733.00s]  a moment, you end up hitting this nice steady state. And while it takes you a
[733.00s -> 737.00s]  little bit of time to discover what the line speed is, eventually the
[737.00s -> 741.00s]  behavior of the protocol is very close to this line speed, and it's operating close
[741.00s -> 746.00s]  to capacity, it's not overwhelming it, and you're not seeing these sawtooths of
[746.00s -> 752.00s]  terrible performance. So that's the slow start state. So in the slow start
[752.00s -> 756.00s]  state, you are increasing the congestion window by a maximum segment size for
[756.00s -> 759.00s]  each acknowledgement. This leads to an exponential increase in the window size.
[759.00s -> 764.00s]  The second state that you can be in is called congestion avoidance. And in
[764.00s -> 769.00s]  this model, when you're in the congestion avoidance state, you increase
[769.00s -> 774.00s]  the congestion window by the maximum segment size squared, divided by the
[774.00s -> 778.00s]  congestion window for each acknowledgement. What this behavior results
[778.00s -> 782.00s]  is, rather than increase by the window by maximum segment size for each
[782.00s -> 786.00s]  acknowledgement, you end up increasing the maximum segment size for each round
[786.00s -> 790.00s]  trip time. So it's an additive increase, whereas this is growing the window
[790.00s -> 795.00s]  exponentially, this is growing the window size linearly.
[801.00s -> 805.00s]  So we have these two states, slow start and congestion avoidance. How do we
[805.00s -> 808.00s]  transition between them? Well, really there are these two goals. One is slow
[808.00s -> 812.00s]  start to quickly find what the network congestion capacity is. That is, how fast
[812.00s -> 816.00s]  can we send things before the network enters congestion and starts buffering
[816.00s -> 821.00s]  packets. And so then, once we are close to that capacity, one is congestion
[821.00s -> 825.00s]  avoidance to very carefully probe. So we're below the congestion points, let's
[825.00s -> 829.00s]  just start slowly increasing until we reach it, then maybe drop down a little
[829.00s -> 832.00s]  bit, then start slowly increasing until we reach it. We basically can use that
[832.00s -> 836.00s]  to stay close to that value and be close to the network capacity. And we
[836.00s -> 839.00s]  have three signals to accomplish this, right? The first is if we're seeing
[839.00s -> 842.00s]  increasing acknowledgements, that means the data transfer is going well, maybe
[842.00s -> 845.00s]  we can speed things up a bit. The second is if we have duplicate
[845.00s -> 849.00s]  acknowledgements. Remember, TCP's using cumulative acknowledgements. So if we're
[849.00s -> 852.00s]  seeing many acknowledgements for the same piece of data, that means TCP is
[852.00s -> 856.00s]  receiving segments, but one of them's missing. So this means something was lost
[856.00s -> 859.00s]  or delayed. The final signal is if there's a timeout. If we've sent a
[859.00s -> 862.00s]  whole bunch of packets or a window of packets and we've heard nothing and
[862.00s -> 865.00s]  there's a timeout, that means something very wrong has happened. Or maybe way
[865.00s -> 868.00s]  off of what the congestion is, maybe the network has suddenly become
[868.00s -> 871.00s]  congested. Because it itself can have dynamic traffic.
[873.00s -> 879.00s]  So this is the TCP Tahoe finite state machine. I'm going to walk through it bit
[879.00s -> 885.00s]  by bit. So when you open a TCP Tahoe connection, you start in a slow start
[885.00s -> 890.00s]  state with a maximum, with a window of a maximum segment size. And recall that
[890.00s -> 894.00s]  your actual window will never grow larger than your flow control window,
[894.00s -> 897.00s]  the minimum of the flow control window and congestion control window. So this
[897.00s -> 901.00s]  is controlling the congestion control window size. Then every time we're in
[901.00s -> 906.00s]  the slow start state and we receive an acknowledgement, we increase the
[906.00s -> 911.00s]  congestion window, this is Cwind, by the maximum segment size. So this is
[911.00s -> 913.00s]  the exponential increase here.
[923.00s -> 928.00s]  Then we have a parameter SS threshold, which is, this stands for slow start
[928.00s -> 933.00s]  threshold. If the congestion window grows larger than the slow start threshold,
[933.00s -> 937.00s]  then we transition to the congestion avoidance state. This means that, hey, we
[937.00s -> 941.00s]  suddenly have a big enough congestion window, then we should slow down our
[941.00s -> 945.00s]  growth. And so we transition to congestion avoidance. Now in the
[945.00s -> 949.00s]  congestion avoidance state, if we receive an acknowledgement, we increase
[949.00s -> 953.00s]  the congestion window by maximum segment size squared divided by the congestion
[953.00s -> 955.00s]  window, this is the linear increase.
[958.00s -> 963.00s]  And so we see that the window size will look like this over time, effectively.
[963.00s -> 970.00s]  Where here is when we hit SS thresh. And this part corresponds to this
[970.00s -> 973.00s]  state, and this part corresponds to this state.
[977.00s -> 981.00s]  But now what happens if we're in the congestion avoidance state and this
[981.00s -> 986.00s]  linear increase goes beyond the congestion capacity of the network? Well then
[986.00s -> 991.00s]  what's gonna happen is we're gonna see a timeout or a triple duplicate ACK. A
[991.00s -> 996.00s]  triple duplicate ACK, this implies a packet was lost. We're seeing these,
[996.00s -> 1001.00s]  these many acknowledgements. And so what TCP Tahoe does on seeing either a
[1001.00s -> 1006.00s]  timeout or triple duplicate ACK is it resets the congestion window to be one.
[1006.00s -> 1012.00s]  And it sets the SS threshold to be the old congestion window divided by two. And
[1013.00s -> 1019.00s]  so what this is gonna do is after say this we see this linear growth and then
[1019.00s -> 1025.00s]  at this point say we see a triple duplicate ACK. What'll happen is that TCP
[1025.00s -> 1031.00s]  Tahoe is going to set, I'll use blue, it's gonna set SS thresh to be half of
[1031.00s -> 1039.00s]  what the congestion window is at that time. It's then going to reenter slow
[1040.00s -> 1046.00s]  start, do an exponential increase until it reaches this SS thresh, which point then
[1046.00s -> 1051.00s]  set SS threshold, which point will then enter congestion avoidance and do a
[1051.00s -> 1056.00s]  linear increase. And so the way to think of this is that upon this triple
[1056.00s -> 1061.00s]  duplicate ACK or this timeout, the TCP Tahoe has discovered what it thinks is
[1061.00s -> 1066.00s]  too much, too fast at transmission rates, window is too big. So then what it
[1066.00s -> 1070.00s]  does is it says okay, I'm gonna exponentially grow my window until I
[1070.00s -> 1074.00s]  reach half of that point and then I'll start linearly increasing it. So that way
[1074.00s -> 1078.00s]  you can hopefully quickly get back to, you know, close to capacity in a
[1078.00s -> 1081.00s]  logarithmic number of steps. But then you don't wanna get too close and
[1081.00s -> 1084.00s]  so you start at half of, half of what that old value was and then start
[1084.00s -> 1088.00s]  linearly increasing again. So this is the basic finite state machine for
[1088.00s -> 1093.00s]  TCP Tahoe. So here I will walk through a simple example. So we start with a
[1093.00s -> 1099.00s]  sender and let's just say SS thresh is equal to four when it starts up. So at
[1099.00s -> 1105.00s]  first it's gonna send a single TCP segment, single maximum segment size
[1105.00s -> 1110.00s]  segment. The receiver, let's just call this one. I'll number them as packets
[1110.00s -> 1116.00s]  for simplicity. The receiver sends an acknowledgement. So at this point, here
[1116.00s -> 1122.00s]  our congestion window is equal to one. Now, since we're in a slow start state,
[1122.00s -> 1131.00s]  it'll become two. It becomes two. And so the sender can send two packets, three
[1131.00s -> 1150.00s]  and four. The receiver receives them. I'm sorry. Two and three. The receiver
[1150.00s -> 1158.00s]  receives them, sends acknowledgements. Now our congestion window is four. Which
[1158.00s -> 1170.00s]  means that we will send four packets. Which would be four, five, six, seven.
[1170.00s -> 1174.00s]  Now at this point, congestion window has reached the slow start threshold.
[1174.00s -> 1179.00s]  Which means that TCP Tahoe is going to exit this ex-, the slow start state and
[1179.00s -> 1185.00s]  enter the congestion avoidance state. And so when these acknowledgements come back,
[1185.00s -> 1191.00s]  it's going to increase the window by one. And so rather than send eight
[1191.00s -> 1197.00s]  packets, congestion window will be five. And it will send five packets. So let's
[1197.00s -> 1202.00s]  just say, I'll just draw one arrow here, of packets eight, nine, ten, eleven,
[1202.00s -> 1207.00s]  twelve. Now let's say that packet eight is lost. It's dropped in the
[1207.00s -> 1210.00s]  network. We've actually reached our congestion point. Well, what will happen?
[1210.00s -> 1214.00s]  Well, the receiver is going to acknowledge eight. It's going to
[1214.00s -> 1217.00s]  acknowledge that eight was received. And remember, this is TCP, so the ACK
[1217.00s -> 1220.00s]  would actually say nine, but I'll just write, write eight for simplicity's
[1220.00s -> 1224.00s]  sake. So we're going to say, aha, I've received eight. Then ten, eleven,
[1224.00s -> 1230.00s]  and twelve arrive. Now TCP is going to then send acknowledgement eight,
[1230.00s -> 1236.00s]  eight, eight. Because it's cumulative acknowledgements, it hasn't received
[1236.00s -> 1239.00s]  nine, it can only say I've received eight, I've received eight, received eight.
[1239.00s -> 1242.00s]  This is a triple duplicate acknowledgement. We have three duplicates.
[1242.00s -> 1247.00s]  So what now TCP-TAO is going to do is it's going to transition back to the
[1247.00s -> 1253.00s]  slow start state. My congestion window is five. So I'm going to set my slow
[1253.00s -> 1259.00s]  start threshold to be equal to half of the congestion window. Right? So let's
[1259.00s -> 1264.00s]  just say we're going to set it to basically 2.5. And enter the slow start
[1264.00s -> 1270.00s]  state again. So I'll send a single packet. Right? Now this packet is going
[1270.00s -> 1275.00s]  to be sent on a timeout. So essentially I'm waiting for the
[1275.00s -> 1279.00s]  acknowledgement nine. I haven't heard it. I'll timeout, and I will send, I will
[1279.00s -> 1284.00s]  resend nine. Then that's the number of packets I can have outstanding.
[1284.00s -> 1290.00s]  Then if an acknowledgement for nine comes back, I can set my congestion
[1291.00s -> 1296.00s]  window to two. But this acknowledgement won't just be for nine, because it's
[1296.00s -> 1300.00s]  received ten, eleven, and twelve. So what that acknowledgement is actually
[1300.00s -> 1304.00s]  going to say is acknowledge twelve. So I now have my congestion window to
[1304.00s -> 1308.00s]  two. I know twelve has been received. I can send thirteen and fourteen. And
[1308.00s -> 1312.00s]  I'm back in the slow start state. Until I reach this SS threshold, which
[1312.00s -> 1316.00s]  point will transition back to congestion avoidance. So that's a basic
[1316.00s -> 1321.00s]  walkthrough of TCP Tahoe and how it behaves. It's moving between slow start
[1321.00s -> 1325.00s]  and congestion avoidance, and how it's using triple duplicate acts in order to
[1325.00s -> 1329.00s]  infer that something has gone wrong and return back to the slow start state.
[1329.00s -> 1332.00s]  It's using that to infer that there's congestion and slow down.
