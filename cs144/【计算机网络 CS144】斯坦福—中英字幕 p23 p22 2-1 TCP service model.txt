# Detected language: en (p=1.00)

[0.00s -> 5.60s]  In this video, you're going to be learning about TCP, the Transmission Control Protocol,
[5.60s -> 9.20s]  which is used by over 95% of all Internet applications.
[9.20s -> 14.28s]  TCP is almost universally used because it provides the reliable end-to-end bi-directional
[14.28s -> 18.08s]  byte stream service that almost all applications want.
[18.08s -> 21.80s]  TCP is an example of the transport layer.
[21.80s -> 25.56s]  When an application calls TCP, it hands it some bytes that it wants delivered to
[25.56s -> 26.72s]  the other end.
[26.72s -> 31.72s]  TCP places these bytes into a TCP segment, and then takes it from there.
[31.72s -> 37.16s]  TCP hands the segments to the IP layer, which encapsulates it into an IP datagram.
[37.16s -> 39.60s]  The IP addresses are added.
[39.60s -> 43.52s]  The IP datagram is handed in turn to the link layer, which builds the link frame,
[43.52s -> 50.92s]  adds the link address, for example the Ethernet addresses, and then sends it onto the wire.
[50.92s -> 55.04s]  When two applications use TCP, they establish a two-way communication channel between
[55.04s -> 57.88s]  the TCP peers at both ends.
[57.88s -> 62.08s]  First, TCP establishes a communication channel from A to B.
[62.08s -> 65.04s]  Then it establishes the channel from B to A.
[65.04s -> 67.84s]  We call the two-way communication a connection.
[67.84s -> 72.00s]  At both ends of the connection, TCP keeps a state machine to keep track of how the
[72.00s -> 73.52s]  connection is doing.
[73.52s -> 77.48s]  We'll see how the state machine works in a separate video.
[77.48s -> 82.24s]  The TCP connection is established using a three-way handshake between hosts A and B.
[82.48s -> 86.88s]  First of all, host A sends a message to B, indicating that the TCP layer at A wants to
[86.88s -> 90.60s]  establish a connection with the TCP layer at B.
[90.60s -> 96.12s]  The message is called a SYN message, which is short for synchronize, because A also
[96.12s -> 100.98s]  sends along the base number it will use to identify bytes in the byte stream.
[100.98s -> 103.72s]  If it sends 0, then the numbers will start at 0.
[103.72s -> 107.52s]  If it sends 1000, then they will start at 1000.
[107.52s -> 110.92s]  B responds with what we call a SYN plus ACK.
[110.92s -> 115.36s]  B signals an ACK because B is acknowledging A's request and agreeing to establish the
[115.36s -> 118.04s]  communication from A to B.
[118.04s -> 123.48s]  The TCP layer at B also sends a SYN back to A to indicate that the TCP layer at B
[123.48s -> 127.48s]  wants to establish a connection with the TCP layer at A.
[127.48s -> 131.08s]  It sends a number 2 indicating the starting number for the byte stream in the reverse
[131.08s -> 132.08s]  direction.
[132.08s -> 137.56s]  Finally, A responds with an ACK to indicate that it is accepting the request for communication
[137.56s -> 139.48s]  in the reverse direction.
[139.48s -> 141.44s]  The connection is now set up in both directions.
[141.44s -> 145.96s]  They are now ready to start sending data to each other.
[145.96s -> 153.16s]  The hosts send data to each other as if it were from a continuous stream of bytes.
[153.16s -> 158.38s]  Assume time is increasing from left to right, and the stream of bytes next to A represents
[158.38s -> 163.90s]  the bytes it wants to send to B. The stream of bytes might exist in advance.
[163.90s -> 168.84s]  For example, they are read from an HTML file describing a static web page.
[168.84s -> 173.28s]  Or it could be a stream being generated on the fly, for example from a video camera.
[173.28s -> 177.44s]  Either way, TCP sees it as a stream of bytes.
[177.44s -> 182.40s]  Data from the application on A is delivered to the application at B. The TCP layers on
[182.40s -> 186.52s]  A and B work together to make sure the stream of bytes is delivered correctly in
[186.52s -> 190.20s]  order to the application at B.
[190.20s -> 194.92s]  The stream of bytes is delivered by TCP segments.
[194.96s -> 200.20s]  A puts bytes from the stream into a TCP segment, hands it to the IP layer, which delivers
[200.20s -> 207.60s]  it to B. The TCP layer at B extracts the bytes to recreate the byte stream and delivers
[207.60s -> 210.80s]  them to the application at B.
[210.80s -> 215.24s]  In practice, the TCP segment may need to be transmitted multiple times, in the case
[215.24s -> 219.92s]  a segment is dropped along the way, or if A doesn't receive an acknowledgement.
[219.92s -> 222.92s]  The TCP segment can be as small as one byte.
[222.92s -> 227.56s]  For example, if you are typing characters in an SSH session, each character is sent
[227.56s -> 232.08s]  one at a time, rather than waiting for the whole segment to fill up.
[232.08s -> 235.44s]  This isn't very efficient when we have lots of data to send, so we can fill the
[235.44s -> 240.56s]  TCP segment all the way up to a maximum IP datagram size.
[240.56s -> 244.54s]  When A and B have finished sending data to each other, they need to close the connection.
[244.54s -> 248.80s]  We say they tear down the connection, which means they tell each other they are closing
[248.80s -> 254.28s]  the connection, and both ends can clean up the state associated with the state machine.
[254.28s -> 259.04s]  The TCP layer at host A can close the connection by sending a FIN message, which is short for
[259.04s -> 261.12s]  FINISH.
[261.12s -> 265.44s]  Host B acknowledges that A no longer has data to send, and stops looking for new data
[265.44s -> 272.52s]  from A. This closes down the data stream from A to B. But B might still have new
[272.52s -> 277.68s]  data to send to A, and is not ready to close down the channel from B to A yet.
[277.68s -> 283.96s]  So the message from B to A carrying the ACK can also carry new data from B to A. B can
[283.96s -> 289.02s]  keep sending new data to A as long as it needs to.
[289.02s -> 295.52s]  Some time later, B finishes sending data to A, and now sends its own FIN to tell A
[295.52s -> 297.76s]  they can close the connection.
[297.76s -> 302.84s]  Host A replies by sending an ACK to acknowledge that the connection is now closed.
[302.84s -> 307.06s]  Because both directions have finished, the connection is now fully closed, and the state
[307.06s -> 310.10s]  can be safely removed.
[310.10s -> 314.22s]  Here is a table summarizing the services provided by TCP.
[314.22s -> 318.52s]  The first three are services TCP provides to the application.
[318.52s -> 325.66s]  As we just saw, it provides a reliable stream of bytes between two applications.
[325.66s -> 329.70s]  TCP uses four mechanisms to make the communication reliable.
[329.70s -> 333.42s]  In other words, to make sure the data is correctly delivered.
[333.42s -> 337.90s]  When a TCP layer receives data, it sends an acknowledgement back to the sender to let
[337.90s -> 341.06s]  it know the data arrived correctly.
[341.06s -> 343.78s]  Check sums detect corrupted data.
[343.78s -> 348.94s]  The TCP header carries a check sum covering the header and the data inside the segment.
[348.94s -> 352.90s]  The check sum is there to detect if the segment is corrupted along the way, for example
[352.90s -> 358.42s]  by a bit error on the wire or by a memory fault inside a router.
[358.42s -> 361.16s]  Sequence numbers detect missing data.
[361.16s -> 365.48s]  Every segment's header carries the sequence number, in the stream of bytes, of the first
[365.48s -> 367.14s]  byte in the segment.
[367.14s -> 371.96s]  For example, if the two sides agree that the sequence starts at 1000, then the first
[371.96s -> 374.90s]  segment will have a sequence number of 1000.
[374.90s -> 379.32s]  If the segment carries 500 bytes of data, then the next segment will carry the sequence
[379.32s -> 382.36s]  number 1500.
[382.36s -> 386.48s]  If a segment gets lost, then the sequence number will be incorrect, and the TCP layer
[386.48s -> 388.24s]  knows some data is missing.
[388.76s -> 392.72s]  It is possible it will show up later, perhaps it took a longer path, or it might have gone
[392.72s -> 397.60s]  missing, in which case the sender will need to resend the data.
[397.60s -> 401.16s]  Flow control prevents overrunning the receiver.
[401.16s -> 406.92s]  If host A is much faster than host B, then it's possible for host A to completely overwhelm
[406.92s -> 412.28s]  host B by sending data so fast that host B can't keep up.
[412.28s -> 417.44s]  TCP prevents this from happening using something we call flow control.
[417.44s -> 421.84s]  In TCP, the receiver keeps telling the sender if it can keep sending.
[421.84s -> 426.24s]  Specifically, it tells the sender how much room it has in its buffers to accept new
[426.24s -> 427.50s]  data.
[427.50s -> 432.88s]  If host B is falling behind, the space drops, possibly all the way to zero.
[432.88s -> 437.40s]  When it has more room, it tells A, and it can send more data.
[440.40s -> 444.16s]  TCP delivers data to the application in the right sequence.
[444.16s -> 448.80s]  In other words, whatever sequence the data was delivered from the application to TCP at
[448.80s -> 455.36s]  host A, this is the same order in which it is sent from TCP to the application at B.
[455.36s -> 460.32s]  If segments arrive at B out of order, the TCP layer resequences them to the correct
[460.32s -> 463.20s]  order using the sequence number.
[463.20s -> 468.88s]  Finally, TCP provides a service to the whole network by controlling congestion.
[469.20s -> 474.24s]  TCP tries to divide up the network capacity equally among all the TCP connections using
[474.24s -> 475.76s]  the network.
[475.76s -> 479.96s]  The congestion control mechanisms in TCP are very complicated, and will devote the whole
[479.96s -> 486.24s]  of Unit 4 to studying congestion control.
[486.24s -> 492.12s]  The TCP segment header is much longer and more complicated than, say, the IP and Ethernet
[492.12s -> 493.12s]  headers.
[493.12s -> 496.28s]  That is because a TCP connection is reliable.
[496.28s -> 500.32s]  In order to make the communication reliable, the two ends of the connection need to exchange
[500.32s -> 503.96s]  more information, so they know which bytes have arrived, which are missing, and the
[503.96s -> 505.64s]  status of the connection.
[505.64s -> 510.20s]  Here's a quick summary of the most important fields in the TCP header.
[510.20s -> 513.08s]  You don't need to remember the layout of the header, but you should learn what
[513.08s -> 514.94s]  each field does.
[514.94s -> 521.40s]  If you need a reference, I'd recommend Wikipedia or the Corosi and Ross textbook.
[521.40s -> 526.12s]  The destination port tells the TCP layer which application the bytes should be delivered
[526.12s -> 528.08s]  to at the other end.
[528.08s -> 532.96s]  When a new connection starts up, the application tells TCP which service to open a connection
[532.96s -> 533.96s]  with.
[533.96s -> 538.36s]  For example, if TCP is carrying web data, it uses port 80, which is the port number
[538.36s -> 539.36s]  for TCP.
[539.36s -> 543.00s]  You'll learn more about port numbers later, but if you're curious, you can look up
[543.00s -> 547.60s]  the well-known port numbers at the IANA, that's spelled I-A-N-A, website.
[547.60s -> 549.64s]  Search for IANA port numbers.
[550.32s -> 553.92s]  You'll find thousands of port numbers defined for different well-known services.
[553.92s -> 559.40s]  For example, when we open a connection to an SSH server, we use destination port 22.
[559.40s -> 564.74s]  For SMTP, the simple mail transfer protocol, we use port 23.
[564.74s -> 568.84s]  Using a well-known port number lets host B identify the application it should establish
[568.84s -> 572.40s]  the connection with.
[572.40s -> 577.00s]  The source port tells the TCP layer at the other end which port it should use to send
[577.00s -> 578.64s]  data back again.
[578.64s -> 584.04s]  In our example, when host B replies to host A, it should place host A's source port
[584.04s -> 588.32s]  number in the destination port field, so that host A's TCP layer can deliver the
[588.32s -> 591.24s]  data to the correct application.
[591.24s -> 597.92s]  When a new connection starts, the initiator of the connection, in our case host A, generates
[597.92s -> 602.64s]  a unique source port number to differentiate the connection from any other connections
[602.64s -> 607.64s]  between host A and B to the same service.
[607.64s -> 611.40s]  The sequence number indicates the position in the byte stream of the first byte in the
[611.40s -> 613.28s]  TCP data field.
[613.28s -> 617.64s]  For example, if the initial sequence number is 1000 and this is the first segment, then
[617.64s -> 620.32s]  the sequence number is 1000.
[620.32s -> 624.12s]  The acknowledgement sequence number tells the other end which byte we're expecting
[624.12s -> 625.16s]  next.
[625.16s -> 629.52s]  It also says that we've successfully received every byte up until the one before this
[629.52s -> 631.44s]  byte number.
[631.44s -> 636.12s]  So for example, if the acknowledgement sequence number is 751, it means we've received
[636.12s -> 640.44s]  every byte up to and including byte 750.
[640.44s -> 643.64s]  Notice that there are sequence numbers for both directions in every segment.
[643.64s -> 648.08s]  This way, TCP piggybacks acknowledgments on the data segments travelling in the other
[648.08s -> 651.36s]  direction.
[651.36s -> 656.32s]  The 16-bits checksum is calculated over the entire header and data, and helps the
[656.32s -> 658.72s]  receiver detect corrupt data.
[658.72s -> 662.64s]  For example, bit errors on the wire, or a faulty memory in a router.
[662.64s -> 668.36s]  You'll learn more about error detection and checksums in a later video.
[668.36s -> 674.12s]  The header length field, the one on the far left, tells us how long the TCP header is.
[674.12s -> 678.32s]  The TCP options fields are, well, optional.
[678.32s -> 683.04s]  They carry extra new header fields that were thought of and added after the TCP standard
[683.04s -> 684.48s]  was created.
[684.48s -> 688.32s]  The header length field tells us how many option fields are present.
[688.32s -> 690.16s]  Usually there are none.
[690.16s -> 694.24s]  Finally, there are a bunch of flags used to signal information from one end of the
[694.24s -> 697.12s]  connection to the other.
[697.12s -> 701.28s]  The ACK flag tells us that the acknowledgement sequence number is valid, and we're acknowledging
[701.28s -> 703.72s]  all of the data up until this point.
[703.72s -> 707.64s]  The SYN flag tells us that we are signalling a synchronise, which is part of the three-way
[707.64s -> 710.12s]  handshake to set up a connection.
[710.12s -> 714.12s]  And the FIN flag signals the closing of one direction of the connection.
[714.12s -> 719.76s]  Finally, the PUSH flag, PSH, tells us the TCP layer at the other end to deliver the
[719.76s -> 723.88s]  data immediately upon arrival, rather than wait for more data.
[723.88s -> 729.32s]  This is useful for sending short segments carrying time-critical data, such as a keystroke.
[729.32s -> 733.16s]  We don't want the TCP layer to wait to accumulate many keystrokes before delivering
[733.16s -> 735.56s]  them to the application.
[735.56s -> 742.80s]  A TCP connection is uniquely identified by five pieces of information in the TCP and IP headers.
[742.80s -> 748.40s]  The IP source and destination address uniquely identify the endpoints, and the IP protocol
[748.40s -> 753.16s]  ID for TCP tells us the connection is TCP.
[753.16s -> 758.08s]  The TCP source and destination ports identify the application processes on the end hosts.
[758.08s -> 764.08s]  Together, at any instant, all five fields uniquely identify the TCP connection internet-wide.
[764.08s -> 770.68s]  Now, the unique ID only holds if a few things hold.
[770.68s -> 775.60s]  First, we need to make sure Host A, the initiator of the connection, picks a unique
[775.60s -> 777.64s]  source port ID.
[777.64s -> 781.36s]  We need to make sure it doesn't accidentally pick the same source port number it already
[781.36s -> 786.04s]  used with another connection to the same service on Host B.
[786.04s -> 789.08s]  Host A uses a simple method to minimize the chances.
[789.08s -> 792.88s]  It increments the source port number for every new connection.
[792.88s -> 799.04s]  The field is 16 bits, so it takes 64K new connections before the new field wraps around.
[799.04s -> 804.40s]  There's also a very slight danger that if Host A suddenly creates a lot of new connections
[804.40s -> 808.92s]  to Host B, it might still wrap around and try to create two connections with the same
[808.92s -> 811.28s]  global ID.
[811.28s -> 815.16s]  If this happened, the bytes from one connection might become confused with the bytes from
[815.16s -> 816.48s]  another connection.
[816.48s -> 820.58s]  This could happen, for example, if a TCP segment somehow lived for a very long time
[820.58s -> 826.40s]  in the network, stuck inside a router buffer, or circulating in a temporary loop.
[826.40s -> 831.74s]  To reduce the chances of confusion, TCP connections initialize with a random initial sequence
[831.74s -> 834.90s]  number to refer to bytes in the byte stream.
[834.90s -> 839.66s]  While not totally foolproof, it does reduce the chances of confusion.
[839.66s -> 844.10s]  When Host A initiates the connection to B, it includes the initial sequence number
[844.10s -> 847.50s]  it will use in the stream of bytes from A to B.
[847.50s -> 854.60s]  When B replies and initiates the connection from B to A, it supplies its own initial
[854.60s -> 857.70s]  sequence number from the stream of bytes from B to A.
[862.74s -> 867.50s]  So to summarize how sequence numbers work, the sequence number in a segment from A to
[867.50s -> 874.38s]  B includes the sequence number of the first byte, offset by the initial sequence number.
[874.38s -> 879.14s]  The acknowledgement sequence number in the segment from B back to A tells us which
[879.14s -> 885.38s]  byte B is expecting next, offset by A's initial sequence number.
[885.38s -> 890.94s]  Let's summarize how TCP port numbers work.
[890.94s -> 898.06s]  Imagine that Host B on the right offers two services, a web server and a mail server.
[898.06s -> 902.90s]  When the web client, for example a Chrome browser on Host A, wants to request a page
[902.90s -> 906.98s]  from the web server on B, it sends the data to TCP.
[906.98s -> 911.56s]  We'll assume TCP has already established a connection with B, so now it just needs
[911.56s -> 912.98s]  to send the data.
[912.98s -> 917.94s]  It creates a segment and uses destination port 80 to tell B it is requesting the data to
[917.94s -> 921.10s]  be sent to the web server.
[921.10s -> 925.72s]  Host A uses a locally generated source port number for B to use when sending data
[925.72s -> 929.04s]  and acknowledgements back again.
[929.04s -> 936.22s]  As usual, the TCP segment is encapsulated into an IP datagram and sent to B.
[936.22s -> 943.50s]  The IP and TCP headers carry the unique ID of the TCP connection internet wide.
[943.50s -> 947.70s]  When the IP datagram arrives at B, the TCP segment is removed.
[947.74s -> 954.82s]  The TCP layer sees that the segment is for port 80 and sends the data to the web server.
[954.82s -> 957.70s]  The TCP Sliding Window.
[957.70s -> 961.22s]  You'll learn about other TCP features in upcoming videos.
[961.22s -> 967.02s]  You'll learn about window-based flow control to stop us from overwhelming the receiver.
[967.02s -> 972.62s]  You'll learn about retransmission and timeouts and different mechanisms to accomplish it.
[972.62s -> 977.18s]  And you'll learn about congestion control in Unit 4.
[977.18s -> 984.46s]  So, in summary, TCP provides, in order, reliable delivery of a stream of bytes between
[984.46s -> 985.90s]  application processes.
