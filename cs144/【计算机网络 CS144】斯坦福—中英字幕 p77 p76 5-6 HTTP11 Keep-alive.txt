# Detected language: en (p=1.00)

[0.00s -> 4.64s]  In this segment, I'm going to cover one very important optimization that occurred
[4.64s -> 9.04s]  in HTTP 1.1, something called the Keep Alive header.
[9.04s -> 12.72s]  HTTP is a basic request response protocol.
[12.72s -> 14.96s]  HTTP 1.0 is very simple.
[14.96s -> 18.32s]  A client wanting to request a document opens a connection.
[18.32s -> 20.40s]  It sends a GET request.
[20.40s -> 23.76s]  The server responds with a status code, such as 200 OK.
[23.76s -> 27.52s]  The document encloses the connection once the response is complete.
[28.16s -> 33.00s]  If the client wants to request a second document, it must open a second connection.
[33.00s -> 37.72s]  When the web was mostly text with maybe an image or two, this approach worked just fine.
[37.72s -> 42.08s]  People handrope their web pages, putting in all of the formatting.
[42.08s -> 45.96s]  Recall our results from analyzing HTTP 1.0.
[45.96s -> 50.20s]  Loading a single page with these parameters takes 230 milliseconds, and loading a page
[50.20s -> 53.04s]  with two images takes over twice as long.
[53.08s -> 56.80s]  A lot of this time is spent opening connections, and if we could request more documents at
[56.80s -> 59.28s]  once, it could be much faster.
[59.28s -> 64.00s]  So the approach HTTP 1.0 uses can be really wasteful.
[64.00s -> 65.96s]  Clients spend a lot of time opening connections.
[65.96s -> 71.04s]  Furthermore, the TCP congestion window doesn't get a chance to grow, since each connection
[71.04s -> 73.04s]  has a new window.
[73.04s -> 79.28s]  HTTP 1.1 solved this problem, by adding a few headers to requests and responses.
[79.32s -> 83.60s]  A request can include a connection header, which tells the server whether it would like
[83.60s -> 87.48s]  the connection to be kept open after the response, or closed.
[87.48s -> 90.88s]  The server can do whatever it wants, but the client can give it a hint.
[90.88s -> 94.48s]  For example, if you're requesting a basic text file, there's no reason to keep the
[94.48s -> 99.56s]  connection open, as the text file won't reference other things to load.
[99.56s -> 103.32s]  A response includes a connection header, which tells the client what the server decided
[103.32s -> 104.52s]  to do.
[104.52s -> 108.00s]  If it decided to keep alive the connection, then the keep-alive header tells the client
[108.04s -> 109.28s]  for how long.
[109.28s -> 113.60s]  Now, the client can send further requests on the same connection.
[113.60s -> 117.04s]  It can also open more connections if it wants, but it doesn't have to.
[117.04s -> 120.12s]  So it turns out this is a big deal.
[120.12s -> 123.76s]  Let's consider a more realistic case than before, where the packetization delay is
[123.76s -> 127.48s]  only 1 millisecond, and the page loads 11 images.
[127.48s -> 131.00s]  Now browsers today usually have more than two open connections, but they also load
[131.00s -> 134.88s]  more than 11 resources on a typical page, so we'll just keep these numbers small
[134.88s -> 137.00s]  for simplicity.
[137.00s -> 143.04s]  We're going to use the same analysis we used when looking at HTTP 1.0 in the HTTP 1.0 video.
[143.04s -> 148.28s]  The slow start window is big enough that we'll never hit congestion control.
[148.28s -> 153.64s]  For HTTP 1.0, this will take 1,421 milliseconds.
[153.64s -> 154.64s]  There's seven rounds.
[154.64s -> 157.04s]  In the first round, we request a page.
[157.04s -> 160.04s]  This takes 203 milliseconds.
[160.04s -> 164.08s]  In the next six rounds, we request two images each, except for the last round where we
[164.08s -> 166.18s]  request only one image.
[166.18s -> 168.22s]  Each round takes 203 milliseconds.
[168.22s -> 177.94s]  So the total time is 203 milliseconds plus 1,218 milliseconds for 1.421 seconds.
[177.94s -> 184.40s]  Now for HTTP 1.1, this will take only 326 milliseconds.
[184.40s -> 185.58s]  We set up the connection.
[185.58s -> 187.54s]  That takes 100 milliseconds.
[187.54s -> 191.34s]  Requesting the page takes another 103 milliseconds.
[191.34s -> 197.06s]  Protecting the 11 images, though, takes only 123 milliseconds.
[197.06s -> 203.02s]  That's 51 milliseconds for the first request, and 72 milliseconds for the 11 responses.
[203.02s -> 208.66s]  50 milliseconds of latency, plus 22 milliseconds of packetization delay.
[208.66s -> 215.78s]  So HTTP 1.1 is over four times faster, because we can send these requests back-to-back
[215.78s -> 220.62s]  in a single connection and don't have to open new connections.
[220.62s -> 227.94s]  HTTP 1.1 has been around for a while, since 1997 or so.
[227.94s -> 234.02s]  Very recently, Google has developed a new protocol called SPDY that improves on HTTP.
[234.02s -> 237.22s]  It does things like allow request pipelining.
[237.22s -> 243.30s]  One issue HTTP sometimes runs into is that the order in which a client requests resources
[243.30s -> 246.18s]  is the same that the server responds.
[246.18s -> 250.38s]  This can be a problem if some resources require a lot of processing.
[250.38s -> 255.94s]  Say you have a dynamically generated webpage through something like Ruby on Rails or Django.
[255.94s -> 261.82s]  Your database is overloaded, and so it's going to take a while to generate the page.
[261.82s -> 266.50s]  But most of the resources are just images that can be sent quickly.
[266.50s -> 271.10s]  If the client requests the slow page first, it won't receive any of the images until
[272.10s -> 273.10s]  it receives a page.
[273.10s -> 276.26s]  It would be nice if the server could respond in a different order and say start sending
[276.26s -> 280.34s]  the images while the page is being generated.
[280.34s -> 283.58s]  SPDY also removes redundant headers.
[283.58s -> 287.38s]  Open up Wireshark and look at some HTTP requests and responses.
[287.38s -> 291.06s]  Very often, there's a lot of redundant information in each response and request.
[291.06s -> 294.82s]  If you could just set some parameters such as the browser type for the duration of
[294.82s -> 300.78s]  a session, rather than send it each time, that would speed things up a lot.
[301.46s -> 304.94s]  SPDY has been in use for a little while, and it's becoming the basis of HTTP 2.0.
[304.94s -> 308.86s]  In a few years, I suspect most sites will be using HTTP 2.0 because of the speed to
[308.86s -> 311.54s]  benefits it will bring, especially for mobile devices.
