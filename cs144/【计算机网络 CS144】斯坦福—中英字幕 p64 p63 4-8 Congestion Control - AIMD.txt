# Detected language: en (p=1.00)

[0.00s -> 4.00s]  So in the video about TCP Reno and New Reno, I said that additive increase,
[4.00s -> 8.00s]  multiplicative decrease turns out to be a really powerful and very effective
[8.00s -> 12.00s]  mechanism for congestion control. In this video, I'm trying to give you a
[12.00s -> 16.00s]  sort of intuition as to why, why it turns out to work so well, and why it
[16.00s -> 20.00s]  is that it's generally used on the internet. So the way to think about
[20.00s -> 24.00s]  this problem of congestion control is that there really are two conflicting
[24.00s -> 28.00s]  requirements in the network. The first is a service provider. What they
[28.00s -> 32.00s]  want to do is they want to maximize their link utilization. That is, they want their
[32.00s -> 36.00s]  network to be completely utilized. They don't want to have idle capacity
[36.00s -> 40.00s]  which is unused. But users want
[40.00s -> 44.00s]  to get a fair share of that. You know, a service provider would be happy
[44.00s -> 48.00s]  if one user just got the entire pipe, but then you're going to lose all of
[48.00s -> 52.00s]  your clients and users will be unhappy. And so the idea is that
[52.00s -> 56.00s]  you'd like an algorithm for congestion control that
[56.00s -> 60.00s]  has the links operate close to utilization
[60.00s -> 64.00s]  but will converge to a point where every user, assuming everything
[64.00s -> 68.00s]  else is equal, will get approximately one nth if they're end users.
[68.00s -> 72.00s]  And in doing this, it's going to avoid congestion collapse if they're still doing useful data.
[72.00s -> 76.00s]  So these are the basic parameters of the problem. We want to maximize link utilization
[76.00s -> 80.00s]  of high link utilization. Meanwhile, everyone gets a fair share of that
[80.00s -> 84.00s]  link utilization, and we want to make sure the network does not
[84.00s -> 88.00s]  rot itself into the ground. So what should your congestion window size be?
[88.00s -> 92.00s]  So it turns out the optimal congestion window size, as we talked about before, is the bandwidth
[92.00s -> 96.00s]  delay product. And this is basically the idea that let's say I have my bandwidth
[96.00s -> 100.00s]  between San Francisco and Boston is
[100.00s -> 104.00s]  ten megabytes per second. And
[104.00s -> 108.00s]  the delay is 100 milliseconds.
[108.00s -> 112.00s]  Well this means that if I can support ten megabytes
[112.00s -> 116.00s]  per second and a congestion window lasts 100 milliseconds, then my congestion
[116.00s -> 120.00s]  window should essentially be one megabyte, right? The product of 100 megabytes per second
[120.00s -> 124.00s]  times 100 milliseconds. Similarly, if my bandwidth
[124.00s -> 128.00s]  is six megabytes per second and
[128.00s -> 132.00s]  my delay is 90 milliseconds
[132.00s -> 136.00s]  then I should be sending approximately a congestion window of
[136.00s -> 140.00s]  540 kilobytes. And this
[140.00s -> 144.00s]  falls out from these values. And then if I'm sending one megabyte per congestion window and there are ten congestion windows,
[144.00s -> 148.00s]  I'll be sending ten megabytes per second, then I'll be sending ten megabytes per second.
[148.00s -> 152.00s]  Similarly, if my congestion window is 540 kilobytes
[152.00s -> 156.00s]  and it's a congestion window every 90 milliseconds, they'll break down
[156.00s -> 160.00s]  to six megabytes per second.
[160.00s -> 164.00s]  So now, a way to think about how a congestion
[164.00s -> 168.00s]  window works over time, or rather how
[168.00s -> 172.00s]  pairs of congestion windows work over time, is something called the Chu-Jain plot.
[172.00s -> 176.00s]  And this is really part of the thing which sort of laid out some, or one of the papers
[176.00s -> 180.00s]  that laid out this first idea of sort of why AMD is a
[180.00s -> 184.00s]  good idea. It's a really nice graphical way. So what we want to do
[184.00s -> 188.00s]  is plot, we have two flows that are competing for the network, and we're
[188.00s -> 192.00s]  going to plot the rate of flow A based on its
[192.00s -> 196.00s]  say, congestion window size, and the rate of, on the x-axis, and the rate of flow B on the
[196.00s -> 200.00s]  y-axis. It's going to be a scatter plot. Now, if the
[200.00s -> 204.00s]  network is fair, A will be equal to B. That is, the rate
[204.00s -> 208.00s]  which A gets will be equal to the rate which B gets, and so the point,
[208.00s -> 212.00s]  the scatter point dot, should fall on this line.
[212.00s -> 216.00s]  Now, and that's the user requirement.
[216.00s -> 220.00s]  Now, if we are
[220.00s -> 224.00s]  maintaining the service provider requirement as we're actually running the network at
[224.00s -> 228.00s]  capacity, then it should be that A plus B, the sum of these two flows,
[228.00s -> 232.00s]  is equal to the capacity of the network. And so this is the service provider
[236.00s -> 240.00s]  requirement. And so what we'd like
[240.00s -> 244.00s]  is a congestion control algorithm that causes, you know, starting wherever we are
[244.00s -> 248.00s]  in this design, where, you know, pick some random point, is going to cause
[248.00s -> 252.00s]  flow A and flow B to gravitate
[252.00s -> 256.00s]  towards this desired point in the center, where we are fair and efficient.
[256.00s -> 260.00s]  We're fully utilizing the link.
[260.00s -> 264.00s]  And so what you can show this is that if we're to the right of this efficiency
[264.00s -> 268.00s]  line, that means we've overloaded the network, so chances are packets are going to be dropped.
[268.00s -> 272.00s]  We're going to see triple duplicate acts. If we're in the green region, then we've underloaded the network.
[272.00s -> 276.00s]  And so we want to get to this point,
[276.00s -> 280.00s]  where we're operating right at the network capacity, but we have fair capacity.
[281.00s -> 285.00s]  Now what this is going to show, what this shows you, this series of T1 through T6,
[285.00s -> 289.00s]  et cetera, is how additive increase and multiplicative decrease behaves.
[289.00s -> 295.00s]  So let's just pick this arbitrary point T1, where flow B is operating at well above
[295.00s -> 299.00s]  its fair share, as you can see, this distance.
[299.00s -> 304.00s]  And the flow A is operating well below its fair share, as you can see by this distance here.
[304.00s -> 308.00s]  So what's going to happen here?
[308.00s -> 312.00s]  Both are in additive increase mode, and they're both going to additively increase
[312.00s -> 316.00s]  their congestion window size and their flow rate until at some point the network
[316.00s -> 319.00s]  becomes overloaded and it drops some packets.
[319.00s -> 323.00s]  At which point then, they multiplicatively decrease their window size
[323.00s -> 328.00s]  and go back into additive increase. And so here's the multiplicative decrease.
[328.00s -> 332.00s]  And then they additively increase. Now because the multiplicative decrease
[332.00s -> 336.00s]  decreases B's rate more than A, it's a multiplicative factor,
[336.00s -> 341.00s]  this then makes the plot, the comparison of A and B, closer to fair.
[341.00s -> 346.00s]  You can see T3 here is bringing the pair of flows closer to the fair line.
[346.00s -> 351.00s]  And that's what we're seeing, since we're reducing each flow by a
[351.00s -> 356.00s]  multiplicative factor over time, and then increasing by an additive factor,
[356.00s -> 360.00s]  over time, they oscillate between overload and underload.
[360.00s -> 364.00s]  In the sense of they're going to push the network until it's just low.
[364.00s -> 368.00s]  In the sense of they're going to push the network until it's just a little bit
[368.00s -> 370.00s]  overloaded, then they back off a little bit.
[370.00s -> 374.00s]  And over time, this scaling, this multiplicative decrease causes them to
[374.00s -> 379.00s]  converge towards this point. And so in fact, in the end case, what
[379.00s -> 384.00s]  we'll see is that, you know, depending on exactly what overload point causes
[384.00s -> 389.00s]  triple duplicate acknowledgments, right, because there will be some cues,
[389.00s -> 393.00s]  etc., you'll see these two flows oscillating along the fair line,
[393.00s -> 397.00s]  underloading the network, then increasing, then overloading it.
[397.00s -> 402.00s]  Oh, they back off, increasing. And so over time, additive increase,
[402.00s -> 407.00s]  multiplicative decrease causes a pair of flows, or a set of flows, to achieve
[407.00s -> 411.00s]  both desired properties. They get a fair share of the capacity
[411.00s -> 415.00s]  of the network, right? They end up moving along this line
[415.00s -> 417.00s]  here. But also, through their additive increase,
[417.00s -> 420.00s]  they're going to be close to the network capacity, right?
[420.00s -> 424.00s]  They're going to, you know, go a little bit past, then a little bit back, then a
[424.00s -> 427.00s]  little bit past. But generally speaking, additive
[427.00s -> 431.00s]  increase, multiplicative decrease will cause flows to converge on this point,
[431.00s -> 434.00s]  the desired equilibrium point of the network.
