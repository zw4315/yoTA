# Detected language: en (p=1.00)

[0.00s -> 3.20s]  All right, actually, it's time to start.
[4.90s -> 7.98s]  All right, okay, as Franz was saying,
[7.98s -> 10.70s]  feel free to interrupt with questions
[10.70s -> 13.74s]  and feel free to leave your camera on
[13.74s -> 16.58s]  so that we can see each other as people.
[17.98s -> 20.46s]  This is gonna be another lecture about logging.
[20.46s -> 24.38s]  This time a case study of the current logging system
[24.38s -> 27.62s]  in Linux's ext3 file system,
[27.64s -> 29.40s]  which is extremely widely used.
[30.74s -> 32.76s]  And we'll try to dip into some of the kind
[32.76s -> 34.52s]  of real world design problems
[34.52s -> 38.92s]  that a high performance file system has to deal with
[38.92s -> 41.76s]  when it adds logging to the file system.
[41.76s -> 44.08s]  I'm just gonna spend a few minutes
[44.08s -> 47.00s]  basically reviewing why we're talking about logging.
[47.88s -> 52.20s]  The reason that we feel logging is pretty important
[52.20s -> 54.72s]  is that it's been a tremendously successful
[54.72s -> 56.68s]  and important idea.
[56.68s -> 60.22s]  It's almost like logging is kind of a magic way
[60.22s -> 63.70s]  to add crash recovery to any,
[63.70s -> 66.40s]  almost any existing storage system.
[67.46s -> 70.06s]  It's sort of a, in many ways, pretty orthogonal
[70.06s -> 72.50s]  to whatever it is you're actually trying to store.
[72.50s -> 74.06s]  And so you see logging applied
[74.06s -> 78.30s]  in a huge number of different storage situations,
[78.30s -> 80.02s]  certainly databases and file systems,
[80.02s -> 82.70s]  but also many very specialized systems
[82.70s -> 85.62s]  that need to store things and recover after crashes.
[85.72s -> 89.80s]  You also see logging used a lot in distributed systems
[89.80s -> 93.94s]  as a way of organizing the recovery from failure.
[93.94s -> 95.14s]  Because among other things,
[95.14s -> 96.98s]  logging is kind of a structured way of saying,
[96.98s -> 98.76s]  well, here's all the things that happened
[98.76s -> 99.80s]  just before the crash.
[99.80s -> 101.38s]  And if we can understand them,
[101.38s -> 104.24s]  then maybe we can recover from the crash more easily.
[105.88s -> 109.74s]  Plus there's a huge amount of interesting stuff to chew on
[109.74s -> 113.86s]  when you try to build high performance logging systems.
[116.60s -> 118.06s]  And as I mentioned a few minutes ago,
[118.06s -> 120.88s]  just as a point of terminology,
[120.88s -> 122.68s]  when we talk about log,
[122.68s -> 124.64s]  it's talking about this exactly the same thing
[124.64s -> 127.10s]  as today's reader reading was talking about
[127.10s -> 130.28s]  when it said, used the word journal, just synonyms.
[131.36s -> 133.72s]  And furthermore, today's reading talked about
[133.72s -> 136.12s]  adding a journal to ext2.
[136.12s -> 139.80s]  The modern name for the resulting file system is ext3,
[142.12s -> 143.92s]  which is how I'm gonna refer to it.
[144.90s -> 148.62s]  Okay, so I wanna spend,
[148.62s -> 153.14s]  the way I'm gonna kind of talk about ext3
[153.14s -> 157.14s]  is by contrasting it to some extent with xv6
[157.14s -> 159.58s]  and explaining ways in which ext3
[159.58s -> 164.58s]  fixes some performance problems that xv6 logging has,
[165.66s -> 168.26s]  and along the way changes a few of the semantics
[168.26s -> 172.84s]  of what happens during crashes.
[174.46s -> 178.46s]  All right, so this is sort of xv6 log review.
[180.78s -> 181.68s]  If you remember,
[188.42s -> 192.90s]  we have a disk, the file system disk for xv6.
[192.90s -> 194.58s]  There's, you know, you can think of it
[194.58s -> 195.86s]  as having two parts.
[195.86s -> 198.34s]  It's got a file system tree on it
[198.34s -> 201.06s]  with a root directory and under the root directory,
[201.06s -> 204.08s]  maybe there's other directories and in those,
[204.08s -> 207.80s]  this might be directory one and directory two.
[207.80s -> 208.92s]  We can think of this as,
[208.92s -> 210.64s]  the file system is just a data structure.
[210.64s -> 212.84s]  It's a tree structure data structure.
[212.84s -> 217.48s]  Maybe it has files sitting in the directories
[217.48s -> 222.32s]  and each file has block numbers of a bunch of blocks in it
[222.32s -> 224.12s]  and there's some other data
[224.12s -> 225.16s]  that's not really tree structured,
[225.16s -> 229.62s]  like there's the bitmap that indicates for every block,
[229.64s -> 232.90s]  whether that block is free or allocated.
[235.44s -> 238.16s]  And the inodes and the directory contents
[238.16s -> 239.60s]  and the bitmap blocks,
[239.60s -> 241.84s]  we're gonna refer to as metadata
[241.84s -> 244.04s]  in contrast to blocks that hold file content,
[244.04s -> 247.74s]  which we'll call file content blocks.
[247.74s -> 250.00s]  Okay, so in addition to the file system,
[251.04s -> 254.24s]  xv6 has a log, it's near the beginning of the disk
[254.24s -> 256.68s]  and the xv6 log is relatively simple.
[256.68s -> 258.60s]  It has this header block,
[260.32s -> 265.32s]  and then some number of blocks that contain updated versions
[265.68s -> 267.62s]  of blocks from the file system,
[267.62s -> 270.40s]  both data blocks and metadata blocks.
[272.54s -> 275.36s]  And in this initial header block,
[275.36s -> 280.36s]  there's the block numbers where these blocks in the log
[281.68s -> 285.12s]  ought to be written to like maybe the first one
[285.12s -> 287.52s]  should go to block 17 and then 29
[288.22s -> 290.58s]  and who knows whatever it might be.
[290.58s -> 291.88s]  And then in the computer,
[293.70s -> 296.14s]  we have some user process that's maybe calling write
[296.14s -> 298.14s]  or create or some other system call
[298.14s -> 299.84s]  that modifies the file system.
[302.18s -> 305.94s]  And there's a block cache in the computer
[305.94s -> 308.64s]  and initially the writes just go to the block cache.
[312.60s -> 315.66s]  It's just copies of blocks from the disk.
[317.58s -> 320.18s]  So initially write updates and file blocks
[320.18s -> 323.18s]  or inodes or whatever, those writes go there.
[323.18s -> 325.44s]  And then at the end of an operation,
[326.58s -> 327.90s]  these blocks are copied to the log.
[327.90s -> 329.54s]  And when we've copied all the blocks to the log,
[329.54s -> 332.54s]  then we write the block numbers to the header block
[332.54s -> 335.54s]  to indicate that this transaction's
[335.54s -> 337.10s]  worth of updates is complete.
[338.22s -> 339.70s]  And in the code for the file system,
[339.70s -> 344.54s]  you'll see that every system call
[344.56s -> 348.44s]  that modifies the file system somewhere has a begin op,
[348.44s -> 352.38s]  which says I'm about to start a group of updates
[352.38s -> 353.96s]  to the file system.
[353.96s -> 356.96s]  Please don't do any of them until I'm finished.
[356.96s -> 360.04s]  So we have, and there's a bunch of block reads and writes
[360.04s -> 362.92s]  and then an end op,
[363.86s -> 366.40s]  which tells the file system logging system
[366.40s -> 368.64s]  completely done all the writes I'm gonna do.
[368.64s -> 372.02s]  So between the begin op and the end op,
[372.02s -> 374.44s]  the writes only go to the cache.
[375.28s -> 378.34s]  And when the system call makes this end op call,
[378.34s -> 381.66s]  then the file system copies the modified blocks
[381.66s -> 383.74s]  from the cache into the log.
[383.74s -> 387.04s]  And after it's written all these modified blocks
[387.04s -> 389.82s]  into the log, only then does the file system
[389.82s -> 394.14s]  write the block numbers in a single disk write
[394.14s -> 395.24s]  to the header block.
[396.26s -> 397.78s]  And that's called the commit point.
[397.78s -> 399.90s]  This is the point before the file system
[399.90s -> 402.20s]  wrote these block numbers to the header block.
[402.20s -> 403.90s]  If a crash had happened,
[403.92s -> 407.56s]  then none of these writes would have been applied
[407.56s -> 409.80s]  after the crash and reboot.
[409.80s -> 412.16s]  After the file system writes these block numbers
[412.16s -> 415.42s]  as a header block, after that disk rate is complete,
[415.42s -> 417.80s]  then it's guaranteed that even if there's a crash
[417.80s -> 420.96s]  at this point, the recovery software will look at the log,
[420.96s -> 423.72s]  see that there's block numbers in the header block
[423.72s -> 426.32s]  and write all these blocks that are mentioned
[426.32s -> 430.02s]  in the header block to their home locations
[430.02s -> 431.14s]  in the file system.
[432.00s -> 434.68s]  And so what's going on here is this is a technique
[434.68s -> 437.20s]  to allow all of the writes that happen
[437.20s -> 440.76s]  in the system call between the begin op and the end op
[440.76s -> 444.14s]  to be atomic with respect to crashes.
[444.14s -> 446.44s]  That is, either all of them happen
[447.36s -> 449.08s]  because the file system got as far as writing
[449.08s -> 451.08s]  the header block before the crash,
[451.08s -> 454.12s]  or none of them happen because a crash happened
[454.12s -> 456.72s]  before the file system wrote the header block.
[458.62s -> 460.68s]  And so it's important that after a crash and restart,
[461.26s -> 463.58s]  there's some recovery software that runs that reads the log,
[463.58s -> 466.76s]  looks at the header block and decides is the header block
[466.76s -> 468.62s]  actually have block numbers in it or not?
[468.62s -> 473.22s]  If it does, it writes, possibly rewrites all these blocks
[473.22s -> 474.72s]  to their home locations.
[474.72s -> 477.14s]  If the header block doesn't have any block numbers in it,
[477.14s -> 479.14s]  then the recovery software does nothing.
[481.30s -> 483.14s]  Any questions about this quick review?
[483.14s -> 488.14s]  Okay, there's a couple of super important points
[496.44s -> 500.92s]  to remember about XV6 and indeed most logging systems.
[500.92s -> 504.48s]  One is that XV6, all logging systems essentially
[504.48s -> 506.52s]  obey what's called the write ahead rule.
[507.66s -> 512.66s]  That is, whenever you have a bunch of writes
[513.36s -> 515.00s]  done by some operation and those writes
[515.00s -> 520.00s]  all need to be atomic, the system has to write
[521.96s -> 526.48s]  all of these updated, all the updated data to the log
[526.48s -> 529.74s]  before it is allowed to apply any of those updates
[529.74s -> 531.84s]  to the home locations in the file system.
[531.84s -> 534.52s]  That is, that we're required to sort of pre-declare
[534.52s -> 538.42s]  all the updates that we wanna have be atomic,
[538.42s -> 540.84s]  pre-declare them in a log before we can apply
[540.84s -> 542.40s]  any of them to the file system.
[542.42s -> 544.18s]  That's called the write ahead rule.
[545.06s -> 549.54s]  And this is really the foundation of how logging
[549.54s -> 551.34s]  allows crash recovery.
[551.34s -> 554.02s]  So the write ahead rule allows this collection
[554.02s -> 558.62s]  of updates to appear atomic with respect to crashes.
[558.62s -> 560.82s]  There's another rule I haven't talked about,
[562.82s -> 567.82s]  which is that we can't free or reuse the log.
[567.90s -> 570.74s]  You know, XV6 uses the log over and over again,
[570.74s -> 572.14s]  once for every system call.
[572.96s -> 575.52s]  We're not allowed to reuse the log until all of the writes
[575.52s -> 577.16s]  that are in the log have actually been written
[577.16s -> 579.16s]  to their home locations on the disk.
[580.48s -> 582.84s]  So there's also what I'll call a freeing rule,
[586.80s -> 591.80s]  which says we can't overwrite or reuse the log until,
[593.64s -> 596.04s]  or the part of the log that holds
[596.04s -> 597.80s]  a particular transaction, you know,
[597.80s -> 599.48s]  set of writes that needs to be atomic.
[599.48s -> 600.92s]  We can't reuse that part of the log
[600.94s -> 603.70s]  until all of the writes that are in that part of the log,
[603.70s -> 608.54s]  all of them have been reflected into the actual home
[610.94s -> 612.34s]  locations in the file system.
[612.34s -> 615.64s]  So the deal in XV6 is that what end op does
[615.64s -> 617.42s]  actually triggers a whole lot of work.
[617.42s -> 620.34s]  First end the file system, you know,
[620.34s -> 621.94s]  as I mentioned, writes all the blocks to the log,
[621.94s -> 624.70s]  writes the header log, writes the header block,
[624.70s -> 628.86s]  and then the file system writes all these blocks
[628.86s -> 629.74s]  to their home locations.
[629.76s -> 632.72s]  This is assuming no crash, which is the ordinary case.
[632.72s -> 636.28s]  So then the file system writes a second time, you know,
[636.28s -> 638.40s]  all these blocks to the home locations on the disk.
[638.40s -> 641.98s]  And then after all the home locations have been updated,
[641.98s -> 644.12s]  only then does the file system go,
[644.12s -> 648.18s]  XV6 file system erase these block numbers
[648.18s -> 650.48s]  from the header block to indicate that,
[650.48s -> 652.24s]  oh, we're done with this transaction
[652.24s -> 653.92s]  and we can reuse the log.
[653.92s -> 656.92s]  And it's critical to erase the block numbers
[656.92s -> 658.76s]  before writing anything new to the log,
[658.78s -> 660.28s]  because we wouldn't want to be in a position
[660.28s -> 661.74s]  where there were some block numbers
[661.74s -> 664.34s]  from a previous transaction in the header,
[664.34s -> 667.74s]  but blocks from a new transaction
[667.74s -> 671.26s]  with presumably different block numbers sitting in the log,
[671.26s -> 674.62s]  because then a crash might apply these contents
[675.66s -> 679.18s]  to the stale block numbers left over in the header block.
[679.18s -> 681.00s]  So you have to erase the header block first.
[681.00s -> 682.88s]  So this is freeing rule that says,
[682.88s -> 686.94s]  before we're allowed to erase a transaction from the log,
[686.96s -> 689.28s]  we have to write all this block to the file system.
[691.04s -> 692.76s]  Okay, so the net effect of this
[692.76s -> 695.82s]  is to make file system updates,
[695.82s -> 698.76s]  which can be complicated and require many writes.
[698.76s -> 700.52s]  The net effects is to make each system call
[700.52s -> 702.12s]  essentially be atomic.
[702.12s -> 703.44s]  All its writes are none of them
[703.44s -> 704.76s]  with respect to crashes.
[706.72s -> 711.72s]  Okay, so the sort of bridge to Linux's logging scheme
[711.72s -> 716.72s]  is a question of what's wrong with xv6 logging?
[717.42s -> 719.90s]  Why doesn't Linux just use exactly the same scheme
[719.90s -> 721.82s]  that xv6 does?
[721.82s -> 723.60s]  And the answer is basically that it's slow.
[723.60s -> 725.82s]  The xv6 scheme is quite slow.
[727.28s -> 729.42s]  Every system call, before a system call like write
[729.42s -> 731.98s]  or create can return an xv6,
[733.06s -> 736.02s]  all of this stuff I just talked about has to complete.
[736.02s -> 739.04s]  So before your file creation system call
[739.04s -> 740.40s]  can return to user space,
[742.58s -> 744.78s]  it has to finish all the stuff that ndop does,
[744.78s -> 746.58s]  which means write every block to the log,
[746.58s -> 747.94s]  write the header block,
[747.94s -> 750.06s]  write all those blocks to their locations here,
[750.06s -> 752.46s]  and then erase the header block, and then you can return.
[752.46s -> 753.90s]  And during that time,
[755.38s -> 757.38s]  not only does each system call take a long time,
[757.38s -> 760.46s]  but nothing else can happen in the file system
[760.46s -> 763.30s]  while any system call is committing
[764.24s -> 766.30s]  and then writing its blocks to their home location.
[766.30s -> 769.06s]  So the system calls really occur one at a time,
[769.08s -> 772.70s]  and each system call requires many disk writes.
[774.08s -> 777.16s]  And the technical term for every system call
[777.16s -> 780.00s]  has to wait for all of its disk rates to complete
[780.00s -> 781.42s]  is called synchronous.
[788.60s -> 790.28s]  Probably spelled differently from that.
[790.28s -> 792.24s]  Anyway, xv6's system calls are synchronous
[792.24s -> 794.64s]  with respect to disk writes, so they're very, very slow.
[794.64s -> 798.24s]  They were horribly slow with mechanical hard drives
[798.26s -> 802.34s]  because each write basically would take 10 milliseconds.
[802.34s -> 803.94s]  We're talking about many writes per system call,
[803.94s -> 808.66s]  so xv6 could only do a few file system modifying
[808.66s -> 810.26s]  system calls per second.
[810.26s -> 813.62s]  And if you ran xv6 on a solid state drive,
[813.62s -> 815.30s]  it'd be faster, but still,
[815.30s -> 817.30s]  not nearly as efficient as it could be.
[819.22s -> 821.10s]  Another more detailed thing to notice about this
[821.10s -> 824.70s]  is that every block is written twice in the xv6 scheme.
[824.70s -> 826.06s]  It's written once to the log
[826.08s -> 828.76s]  and then a second time to the disk.
[828.76s -> 830.92s]  And so this is also something that,
[830.92s -> 832.00s]  there's good reasons for that,
[832.00s -> 836.70s]  but it's something that ext3 partially fixes.
[838.76s -> 842.72s]  Okay, so onto Linuxes, onto today's reading,
[842.72s -> 847.72s]  and I'm gonna talk about the ext3 file system,
[851.04s -> 854.88s]  which is what today's reading had turned into
[854.94s -> 857.18s]  a few years later after a bit more development
[858.14s -> 860.10s]  and is widely used.
[861.70s -> 866.12s]  Okay, so ext3,
[868.70s -> 873.58s]  it's actually a modification previous log list file system.
[873.58s -> 876.74s]  And so they really did play this game
[876.74s -> 878.66s]  of taking an existing storage system
[878.66s -> 880.66s]  and sort of layering logging on top of it
[880.66s -> 885.66s]  in a way that left the underlying ext2 file system
[886.44s -> 889.92s]  almost unmodified, although not quite.
[889.92s -> 894.60s]  And so in a sense, the logging was a very kind of easy,
[894.60s -> 896.96s]  at least in principle, easy upgrade for them.
[898.88s -> 903.56s]  Ext3 keeps data structures that are similar
[908.32s -> 910.32s]  to xv6s in memory.
[910.34s -> 914.86s]  There's a block cache, it's a write back cache.
[918.50s -> 921.06s]  So there's a bunch of cache blocks.
[921.06s -> 922.38s]  Some of them are clean in the sense
[922.38s -> 923.94s]  that they haven't been modified since,
[923.94s -> 924.98s]  identical to what's in the disk.
[924.98s -> 926.46s]  Some of them dirty in the sense
[926.46s -> 927.98s]  that they've been written to
[927.98s -> 929.70s]  since they were read from the disk.
[929.70s -> 930.98s]  And some of them are pinned
[930.98s -> 931.98s]  and that they're not allowed
[931.98s -> 934.04s]  to be written back to the disk
[934.04s -> 935.50s]  because of the write back rule.
[935.50s -> 938.46s]  I mean, because of the freeing rule, the write ahead rule.
[939.44s -> 944.44s]  Ext3 also maintains some transaction information.
[950.40s -> 952.12s]  It can maintain information actually
[952.12s -> 955.28s]  about multiple transactions that are concurrently
[955.28s -> 957.68s]  in different stages of execution.
[957.68s -> 960.98s]  So there might be a number of different transactions
[960.98s -> 965.28s]  that the Ext3 system is keeping track of.
[965.28s -> 967.96s]  Each one, each transaction has a sequence number.
[969.40s -> 974.40s]  A set of block numbers that the transaction system
[975.44s -> 977.36s]  is logging system is remembering
[977.36s -> 981.28s]  are blocks modified by that transaction.
[981.28s -> 986.28s]  So these are a set of block numbers.
[986.44s -> 988.84s]  And this really refers to cache blocks
[988.84s -> 990.88s]  because any modifications, at least initially,
[990.88s -> 992.40s]  you happen only in the cache.
[993.40s -> 995.56s]  And then a set of what are called handles.
[999.00s -> 1001.64s]  Which are information about system calls
[1001.64s -> 1003.48s]  that are still currently executing
[1003.48s -> 1005.52s]  and as part of this transaction
[1005.52s -> 1008.54s]  and reading and writing cached blocks.
[1010.04s -> 1011.14s]  And on the disk,
[1015.12s -> 1017.28s]  on the disk, just like xv6,
[1017.28s -> 1019.76s]  there's the usual file system tree,
[1019.76s -> 1023.72s]  it's inodes and directory blocks and files and whatnot.
[1023.72s -> 1027.68s]  And there's bitmap blocks indicating
[1028.76s -> 1032.56s]  whether each data block is allocated or free.
[1032.56s -> 1034.04s]  And so these are what I'll be calling
[1034.04s -> 1036.68s]  the home locations of file system blocks.
[1036.68s -> 1039.54s]  And then on a sort of designated part of the disk,
[1041.44s -> 1042.34s]  there's the log.
[1044.52s -> 1046.88s]  And so far, this is pretty similar to xv6.
[1046.88s -> 1051.12s]  The main difference is the Ext3's ability
[1051.12s -> 1055.24s]  to keep track of multiple transactions at the same time
[1055.24s -> 1058.14s]  in sort of different stages of their execution.
[1058.46s -> 1062.72s]  Now I want to look more closely
[1062.72s -> 1067.00s]  at what's inside the log in Ext3.
[1067.00s -> 1070.84s]  It's a bit different from what's in the xv6 log.
[1077.90s -> 1079.40s]  This is the log format.
[1084.42s -> 1085.36s]  At the beginning of the log,
[1085.36s -> 1087.40s]  there's something called the super block.
[1088.46s -> 1093.46s]  And the super block, this is the log super block,
[1093.80s -> 1096.12s]  different from the file system super block.
[1097.40s -> 1099.48s]  The log super block contains the offset
[1099.48s -> 1104.48s]  and sequence number of the first valid transaction
[1105.28s -> 1106.12s]  in the log.
[1106.12s -> 1108.04s]  So it's gonna have an offset.
[1108.04s -> 1110.80s]  This is just a byte number or block number in the log,
[1110.80s -> 1112.80s]  and then the sequence number.
[1112.80s -> 1114.92s]  Remember I said that every transaction
[1114.92s -> 1116.56s]  has its own sequence number.
[1116.56s -> 1118.00s]  And then the rest of the log,
[1118.58s -> 1121.34s]  the log is just a bunch of sequential blocks on disks
[1121.34s -> 1122.64s]  of a known size.
[1125.34s -> 1126.98s]  Every transaction, the rest of the log
[1126.98s -> 1128.26s]  consists of transactions.
[1128.26s -> 1131.54s]  Each transaction consists of a descriptor block,
[1134.62s -> 1137.20s]  which contains block numbers,
[1137.20s -> 1141.56s]  just as in much like the header block in the xv6.
[1143.22s -> 1146.64s]  And then the set of, for each of these block numbers,
[1146.64s -> 1150.18s]  the actual updated content block,
[1151.14s -> 1152.46s]  corresponding to that block number.
[1152.46s -> 1154.22s]  And then finally, for a transaction
[1154.22s -> 1156.30s]  that's actually finished and committed,
[1157.20s -> 1158.66s]  there'll be a commit block.
[1161.66s -> 1163.70s]  And this is a separate block in the log.
[1165.42s -> 1168.46s]  And because there can be more than one
[1168.46s -> 1169.46s]  transaction in the log,
[1169.46s -> 1172.74s]  that commit block may be followed by
[1172.74s -> 1175.74s]  the next transaction's descriptor block,
[1175.76s -> 1177.12s]  and then some data blocks,
[1177.12s -> 1182.12s]  and then maybe the next transaction's commit block.
[1183.68s -> 1185.12s]  So we can have multiple,
[1185.12s -> 1186.28s]  the log file can be quite long
[1186.28s -> 1188.92s]  and contain many transactions in it.
[1192.08s -> 1194.80s]  So we can think of this offset and sequence numbers
[1194.80s -> 1196.80s]  basically between them,
[1196.80s -> 1200.00s]  pointing to the very first,
[1200.00s -> 1202.68s]  the beginning of the earliest,
[1202.70s -> 1205.86s]  lowest numbered valid transaction in the log.
[1208.06s -> 1212.10s]  A little detail here that's,
[1212.10s -> 1214.18s]  will become important in a little while
[1214.18s -> 1216.70s]  is that these, the descriptor blocks
[1216.70s -> 1218.34s]  and the commit blocks,
[1220.02s -> 1221.74s]  in order to be able to help distinguish them
[1221.74s -> 1223.96s]  from data blocks,
[1223.96s -> 1226.80s]  when they're scanning log after a crash and recovery,
[1226.80s -> 1228.28s]  the descriptor and the commit blocks
[1228.28s -> 1230.86s]  start with a magic number,
[1230.88s -> 1233.84s]  which is just some 32-bit number
[1233.84s -> 1238.84s]  that is unlikely to occur in data.
[1240.44s -> 1244.00s]  And that helps the log software distinguish
[1245.40s -> 1247.76s]  descriptor and commit blocks from data blocks.
[1251.52s -> 1253.64s]  Okay, with this in mind,
[1253.64s -> 1254.68s]  with this structure in mind,
[1254.68s -> 1257.04s]  I'm gonna talk about the high level,
[1257.04s -> 1259.98s]  the ways that EXE3 gets good performance.
[1260.00s -> 1263.28s]  And there's really three main, yes.
[1263.28s -> 1264.12s]  I have a question.
[1264.12s -> 1266.56s]  Is it possible for at least in this system
[1266.56s -> 1269.36s]  to have a descriptor block before the commit block,
[1269.36s -> 1272.06s]  let's say two transactions going on at the same time?
[1273.04s -> 1277.12s]  There can be multiple transactions in the log.
[1278.82s -> 1280.14s]  Does the transaction need to finish
[1280.14s -> 1282.28s]  before the next one can start?
[1282.28s -> 1284.52s]  Yeah, we'll talk in a moment about that,
[1284.52s -> 1286.80s]  but it is the case, yes,
[1286.80s -> 1291.80s]  that there's only one open transaction at a time.
[1293.22s -> 1297.18s]  And this is really not quite the right picture for that
[1297.18s -> 1299.18s]  because the current open transaction,
[1299.18s -> 1301.64s]  the current open transaction is the transaction
[1301.64s -> 1306.42s]  into which system calls are performing their writes.
[1306.42s -> 1308.02s]  And so the current open transaction
[1308.02s -> 1309.50s]  really only exists in memory
[1310.74s -> 1313.98s]  and because current system calls are sort of updating,
[1314.04s -> 1317.40s]  they're just updating the cached file system blocks
[1317.40s -> 1318.92s]  in memory.
[1318.92s -> 1322.56s]  When the EXE3 system decides to finish
[1322.56s -> 1324.86s]  the current open transaction,
[1326.56s -> 1329.44s]  after it decides to finish it, it'll do two things.
[1329.44s -> 1331.46s]  One is it'll start a new open transaction,
[1331.46s -> 1333.04s]  which will be the next transaction,
[1333.04s -> 1338.04s]  and it will then write the just finished transaction.
[1338.16s -> 1340.76s]  It'll start writing the just finished transaction to disk,
[1340.76s -> 1343.16s]  which may actually take quite a while.
[1343.26s -> 1348.26s]  So the full story is that there's a bunch
[1349.18s -> 1352.66s]  of older transactions on disk that all of which are closed
[1352.66s -> 1356.56s]  plus one open transaction really only exists in memory.
[1357.78s -> 1360.90s]  And at least initially these transactions that are on disk
[1361.90s -> 1365.54s]  may only exist in the form of the log records
[1365.54s -> 1367.46s]  and haven't initially at least been written
[1367.46s -> 1368.58s]  to their home locations.
[1368.58s -> 1370.74s]  And then after a while in the background,
[1371.44s -> 1374.04s]  the starting with the oldest transaction,
[1374.04s -> 1379.04s]  the logging system will write these updated blocks
[1379.52s -> 1381.08s]  in a log to their home locations.
[1381.08s -> 1382.28s]  And then once that's been done
[1382.28s -> 1384.72s]  for each complete transaction,
[1384.72s -> 1388.48s]  then the logging system can free and reuse
[1388.48s -> 1390.16s]  this space in the log.
[1390.16s -> 1391.80s]  And so this is really a circular log.
[1391.80s -> 1394.60s]  When you get to the end of the log,
[1394.60s -> 1398.88s]  the logging system starts using the blocks
[1398.94s -> 1401.54s]  at the beginning and has to free them,
[1403.10s -> 1404.38s]  free these blocks by writing them
[1404.38s -> 1406.74s]  to their home locations before it can reuse them.
[1408.66s -> 1413.06s]  Okay, so there's three ways that the system gets,
[1413.06s -> 1414.90s]  the ext3 gets good performance.
[1416.00s -> 1419.40s]  One is that it has asynchronous system calls.
[1419.40s -> 1423.62s]  That is system calls return before they've written the disk
[1423.62s -> 1426.58s]  the system called just updates the cache blocks
[1426.60s -> 1429.64s]  in memory and then returns never has to write the disk,
[1429.64s -> 1431.68s]  never has to wait for disk writes,
[1431.68s -> 1433.44s]  although may wait for disk reads.
[1434.72s -> 1437.98s]  The next big idea for performance is batching.
[1440.96s -> 1445.08s]  We can batch many system calls into a single transaction.
[1445.08s -> 1448.10s]  And the final big idea for performance is concurrency.
[1451.48s -> 1452.56s]  And these are all the things,
[1452.56s -> 1455.08s]  these are basically the things that ext3 does
[1455.08s -> 1458.02s]  that xv6 doesn't do.
[1459.58s -> 1460.86s]  Okay, so I'm gonna talk about
[1460.86s -> 1463.70s]  each one of these three performance techniques.
[1467.26s -> 1470.74s]  Oh, sorry, I wanted to ask about batching.
[1470.74s -> 1471.58s]  Yes.
[1471.58s -> 1475.46s]  Doesn't xv6 allow for there to be multiple system calls
[1475.46s -> 1480.46s]  that do start up and up like at kind of the same time?
[1480.96s -> 1485.24s]  So then they will commit together?
[1485.24s -> 1488.20s]  Yeah, that's true, xv6 is a limited amount of batching.
[1490.40s -> 1491.24s]  Thank you.
[1491.24s -> 1492.08s]  Yeah.
[1495.36s -> 1498.36s]  Okay, so first asynchronous system calls.
[1507.52s -> 1509.40s]  This just means the system calls return,
[1509.40s -> 1511.02s]  but they were all modified blocks in the cache
[1511.02s -> 1514.70s]  and then return and don't particularly,
[1514.70s -> 1516.14s]  don't trigger disk writes.
[1517.30s -> 1518.90s]  So this has the obvious advantage
[1518.90s -> 1521.02s]  of the system calls return quickly.
[1522.46s -> 1525.22s]  It also allows for IO concurrency.
[1525.22s -> 1529.26s]  That is the application can make some file system
[1529.26s -> 1531.54s]  system calls that imply that the file system
[1531.54s -> 1534.72s]  ought to do a bunch of disk operations, disk writes,
[1534.72s -> 1537.58s]  but the application can then return to computing
[1538.56s -> 1541.20s]  in parallel with the file system,
[1541.20s -> 1543.28s]  doing whatever the rights are that are required
[1543.28s -> 1544.76s]  by those system calls.
[1545.84s -> 1547.60s]  So this is called IO concurrency.
[1548.64s -> 1550.96s]  And without asynchronous system calls,
[1550.96s -> 1553.28s]  it's hard to get IO concurrency.
[1554.84s -> 1558.28s]  Hard to get overlap between disk operations
[1558.28s -> 1560.54s]  and application computing if the applications
[1560.54s -> 1563.28s]  always have to wait for the disk writes to complete.
[1564.14s -> 1566.90s]  And the other thing that's nice
[1566.90s -> 1570.10s]  about asynchronous system calls is that they allow,
[1570.10s -> 1573.26s]  they make it easier to do large amounts of batching.
[1573.26s -> 1575.02s]  So there's sort of help batching.
[1578.90s -> 1582.58s]  The downside of asynchronous system calls is that
[1584.70s -> 1587.74s]  it means that just because a system calls return
[1587.74s -> 1592.74s]  doesn't mean that the work that the system call
[1593.60s -> 1595.88s]  ought to have done has actually been completed.
[1595.88s -> 1598.96s]  So for example, if you write a program that creates a file
[1598.96s -> 1601.68s]  and writes some data to it and then closes the file
[1601.68s -> 1605.14s]  and then prints done on the console to the user,
[1606.08s -> 1609.68s]  and then you pull out the power plug on your computer,
[1609.68s -> 1612.20s]  after you restart the computer, your data may not be there
[1612.20s -> 1614.16s]  even though all the system calls returned.
[1614.16s -> 1616.32s]  And even though the programs are just said,
[1616.32s -> 1619.92s]  look, I called those system calls and they returned.
[1619.94s -> 1624.94s]  And this means that in a world with asynchronous system calls
[1625.14s -> 1627.38s]  applications have to be written more carefully
[1627.38s -> 1630.38s]  if they care about their behavior
[1630.38s -> 1632.38s]  with respect to crashes.
[1632.38s -> 1634.14s]  This is actually kind of a big deal.
[1636.42s -> 1641.42s]  In XV6, if a write returned, the data was on the disk
[1641.98s -> 1643.90s]  and would be there after a crash.
[1643.90s -> 1646.30s]  In EST3, if a write returns,
[1647.12s -> 1649.88s]  you don't know anything about what'll happen after a crash,
[1649.88s -> 1651.08s]  may or may not be there.
[1652.92s -> 1655.62s]  So it is possible, despite asynchronous system calls,
[1655.62s -> 1657.92s]  to write careful programs, like databases need
[1657.92s -> 1660.80s]  to be careful, text editors need to be careful.
[1660.80s -> 1663.66s]  I write out a file, I do not want,
[1663.66s -> 1665.80s]  if there's a power failure while I'm writing out a file
[1665.80s -> 1669.00s]  in my text editor, I don't wanna, after restarting,
[1669.00s -> 1670.88s]  just see garbage or a partial file.
[1670.88s -> 1674.00s]  I wanna see either the old file or the new file.
[1674.02s -> 1676.94s]  And so the file system also provides some techniques
[1676.94s -> 1681.94s]  for careful applications to get predictable behavior
[1683.26s -> 1684.18s]  despite crashes.
[1684.18s -> 1686.26s]  And the main tool for that is called,
[1686.26s -> 1689.98s]  it's a system call called fsync,
[1689.98s -> 1693.22s]  which all Unix systems have.
[1693.22s -> 1696.58s]  And what this basically says is that you pass
[1696.58s -> 1699.42s]  it a file descriptor and it tells the file system,
[1699.42s -> 1702.06s]  look, actually do all of the writes.
[1702.06s -> 1703.58s]  I may have called write a bunch of times
[1704.12s -> 1706.92s]  and called fsync, I now want you to actually do the writes
[1706.92s -> 1708.96s]  and don't return from this system call
[1708.96s -> 1711.64s]  until the writes are on disk and are guaranteed
[1711.64s -> 1714.64s]  to be still there if there's a crash.
[1714.64s -> 1717.52s]  So if you look at the source code for databases
[1717.52s -> 1720.12s]  or text editors or a number of other programs
[1720.12s -> 1721.40s]  that really care about their data,
[1721.40s -> 1725.12s]  you'll see sort of carefully placed calls to fsync
[1725.12s -> 1730.12s]  in order to sort of overcome this fight back
[1730.32s -> 1732.20s]  against these asynchronous system calls.
[1732.22s -> 1734.58s]  Most programs though, like your compiler,
[1734.58s -> 1738.34s]  it's no big deal if the output of the compiler goes away
[1738.34s -> 1741.22s]  if there's a crash and therefore many, many programs
[1741.22s -> 1742.98s]  don't call fsync are very happy to get
[1742.98s -> 1746.02s]  the good performance of asynchronous system calls
[1746.02s -> 1748.46s]  and are not worried about their crash behavior.
[1751.62s -> 1753.06s]  Okay, so.
[1753.06s -> 1755.94s]  Is this also called like flush sometimes?
[1755.94s -> 1757.98s]  Cause I think that words,
[1757.98s -> 1759.78s]  I've heard that word before a lot.
[1759.78s -> 1760.62s]  Yeah, yeah.
[1760.96s -> 1763.08s]  A reasonable way to explain what fsync does
[1763.08s -> 1765.84s]  is that it flushes all previous rights
[1765.84s -> 1768.48s]  to this file to the disk and only returns that.
[1768.48s -> 1771.08s]  So, flush is a reasonable word for this.
[1771.08s -> 1772.44s]  Flushing rights to disk.
[1776.16s -> 1777.72s]  Okay, so that's asynchronous system calls.
[1777.72s -> 1782.72s]  The next technique that ext3 uses is batching.
[1782.72s -> 1787.72s]  And the game here is that there's at any one time,
[1791.58s -> 1796.58s]  there's always one open transaction in ext3.
[1801.50s -> 1804.46s]  A transaction in ext3 can actually hold the rights
[1804.46s -> 1807.74s]  of many different, many distinct system calls.
[1809.14s -> 1810.72s]  So what ext3 does is says,
[1810.72s -> 1812.34s]  well, I'm gonna start a new transaction now
[1812.92s -> 1814.84s]  and then for the next couple of seconds,
[1814.84s -> 1817.12s]  all system calls that execute are,
[1818.00s -> 1821.26s]  their rights are part of that one big transaction.
[1821.26s -> 1824.80s]  I think by default, ext3 only creates a new transaction
[1824.80s -> 1826.04s]  every five seconds.
[1826.04s -> 1828.82s]  So each transaction can have up to five seconds
[1828.82s -> 1830.36s]  worth of system calls in it.
[1830.36s -> 1831.68s]  All as a huge batch.
[1831.68s -> 1833.76s]  And then at the end of the five seconds,
[1835.60s -> 1838.44s]  ext3 will commit this single big transaction
[1838.44s -> 1840.84s]  that may have hundreds of updated blocks in it.
[1841.70s -> 1845.46s]  Commit this transaction to disk as a single transaction.
[1845.46s -> 1847.26s]  And so the reason why this is a win,
[1848.18s -> 1851.38s]  first of all, it spreads some fixed transaction costs,
[1851.38s -> 1853.54s]  amortizes some fixed transaction costs
[1853.54s -> 1854.90s]  across many system calls.
[1854.90s -> 1857.62s]  So for example, you have to write the descriptor block
[1857.62s -> 1860.94s]  and the commit block and you have to seek
[1860.94s -> 1861.78s]  on a mechanical drive,
[1861.78s -> 1864.06s]  at least you have to seek and let the drive rotate
[1864.06s -> 1865.34s]  to the place where the log is.
[1865.34s -> 1866.94s]  And those are significant costs
[1868.02s -> 1869.90s]  and they only have to be done once per batch
[1869.96s -> 1871.48s]  instead of once per system call.
[1871.48s -> 1874.60s]  So it lowers the impact of those costs.
[1876.72s -> 1878.38s]  The other big deal is that,
[1878.38s -> 1881.88s]  another big deal is that it allows write absorption.
[1883.44s -> 1884.28s]  That is,
[1888.02s -> 1891.44s]  it's often the case that you have a whole sequence
[1891.44s -> 1893.28s]  of system calls that end up modifying
[1893.28s -> 1895.88s]  the very same blocks over and over again.
[1895.88s -> 1899.52s]  So for example, if I create a whole bunch of files,
[1900.10s -> 1901.38s]  I need to allocate a bunch of inodes
[1901.38s -> 1905.06s]  and that means all the inodes are small, maybe 64 bytes.
[1905.06s -> 1907.10s]  So many, many inodes fit in the block.
[1907.10s -> 1909.42s]  So creating a bunch of files in a row
[1909.42s -> 1913.34s]  is gonna dirty many inodes in a few blocks
[1914.22s -> 1916.14s]  because there's many inodes for block.
[1916.14s -> 1920.70s]  Similarly, if I'm writing a bunch of data to a file,
[1920.70s -> 1922.78s]  I may need to allocate a lot of data blocks.
[1922.78s -> 1927.78s]  I may flip many of the bits in the block free map.
[1928.68s -> 1931.22s]  And if I allocate blocks that are next to each other,
[1931.22s -> 1933.50s]  their bits are gonna be in the same block.
[1933.50s -> 1936.52s]  And so I may flip many bits in just one block.
[1936.52s -> 1938.64s]  So many system calls, again,
[1940.12s -> 1942.28s]  may end up writing the same blocks over and over again.
[1942.28s -> 1945.00s]  And in the system with batching,
[1946.00s -> 1947.84s]  those many, many writes of the same blocks
[1947.84s -> 1951.76s]  just happen very quickly to the cached,
[1951.76s -> 1953.16s]  just to the cached copies of the blocks
[1953.16s -> 1954.64s]  because we're not writing the disk.
[1954.78s -> 1959.54s]  And then we write those small number of blocks to the disk
[1959.54s -> 1961.66s]  only once at the end of the transaction.
[1961.66s -> 1966.32s]  And the single block writing into the log
[1966.32s -> 1968.98s]  reflects many, many system calls
[1968.98s -> 1970.66s]  with the modifications to the same block.
[1970.66s -> 1974.70s]  So this write absorption can be reduced
[1974.70s -> 1977.26s]  the amount of disk, the total number of times
[1977.26s -> 1979.28s]  we have to write the block dramatically
[1979.28s -> 1983.10s]  compared to a synchronous system like XV6.
[1985.30s -> 1988.78s]  And the final big win is disk scheduling.
[1991.62s -> 1992.52s]  In general,
[1995.14s -> 1996.42s]  even if we,
[1997.74s -> 2001.38s]  suppose we have to write 1,000 blocks to the disk,
[2001.38s -> 2003.28s]  it turns out to be much more efficient,
[2003.28s -> 2004.54s]  certainly in mechanical drives,
[2004.54s -> 2006.34s]  but even in solid state drives
[2006.34s -> 2009.02s]  to write 1,000 blocks all at once
[2009.02s -> 2013.08s]  to sequential locations as you would do to a log,
[2013.08s -> 2016.74s]  it's much faster to do that than to write 1,000 blocks
[2016.74s -> 2019.54s]  one at a time to different locations,
[2019.54s -> 2021.58s]  or even 1,000 blocks,
[2021.58s -> 2025.62s]  even write the same block 1,000 times in a log.
[2026.90s -> 2031.08s]  So by handing the disk large batches of writes to do,
[2032.06s -> 2033.86s]  the disk can be much more efficient.
[2034.82s -> 2037.04s]  There's also, not only do we get an efficiency
[2037.04s -> 2038.86s]  from writing a large number of blocks
[2038.86s -> 2040.46s]  sequentially in the log,
[2040.48s -> 2043.18s]  but even when we go to write the home locations
[2043.18s -> 2047.72s]  for a batch of the writes resulting
[2047.72s -> 2050.68s]  from a batch of operations in a single big transaction,
[2050.68s -> 2054.40s]  even then, if we can hand a very large number of writes
[2054.40s -> 2056.58s]  to the drive, even if they're to different locations,
[2056.58s -> 2059.04s]  because they're to the home locations
[2059.04s -> 2061.52s]  referred to by many different system calls,
[2061.52s -> 2064.68s]  if we allow the disk to schedule
[2064.68s -> 2067.20s]  a large number of distinct writes,
[2067.20s -> 2068.84s]  it can pick an order to do them in
[2068.86s -> 2070.58s]  that's particularly efficient.
[2070.58s -> 2071.58s]  And on a mechanical drive,
[2071.58s -> 2075.98s]  this would involve sorting them
[2075.98s -> 2078.82s]  and sorting them by track number on the drive
[2078.82s -> 2083.22s]  and doing just a little seek from one to the next.
[2083.22s -> 2084.26s]  And it can do this sort
[2084.26s -> 2087.82s]  if you give it all of the blocks at the same time.
[2087.82s -> 2089.10s]  But even on a solid state drive,
[2089.10s -> 2092.26s]  it turns out there's smaller wins to be gotten
[2092.26s -> 2095.30s]  from giving the disk lots of work to do.
[2095.30s -> 2097.02s]  Anyway, so you can only really get
[2097.04s -> 2099.56s]  this kind of disk scheduling
[2099.56s -> 2101.64s]  if you have very large batches of writes
[2101.64s -> 2102.70s]  to get to the drive.
[2102.70s -> 2104.60s]  So that's another win from batching.
[2108.22s -> 2109.06s]  All right.
[2110.44s -> 2115.44s]  And the final big win that ESC3 gets is concurrency.
[2117.40s -> 2121.34s]  It's really got two kinds of concurrency
[2121.34s -> 2122.48s]  that it benefits from.
[2122.48s -> 2127.48s]  Compared to xv6.
[2133.50s -> 2136.34s]  One is that it can allow many system calls
[2136.34s -> 2137.66s]  to execute at the same time.
[2137.66s -> 2142.66s]  So we can have many individual system calls in parallel.
[2144.54s -> 2149.54s]  Because at least until ESC3 decides to close
[2152.50s -> 2155.78s]  out and commit the current transaction,
[2157.06s -> 2158.62s]  the system calls don't have to wait for each other.
[2158.62s -> 2159.82s]  They can all modify blocks
[2159.82s -> 2161.18s]  that are part of the current transaction.
[2161.18s -> 2162.98s]  And all these many, many system calls
[2162.98s -> 2167.38s]  can execute in parallel and contribute blocks
[2167.38s -> 2168.66s]  to the current transaction.
[2168.66s -> 2171.34s]  That's particularly important on a multi-core machine
[2171.34s -> 2172.66s]  where we don't want to have the different cores
[2172.66s -> 2174.02s]  be waiting for a lock.
[2174.90s -> 2178.62s]  In xv6, it's often the case that you're not allowed,
[2178.62s -> 2179.90s]  a system call can't proceed
[2179.92s -> 2184.92s]  because the current transaction is busy doing something else.
[2185.88s -> 2187.68s]  Most of the time in the ESC3,
[2188.88s -> 2192.00s]  many system calls can modify the current transaction.
[2193.16s -> 2196.00s]  The other way that ESC3 gets concurrency
[2196.00s -> 2199.48s]  is that there can be multiple transactions,
[2199.48s -> 2202.76s]  older transactions in different stages of execution.
[2205.76s -> 2209.56s]  So it's true a system calls in only one open transaction
[2210.38s -> 2211.22s]  can receive system calls,
[2211.22s -> 2212.74s]  but the other transactions that are writing things to disk
[2212.74s -> 2214.14s]  can go on in parallel.
[2214.14s -> 2217.32s]  So many older transactions.
[2219.52s -> 2223.90s]  And the different sort of stages in a transaction's life
[2223.90s -> 2225.62s]  that can go on in parallel.
[2226.90s -> 2228.96s]  First, there's the one open transaction.
[2231.66s -> 2235.08s]  There can be some number of transactions that are recent
[2235.08s -> 2237.66s]  and the file system is committing them,
[2237.68s -> 2240.48s]  but it's still writing their blocks to the disk.
[2240.48s -> 2243.28s]  So we have some number of transactions
[2243.28s -> 2245.60s]  that are currently committing to the log.
[2249.36s -> 2251.16s]  And we don't have to wait for these to finish.
[2251.16s -> 2253.28s]  That is, we can continue with system calls
[2253.28s -> 2255.32s]  in the new open transaction
[2255.32s -> 2258.36s]  while the previous transaction is still writing to the log
[2258.36s -> 2261.84s]  and hasn't actually finished committing yet.
[2261.84s -> 2263.00s]  Of course, this stage ends
[2263.00s -> 2266.44s]  when the transaction writes its commit block to the disk,
[2266.44s -> 2267.28s]  the log.
[2268.94s -> 2273.46s]  There can be transactions that are even older transactions
[2273.46s -> 2278.18s]  that are writing their blocks from the cache
[2278.18s -> 2282.30s]  to the home locations of the modified blocks.
[2282.30s -> 2286.50s]  And finally, this doesn't take much work,
[2286.50s -> 2291.14s]  but there can be the oldest transactions are being freed.
[2293.06s -> 2294.72s]  This doesn't really take work itself.
[2294.74s -> 2298.86s]  The work is really writing the transactions
[2298.86s -> 2300.98s]  to the blocks of their home locations.
[2300.98s -> 2304.28s]  But anyway, there's typically multiple transactions
[2304.28s -> 2306.56s]  in existence in these different stages.
[2307.54s -> 2311.36s]  And so in particular, new system calls can execute
[2311.36s -> 2313.22s]  without waiting for older transactions
[2313.22s -> 2315.66s]  to either finish committing to the log
[2315.66s -> 2319.22s]  or finish writing their blocks to their home locations.
[2319.22s -> 2322.80s]  In contrast to XV6 where new system calls had to wait
[2322.80s -> 2327.80s]  for this to complete for the one previous transaction.
[2328.18s -> 2329.58s]  I have a quick question.
[2329.58s -> 2332.22s]  So how does it work when there's an operation
[2332.22s -> 2335.18s]  or when something is writing to a cache block
[2335.18s -> 2338.38s]  and the block is also being written to the disk?
[2338.38s -> 2342.76s]  Okay, so that is indeed a problem.
[2349.72s -> 2351.58s]  There's a potential difficulty here
[2351.58s -> 2356.58s]  because the stuff that a transaction writes to the log
[2356.88s -> 2360.68s]  should only include updates made by system calls
[2360.68s -> 2362.04s]  that were in that transaction.
[2362.04s -> 2365.64s]  It shouldn't include any block updates
[2365.64s -> 2368.60s]  made by system calls that came after that transaction.
[2369.72s -> 2374.72s]  Because if you did, you'd risk sort of having in the log
[2375.22s -> 2377.98s]  committing but having in the log updates
[2377.98s -> 2382.48s]  that only represent partial system calls.
[2382.48s -> 2384.54s]  Whereas we wanna make sure that a transaction
[2384.54s -> 2389.54s]  only contains all of any given system calls updates.
[2389.60s -> 2393.20s]  So we can't afford to have a transaction include updates
[2393.20s -> 2395.90s]  made by anything that happened after the transaction
[2395.90s -> 2398.94s]  started to close.
[2398.94s -> 2401.58s]  And the way you see three deals with that
[2401.58s -> 2404.54s]  is that at least notionally it makes a copy
[2405.36s -> 2408.08s]  when it decides to wrap up the current open transaction,
[2408.08s -> 2411.72s]  it makes a copy of all the blocks for that transaction
[2411.72s -> 2415.10s]  as of the time it closed out this transaction.
[2415.10s -> 2417.60s]  So it sort of makes copies of all the blocks
[2417.60s -> 2420.08s]  and then it's though that copy of the blocks
[2420.08s -> 2423.64s]  that the transaction commits into its log
[2423.64s -> 2427.64s]  and any newer transactions have their own copy of that
[2427.64s -> 2428.76s]  block that they modify.
[2428.76s -> 2430.68s]  It's a different copy from the one
[2430.68s -> 2432.22s]  we're committing to the log.
[2432.76s -> 2435.52s]  And in order to make this efficient,
[2435.52s -> 2438.08s]  the system actually uses a kind of copy on rate scheme
[2438.08s -> 2441.84s]  to avoid making the copies until it actually notices
[2441.84s -> 2445.12s]  that a newer transaction needs to write that block.
[2445.12s -> 2446.28s]  Cool, that makes sense.
[2446.28s -> 2447.10s]  Thank you.
[2447.10s -> 2447.94s]  Yeah.
[2450.80s -> 2453.94s]  Okay, good.
[2453.94s -> 2456.92s]  And so the reason why concurrency helps performance again
[2456.92s -> 2461.20s]  is that it can help us if we can run system calls
[2461.20s -> 2464.06s]  in parallel, we can get multi-core parallelism
[2464.06s -> 2468.62s]  and if we can run applications and system calls
[2468.62s -> 2470.22s]  at the same time we're writing the disk,
[2470.22s -> 2473.42s]  then we can get IO concurrency that is overlapped
[2473.42s -> 2478.42s]  between CPU and CPU execution and disk IO
[2478.82s -> 2481.80s]  and all of these sort of help use the hardware
[2481.80s -> 2484.70s]  resources, the machine more efficiently, more intensively.
[2486.58s -> 2489.16s]  All right, any questions about concurrency?
[2492.20s -> 2497.20s]  All right, I want to just give you a taste
[2497.34s -> 2500.22s]  of what the actual file system code.
[2500.22s -> 2504.02s]  If you look at the Linux source for the file system,
[2506.14s -> 2508.34s]  sort of at a somewhat abstract level,
[2508.34s -> 2511.58s]  this is the way each system call looks.
[2511.58s -> 2514.28s]  So you might have a unlink system call.
[2516.76s -> 2519.62s]  And this is, you know, can be pretty familiar
[2519.62s -> 2524.58s]  from XV6, we need to, every system call needs to say,
[2524.58s -> 2527.12s]  here's the beginning of the sequence of writes.
[2527.12s -> 2528.72s]  You know, I'm about to do a sequence of writes
[2528.72s -> 2530.80s]  and they need to be atomic with respect to crashes.
[2530.80s -> 2533.92s]  So every system call, well, in any transaction system,
[2533.92s -> 2536.88s]  there has to be a clear sort of begin and end,
[2536.88s -> 2539.72s]  you know, everything between these two points
[2539.72s -> 2540.84s]  needs to be atomic.
[2541.76s -> 2546.76s]  And there's a start call that system call code makes.
[2549.72s -> 2553.08s]  And it turns out that EFC3 has to be aware
[2553.08s -> 2555.86s]  of the different system calls that are active
[2555.86s -> 2559.16s]  for reasons I'll explain in a minute or two.
[2559.16s -> 2561.24s]  So every system call when a call's started
[2561.24s -> 2563.92s]  actually gets what's called a handle.
[2563.92s -> 2565.40s]  It's a sort of unique identifier
[2565.40s -> 2568.48s]  of this particular system call.
[2568.48s -> 2572.44s]  And the writes that it makes are the logins,
[2572.44s -> 2573.66s]  the file system sort of keeps track,
[2573.66s -> 2574.72s]  oh yeah, that write was done
[2574.72s -> 2578.20s]  by this particular system call.
[2578.22s -> 2580.58s]  And then the system call needs to read and write blocks
[2580.58s -> 2583.02s]  and so it makes a, to get hold of a block
[2583.02s -> 2588.02s]  or really a buffer, a block cache buffer
[2588.02s -> 2591.58s]  makes a get call and it tells it the handle
[2591.58s -> 2594.28s]  and then the block number it needs to read or write.
[2597.18s -> 2598.50s]  And it may do a bunch of these right
[2598.50s -> 2601.22s]  if you need to modify many blocks.
[2602.64s -> 2603.82s]  And then when it modifies,
[2603.82s -> 2606.26s]  so then it will modify the blocks in the cache.
[2608.58s -> 2613.58s]  And when it's done, this particular system call is done,
[2614.82s -> 2619.82s]  it makes a stop call and passes the handle
[2620.26s -> 2621.18s]  to the stop call.
[2624.66s -> 2629.58s]  So a lot of what this is about
[2629.58s -> 2631.90s]  is informing the logging system.
[2631.90s -> 2635.34s]  Once a system call starts, a transaction's not allowed
[2635.34s -> 2637.34s]  to commit until all the system calls
[2637.36s -> 2640.28s]  that started in that transaction have finished.
[2640.28s -> 2645.28s]  So, and because there can be multiple transactions,
[2646.68s -> 2648.24s]  the system has to be able to,
[2648.24s -> 2650.56s]  one of the reasons for the handles is so the system,
[2650.56s -> 2652.88s]  the file system can remember for each system call
[2652.88s -> 2655.00s]  which transaction it was part of.
[2655.00s -> 2657.56s]  So it knows, oh, and this just finishes.
[2658.92s -> 2660.32s]  That's one of the system calls
[2660.32s -> 2661.96s]  a particular transaction was waiting for
[2661.96s -> 2663.56s]  before it could actually commit.
[2664.18s -> 2667.82s]  We pass the handle to the get system calls
[2667.82s -> 2671.70s]  so that every transaction has a bunch of blocks
[2671.70s -> 2673.34s]  that are associated with it,
[2673.34s -> 2676.14s]  that were the blocks modified as part of that transaction.
[2676.14s -> 2677.74s]  And so what we're saying here
[2677.74s -> 2680.22s]  as well as getting a pointer to the block
[2680.22s -> 2681.54s]  is we're telling the logging system,
[2681.54s -> 2685.06s]  look, this block number is part of the transaction
[2685.06s -> 2687.20s]  that this handle refers to.
[2690.42s -> 2692.90s]  The stop call doesn't actually cause a commit,
[2692.92s -> 2694.24s]  it just tells the logging system,
[2694.24s -> 2697.24s]  look, you have one fewer system calls
[2697.24s -> 2700.18s]  that are active in this transaction.
[2701.32s -> 2703.00s]  And so a transaction can only commit
[2703.00s -> 2705.44s]  if all of the system calls that started
[2705.44s -> 2707.96s]  in this transaction have called stop.
[2707.96s -> 2710.00s]  So the transaction has to do some bookkeeping,
[2710.00s -> 2711.84s]  has to remember all the handles that started
[2711.84s -> 2714.64s]  so that it can sort of check them off
[2714.64s -> 2716.28s]  as those system calls finish.
[2719.48s -> 2721.64s]  So with this structure in mind,
[2721.66s -> 2724.34s]  I'm just gonna lay out the complete sequence
[2724.34s -> 2727.54s]  of what it takes to commit a transaction.
[2727.54s -> 2731.70s]  So at some point when every five seconds
[2731.70s -> 2733.86s]  the file system is gonna think to itself,
[2733.86s -> 2735.20s]  oh, now would be a good time
[2735.20s -> 2737.20s]  to commit the current open transaction.
[2738.18s -> 2739.98s]  And so here's what happens when the,
[2741.38s -> 2743.70s]  here's what's involved in the file system
[2745.30s -> 2746.34s]  committing a transaction.
[2746.34s -> 2747.90s]  So these are like steps.
[2751.64s -> 2756.64s]  So first, we have to block any new system calls, right?
[2760.50s -> 2764.50s]  We need to have our transaction
[2764.50s -> 2767.66s]  reflect only entire system calls.
[2767.66s -> 2769.66s]  So we don't wanna let anything new start
[2771.78s -> 2774.06s]  when we're trying to commit this transaction.
[2774.06s -> 2775.90s]  We wanna only include system calls
[2775.90s -> 2778.14s]  that have already started.
[2778.14s -> 2780.20s]  So we need to block new system calls.
[2780.20s -> 2782.36s]  There's actually another reason I'll talk about
[2784.70s -> 2786.66s]  why we need to block new system calls.
[2789.02s -> 2791.12s]  This is actually a little bit of a performance defect.
[2791.12s -> 2793.62s]  There's gonna be a period of time here
[2793.62s -> 2796.34s]  when system calls have to wait
[2796.34s -> 2799.50s]  and are not allowed to execute, so that's too bad.
[2799.50s -> 2801.86s]  The second step is that there were a bunch
[2801.86s -> 2803.14s]  of system calls that already started
[2803.14s -> 2805.66s]  that are part of this transaction,
[2805.66s -> 2807.74s]  that we need to wait for them to finish.
[2807.76s -> 2812.16s]  So we need to wait for the outstanding system calls
[2813.86s -> 2815.36s]  that are in this transaction.
[2818.48s -> 2819.84s]  Because of course we want the transaction
[2819.84s -> 2822.28s]  to reflect all of their rights.
[2822.28s -> 2825.08s]  So we need to wait for them to finish.
[2825.08s -> 2826.52s]  The next thing that happens is,
[2826.52s -> 2828.48s]  once all the system calls for this transaction
[2828.48s -> 2831.00s]  are finished and have done their rights into the cache,
[2831.00s -> 2833.28s]  it turns out then it's okay to start a new transaction
[2833.28s -> 2835.64s]  and let these blocked system calls continue.
[2835.66s -> 2838.62s]  So now we're gonna open a new transaction
[2838.62s -> 2842.22s]  for any subsequent system calls.
[2848.02s -> 2849.94s]  But now I'm continuing the story
[2849.94s -> 2852.82s]  with our original transaction, which is now closed.
[2854.06s -> 2857.04s]  So you remember the log next in ext3
[2857.04s -> 2860.90s]  contains descriptors and data blocks and commit blocks.
[2860.90s -> 2863.98s]  So now we know the full set
[2864.00s -> 2868.84s]  of blocks modified by all the system calls
[2868.84s -> 2870.48s]  that were in this transaction,
[2870.48s -> 2872.84s]  because they all called get with a handle
[2872.84s -> 2876.44s]  that told us about what transaction they were part of.
[2876.44s -> 2878.24s]  So we know the full set of modified blocks
[2878.24s -> 2879.46s]  for this transaction.
[2879.46s -> 2881.36s]  So now we can write a descriptor block
[2885.12s -> 2887.20s]  that has all the block numbers
[2889.32s -> 2892.06s]  for all the blocks that are dirty in this transaction.
[2893.98s -> 2898.98s]  We're also gonna write the actual modified blocks
[2900.48s -> 2904.80s]  from the disk cache into the log.
[2904.80s -> 2907.28s]  And in fact, if somebody asks a question about,
[2907.28s -> 2908.92s]  oh, what happens if the next transaction
[2908.92s -> 2909.76s]  modifies this block?
[2909.76s -> 2911.40s]  What we're actually writing in this stage
[2911.40s -> 2916.40s]  is the sort of saved copies of this transaction's blocks
[2917.20s -> 2919.04s]  as of the time when it finished.
[2920.02s -> 2925.02s]  So we're gonna write the actual blocks to the log.
[2931.62s -> 2935.94s]  And now we're gonna wait for these writes to finish.
[2940.54s -> 2945.54s]  So these need to finish before we can proceed.
[2946.98s -> 2948.54s]  Once the descriptor and the data blocks
[2949.12s -> 2951.08s]  are sort of guaranteed to be on the disk,
[2951.08s -> 2953.82s]  then we can write the commit record to the log.
[2960.28s -> 2962.04s]  And once that write is finished,
[2963.36s -> 2965.12s]  we have to wait for it to finish.
[2970.52s -> 2973.32s]  So we're waiting for the commit write to finish.
[2973.32s -> 2976.70s]  At this point, once the commit write is finished,
[2976.76s -> 2980.04s]  this transaction, the sort of technical term
[2980.04s -> 2982.78s]  is that this transaction has reached its commit point.
[2982.78s -> 2987.32s]  That is, it's guaranteed, the writes in this traction
[2987.32s -> 2990.04s]  are guaranteed to survive a crash at this point.
[2990.04s -> 2994.60s]  If a crash had occurred before writing the commit block,
[2994.60s -> 2996.76s]  the writes in the transaction would not appear
[2996.76s -> 3000.92s]  after a crash and reboot and running the recovery software.
[3000.92s -> 3003.84s]  If a crash occurs now after this commit point,
[3003.84s -> 3006.20s]  after the commit block has been to the disk,
[3007.56s -> 3010.12s]  then they're guaranteed to, those writes,
[3010.12s -> 3012.96s]  all the writes in the transaction are guaranteed
[3012.96s -> 3015.56s]  to appear after a crash, reboot, and recovery.
[3017.16s -> 3022.08s]  Okay, and now, not only now, in the background,
[3022.08s -> 3023.84s]  all of this kind of happened in the background.
[3023.84s -> 3026.34s]  No process was really waiting for this stuff.
[3027.76s -> 3031.42s]  Now we can write the transactions blocks
[3031.42s -> 3033.56s]  to their home locations in the file system.
[3036.70s -> 3041.70s]  And as I'll talk about in a few minutes,
[3046.88s -> 3049.72s]  after all of these writes have completed,
[3051.36s -> 3054.72s]  for all the blocks that are part of this transaction,
[3054.72s -> 3059.72s]  then only then can we reuse that part of the log.
[3062.84s -> 3066.20s]  So in a very busy system, if the head of the log
[3066.74s -> 3067.70s]  catches up with the tail, there may actually,
[3067.70s -> 3069.98s]  we may not be able to start a new transaction
[3069.98s -> 3071.98s]  until all of these writes have finished
[3071.98s -> 3075.56s]  for the oldest transaction, because we may need log space
[3075.56s -> 3079.30s]  and we may need to reuse the oldest transaction's log space
[3079.30s -> 3082.90s]  we have to write for it to write all its cache blocks
[3082.90s -> 3084.90s]  to their home locations.
[3084.90s -> 3087.58s]  This usually, people try to make the log big enough
[3087.58s -> 3089.46s]  that this happens pretty rarely
[3089.46s -> 3092.14s]  so that this stuff can go on in the background.
[3094.58s -> 3096.18s]  Any questions about these steps?
[3096.20s -> 3101.20s]  Oh, sorry, where are those run?
[3101.54s -> 3102.46s]  Oh, this way?
[3102.46s -> 3107.34s]  Right, for doing this file system stuff.
[3109.46s -> 3110.70s]  Can you say that again?
[3110.70s -> 3113.18s]  Oh, so you said that no process is waiting
[3113.18s -> 3116.58s]  for those things to get done.
[3116.58s -> 3119.66s]  So where are they scheduled?
[3119.66s -> 3120.76s]  Where are they run?
[3121.62s -> 3124.20s]  Oh, there's a background thread.
[3126.20s -> 3131.20s]  There's a background thread in the kernel dedicated.
[3131.62s -> 3132.62s]  I see, thank you.
[3137.54s -> 3142.22s]  Got a question actually about reusing part of the log.
[3142.22s -> 3145.58s]  So let's say eventually we start using
[3145.58s -> 3150.26s]  a particular section of log and the log,
[3150.26s -> 3152.76s]  that particular, I think just as mentioned,
[3152.76s -> 3155.70s]  that particular log of, particular part of the log
[3156.20s -> 3160.72s]  actually in my new transaction actually ends up using
[3160.72s -> 3163.32s]  the whole log part that was just freed up
[3163.32s -> 3164.80s]  and there's nothing else.
[3164.80s -> 3167.84s]  There's no more space for the log.
[3167.84s -> 3170.16s]  Would the log then like with the system,
[3170.16s -> 3175.16s]  just wait until another portion of log is freed up
[3175.24s -> 3177.36s]  or would it do something else too?
[3178.40s -> 3180.18s]  Yes, it'll wait.
[3181.46s -> 3183.52s]  Let me just draw a picture
[3183.52s -> 3185.70s]  just to help me make sure I'm answering
[3185.70s -> 3187.54s]  the right question here.
[3187.54s -> 3191.00s]  We can think of the log as just this linear part
[3191.00s -> 3193.46s]  of the disk and at any given time,
[3193.46s -> 3198.46s]  maybe the oldest valid transaction is T seven
[3199.38s -> 3202.72s]  and then there's T eight in this region
[3202.72s -> 3206.18s]  and we have T nine and we wanna start,
[3207.06s -> 3209.08s]  we wanna put T 10 here.
[3209.08s -> 3214.08s]  Let's see, one, we'd like to start a new transaction
[3221.34s -> 3222.24s]  and put it here.
[3225.62s -> 3230.62s]  We may have to wait for T seven to write all its blocks
[3232.62s -> 3235.06s]  to their home locations so that we can free it.
[3236.12s -> 3238.74s]  And that may mean that the transaction stuff
[3239.28s -> 3243.08s]  in transaction 10 may have to pause waiting
[3243.08s -> 3246.04s]  for this space in the log to free up.
[3247.20s -> 3248.56s]  Is that what you're talking about?
[3248.56s -> 3252.64s]  Yeah, so it could be the case at the beginning
[3253.52s -> 3256.36s]  I can put in blocks for transaction 10
[3256.36s -> 3258.72s]  in the actual free space right now
[3258.72s -> 3261.36s]  but eventually if the log grows big enough,
[3261.36s -> 3263.28s]  it's just gonna run out of free space
[3263.28s -> 3264.28s]  and at that point, it's just gonna wait
[3264.28s -> 3267.56s]  for transaction seven to be recorded.
[3267.86s -> 3271.26s]  Yes, yes, certainly if there's enough activity going on
[3271.26s -> 3273.46s]  and the log wraps around quickly enough,
[3273.46s -> 3278.46s]  you may end up having to wait for new system calls.
[3280.04s -> 3282.26s]  We may not even be able to start the system calls
[3282.26s -> 3285.98s]  because before we can free up space in the log
[3285.98s -> 3288.34s]  for the blocks that they're gonna modify.
[3288.34s -> 3291.34s]  And if you care about the diesels of this,
[3291.34s -> 3293.90s]  it turns out there's some potential deadlocks here
[3294.40s -> 3299.40s]  that require, that mean that ext3 ends up,
[3301.80s -> 3303.64s]  system calls have to pre-declare
[3303.64s -> 3305.60s]  how many blocks they're gonna need
[3305.60s -> 3310.60s]  so that the logging system knows sort of how much
[3310.64s -> 3314.68s]  can reason about whether there's enough space
[3314.68s -> 3316.12s]  for this transaction.
[3316.12s -> 3318.32s]  Because we don't wanna allow a transaction to start
[3318.32s -> 3321.68s]  that we wouldn't actually be able to commit into the log.
[3324.88s -> 3326.32s]  Okay.
[3326.32s -> 3330.08s]  Let's say it's the new log
[3330.08s -> 3331.70s]  or the new transaction you're trying to put
[3331.70s -> 3335.08s]  goes to like eight, transaction eight.
[3335.08s -> 3338.16s]  So you would have to wait for seven and eight, right?
[3338.16s -> 3339.84s]  So how does that work?
[3339.84s -> 3344.84s]  You mean, okay, so transaction seven
[3344.88s -> 3346.76s]  and transaction eight and transaction nine,
[3346.76s -> 3349.02s]  at least in this diagram have all completed
[3349.02s -> 3352.24s]  or all the system calls have finished
[3352.24s -> 3355.94s]  and these transactions are committed in the log
[3355.94s -> 3358.02s]  because these are the old transactions.
[3358.02s -> 3361.06s]  So in this picture, at least,
[3361.06s -> 3363.10s]  we're just starting transaction 10.
[3364.24s -> 3365.42s]  And so new system calls
[3365.42s -> 3367.70s]  are gonna be writing into transaction 10.
[3370.80s -> 3374.18s]  Right, but you said that transaction 10
[3374.18s -> 3376.82s]  is not big enough to fill that space
[3376.82s -> 3380.90s]  so you need to free transaction seven, right?
[3380.90s -> 3381.74s]  Yes.
[3382.16s -> 3384.40s]  So you would have to wait for that to commit to disk.
[3385.84s -> 3386.68s]  Yes.
[3386.68s -> 3391.68s]  But what happens if 10 is bigger than seven,
[3391.76s -> 3393.36s]  like it goes to eight transactions?
[3393.36s -> 3394.92s]  Then we have to wait for two.
[3396.00s -> 3398.08s]  Yeah, we may have to wait for,
[3398.08s -> 3400.28s]  however big transaction 10 is,
[3402.80s -> 3405.00s]  we need enough space on the disk to fit it
[3405.00s -> 3407.64s]  and not enough space in the log to fit it.
[3407.64s -> 3409.16s]  And so indeed, if transaction 10
[3409.16s -> 3411.36s]  and it turns out being big,
[3411.86s -> 3416.86s]  it may need to force multiple of the oldest transactions
[3418.62s -> 3422.14s]  to write to their home locations and free themselves.
[3422.14s -> 3424.74s]  I guess how does code for that work?
[3424.74s -> 3427.54s]  Like, does it like just run through how big it is
[3427.54s -> 3429.54s]  and like say, hey, there's a transaction here
[3429.54s -> 3430.38s]  and a transaction here
[3430.38s -> 3432.82s]  and it's like, I have to wait for both of them?
[3433.70s -> 3438.70s]  The file system knows how big all the transactions
[3439.56s -> 3443.84s]  in the log are and remembers.
[3443.84s -> 3446.04s]  I mean, actually the file system remembers quite a bit
[3446.04s -> 3447.72s]  about each of these older transactions.
[3447.72s -> 3450.74s]  It knows for each one, whether it's written,
[3452.16s -> 3454.28s]  the file system keeps track of for every block
[3454.28s -> 3456.80s]  and each of these older transactions,
[3456.80s -> 3460.32s]  whether it has written that block to the home location
[3460.32s -> 3462.96s]  so that it can know, oh, I've written,
[3462.96s -> 3466.24s]  it can know whether or not and recognize the point
[3466.24s -> 3467.28s]  at which it's finished writing
[3467.28s -> 3468.74s]  all the transaction sevens blocks
[3468.74s -> 3469.78s]  or transaction six blocks.
[3469.78s -> 3473.12s]  So there's quite a lot of bookkeeping going on here
[3473.12s -> 3476.54s]  for the file system to understand and detail
[3476.54s -> 3479.56s]  the state of every old transaction.
[3486.44s -> 3487.28s]  Okay.
[3489.54s -> 3492.94s]  Okay, so indeed there's on the topic
[3492.94s -> 3494.38s]  of how to reuse log space,
[3494.38s -> 3495.68s]  there's one little detail here
[3495.70s -> 3497.84s]  that needs to be said.
[3497.84s -> 3500.28s]  If you remember at the beginning of the,
[3500.28s -> 3502.58s]  let me write a new diagram.
[3503.92s -> 3506.60s]  There's actually a super block,
[3506.60s -> 3510.46s]  the log super block at the beginning of the log.
[3511.48s -> 3514.60s]  And so at any given time,
[3514.60s -> 3516.44s]  you might have the log super block
[3516.44s -> 3520.94s]  and then some set of transactions.
[3522.60s -> 3524.24s]  Maybe it was transaction four,
[3524.24s -> 3526.52s]  which is the newest transaction
[3526.52s -> 3531.52s]  and then transaction one and the older transactions.
[3532.26s -> 3533.52s]  And so what this means is that,
[3533.52s -> 3535.36s]  of course the log is wrapped around.
[3540.22s -> 3545.00s]  And the rule for whether we could reuse
[3545.00s -> 3546.78s]  a part of the log,
[3546.78s -> 3547.72s]  now I've mentioned this before,
[3547.72s -> 3549.04s]  I just want to say it again,
[3549.04s -> 3550.32s]  is that we can reuse the log,
[3550.32s -> 3552.78s]  say we can reuse this part of the log
[3552.78s -> 3554.30s]  that transaction two is in,
[3554.30s -> 3555.96s]  if T2 has committed
[3556.94s -> 3559.48s]  and all of T2's blocks have been written
[3559.48s -> 3562.62s]  to their home locations in the file system
[3562.62s -> 3564.94s]  so that there can never be any need
[3564.94s -> 3568.46s]  after a crash to replay these blocks.
[3570.78s -> 3574.50s]  And if all transactions prior to transaction two
[3574.50s -> 3576.54s]  have also been freed.
[3576.54s -> 3578.26s]  So if those conditions are all true,
[3578.26s -> 3581.14s]  then we can free and reuse
[3581.18s -> 3583.02s]  the part of the log that T2 sits in.
[3585.10s -> 3586.30s]  So we can only reuse T2
[3586.30s -> 3590.98s]  and after T2 is after T1 has finished all committing
[3590.98s -> 3594.62s]  and writing its blocks to the home locations also.
[3594.62s -> 3598.74s]  And then this super block for the convenience
[3598.74s -> 3601.42s]  of the recovery software after a crash,
[3601.42s -> 3603.18s]  if we decide that we can,
[3603.18s -> 3605.72s]  if the file system decides it can free
[3605.72s -> 3608.54s]  and reuse a particular part of the log,
[3609.54s -> 3612.26s]  it rewrites the super block to,
[3612.26s -> 3613.46s]  the super block has a pointer
[3613.46s -> 3618.46s]  to the first transaction of the log.
[3618.74s -> 3622.18s]  And so as part of freeing part of the log,
[3622.18s -> 3624.18s]  the file system modifies a super block
[3624.18s -> 3625.58s]  to point to the new,
[3625.58s -> 3630.42s]  the beginning of the now oldest transaction in the log.
[3631.54s -> 3633.82s]  And then if there's a crash,
[3633.82s -> 3636.22s]  the recovery software reads the super block,
[3636.22s -> 3637.82s]  finds the beginning of the log.
[3638.54s -> 3643.54s]  Okay, so if there's a crash,
[3644.94s -> 3649.94s]  of course, a crash causes everything in RAM to evaporate.
[3651.78s -> 3654.34s]  So all that bookkeeping that the file system is keeping
[3654.34s -> 3656.82s]  about what blocks have been written
[3656.82s -> 3657.68s]  to their home locations,
[3657.68s -> 3660.82s]  that's all lost if there's a crash or a power failure.
[3660.82s -> 3663.02s]  However, so one of the assumptions
[3663.02s -> 3664.98s]  is there's nothing useful in RAM.
[3664.98s -> 3668.22s]  The only stuff that can be preserved
[3668.74s -> 3670.50s]  across a crash is whatever's on the disk.
[3671.78s -> 3674.62s]  But we are absolutely in all these discussions
[3674.62s -> 3678.02s]  about logging, assuming that the disk is completely intact,
[3678.02s -> 3680.02s]  that nothing went wrong with the disk.
[3681.36s -> 3683.50s]  So maybe the right model for you to think of in terms
[3683.50s -> 3684.82s]  of is that there was a power failure,
[3684.82s -> 3685.90s]  that everything was humming along
[3685.90s -> 3686.90s]  and then the power failed
[3686.90s -> 3689.22s]  and the system just stopped at some point.
[3689.22s -> 3692.16s]  And the disk is after power is restored,
[3692.16s -> 3694.34s]  the disk just has whatever it had on it
[3694.34s -> 3696.62s]  at the point of the power failure.
[3696.66s -> 3699.78s]  So we're absolutely not considering situations
[3699.78s -> 3703.30s]  in which the disk was somehow corrupted
[3703.30s -> 3705.88s]  or destroyed by the crash.
[3710.78s -> 3712.98s]  And so the crash, of course, may interrupt
[3714.90s -> 3717.54s]  whatever transactions were in the middle of committing
[3717.54s -> 3719.74s]  or not yet committing yet or whatever,
[3719.74s -> 3724.74s]  the crash may interrupt either the commit of a transaction
[3724.82s -> 3728.14s]  or the writing of a transaction's blocks
[3728.14s -> 3730.14s]  into their home locations.
[3730.14s -> 3733.80s]  So what that means is that the on-disk log,
[3733.80s -> 3736.16s]  when the power is restored and recovery software is run,
[3736.16s -> 3740.66s]  it's gonna have a bunch of older complete transactions,
[3740.66s -> 3742.22s]  that may be T1 and T2.
[3744.78s -> 3749.14s]  Let me pick up a new example for recovery.
[3750.14s -> 3753.46s]  Let's say we have, again, the super block
[3755.74s -> 3760.42s]  and maybe at the time of the crash,
[3760.42s -> 3765.42s]  the oldest transaction was T6 and then there's T7
[3768.70s -> 3771.90s]  and we wrapped around still before the crash to T8.
[3773.18s -> 3778.18s]  And there was a T5, but T8, let us imagine,
[3778.18s -> 3783.18s]  has overwritten the first part of T5
[3785.58s -> 3789.06s]  because T5 was, we know that T5 was freed
[3789.06s -> 3791.86s]  before the crash, but recovery software
[3791.86s -> 3793.42s]  doesn't necessarily know that.
[3795.66s -> 3800.22s]  And let's say the super block points to T6
[3800.22s -> 3804.46s]  as being the start of the oldest valid transaction.
[3804.46s -> 3807.04s]  So T5 is free.
[3809.86s -> 3811.48s]  We're gonna reboot with an attack disk.
[3811.48s -> 3813.42s]  The recovery software reads the super block
[3813.42s -> 3817.18s]  and so then it knows where the beginning of the log is.
[3817.18s -> 3819.58s]  Then the recovery software is gonna scan forward
[3819.58s -> 3822.78s]  in the log to try to find the end of the log.
[3824.54s -> 3828.60s]  But we need to have a way for it to actually figure out,
[3828.60s -> 3831.38s]  oh, that's the end of the log.
[3832.38s -> 3837.38s]  The way it does that is we know that every transaction
[3838.78s -> 3841.38s]  consists of a descriptor block that indicates
[3841.38s -> 3844.26s]  how many data blocks are on the transaction.
[3844.26s -> 3845.62s]  So the descriptor block says, oh yeah,
[3845.62s -> 3848.40s]  there's 17 data blocks and we expect 17 data blocks
[3848.40s -> 3849.90s]  and finally a commit record.
[3851.08s -> 3852.62s]  And then another descriptor record
[3852.62s -> 3854.58s]  and then the number of data blocks
[3854.58s -> 3856.58s]  implied by the descriptor block
[3856.58s -> 3858.08s]  and then another commit block.
[3859.00s -> 3861.74s]  And so the log software's gonna scan forward.
[3862.64s -> 3864.32s]  Maybe T6 and T7 are fine.
[3864.32s -> 3865.52s]  Then it's gonna look at T8.
[3865.52s -> 3867.24s]  T8's got some descriptor block.
[3868.80s -> 3872.34s]  And then the recovery software's gonna look forward
[3872.34s -> 3876.80s]  to where the end of transaction eight should be
[3876.80s -> 3881.64s]  and look for a commit block.
[3881.64s -> 3884.00s]  And so there's a couple of things
[3884.00s -> 3884.88s]  that may have happened here.
[3884.88s -> 3888.84s]  It could be that transaction eight did commit
[3888.84s -> 3892.36s]  and that the recovery software finds the commit block.
[3892.36s -> 3895.42s]  It'll then look for another,
[3895.42s -> 3896.28s]  you know, it doesn't know
[3896.28s -> 3899.12s]  that transaction eight's the last transaction.
[3899.12s -> 3900.08s]  Needs to figure that out.
[3900.08s -> 3902.70s]  So it's gonna look at the very next block
[3902.70s -> 3906.68s]  to see if this is a valid descriptor block.
[3908.84s -> 3910.12s]  Now, we know that this block
[3910.12s -> 3911.86s]  was really just a random block
[3911.86s -> 3913.12s]  in the middle of transaction five
[3913.12s -> 3915.08s]  and not a descriptor block at all.
[3915.08s -> 3917.76s]  And the question is how can the recovery software
[3917.76s -> 3919.34s]  reliably distinguish between,
[3919.34s -> 3922.38s]  oh, this is just some data block
[3922.38s -> 3923.80s]  in the middle of an old transaction
[3923.80s -> 3926.68s]  or it's the, maybe the descriptor block
[3926.68s -> 3928.04s]  for transaction nine.
[3929.94s -> 3933.00s]  Any guesses for a reliable method to do that?
[3933.00s -> 3935.08s]  Is that the magic number?
[3935.08s -> 3935.92s]  Yeah.
[3935.92s -> 3938.26s]  Or is there just a reserved bit?
[3938.26s -> 3939.10s]  There is indeed.
[3939.10s -> 3941.12s]  Every descriptor and commit block
[3941.12s -> 3944.12s]  starts with some magic number.
[3944.12s -> 3945.60s]  Just a 32-bit value
[3945.60s -> 3947.58s]  that the recovery software is looking for.
[3947.58s -> 3949.84s]  I don't actually know what it is.
[3949.84s -> 3953.30s]  So definitely the game is that
[3953.30s -> 3954.80s]  we come to the end of transaction eight.
[3954.80s -> 3957.60s]  If the very next block starts with the magic number,
[3958.60s -> 3960.88s]  then the recovery software's gonna assume that,
[3960.88s -> 3962.92s]  oh, this is a valid descriptor block.
[3965.68s -> 3967.14s]  Could it?
[3967.14s -> 3968.90s]  Sorry, quick question.
[3968.90s -> 3973.70s]  Would it be unreliable to try to interpret it
[3973.70s -> 3976.42s]  as a descriptor block,
[3976.42s -> 3980.02s]  try to read the number of data blocks that it specifies,
[3980.02s -> 3982.32s]  then see if there's a commit block
[3982.32s -> 3985.82s]  at the expected location after that number of blocks?
[3987.54s -> 3988.58s]  Well, certainly if this block
[3988.58s -> 3990.70s]  does look like a descriptor block,
[3990.70s -> 3992.34s]  then it will skip forward
[3992.34s -> 3994.90s]  and try to read the corresponding commit block.
[3994.90s -> 3996.30s]  And if that commit block doesn't look like
[3996.30s -> 3997.82s]  a commit block with the right magic number,
[3997.86s -> 4000.12s]  then it will not believe in this transaction.
[4005.26s -> 4008.26s]  The one little remaining detail here is that
[4008.26s -> 4010.14s]  this block that we're looking at here
[4010.14s -> 4011.02s]  and we're wondering,
[4011.02s -> 4013.58s]  or the recovery software is wondering
[4013.58s -> 4015.46s]  if it's a descriptor block,
[4015.46s -> 4017.82s]  this could be just a block
[4017.82s -> 4019.50s]  right in the middle of transaction five
[4019.50s -> 4022.74s]  containing any arbitrary bit pattern.
[4022.74s -> 4025.16s]  It could be just like the data block from a file
[4025.20s -> 4027.80s]  that just happens to begin with the magic number.
[4030.04s -> 4031.88s]  So, as a final detail,
[4031.88s -> 4034.64s]  the logging system needs to be able to distinguish
[4034.64s -> 4036.26s]  between a valid descriptor block
[4036.26s -> 4037.88s]  that starts with this magic number
[4037.88s -> 4040.40s]  and just some data block
[4040.40s -> 4042.20s]  that starts with the magic number.
[4043.92s -> 4046.72s]  And you can imagine various ways of doing that.
[4046.72s -> 4049.48s]  In fact, what ext3 does is
[4049.48s -> 4051.40s]  whenever it's gonna write a block to the log
[4051.40s -> 4053.80s]  that's not a descriptor block or a commit block,
[4053.80s -> 4055.96s]  if that block starts with the magic number,
[4055.96s -> 4057.84s]  it replaces that with zero
[4057.84s -> 4061.04s]  and sets a bit corresponding to that block
[4061.04s -> 4063.40s]  in that transaction's descriptor block.
[4063.40s -> 4067.96s]  Then that bit means this particular data block
[4067.96s -> 4069.16s]  started with the magic number
[4069.16s -> 4071.28s]  and we replaced it with zero.
[4071.28s -> 4073.48s]  And then if the recovery software ever needs
[4073.48s -> 4075.16s]  to replay that block,
[4075.16s -> 4077.38s]  so let's say transaction eight had one of these blocks
[4077.38s -> 4079.56s]  that originally started with the magic number,
[4079.56s -> 4082.60s]  it's gonna set the bit, this magic flag,
[4082.76s -> 4084.88s]  corresponding to that block and the descriptor block
[4084.88s -> 4087.16s]  and replace magic number with zero.
[4087.16s -> 4088.96s]  If recovery has to replay this block,
[4088.96s -> 4090.08s]  it'll see that flag
[4090.08s -> 4092.96s]  and before replaying this block to its own location,
[4092.96s -> 4095.42s]  will replace the zero with the magic number.
[4096.44s -> 4101.12s]  And therefore, no block other than a descriptor
[4101.12s -> 4104.92s]  or commit block can possibly start with the magic number
[4104.92s -> 4105.84s]  in this logging system.
[4105.84s -> 4107.72s]  So we never have this ambiguity.
[4107.72s -> 4110.16s]  If the block after a commit block
[4110.16s -> 4111.08s]  starts with a magic number,
[4111.08s -> 4113.94s]  then it must be a descriptor block.
[4118.36s -> 4121.92s]  Okay, all right, so recovery, we were doing recovery.
[4121.92s -> 4126.92s]  It starts at the block that the super block says
[4127.50s -> 4129.16s]  is the beginning of the oldest transaction,
[4129.16s -> 4132.62s]  it scans forward and it'll scan forward until,
[4135.52s -> 4136.48s]  look at the descriptor,
[4136.48s -> 4138.72s]  is there a corresponding commit block?
[4138.76s -> 4140.96s]  And it'll stop as soon as it sees,
[4140.96s -> 4143.16s]  oh, the block following a commit block
[4143.16s -> 4144.88s]  wasn't a descriptor block at all.
[4145.76s -> 4149.36s]  Or, yeah, the block following a commit block
[4149.36s -> 4150.32s]  is a descriptor block,
[4150.32s -> 4155.32s]  but what should have been the corresponding commit block
[4155.64s -> 4157.60s]  is not in fact a valid commit block,
[4157.60s -> 4158.76s]  it doesn't have the magic number.
[4158.76s -> 4160.32s]  So at that point, it'll stop
[4161.32s -> 4164.36s]  and recovery software will declare the log to have ended
[4165.36s -> 4169.96s]  at the point where the last valid commit block.
[4169.96s -> 4170.80s]  And it will ignore,
[4170.80s -> 4173.08s]  there may be a partial transaction after this
[4173.08s -> 4175.64s]  that started to commit but didn't finish,
[4175.64s -> 4178.60s]  but the recovery software ignores that partial transaction
[4178.60s -> 4180.30s]  because it doesn't have all the writes,
[4180.30s -> 4182.72s]  so it can't restore it atomically.
[4182.72s -> 4185.08s]  And then the recovery software will go through,
[4185.08s -> 4188.94s]  go back to the beginning of the log and replay each block,
[4188.94s -> 4191.90s]  rewrite each block to its home location,
[4191.94s -> 4196.82s]  all through the log up to the last valid commit block.
[4199.58s -> 4203.66s]  And then it can restart the best of the operating system,
[4203.66s -> 4205.18s]  start the rest of the operating system
[4205.18s -> 4207.78s]  and ordinary programs can run.
[4207.78s -> 4209.30s]  Of course, before recovery finishes,
[4209.30s -> 4211.70s]  you can't run any programs
[4211.70s -> 4215.98s]  because the file system isn't valid.
[4218.86s -> 4220.30s]  Any questions about recovery?
[4221.30s -> 4223.44s]  I have a quick question.
[4224.34s -> 4225.94s]  I think you mentioned this before,
[4225.94s -> 4229.52s]  but what parts of this logging transaction scheme
[4229.52s -> 4232.72s]  is missing in XV6?
[4233.88s -> 4235.92s]  The main thing that's missing in XV6
[4235.92s -> 4239.34s]  is the ability to have multiple transactions in the log.
[4239.34s -> 4241.42s]  So in XV6, there's only ever
[4241.42s -> 4243.86s]  at most one transaction in the log.
[4243.86s -> 4246.42s]  And so you can't,
[4246.42s -> 4248.34s]  you don't get this concurrency in XV6
[4248.38s -> 4251.70s]  where while I'm executing system calls
[4251.70s -> 4254.86s]  from transaction seven,
[4254.86s -> 4256.60s]  that are gonna go into transaction seven
[4256.60s -> 4258.14s]  in parallel with that,
[4258.14s -> 4262.80s]  ext3 can be committing transaction six to the disk.
[4263.86s -> 4264.86s]  That's not available.
[4264.86s -> 4269.86s]  That concurrency is not possible in ext in XV6
[4272.78s -> 4276.26s]  because the log holds just the one transaction.
[4276.26s -> 4277.98s]  So we have to completely do all the work
[4278.50s -> 4281.10s]  for one transaction before we're allowed to start anything
[4281.10s -> 4282.72s]  with the next transaction.
[4283.78s -> 4284.92s]  And so it's correct and simple,
[4284.92s -> 4288.82s]  but you don't get a lot of parallelism out of XV6.
[4289.74s -> 4291.22s]  Okay, thank you.
[4291.22s -> 4292.54s]  Are you saying that
[4292.54s -> 4294.82s]  it can still have multiple transaction blocks,
[4294.82s -> 4297.60s]  but it just can't execute them asynchronously?
[4299.54s -> 4301.46s]  Would that be correct?
[4301.46s -> 4302.60s]  XV6.
[4302.60s -> 4303.98s]  And XV6?
[4304.58s -> 4307.22s]  Yeah, it only has the,
[4308.18s -> 4309.62s]  once it decides to,
[4311.78s -> 4313.58s]  I mean, the picture is a little bit confused
[4313.58s -> 4318.38s]  because XV6 can allow more than one system call
[4318.38s -> 4319.74s]  into a single transaction.
[4319.74s -> 4323.38s]  So XV6 actually does have some of this concurrency in it
[4323.38s -> 4325.10s]  and some of this batching.
[4325.10s -> 4328.50s]  But once XV6 decides to start committing a transaction,
[4329.62s -> 4332.38s]  it has to completely finish with that transaction,
[4332.38s -> 4334.86s]  commit it to disk, write the header block,
[4334.86s -> 4337.52s]  write the blocks to the home locations,
[4337.52s -> 4340.74s]  and then erase the transaction from the log.
[4340.74s -> 4341.82s]  It has to do all that stuff
[4341.82s -> 4345.22s]  before it can execute any new system calls
[4345.22s -> 4348.74s]  because there's nowhere to put the modifications
[4348.74s -> 4349.58s]  for the new system calls
[4349.58s -> 4352.74s]  until the previous transaction is completely finished.
[4352.74s -> 4355.22s]  So XV6 sort of alternates between,
[4355.22s -> 4357.14s]  it can run a few system calls
[4357.14s -> 4359.50s]  and then commit a transaction
[4359.50s -> 4360.74s]  and then run a few more system calls,
[4360.78s -> 4362.82s]  but it can't sort of overlap those two.
[4363.82s -> 4365.38s]  I see, you see three can.
[4366.38s -> 4367.54s]  Thank you.
[4367.54s -> 4368.38s]  Yeah.
[4376.92s -> 4377.76s]  Okay.
[4379.22s -> 4381.34s]  So that was the relatively straightforward part
[4381.34s -> 4384.14s]  of EXT3 design.
[4385.52s -> 4389.54s]  It turns out there's also a bunch of tricky details,
[4389.56s -> 4391.58s]  a few of which I want to talk about.
[4391.58s -> 4396.42s]  So I mentioned before that there's an open transaction,
[4396.42s -> 4399.42s]  but when EXT3 decides that it wants to close
[4399.42s -> 4400.86s]  the open transaction,
[4401.88s -> 4403.58s]  it has to wait for all system calls
[4403.58s -> 4405.66s]  in that transaction to finish
[4405.66s -> 4409.94s]  before any new transactions are allowed to start.
[4409.94s -> 4412.74s]  So maybe a picture for that is that,
[4412.74s -> 4417.74s]  we had our original old transaction T1,
[4418.42s -> 4420.26s]  and there were multiple system calls
[4420.26s -> 4424.14s]  that executing in transaction one.
[4424.14s -> 4426.22s]  If we want to close transaction one,
[4426.22s -> 4428.38s]  we have to stop accepting new system calls
[4428.38s -> 4430.42s]  because we want to wait for the existing ones to finish
[4430.42s -> 4432.18s]  before we can commit.
[4432.18s -> 4435.70s]  But until all these system calls finished,
[4435.70s -> 4439.06s]  no new system calls are allowed to start in the EXT3.
[4439.06s -> 4441.50s]  So if there's some transaction two here,
[4441.50s -> 4444.50s]  nothing is allowed to happen in transaction two,
[4444.50s -> 4445.58s]  nothing's allowed to,
[4445.58s -> 4446.82s]  system calls are allowed to start
[4446.86s -> 4449.78s]  until these system calls have finished.
[4449.78s -> 4452.38s]  And only then can transaction two
[4452.38s -> 4455.50s]  start accepting system calls.
[4455.50s -> 4459.08s]  So there's a period of time here
[4459.08s -> 4462.46s]  in which new system calls are all blocked.
[4462.46s -> 4464.10s]  And so that reduces performance
[4464.10s -> 4466.38s]  because it could have been executing system calls,
[4466.38s -> 4467.94s]  but we're not allowed to.
[4467.94s -> 4472.54s]  And the question is how come EXT3
[4472.54s -> 4476.10s]  doesn't allow new system calls to start in transaction two
[4476.14s -> 4479.74s]  until all system calls in transaction one have finished?
[4483.06s -> 4485.26s]  It's a good question because it limits performance.
[4485.26s -> 4487.04s]  So let me give you an example.
[4487.04s -> 4490.16s]  If EXT3 didn't do this,
[4490.16s -> 4493.66s]  then the following bad situation could arise.
[4494.82s -> 4496.78s]  So let's suppose transaction one
[4496.78s -> 4498.38s]  just has one system call in it,
[4500.06s -> 4504.34s]  and it's a create, a system call to create a file,
[4504.38s -> 4506.38s]  maybe a file called X.
[4506.38s -> 4510.58s]  And the idea is that before this create is finished,
[4510.58s -> 4512.70s]  the file system decides it wants to start
[4512.70s -> 4515.08s]  a new transaction, open up a new transaction,
[4515.08s -> 4518.14s]  and it's gonna accept any system calls after the create
[4518.14s -> 4520.94s]  in this new transaction, transaction T2.
[4520.94s -> 4525.10s]  So we're gonna say T2 starts before T1 finishes,
[4525.10s -> 4528.56s]  and we start executing system calls now in transaction two.
[4530.46s -> 4533.86s]  And maybe transaction T2 calls unlink on some other file.
[4534.38s -> 4537.80s]  Well, that unlink will free the inode associated with Y.
[4539.02s -> 4544.02s]  And so maybe I'm having time go this way in my diagram.
[4546.74s -> 4548.46s]  Maybe at this point in time,
[4548.46s -> 4551.82s]  transaction two marks the inode as free,
[4551.82s -> 4554.02s]  marks the inode for Y as free.
[4554.02s -> 4557.06s]  Create, of course, has to allocate an inode for X.
[4557.06s -> 4560.22s]  Maybe it allocates an inode at this point in time.
[4560.22s -> 4563.06s]  Well, because the create is allocating
[4563.10s -> 4567.06s]  after the unlink freed, it might reuse the same inode.
[4567.06s -> 4570.82s]  So maybe X is gonna get the same inode that Y had,
[4570.82s -> 4574.30s]  say maybe inode 17, right?
[4574.30s -> 4577.06s]  And then, you know, which is okay,
[4577.06s -> 4578.34s]  because unlink freed this inode,
[4578.34s -> 4580.68s]  so it doesn't look like a problem yet.
[4581.70s -> 4583.40s]  The point is we're trying to close transaction one.
[4583.40s -> 4584.66s]  So then when the create finishes,
[4584.66s -> 4587.38s]  we close transaction one, and we're gonna write,
[4587.38s -> 4589.06s]  let's say transaction one actually commits,
[4589.06s -> 4591.94s]  we write all of its modifications to disk.
[4591.94s -> 4592.90s]  Fantastic.
[4593.74s -> 4597.14s]  However, supposing after the unlink takes a while,
[4597.14s -> 4600.34s]  it hasn't finished yet, supposing after this commit
[4600.34s -> 4604.42s]  finishes, there's a crash, right?
[4607.12s -> 4608.98s]  When the recovery software runs,
[4608.98s -> 4611.34s]  it's gonna see that transaction one committed
[4612.96s -> 4614.74s]  and that transaction two didn't.
[4614.74s -> 4616.02s]  So the recovery software's gonna just
[4616.02s -> 4617.98s]  completely ignore transaction two.
[4617.98s -> 4621.02s]  So that means the unlink never took place.
[4621.78s -> 4625.38s]  The recovery software won't perform
[4625.38s -> 4627.12s]  the unlink's writes to the disk.
[4627.12s -> 4629.10s]  Therefore, won't free the inode,
[4630.42s -> 4633.46s]  won't delete Y after the crash and recovery Y
[4633.46s -> 4634.74s]  will still exist.
[4634.74s -> 4636.82s]  It'll still be using inode 17.
[4636.82s -> 4639.58s]  However, the creates transaction did complete,
[4639.58s -> 4642.82s]  and therefore X is gonna be using inode 17 as well.
[4642.82s -> 4646.74s]  And so now we mistakenly have two files
[4646.74s -> 4649.22s]  that happen to be using the same inode,
[4649.30s -> 4651.06s]  which means they'll share content or write to one
[4651.06s -> 4655.94s]  will mysteriously show up in the other file,
[4655.94s -> 4658.34s]  which is completely the wrong thing.
[4658.34s -> 4660.78s]  The whole point was when we wanted to unlink Y
[4660.78s -> 4662.56s]  and use a freed inode in X,
[4662.56s -> 4665.02s]  not an inode that was already in use.
[4665.02s -> 4667.50s]  So something's gone terribly wrong here.
[4668.94s -> 4672.94s]  And the one way of thinking about it is that unlink
[4675.54s -> 4678.50s]  in what should have been transaction two wrote a block,
[4678.50s -> 4682.70s]  modified a block, and essentially that modified block
[4682.70s -> 4685.30s]  was used by an earlier transaction.
[4685.30s -> 4687.98s]  So a later transaction modified a block
[4687.98s -> 4691.82s]  and that modified block was seen by an earlier transaction
[4691.82s -> 4696.40s]  and indeed information base on this modification
[4696.40s -> 4700.04s]  from transaction two was incorporated into transaction one.
[4702.34s -> 4705.34s]  But that means that we've lost atomicity here
[4705.34s -> 4708.02s]  because the whole, you know, the goal of this
[4708.54s -> 4710.30s]  was that all of the modifications for the unlink
[4710.30s -> 4713.62s]  should occur or none of them, not just some of them.
[4713.62s -> 4715.10s]  But what's essentially happened here
[4715.10s -> 4718.30s]  is because transaction one committed the free
[4718.30s -> 4722.22s]  of this inode, it means that some of transaction two's
[4722.22s -> 4726.58s]  modifications actually occurred, but others did not.
[4726.58s -> 4731.34s]  We've broken atomicity by including a later transaction's
[4731.34s -> 4733.62s]  write in an earlier transaction.
[4734.98s -> 4737.46s]  You can actually imagine multiple different ways
[4737.90s -> 4739.54s]  of dealing with this, right?
[4740.90s -> 4743.90s]  Maybe CREATE could notice that 17 had been freed
[4743.90s -> 4748.62s]  by a future transaction and not use that inode.
[4748.62s -> 4752.54s]  In fact, EXT3 takes a sort of pretty simple approach
[4752.54s -> 4756.34s]  to this, it doesn't allow any system call to start
[4757.22s -> 4760.58s]  until all system calls from the previous transaction
[4760.58s -> 4764.42s]  have finished, so there's no possibility of a transaction,
[4764.42s -> 4766.70s]  of a system call from transaction one seeing
[4766.70s -> 4770.94s]  a modify, seeing an update from a system call
[4770.94s -> 4772.70s]  in a future transaction.
[4772.70s -> 4776.34s]  Essentially all of the unlink is pushed, is blocked,
[4776.34s -> 4780.06s]  not allowed to start until T1 commits.
[4781.46s -> 4782.74s]  Any questions about this?
[4785.70s -> 4790.70s]  So I have a question about what exactly happens
[4792.18s -> 4794.98s]  when you close an open transaction?
[4794.98s -> 4799.98s]  Does it snapshot the current state of the cache?
[4801.62s -> 4803.86s]  Yes, that's exactly right.
[4803.86s -> 4807.46s]  So when we close this transaction, at least in principle,
[4807.46s -> 4809.78s]  the system makes a copy of all the blocks
[4809.78s -> 4813.02s]  that were modified by system calls in this transaction,
[4813.02s -> 4816.02s]  the logging system makes a copy of them in the cache,
[4816.02s -> 4819.66s]  a sort of private copy just so this transaction
[4819.66s -> 4821.14s]  can commit them.
[4821.14s -> 4823.34s]  And then future transactions execute
[4823.34s -> 4825.78s]  sort of on the real cached blocks,
[4825.78s -> 4828.66s]  this transaction commits from its private copy
[4828.66s -> 4830.70s]  of the blocks it modified.
[4830.70s -> 4832.50s]  And then when it's done committing those,
[4832.50s -> 4834.74s]  its private copy of those blocks to disk,
[4834.74s -> 4836.50s]  you can throw those copies away.
[4842.30s -> 4843.14s]  Yes.
[4845.66s -> 4850.66s]  Okay, it turns out this is one of about half a dozen
[4851.66s -> 4856.10s]  or a dozen sort of similar little quirks
[4856.10s -> 4858.38s]  that ext3 has to deal with
[4858.38s -> 4861.66s]  because in order to support concurrency,
[4861.66s -> 4865.50s]  there's a whole bunch of kind of similar little ordering
[4865.50s -> 4868.38s]  niggles that have to be the sort of special cases
[4868.38s -> 4870.06s]  that ext3 has to get right,
[4872.34s -> 4874.38s]  which we don't have time to talk about.
[4874.38s -> 4876.94s]  But the take home points that I want people to remember
[4876.94s -> 4879.66s]  about logging and about ext3,
[4879.70s -> 4883.58s]  first, just the general point that what logs are all about
[4883.58s -> 4886.10s]  is making multi-step disk updates,
[4886.10s -> 4889.06s]  atomic all or nothing with respect to crashes.
[4889.06s -> 4892.18s]  Like, that's the main thing to remember about logging.
[4893.46s -> 4895.26s]  The logging, the correctness of logging
[4895.26s -> 4896.90s]  depends on this right ahead rule.
[4896.90s -> 4898.94s]  That's another critical thing to remember.
[4898.94s -> 4902.42s]  You'll hear right ahead log and right ahead rule a lot
[4902.42s -> 4905.46s]  in the kind of crash recovery business.
[4905.46s -> 4908.50s]  And the right ahead rule says that you have to commit
[4908.50s -> 4911.74s]  all changes to the log before you're allowed to make
[4911.74s -> 4914.86s]  any of the modifications to the home locations
[4914.86s -> 4915.94s]  in the file system.
[4917.86s -> 4920.38s]  And recovery absolutely relies on this rule.
[4921.98s -> 4924.82s]  A lot of the point, at least for file systems,
[4924.82s -> 4928.82s]  a lot of the point of logging is simply fast recovery.
[4928.82s -> 4930.98s]  The log may have a couple hundred blocks in it.
[4930.98s -> 4932.58s]  You can replay a couple hundred blocks
[4932.58s -> 4934.78s]  in way under a second.
[4934.78s -> 4937.26s]  And then boom, your file system,
[4937.26s -> 4940.90s]  even a very large one is now fit for use.
[4940.90s -> 4943.10s]  And a final point for sort of more detailed point
[4943.10s -> 4945.90s]  about the XD3 is that it uses batching and concurrency
[4945.90s -> 4950.90s]  to get considerably better performance than XV6 does,
[4951.02s -> 4956.02s]  although at the case of considerably higher complexity
[4956.82s -> 4959.46s]  to support concurrency than XV6 had.
[4961.94s -> 4963.22s]  And that's all for today.
[4963.22s -> 4965.58s]  I'm happy to take questions.
[4968.26s -> 4973.10s]  Hi, I had another question it's about,
[4973.10s -> 4978.10s]  so you said that things that there's a file,
[4978.34s -> 4981.70s]  like a file system thread that does all this stuff.
[4981.70s -> 4985.22s]  There must be only one of this threads
[4985.22s -> 4989.34s]  because otherwise it could do basically
[4989.34s -> 4991.10s]  what you just talked about, right?
[4994.38s -> 4996.70s]  It may indeed be that there's just one.
[4996.74s -> 4998.90s]  I actually don't know how many there are.
[4998.90s -> 5002.10s]  One is certainly a particularly attractive number
[5002.10s -> 5005.34s]  because a lot of the rationale
[5005.34s -> 5006.66s]  for why the logging is correct
[5006.66s -> 5009.46s]  is that the older transactions
[5009.46s -> 5012.78s]  are committed before newer transactions.
[5013.90s -> 5016.26s]  I don't think it's a logical necessity
[5016.26s -> 5019.62s]  that there'd be only one thread though.
[5019.62s -> 5024.22s]  You could imagine old transactions
[5024.22s -> 5026.58s]  committing in an overlapped way,
[5027.70s -> 5030.06s]  essentially using multiple threads,
[5031.18s -> 5032.46s]  one for each transaction.
[5033.50s -> 5035.34s]  Oh, okay, I see.
[5035.34s -> 5036.50s]  Yeah.
[5036.50s -> 5037.38s]  Okay, I see.
[5038.58s -> 5040.02s]  I have a quick question.
[5040.02s -> 5042.26s]  In when you're talking about crashes
[5042.26s -> 5046.14s]  and you had that diagram of T8 rewriting T5
[5047.46s -> 5048.58s]  that was being freed.
[5049.58s -> 5054.58s]  Um, so what happens if T8 hasn't actually committed
[5055.10s -> 5057.38s]  at the point of the crash?
[5057.38s -> 5060.14s]  Because there could be maybe T5,
[5060.14s -> 5064.34s]  if it's being freed as something needs to rewrite it,
[5064.34s -> 5067.78s]  then there could be a commit block from T5 that exists
[5069.66s -> 5071.38s]  in maybe a location where T8
[5071.38s -> 5073.94s]  would have predicted it to exist.
[5073.94s -> 5076.46s]  And then couldn't that inaccurately represent
[5076.50s -> 5079.14s]  that T8 had actually been committed?
[5079.14s -> 5082.18s]  Okay, so let me try to draw out this scenario.
[5082.18s -> 5083.42s]  Yeah.
[5083.42s -> 5087.42s]  So we have this ancient transaction T5, right?
[5091.98s -> 5095.18s]  And maybe a T6, who cares?
[5095.18s -> 5098.82s]  And then we're wrapped around a T8
[5098.82s -> 5100.66s]  and T8 started somewhere.
[5100.66s -> 5103.62s]  Now it's because T5 is freed,
[5103.66s -> 5106.66s]  and T8 is starting to eat up T5.
[5110.78s -> 5114.90s]  That is the end of T8 is overrun, the beginning of T5.
[5114.90s -> 5116.54s]  Is that okay?
[5116.54s -> 5119.94s]  And the worry is, okay, of course, if T8 did commit,
[5119.94s -> 5121.30s]  then it'll end up in a commit block
[5121.30s -> 5123.78s]  and it'll all look pretty reasonable
[5124.78s -> 5126.34s]  if there's a crash in recovery.
[5126.34s -> 5127.42s]  And the scenario you're worried about
[5127.42s -> 5129.50s]  is that T8 did not commit.
[5129.50s -> 5132.62s]  Right, and maybe it did not commit
[5132.66s -> 5134.74s]  right before writing the commit block.
[5134.74s -> 5137.22s]  Okay, so the juicy, yeah, exactly.
[5137.22s -> 5142.22s]  So T8 just happens to be gonna put its commit block
[5142.86s -> 5146.18s]  in exactly the same place where T5 put its commit block,
[5146.18s -> 5147.90s]  but it didn't quite get the writing the commit block.
[5147.90s -> 5152.06s]  It's all good, except we have a totally correct T8,
[5152.06s -> 5154.38s]  but it's T5's commit block.
[5154.38s -> 5155.62s]  Yeah.
[5155.62s -> 5156.70s]  And you're wondering, gosh,
[5156.70s -> 5158.38s]  it looks just like a commit block.
[5158.38s -> 5161.90s]  Okay, the answer is that the descriptor blocks
[5162.02s -> 5163.42s]  and commit blocks, as well as everything else,
[5163.42s -> 5165.74s]  have the sequence number of the transaction.
[5165.74s -> 5168.74s]  So this descriptor block has an eight in it,
[5170.26s -> 5174.10s]  but T5's commit descriptor, doesn't matter,
[5174.10s -> 5177.10s]  but T5's commit block has a five in it.
[5177.10s -> 5178.42s]  Okay, yeah, that makes sense.
[5178.42s -> 5180.10s]  And so, yeah, it's looking for eight
[5180.10s -> 5181.66s]  as well as the magic number.
[5181.66s -> 5182.78s]  Cool. Good question.
[5184.78s -> 5186.06s]  Wait, but in this case,
[5186.06s -> 5189.38s]  wouldn't you also have the descriptor block of T5?
[5189.38s -> 5192.26s]  So you don't really need the numbers.
[5194.34s -> 5196.18s]  Well, in this particular case,
[5196.18s -> 5200.30s]  so yeah, T5 used to have a descriptor block here
[5200.30s -> 5201.54s]  with a five in it.
[5201.54s -> 5205.66s]  However, T8 is so large that T8 over wrote
[5205.66s -> 5210.14s]  this descriptor block with one of its own data blocks.
[5210.14s -> 5212.98s]  So that T5 descriptor block's now gone
[5212.98s -> 5216.18s]  and been replaced by a T8 data block.
[5216.18s -> 5218.70s]  So yeah, it used to be evidence for transaction five,
[5218.86s -> 5220.30s]  but now it's gone.
[5224.10s -> 5226.70s]  So do we know the size of transaction eight
[5226.70s -> 5228.18s]  before we started?
[5240.82s -> 5242.58s]  Sorry, this is a complex question.
[5244.94s -> 5247.02s]  It's probably the case that,
[5249.26s -> 5254.26s]  okay, when T8 was opened as the active transaction
[5254.54s -> 5256.22s]  that system calls were writing into,
[5256.22s -> 5257.38s]  at that point in time,
[5257.38s -> 5260.10s]  the system didn't know how big T8 was going to be.
[5261.02s -> 5264.38s]  When the system starts committing T8,
[5264.38s -> 5269.38s]  it does know how big T8 is.
[5270.06s -> 5272.30s]  The system doesn't start committing T8
[5272.30s -> 5273.98s]  until after T8 is closed
[5273.98s -> 5276.90s]  and all of its system calls are finished.
[5276.90s -> 5278.54s]  And at that point, the system knows.
[5279.38s -> 5280.62s]  I mean, it saw all the writes that were done,
[5280.62s -> 5282.54s]  you know, all the writes for T8 have completed,
[5282.54s -> 5283.62s]  all the system calls are completed,
[5283.62s -> 5285.42s]  so the system knows how big it is.
[5286.30s -> 5288.58s]  And one reason why that must be
[5288.58s -> 5291.46s]  is that the descriptor block holds
[5291.46s -> 5294.06s]  the complete list of blocks in that transaction.
[5294.06s -> 5295.74s]  And so at the time the descriptor block was written,
[5295.74s -> 5297.42s]  which was its first,
[5297.42s -> 5299.18s]  the logging system knew how many blocks
[5299.18s -> 5301.22s]  that were gonna be in T8.
[5303.66s -> 5304.62s]  Yeah.
[5304.62s -> 5306.34s]  Oh, okay, I see, I see.
[5306.34s -> 5307.18s]  Thank you.
[5309.54s -> 5313.26s]  Why don't we just kind of like have the commit information
[5313.26s -> 5316.66s]  in the descriptor block and avoid this kind of problem?
[5316.66s -> 5319.62s]  Because I know it's not great that we have to go back
[5319.62s -> 5322.18s]  and like ride back to a location,
[5322.18s -> 5325.74s]  like not in sequence, but wouldn't that help?
[5325.74s -> 5327.38s]  Okay, so the proposal is that
[5327.38s -> 5329.14s]  instead of having a commit block,
[5330.90s -> 5332.46s]  we basically have the descriptor block act
[5332.46s -> 5333.74s]  as a commit block.
[5333.74s -> 5336.70s]  And XV6 actually is very much like this.
[5339.54s -> 5341.10s]  And you know, you could do it.
[5343.94s -> 5346.58s]  And in fact, I think you can do it without,
[5346.58s -> 5350.38s]  at least in EXC3 without sacrificing efficiency.
[5350.38s -> 5352.22s]  However, you have to play the same,
[5352.22s -> 5353.90s]  you have to structure this in the same way
[5353.90s -> 5355.78s]  that XV6 does, namely,
[5359.82s -> 5361.06s]  if there's a, you know,
[5361.06s -> 5362.54s]  there have to be something in the descriptor block
[5362.54s -> 5365.46s]  that indicates this is a committed transaction.
[5365.50s -> 5368.82s]  And we're not allowed to set whatever that flag is
[5368.82s -> 5371.78s]  until after all of the data blocks have been written.
[5371.78s -> 5373.42s]  So the routine would have to be,
[5373.42s -> 5375.90s]  we don't write the commit block first.
[5375.90s -> 5377.34s]  Instead, we write all the data blocks
[5377.34s -> 5379.02s]  for transaction age first.
[5379.02s -> 5381.70s]  And then we go back and write the commit block
[5381.70s -> 5385.46s]  with the block numbers or the descriptor block,
[5385.46s -> 5388.70s]  whatever it is now, and some kind of magic.
[5388.70s -> 5391.82s]  This is really a committed transaction.
[5391.82s -> 5393.26s]  So we could write all the data blocks
[5393.30s -> 5395.42s]  and then go back and write the commit block,
[5395.42s -> 5399.14s]  the descriptor commit block, whatever.
[5399.14s -> 5400.18s]  I don't know any,
[5402.18s -> 5405.06s]  I don't know any reason why this couldn't be made to work.
[5406.66s -> 5408.22s]  It, I don't think it,
[5410.26s -> 5412.54s]  it doesn't, I don't think it really eliminates
[5412.54s -> 5414.42s]  any of the problems we've discussed
[5414.42s -> 5416.94s]  because we still have this problem, you know,
[5416.94s -> 5419.62s]  the original problem was, gosh, how do we distinguish,
[5419.62s -> 5420.82s]  you know, this commit block,
[5420.82s -> 5423.70s]  this stale commit block from transaction five
[5423.70s -> 5425.98s]  from a true commit block for transaction eight?
[5425.98s -> 5427.86s]  We're gonna have the same problem here.
[5427.86s -> 5430.86s]  You know, this, it could be that what's sitting here,
[5430.86s -> 5433.18s]  you know, just happens to be the descriptor block
[5433.18s -> 5435.54s]  from transaction five.
[5435.54s -> 5436.90s]  And so, you know, maybe we've gone ahead
[5436.90s -> 5438.70s]  and written all the data blocks for transaction eight
[5438.70s -> 5440.18s]  and then there was a crash.
[5440.18s -> 5441.86s]  The recovery software still needs to be able
[5441.86s -> 5443.58s]  to tell the difference between,
[5444.50s -> 5446.22s]  to be able to look at this descriptor block
[5446.22s -> 5448.18s]  and say, wait a minute,
[5448.18s -> 5449.78s]  you know, there's something wrong here.
[5449.78s -> 5452.02s]  Even though this looks like a valid descriptor block,
[5452.02s -> 5453.54s]  it's not really.
[5453.54s -> 5456.02s]  And so we'd still have to have the magic number
[5456.02s -> 5459.02s]  and the transaction number, the sequence number.
[5460.54s -> 5461.78s]  Oh yeah, that makes sense.
[5461.78s -> 5463.78s]  Yeah, I was just thinking like we'd have,
[5463.78s -> 5465.66s]  we kind of have like the commit part
[5465.66s -> 5466.66s]  in the descriptor block,
[5466.66s -> 5468.62s]  but obviously like when we start T8,
[5468.62s -> 5471.02s]  we write the descriptor block saying it's uncommitted,
[5471.02s -> 5472.18s]  then we write the data blocks,
[5472.18s -> 5475.70s]  then we say it's a committed descriptor block now.
[5475.70s -> 5478.58s]  The thing that could be saved here is the expense
[5478.58s -> 5480.30s]  of waiting for these writes
[5480.30s -> 5482.78s]  and then writing a commit block, right?
[5482.78s -> 5484.38s]  That wait is quite expensive.
[5484.38s -> 5486.14s]  We're not allowed to start the write of the commit block
[5486.14s -> 5489.02s]  until the data blocks are on the disk.
[5489.02s -> 5492.46s]  And I don't think,
[5492.46s -> 5494.82s]  we have to have the same wait before we,
[5494.82s -> 5497.66s]  in the sort of new single block scheme,
[5497.66s -> 5499.90s]  we have to have the same wait
[5499.90s -> 5502.34s]  before we're allowed to write this new descriptor block.
[5502.34s -> 5504.86s]  So it saves a block, but it doesn't save a,
[5504.86s -> 5506.66s]  I don't think it would save much time.
[5507.50s -> 5512.50s]  The trick that later versions of the Linux file system play
[5513.14s -> 5516.22s]  that sort of does do what I think you're hoping for,
[5518.06s -> 5521.22s]  you know, the, this is sort of looking into the,
[5521.22s -> 5524.42s]  you know, ext4 does the following
[5524.42s -> 5527.02s]  for better efficiency of writing the commit blocks.
[5528.82s -> 5533.82s]  It, ext4 will write out all the data blocks
[5534.22s -> 5536.70s]  and the commit block at the same time.
[5537.90s -> 5540.94s]  That is, it doesn't wait for the data block writes
[5540.94s -> 5542.70s]  to finish before it writes the commit block.
[5542.70s -> 5545.22s]  So it doesn't have this long pause.
[5545.22s -> 5547.30s]  But then there's this terrible issue
[5547.30s -> 5548.74s]  of what happens if the disk, you know,
[5548.74s -> 5551.26s]  the disk is free to do writes out of order.
[5551.26s -> 5554.38s]  What if the disk writes the commit block first
[5554.38s -> 5557.26s]  before it actually performs the writes for the data blocks
[5557.26s -> 5558.10s]  and then there's a crash.
[5558.10s -> 5559.42s]  Then we have a commit block
[5559.42s -> 5562.22s]  without the disk ever having written the data blocks.
[5562.26s -> 5564.34s]  And the way ext4 solves that
[5567.06s -> 5572.06s]  is it has a checksum in the commit block,
[5572.14s -> 5574.58s]  over a checksum over all the data blocks.
[5576.26s -> 5578.66s]  And so if there's a crash happens
[5578.66s -> 5579.94s]  after the commit block was written,
[5579.94s -> 5581.22s]  but before the data blocks were written,
[5581.22s -> 5583.36s]  the checksum won't work out.
[5583.36s -> 5584.98s]  The recovery software will look at this checksum
[5584.98s -> 5587.02s]  and then it'll compute the checksum over the data blocks
[5587.02s -> 5588.68s]  that are actually in the log.
[5588.68s -> 5589.52s]  If they're not the same,
[5589.52s -> 5591.62s]  it knows that something went wrong.
[5591.86s -> 5595.76s]  And so by doing this ext4 basically saves,
[5595.76s -> 5596.60s]  on a mechanical drive,
[5596.60s -> 5600.94s]  saves an entire rotation that would happen
[5600.94s -> 5604.30s]  if it had to wait for the data blocks before it commits.
[5606.86s -> 5608.26s]  Okay, thanks.
[5608.26s -> 5609.10s]  Sure.
[5613.84s -> 5615.34s]  Oh, that's cool.
[5618.38s -> 5619.50s]  I love this stuff.
[5620.14s -> 5622.56s]  This is very cool.
[5623.50s -> 5625.78s]  I wanted to ask also about the data blocks,
[5625.78s -> 5628.30s]  just the content blocks.
[5628.30s -> 5629.78s]  So I think I got confused,
[5629.78s -> 5633.10s]  but where in the steps that we were talking about
[5634.32s -> 5636.40s]  on your, one of your previous boards,
[5636.40s -> 5638.72s]  where would that be done?
[5639.98s -> 5641.34s]  Where would which be done?
[5641.34s -> 5644.42s]  So like not the metadata blocks,
[5644.42s -> 5646.50s]  but the actual-
[5646.50s -> 5648.18s]  File content.
[5648.18s -> 5649.02s]  Yeah.
[5649.46s -> 5651.02s]  Okay, this is a,
[5651.02s -> 5654.12s]  there's sort of multiple answers to this.
[5654.12s -> 5654.96s]  In,
[5657.58s -> 5660.98s]  ext3 has multiple modes
[5664.14s -> 5665.64s]  for what happens to the data blocks.
[5665.64s -> 5669.44s]  I think there's three, two of which I remember.
[5670.84s -> 5672.54s]  There's journaled data
[5675.62s -> 5677.08s]  and ordered data.
[5678.08s -> 5681.64s]  And when you configure an ext3 file system,
[5681.64s -> 5683.68s]  you tell Linux which you want.
[5686.42s -> 5689.64s]  If you ask for journaled data,
[5689.64s -> 5691.64s]  then file content just goes right into the log.
[5691.64s -> 5692.84s]  There's nothing special going on.
[5692.84s -> 5695.36s]  If you write data to a file,
[5695.36s -> 5697.58s]  you know, and that causes the inode to be updated,
[5697.58s -> 5700.64s]  then the log is gonna contain your data
[5700.64s -> 5702.30s]  and the updated inode.
[5703.76s -> 5706.56s]  You know, everything gets modified, goes in the log.
[5708.04s -> 5708.88s]  So that's journaled data.
[5708.88s -> 5710.04s]  But of course it's quite slow,
[5710.04s -> 5711.28s]  or slower than you might hope,
[5711.28s -> 5715.56s]  because, you know,
[5715.56s -> 5717.68s]  now if you write a whole bunch of data,
[5717.68s -> 5719.14s]  it has to be written once to the log
[5719.14s -> 5720.92s]  and then a second time to the home location.
[5720.92s -> 5722.36s]  So the journaled data scheme
[5722.36s -> 5725.98s]  is sort of straightforward, but slow.
[5728.32s -> 5730.84s]  Then there's this other ordered data scheme,
[5730.84s -> 5733.50s]  the people, it's actually the most popular mode,
[5734.50s -> 5738.36s]  that doesn't write the data to the log.
[5738.36s -> 5739.74s]  In the ordered data scheme,
[5739.74s -> 5742.74s]  only metadata like inodes and directory blocks
[5742.74s -> 5744.04s]  are written to the log.
[5744.04s -> 5747.10s]  And file content block is just written directly
[5747.10s -> 5749.20s]  to the home locations in the file system.
[5750.34s -> 5751.62s]  And so it's a lot faster,
[5751.62s -> 5755.40s]  because you don't have to write the file content twice.
[5755.40s -> 5756.94s]  It does lead to more complexity though,
[5756.94s -> 5761.94s]  because if you,
[5762.18s -> 5765.94s]  you can't just write the file data anytime you want,
[5765.94s -> 5767.66s]  because then there's a risk that,
[5769.42s -> 5770.86s]  if you don't worry about the order
[5770.86s -> 5773.38s]  in which you write the inodes versus the file data,
[5773.38s -> 5777.12s]  there's the risk that you might do a write
[5777.12s -> 5780.16s]  that causes a new block to be allocated for a file,
[5781.02s -> 5785.18s]  and have the updated inode be written into the log
[5785.18s -> 5787.42s]  and committed, and then have a crash happen
[5787.42s -> 5789.44s]  before you get around to writing
[5789.44s -> 5791.74s]  the actual file content to the disk.
[5792.38s -> 5793.82s]  And then after recovery,
[5793.82s -> 5795.86s]  what you would see is the inode
[5795.86s -> 5798.38s]  with the newly allocated data block,
[5798.38s -> 5801.06s]  but the old contents of that data block
[5801.06s -> 5804.44s]  from whatever file previously used that data block.
[5805.54s -> 5807.38s]  And so if you're running a system
[5807.38s -> 5809.82s]  that has multiple users, like an Athena system,
[5809.82s -> 5811.70s]  then it could be that one user
[5811.70s -> 5814.74s]  will end up having a file that contains contents
[5814.74s -> 5817.62s]  from another user's deleted file,
[5817.62s -> 5819.12s]  if we're not careful about the order
[5819.12s -> 5823.00s]  in which we write the data versus the inodes.
[5825.60s -> 5828.64s]  AEXT3 ordered data mode solves this
[5828.64s -> 5833.00s]  by not committing the modified inode
[5833.00s -> 5837.04s]  until after the file content has been written to disk.
[5837.04s -> 5839.72s]  So if you're an application and you write to a file,
[5839.72s -> 5843.04s]  and that write causes a new block to be allocated,
[5843.04s -> 5846.40s]  the file system will write the new file content
[5846.40s -> 5848.08s]  to the newly allocated block,
[5848.08s -> 5849.72s]  and once that write is finished,
[5849.72s -> 5852.32s]  only then will it commit the transaction
[5853.84s -> 5856.38s]  that causes the inode to be updated
[5856.38s -> 5857.72s]  to have the new block number.
[5857.72s -> 5860.28s]  And that means that a crash,
[5860.28s -> 5861.76s]  if there's a crash that's gonna be happening
[5861.76s -> 5863.40s]  between when you wrote the data,
[5863.40s -> 5864.32s]  or after you wrote the data,
[5864.32s -> 5865.80s]  and before you wrote the inode,
[5865.80s -> 5870.80s]  therefore won't reveal somebody else's old deleted data block
[5871.24s -> 5872.64s]  to the new user file.
[5872.64s -> 5877.64s]  Okay, I see.
[5877.64s -> 5878.48s]  Okay, I see.
[5878.48s -> 5882.28s]  But it could still have the data, but not the inode.
[5882.28s -> 5883.58s]  Yeah, you might allocate,
[5885.28s -> 5887.64s]  if there's a crash after you wrote the data block,
[5887.64s -> 5888.84s]  before you wrote the inode,
[5888.84s -> 5891.12s]  then you'll have updated the data block,
[5891.12s -> 5892.00s]  but it doesn't matter,
[5892.00s -> 5894.40s]  because not only did you not write the inode,
[5894.40s -> 5898.60s]  you also didn't write the updated block,
[5898.60s -> 5899.80s]  free bitmap block,
[5899.80s -> 5901.36s]  and so that block will still be free
[5901.36s -> 5903.16s]  and can be allocated for something else,
[5903.16s -> 5904.76s]  so you don't even lose a block.
[5905.76s -> 5908.00s]  All right, and if it was an old block,
[5908.00s -> 5910.84s]  then it's still okay, right?
[5910.84s -> 5911.96s]  Say that again.
[5911.96s -> 5915.12s]  If it was just the same block,
[5915.12s -> 5917.04s]  it just writes some new data to it,
[5917.04s -> 5922.04s]  but same block, same size, same location.
[5923.92s -> 5925.48s]  But we already wrote,
[5925.48s -> 5927.72s]  like it's not that we created a new block,
[5927.72s -> 5929.92s]  but in the old block,
[5929.92s -> 5932.12s]  we just wrote some extra data,
[5932.12s -> 5933.36s]  but it was a little bit,
[5933.36s -> 5935.26s]  so it didn't need to create a new one.
[5936.32s -> 5937.24s]  Yeah, we wrote data.
[5937.24s -> 5940.20s]  We ended up writing data to a block
[5940.20s -> 5941.96s]  that was not in use by any file.
[5942.84s -> 5945.04s]  So it's not visible.
[5945.04s -> 5945.86s]  Right.
[5945.86s -> 5946.70s]  Okay, I see.
[5946.70s -> 5948.16s]  Thank you.
[5948.16s -> 5949.00s]  Goodbye.
