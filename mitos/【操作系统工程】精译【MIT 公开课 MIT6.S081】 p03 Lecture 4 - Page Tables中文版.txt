# Detected language: en (p=1.00)

[0.00s -> 12.00s]  Sound check. Can everybody hear me?
[12.00s -> 23.52s]  All good. Okay. So welcome to the next lecture in SO81. Wherever you are. I hope that the
[23.52s -> 28.96s]  folks in the West Coast or in Florida and Alabama do okay, given all the terrible
[28.96s -> 37.44s]  circumstances there. So the topic for today is virtual memory. Particularly, we're going
[37.44s -> 42.24s]  to talk about page tables. We'll return to this topic a few times. There will be multiple
[42.24s -> 48.40s]  political memory lectures. And maybe just to start off and get our question and answer going again,
[50.48s -> 55.44s]  I would like to ask you a little bit, what do you remember about virtual memory from
[55.44s -> 63.52s]  004 maybe and or 603 if you've taken that. I'll tell you my own sort of view on virtual memory,
[63.52s -> 67.52s]  which is why I took it to where I first heard about it or learned about it as a student.
[67.52s -> 72.00s]  I thought it was pretty straightforward. How hard can it be? It's a table that maps
[72.00s -> 76.48s]  virtual addresses to physical addresses. Now, maybe a little more complicated, but
[77.44s -> 82.32s]  not that complicated. And only when you start programming with it, I should really have learned
[82.32s -> 92.08s]  that from memory is tricky and fascinating and very powerful. And so hopefully in the next
[92.08s -> 98.00s]  couple of lectures and the next couple of labs, you'll appreciate virtual memory from
[98.00s -> 102.96s]  that perspective. We will ask you a couple of people here that are online, what do you remember
[103.68s -> 109.36s]  about virtual memory from either 004 or 603 if you've taken it. And again, I'm just going to
[109.36s -> 116.24s]  call out some names and share your memories about Adela Yang.
[121.60s -> 126.80s]  Sorry, what was the question? What do you remember about virtual memory from maybe
[126.80s -> 134.00s]  004 or 603 if you've taken that. It uses like offset to save on like
[134.80s -> 138.16s]  remembering virtual address to physical address mappings.
[139.92s -> 143.20s]  Okay. How about Abrams Gondera?
[148.32s -> 149.60s]  Abrams, are you online?
[151.44s -> 158.40s]  Yeah. My memory is that it uses like it's a way of one protecting the physical hardware
[158.40s -> 164.72s]  by kind of a user-grown representation of it. And then yeah, you just have like some virtual
[164.72s -> 170.80s]  address things like at least in 004 just like 12 bits that maps to some physical address
[171.92s -> 174.56s]  that's usually I think 16 bits or 64 bits.
[178.16s -> 181.36s]  Okay. How about Vivek Pandit?
[181.36s -> 193.12s]  What I remember was you can have each process has a separate address space and
[195.36s -> 199.44s]  the memory management unit or I mean some other technique can be used to map
[200.48s -> 204.88s]  the virtual addresses of the address space of each of the processes to the physical
[205.52s -> 214.48s]  physical address. And the virtual address, the lower bits are kind of the same so that
[215.52s -> 220.00s]  the mapping is in blocks which helps with performance.
[222.64s -> 223.28s]  Wesley Ru.
[228.16s -> 232.56s]  Yeah, I guess what I remember most is that virtual
[232.56s -> 239.12s]  addressing allows us to protect the physical addresses from each process.
[239.84s -> 245.44s]  And we can use some like clever manipulations so that the bits that correspond to the physical
[245.44s -> 248.96s]  address can be used somehow in the virtual addresses as well.
[251.28s -> 252.16s]  Wilson Spearman.
[257.20s -> 262.00s]  Yeah, I remember it's really fundamental to isolation because every process can basically
[262.64s -> 266.40s]  pretend that it has its own set of memory to use.
[268.40s -> 271.84s]  Yeah, good, good. Well, so clearly, that's awesome.
[273.04s -> 277.52s]  So clear two things here, correct? One is, you know, there's some form of mapping
[278.40s -> 281.12s]  and that mapping is helpful in sort of achieving isolation.
[281.92s -> 286.48s]  This is exactly the reason we're talking about virtual memory, you know, isolation.
[287.20s -> 291.76s]  So what we'll see is that in the next, you know, the next couple of lectures,
[291.76s -> 293.84s]  in particular when you start programming your virtual memory,
[294.72s -> 298.24s]  really get an in-depth understanding of what its power is.
[299.76s -> 303.52s]  And so to get a sense of that, you know, this is the first lecture and mostly focusing
[303.52s -> 309.44s]  on the mechanisms for virtual memory. And then later we can see how we can use
[309.44s -> 311.68s]  these mechanisms to achieve, you know, cool tricks.
[312.88s -> 318.16s]  So the topic for today or the agenda for today, the plan is sort of threefold.
[319.04s -> 323.12s]  First, I'm going to talk about address spaces, as some of you mentioned in your,
[324.56s -> 330.16s]  just in the, just mentioned, just briefly mentioned in response to this question.
[331.28s -> 334.00s]  Then I'm going to talk about the paging hardware, or paging hardware.
[335.28s -> 338.48s]  And I'm going to focus, of course, on the paging hardware of the RISC-V.
[340.32s -> 341.92s]  But basically every processor,
[342.48s -> 346.96s]  a modern processor has some form of paging hardware.
[346.96s -> 353.76s]  That's sort of the, if you will, the default mechanism for actually supporting virtual memory.
[354.48s -> 362.88s]  And then the last part of the lecture is going to walk through some XP6 virtual memory code and
[364.64s -> 369.92s]  layout of, you know, the kernel address space and user address spaces.
[370.88s -> 372.48s]  So that's the main plan.
[376.48s -> 382.56s]  Okay, so I guess, you know, a number of you mentioned in the response to this question,
[382.56s -> 389.44s]  you know, one driving reason to have virtual memory is because you can use it to achieve
[389.44s -> 394.16s]  isolation. If you set up the page tables correctly and program them correctly, then
[394.16s -> 399.28s]  you can in principle achieve strong isolation. And so let's just remind those again, you know,
[399.28s -> 403.52s]  what we want with from isolation, let's just say, you know, our standard picture,
[403.52s -> 408.24s]  we have some user applications like Shell, you know, CAT, you know, all the util
[408.24s -> 414.56s]  things that you've built in lab one. And, you know, we have the kernel or,
[414.56s -> 418.64s]  you know, kernel sitting alone through the operating system or sitting in kernel space.
[419.52s -> 425.60s]  And, you know, what we like to do is sort of have, you know, boxes around these
[426.40s -> 432.96s]  applications so that they can really affect each other. And similarly, you know, we want them to
[432.96s -> 437.68s]  be completely sort of independent of the kernel in the operating system so that like if an
[437.68s -> 442.72s]  application does something either accidentally bad or maliciously bad, then it doesn't really
[442.72s -> 449.44s]  affect the operating system. So that's our goal. And the particular aspect of the problem
[449.44s -> 455.12s]  that we want to focus on today is the memory side of things. So we really want to focus on
[455.12s -> 462.48s]  memory isolation. And by default, you know, if we don't do anything, you know, we don't really
[462.48s -> 466.96s]  have memory isolation, right? Because if you think about it, you know, there's going to be one,
[466.96s -> 470.96s]  you know, the RISC-V board that I showed you last week, you know, has like a memory,
[470.96s -> 477.28s]  a bunch of DRAM chips. And in the DRAM chips, you know, the code for these applications
[478.56s -> 484.88s]  is stored somewhere in the memory is the kernel, you know, text and data stack everything.
[484.88s -> 490.64s]  Somewhere in memory is the shell if the shell is running. Somewhere in memory is the KET program.
[492.80s -> 496.40s]  And so there's one sort of physical memory, you know, starting from some address zero to,
[496.40s -> 500.96s]  you know, some, you know, big address, you know, depending on how much memory we have,
[500.96s -> 505.44s]  really have in our machine. And in that physical memory, all these programs must be present,
[505.44s -> 509.36s]  you know, otherwise, you know, the processor can't even execute their instructions.
[510.24s -> 514.72s]  And so about the RISC, you know, clearly here is that let's say, you know,
[514.72s -> 518.16s]  let's make it a little bit, you know, simplistic, but let's say, you know, the shell,
[518.16s -> 524.88s]  you know, sits for that address zero to address 200, or 2000, from 1000 to 2000.
[526.00s -> 532.48s]  And let's say, you know, the, you know, whatever cat has a program error, it loads, you know,
[532.48s -> 540.56s]  in a register a zero, let's say it loads 1000, the address basically corresponding to the start
[540.56s -> 546.40s]  of the shell. And then, you know, by accident, you know, executes the instruction, you know,
[546.40s -> 554.16s]  dollar seven, a zero, right, which has the effect of the basically it writes the value seven
[554.16s -> 558.64s]  to the address, you know, 1000. And so and then it would be scribbling over, you know,
[559.12s -> 564.00s]  basically the memory image that belongs to the shell. And so that would be, you know,
[564.00s -> 571.52s]  certainly not, that certainly would break isolation and be quite undesirable. And so, you know,
[571.52s -> 575.68s]  we want something that basically really separates these memories from the different programs from
[575.68s -> 581.36s]  each other so that things like that just cannot happen. So one way, you know, to do that
[581.76s -> 586.00s]  is an idea that's typically called address spaces.
[592.80s -> 598.56s]  And the basic idea is straightforward. What we want to do is basically give every
[598.56s -> 604.72s]  application, including the kernel, its own address space. And so we can think about this,
[604.72s -> 610.16s]  like we just kept running, you know, it has an address space starting at zero, you know,
[610.16s -> 614.56s]  to whatever some maximum value, you know, there's a shell run has an address space,
[614.56s -> 620.00s]  its own address space, also starting at address zero, and going through some value, you know,
[620.00s -> 627.60s]  the kernel has its own address space, OS has its own address space. And so one example,
[627.60s -> 631.36s]  when kept, you know, refers to really, we go back to our, you know, the example of the
[631.36s -> 640.96s]  previous slide where we did whatever store seven to, you know, a zero. And let's say in a zero,
[640.96s -> 645.36s]  there's the value of 1000. You know, if cat, you know, executes an instruction,
[646.24s -> 652.64s]  will write to the address 1000, but it's its own address 1000. It's not, you know, the address
[652.64s -> 658.16s]  of the 1000 of the shell. So basically, every program runs with its own address space,
[658.16s -> 663.36s]  that's its own value. And those address spaces are completely independent. You know,
[663.36s -> 668.88s]  in this notion of different address spaces, cat doesn't really have an ability to even refer
[668.88s -> 676.24s]  to an address that actually belongs to the shell. And so that's sort of the game that
[676.24s -> 680.00s]  were the end goal that we'd like to achieve, because it's going to provide us with strong
[680.00s -> 684.48s]  isolation, because, you know, it's just not possible for cat to refer to any other memory
[684.48s -> 691.36s]  that is not, you know, its own. And so our goal now is to basically sort of figure out how to
[691.36s -> 697.44s]  multiplex, if you will, all these different address spaces on a single physical memory,
[697.44s -> 701.52s]  because in the end, we only have one DRAM chips, where, you know,
[701.52s -> 711.20s]  or RAM chips where the memory is located. And so that's our plan. Okay, yeah, Amir,
[711.20s -> 712.16s]  you have a question. Go ahead.
[714.48s -> 721.68s]  Yeah, so I'm wondering, in the configuration of the physical hardware, there's only so much space.
[722.48s -> 726.80s]  And in the virtual memory layout, there's also a max virtual address.
[728.08s -> 731.92s]  By design is the virtual address made to be small enough?
[732.72s -> 737.44s]  I know that it no, not necessarily, you know, the virtual address space could be bigger than
[737.44s -> 740.48s]  the physical memory, the physical memory could be bigger than the virtual address space.
[741.36s -> 744.72s]  And we'll see in a second how that all can happen. And it's actually one of the, you know,
[744.72s -> 749.28s]  cool parts about, as you will see with page tables, that's extremely flexible.
[750.48s -> 757.20s]  So is it is it possible that, like, the physical memory gets exhausted? Because
[757.20s -> 760.16s]  so many processes use up all their virtual space?
[760.16s -> 764.96s]  Yeah, that's certainly possible. And we'll see in a second how, for example, you know,
[764.96s -> 769.28s]  you have a bunch of big applications that each have big page tables, and they allocate a lot
[769.28s -> 771.12s]  of memory, you know, so you can run out of memory.
[772.16s -> 772.96s]  I see. Thanks.
[772.96s -> 776.96s]  And so where does this show up in xv6? Anybody?
[780.80s -> 786.56s]  You sort of touched on it a little bit in the Cisco lab that you're currently doing.
[789.60s -> 790.80s]  Where are pages allocated?
[790.80s -> 799.92s]  Where, if you do the Cisco lab and you finished it, you know,
[799.92s -> 803.28s]  one part of the fiscal lab is printing how much free memory there is.
[806.00s -> 807.12s]  Kalloc?
[807.12s -> 810.56s]  Yeah, Kalloc, right. So Kalloc has a list of free pages.
[810.56s -> 815.12s]  If that list of free pages is empty, or runs out at some point, then, you know,
[815.12s -> 819.52s]  Kalloc is going to return a null pointer. And hopefully the operating system does something
[819.52s -> 822.96s]  sensible and that basically propagates back to the user application saying like,
[822.96s -> 826.88s]  well, you know, no more memory for you or no more memory in total for nobody.
[829.28s -> 834.48s]  Okay. And it's the job of the OS to handle those cases gracefully,
[834.48s -> 838.24s]  where gracefully generally means, you know, propagating an error message to the user application.
[838.24s -> 849.76s]  Okay, good. So how do we implement these address spaces?
[850.40s -> 854.24s]  You know, how to basically multiplex all these address spaces across a single physical memory.
[854.80s -> 860.80s]  And the most common approach and a very flexible approach is to use page tables.
[860.80s -> 871.84s]  And the idea is, and this is a hardware support. So this is implemented in hardware
[871.84s -> 877.20s]  by the processor or by a unit called the memory management unit. And so the picture that you sort
[877.20s -> 882.32s]  of should have in your head is, you know, yeah, the CPU that executes instructions,
[882.40s -> 884.48s]  like whatever our, you know,
[887.12s -> 895.04s]  our store instruction that was, you know, putting $7 into a0 indirect.
[895.84s -> 900.48s]  So it executes those kinds of instructions. And, you know, when it executes one of the store
[900.48s -> 904.00s]  instruction, load instruction, or whatever, anything that actually has an address,
[904.00s -> 908.00s]  you know, that address, we're going to think about as a virtual address. So it's not a
[908.00s -> 912.96s]  physical address, it's a virtual address. And so, for example, the value in a0 that we're using
[912.96s -> 921.28s]  here, say that's 1000, 0x, you know, 1000, that is a virtual address. And a virtual address
[921.28s -> 925.76s]  is basically routed through something what's called the memory management unit.
[930.08s -> 937.44s]  And the memory management unit translates it into a physical address. And that physical address,
[937.44s -> 942.96s]  then, you know, is actually used to index into memory, and load whatever value or
[943.76s -> 949.84s]  store whatever value needs to be written there. And so the CPU from the CPU point of view,
[949.84s -> 955.76s]  it always issues every instruction that it issues. Once the MMU is enabled, our virtual
[955.76s -> 960.88s]  addresses. And to translate these virtual addresses, the physical addresses, basically,
[960.96s -> 967.52s]  the MMU has a table. And, you know, the virtual address on one side, physical address on one side,
[967.52s -> 974.16s]  and the other side, for example, here is, you know, our entry for 1000. And maybe that maps to
[974.16s -> 980.40s]  whatever, you know, 0x, whatever, you're making something up with like some big value,
[981.04s -> 984.72s]  you know, somewhere in physical memory. So there's a mapping between virtual and physical
[985.52s -> 991.04s]  is quite flexible. So on one side, we have the virtual address on the other side of the physical
[991.04s -> 997.84s]  addresses. Typically, you know, this this mapping itself is also stored in memory.
[998.40s -> 1006.32s]  And so the CPU has some register that basically points to that contains the physical address
[1006.32s -> 1012.08s]  of where the page table is stored. So somewhere in the basically the page table or this map
[1012.08s -> 1018.48s]  somewhere stored in physical memory, let's say, you know, whatever, you know, address 10. And
[1018.48s -> 1026.08s]  basically this register, which is called on the RISC-V, SATP, you know, stores the address 10.
[1026.08s -> 1032.08s]  And so that the CPU can tell the memory management unit where to find, you know,
[1032.08s -> 1039.44s]  basically the map to actually translate virtual to physical addresses. And then the basic idea
[1039.44s -> 1048.08s]  is to give every application its own map. So CAD is going to have its map. So every map
[1050.24s -> 1055.20s]  its own. Yeah. Vivek, go ahead.
[1057.68s -> 1067.36s]  So the MMU, you said, it doesn't necessarily store the mapping. So does it just do
[1067.36s -> 1072.88s]  the translation? Like it will read the memory and do the translation, but not necessarily
[1074.00s -> 1077.68s]  store the mappings? That's exactly the right picture that you should have in your head.
[1080.88s -> 1086.96s]  And with every map, okay, so the map itself is stored in memory, the MMU just basically walks
[1086.96s -> 1090.32s]  or looks up into the map. And we'll see in a second that, you know, this map is slightly
[1090.32s -> 1098.56s]  more complicated than what you're drawing here. So every app has its own map,
[1100.56s -> 1106.64s]  right? And that map basically defines its address space. And so when the CPU or when
[1106.64s -> 1111.04s]  the operating system switches the CPU from one process or from one application to another
[1111.04s -> 1119.44s]  application, it also switches the content of this SATP register to store the root of the map
[1119.44s -> 1124.72s]  of the appropriate process. And so in that way, basically, you know, multiple applications
[1124.72s -> 1129.36s]  can run on the CPU every time we switch between from one application to the next application,
[1129.36s -> 1135.60s]  we also switch the SATP register to point to the appropriate map for that application.
[1135.60s -> 1143.36s]  And in that way, basically, the virtual addresses for CAD are translated differently than the
[1143.36s -> 1147.76s]  virtual addresses for the shell because, you know, each one of them has their own map.
[1150.40s -> 1151.04s]  That make sense?
[1154.72s -> 1163.12s]  Okay, so the way this is the basic plan and the way I've drawn or explained it so far
[1163.12s -> 1167.76s]  is pretty naive and unreasonable. Yeah, David, go ahead.
[1169.04s -> 1179.20s]  I'm sorry. So you said the SATP register gets modified for the process. I am guessing the value
[1180.00s -> 1184.80s]  for the SATP register for each process is stored by the kernel?
[1184.80s -> 1189.04s]  Yes, yes, the kernel is writing the SATP register. In fact, writing or reading,
[1189.84s -> 1195.52s]  particularly writing the SATP register is a privilege instruction. So the user application
[1195.52s -> 1200.16s]  cannot just update the page map register and say like, I want to run with this page map now,
[1200.88s -> 1206.64s]  because that would violate isolation. So it's only the kernel only coding kernel
[1206.80s -> 1209.60s]  can actually update it. I see.
[1212.00s -> 1216.00s]  Okay, so as I said, this picture is pretty naive. You know, one thing I haven't really
[1216.00s -> 1222.32s]  said anything about how this actually map works. And, you know, the way I've drawn out
[1222.32s -> 1226.64s]  seems to indicate, you know, basically for every virtual address, you have an entry in the map.
[1228.16s -> 1230.64s]  And if you do that, how big would the map be?
[1230.64s -> 1234.40s]  On RISC-V?
[1240.64s -> 1247.76s]  Anybody? How many addresses are there on the RISC-V in principle? Or how big,
[1247.76s -> 1249.68s]  how many addresses go to a register store?
[1250.64s -> 1257.68s]  The registers are 64-bit wide. So how many addresses?
[1260.72s -> 1264.88s]  Anybody? I know I'm insulting your intelligence by asking these questions.
[1268.32s -> 1270.72s]  We have some answers in the chat, like 2 to the 64.
[1270.72s -> 1275.68s]  Ah, I didn't see the chat, sorry. Yeah, 2 to the 64. Let's see if I can actually pop up the
[1275.68s -> 1283.04s]  chat so I can see it. Yeah, 2 to the 64. Thank you.
[1285.20s -> 1292.08s]  All right, so this table would be gigantic. In fact, all memory would be consumed by just
[1292.08s -> 1296.48s]  having that table. So that seems unreadable. And so, in fact, you know, that's not how
[1296.48s -> 1301.20s]  things work. In fact, I'm going to go in two steps to actually how it actually works in the
[1301.20s -> 1309.52s]  RISC-V. So step one is, you know, don't play the game per address, but do it per page.
[1312.80s -> 1318.32s]  So you translate a page at a time, and the page on the RISC-V is 4 kilobytes,
[1320.08s -> 1326.80s]  which is 4,096 bytes. And this is pretty common. Almost all processors, you know,
[1326.80s -> 1330.80s]  use roughly page size of 4 kilobytes or support a page size of 4 kilobytes.
[1331.60s -> 1336.16s]  And so now, again, translation works slightly differently. So if here we have our virtual address
[1337.52s -> 1344.32s]  and basically we split it in two pieces, an index and an offset. And so the offset
[1344.32s -> 1350.72s]  is basically the byte within the page. And so when we do, when the MMU does the translation,
[1350.72s -> 1357.68s]  it takes the index, indexes into the map. That gives you, you know, some physical page number,
[1358.56s -> 1365.36s]  in memory. And that physical page number that points to some physical page of 4,096 bytes.
[1366.32s -> 1371.76s]  And then the offset part basically indexes into that physical page. So, for example,
[1371.76s -> 1380.40s]  the offset is, you know, 12. Then, you know, the 12th entry of that page is actually
[1381.20s -> 1388.16s]  used. A lot of you people, a lot of you answered this in the, mentioned it in response to the
[1388.16s -> 1393.12s]  question that there's always some scheme of like taking an offset and adding that to the
[1393.12s -> 1400.96s]  base of the page to obtain the actual memory, physical memory location where a value is stored
[1400.96s -> 1406.88s]  or where value will be loaded to. And one of the interesting things about the RISC-V is,
[1406.88s -> 1413.04s]  and this is in response to some of the questions that somebody asked earlier, the physical or the
[1413.04s -> 1419.28s]  virtual addresses are 64 bits, which makes totally sense, correct, because the RISC-V is
[1419.28s -> 1427.76s]  64-bit register. But in fact, on the RISC-V processor that we're using, not all the 64
[1427.76s -> 1435.76s]  bits actually used, namely the top 25 are actually not used at all. And so that limits
[1435.76s -> 1440.72s]  the size of a virtual address, right, that limits the size of a virtual address space to 2 to the power
[1440.72s -> 1457.52s]  39, which is roughly 512 gigabytes. And so, of course, you know, later versions of the processor
[1457.52s -> 1461.76s]  might support bigger address spaces if that isn't necessary, and that could then be done. And so
[1461.84s -> 1466.72s]  for example, some of those 25 bits that are basically unused, you know, could be used to
[1467.52s -> 1474.64s]  build bigger virtual address spaces. And so in the index in that, you know, where 39 bits left,
[1474.64s -> 1480.88s]  you know, as the virtual address, 27 bits are indexed, and we'll see in a second why they're 27,
[1482.24s -> 1489.04s]  are indexed, and then the 12 are offset. And, you know, they have to be 12, right, because 2 to
[1489.04s -> 1497.60s]  the power 12 is, you know, 4,096. All right, so that's virtual addresses. On the RISC-V
[1497.60s -> 1501.12s]  physical addresses, as you can see here, are actually 56 bits wide.
[1506.08s -> 1511.12s]  So the physical memory, you know, can be bigger than the single virtual address space,
[1512.08s -> 1516.16s]  but it's limited to the power of 56. And most boards probably, you know,
[1516.16s -> 1521.20s]  they don't support 2 to the power of 56 physical memory, because there's a gigantic amount of
[1521.20s -> 1526.40s]  physical memory, but in principle, a board could, you know, if you could manufacture it,
[1526.96s -> 1532.64s]  support 2 to the power of 56 for physical memory. And so in this scheme, then if you do 56
[1533.44s -> 1538.00s]  bits for the physical address, 44 are basically the physical page number, the PPN,
[1538.00s -> 1542.64s]  and 12 again are the offset that are inherited directly from the virtual address.
[1542.64s -> 1545.84s]  Does that all make sense?
[1548.80s -> 1553.36s]  So I'm going to stop for a second here, so you collect your thoughts. The other point I
[1553.36s -> 1560.24s]  wanted to make here is that this material is important, so just ask questions, the details
[1560.24s -> 1565.44s]  matter, and it will be a large part of, you know, you really need to understand all this stuff
[1566.00s -> 1572.32s]  to be able to basically do the next lab, the page table lab. Yeah, Amir, go ahead, please.
[1573.44s -> 1576.72s]  If you can go back one slide, the screen is unclear.
[1579.04s -> 1582.56s]  Which one, the page table slide? Yeah.
[1588.40s -> 1594.96s]  This one? No, the most recent one, but it also doesn't really matter. Yeah, this is perfect,
[1594.96s -> 1602.00s]  thank you. So I'm wondering, this 4096 byte range, which we've called a page,
[1602.56s -> 1608.08s]  is that assigned as a continuous chunk in memory? Yes, there's a continuous physical,
[1608.08s -> 1616.00s]  you know, continuous range of 4096 bytes in memory. I see, and then...
[1616.80s -> 1624.16s]  The map had a granularity of 4,596 bytes. Okay, and then 12, the offset,
[1624.88s -> 1630.00s]  like 2 to the 12 is 4,096, so that's sufficient to cover each of the chunks? Yeah,
[1630.64s -> 1637.76s]  each byte in the page. And where does the 56 come from in the diagram? I could follow
[1638.32s -> 1642.72s]  up until then, but I didn't get where that came from. The designers crooked up,
[1643.36s -> 1646.56s]  so the hardware designers decide how big, you know, a physical address is,
[1647.12s -> 1652.96s]  basically for whatever board they want to design. And so the RISC-V designers
[1653.68s -> 1656.64s]  decided that 56-bit physical addresses were a good idea.
[1659.12s -> 1663.04s]  And presumably the way they come up with these numbers is they look at technology trends
[1663.76s -> 1667.28s]  and say like, well, we want to be able for the next sort of five years, you know,
[1667.28s -> 1671.68s]  we don't want to predict that physical memory will be ever bigger than 2 to the power of 56.
[1672.88s -> 1676.40s]  And probably they're thinking it won't be bigger than, you know, something much smaller, but then,
[1676.40s -> 1680.48s]  you know, give them some leeway, you know, in case, you know, their prediction is wrong,
[1681.36s -> 1688.08s]  they pick a slightly bigger number. Does that make sense? Yeah, thanks. Yeah,
[1688.08s -> 1694.32s]  a lot of people ask about this. Anybody else who raised their hand? I think there's a bunch
[1694.32s -> 1698.72s]  of people asking questions, and unfortunately my Zoom doesn't show, it's more than two people
[1698.80s -> 1701.12s]  raise hands, it's just multiple people are raising their hand.
[1701.92s -> 1704.00s]  So please jump in if you have a question.
[1708.48s -> 1716.64s]  Okay, if not, I have a question. Yeah, go ahead. So if the virtual memory is up to
[1716.64s -> 1723.20s]  2 to the power of 27 and the physical memory is up to the power 2 to the 56, right, so
[1724.00s -> 1731.60s]  we could have multiple processes that could exhaust all their virtual memories without
[1732.32s -> 1735.36s]  using up all the physical memory, right? That's correct.
[1740.40s -> 1747.92s]  That's actually correct. Okay, I have a question too. Yeah, go ahead. So this 56
[1747.92s -> 1754.00s]  for the physical address, is that the number of possible memory locations?
[1754.72s -> 1758.88s]  I don't think it's the number of bits, right, because this is a 64-bit machine.
[1759.92s -> 1766.88s]  That 56 could go up to 64, but they just chose it to have just 56. That's correct.
[1766.88s -> 1770.96s]  That's correct, and one way to think about it, then they only have to run 56 wires on the
[1770.96s -> 1775.12s]  board as opposed to 64. I see, I see.
[1778.56s -> 1785.52s]  Okay, I also have a question. So kind of, could you go back one slide maybe?
[1785.52s -> 1793.84s]  Yep. So from the CPU, we go through the MMU and then to the memory.
[1794.80s -> 1802.48s]  But where, where here is the distinction for different processes? Because like each process,
[1802.48s -> 1810.80s]  like process, like the shell process has something at address like 0x1000 and then the LS process
[1810.80s -> 1816.48s]  also has something at address 0x1000, so we need to translate those to different physical,
[1817.36s -> 1825.44s]  so the SAP register contains the register, contains the address of which map to use.
[1826.64s -> 1830.96s]  So LS runs with zone map, you know, cat runs with zone map.
[1830.96s -> 1835.04s]  Okay, so, so each process will have its completely own map.
[1835.04s -> 1837.20s]  Yep. Makes sense. Thank you.
[1837.84s -> 1844.08s]  And in fact, there's a great leeway to the next point. So if every process has its own map,
[1845.04s -> 1848.16s]  you know, how big is this map like that I've drawn here?
[1849.04s -> 1852.40s]  Well, that map is two to the power of 27 entries, correct?
[1855.04s -> 1860.24s]  And that's pretty big. And that would fill physical memory reasonable quickly
[1860.24s -> 1864.88s]  if every process exactly had a complete, you know, populated map, right?
[1864.88s -> 1868.32s]  Then there's gigantic, you know, means that every process is very big.
[1868.32s -> 1873.20s]  And so in fact, this is not the way the hardware actually stores page tables.
[1873.28s -> 1877.36s]  You know, you can think about it conceptually as an array, you know, going from 0 to 2 to the
[1877.36s -> 1882.40s]  power of 27, but actually is not what happens in practice. In practice, it's a multi-level
[1883.28s -> 1886.00s]  structure. And here is actually the real RISC-V
[1889.12s -> 1893.68s]  page table structure and what the hardware implements.
[1895.04s -> 1901.92s]  And so what happens with the 27 bits that we saw earlier, the index, it's actually split in
[1902.48s -> 1912.56s]  three 9-bit numbers. And the first, the top 9 bits are used to index into the top-level page table
[1913.36s -> 1916.80s]  directory as they are called. And so in one directory, you know,
[1916.80s -> 1923.60s]  one of these guys, you know, is 496 bytes, 4,096 bytes, just like a page size.
[1924.96s -> 1929.92s]  A PTE entry, one of these entries in the thing is 64 bytes.
[1931.92s -> 1936.56s]  64 bits, I mean, sorry, like the register, so 8 bytes.
[1937.20s -> 1939.92s]  And so there's going to mean that if you do 496
[1940.88s -> 1946.24s]  divided by 8, it means there are 512 entries in one of those directory pages.
[1947.60s -> 1952.88s]  So basically what happens is the SAPP points to the top root directory.
[1952.88s -> 1958.32s]  We take the top-level 9 bits, index into the page directory, and that gives us a new
[1958.32s -> 1964.24s]  physical page number. And that physical page number is the page directory for the next level.
[1964.24s -> 1971.12s]  So then we use the next level index to index into that page directory and then, you know,
[1971.12s -> 1976.00s]  and so forth, you know, we like the final one, you know, we get the bottom-level page directory
[1976.00s -> 1980.64s]  and that basically gives us the entry that maps the virtual address to a physical address.
[1983.84s -> 1987.44s]  So in some sense, it's very similar to what I showed you in the previous slide,
[1987.44s -> 1991.12s]  except, you know, basically the index happens in three steps instead of one step.
[1991.12s -> 1994.64s]  And this is the advantage, the main advantage of the scheme is that then
[1994.64s -> 1997.60s]  if large parts of the address space are not being used,
[1997.60s -> 1999.84s]  you don't have to have any page table entries for them.
[2001.04s -> 2003.52s]  As an example, let's say you have an address space
[2004.48s -> 2007.84s]  that has only one page, like the bottom page.
[2007.84s -> 2013.76s]  There's 4,096 and no other pages are in the address space.
[2013.76s -> 2017.68s]  So only addresses zero to 4,096 are actually mapped.
[2017.68s -> 2022.96s]  How many page table entry or page table directors do you need to map that particular page?
[2027.52s -> 2033.28s]  Well, you need one at the top, correct? And you need basically value in that entry for zero.
[2034.72s -> 2037.60s]  The top-level nine bits, you know, of zero over zero.
[2037.60s -> 2042.96s]  So you need an entry for zero. So that means you need one middle-level entry,
[2042.96s -> 2047.12s]  you know, that basically corresponds to the next, you know, nine zero bits,
[2047.12s -> 2049.52s]  and then one entry for the next nine zero bits.
[2050.32s -> 2055.12s]  And so basically we get away with three page directories.
[2059.60s -> 2062.00s]  And in our previous scheme, on the previous slide,
[2062.00s -> 2064.64s]  correct, we have two to the power of 27 entries.
[2064.64s -> 2068.56s]  And now we're basically have to have three times whatever 512 entries and we're done.
[2068.56s -> 2074.88s]  And that's the main reason why, you know, the actual hardware
[2074.88s -> 2078.96s]  has this hierarchical or multi-level tree scheme.
[2080.80s -> 2085.44s]  Any questions about this because it's pretty important? Samir, go ahead.
[2088.08s -> 2095.84s]  So my question is, since the PPN number from each page table is 44 bits,
[2096.72s -> 2102.16s]  and the second, say the middle table resides on the virtual memory,
[2102.16s -> 2104.48s]  where do we get the missing 12 bits from?
[2105.76s -> 2110.40s]  The final 12 bits? Okay, so you're saying these 44, correct?
[2111.20s -> 2111.68s]  Yes.
[2111.68s -> 2115.28s]  What is going on with that? Well, all page directories are page aligned.
[2116.40s -> 2123.84s]  And so basically their physical page number is 44 plus the 12 zero bits.
[2125.84s -> 2130.00s]  And so what actually happens if we look at these PTE entries,
[2130.00s -> 2132.16s]  you know, they're all have the same sort of form, correct?
[2132.16s -> 2137.60s]  If you look at one of these guys, they're 44 bits, they're 12 bits zeros,
[2137.60s -> 2143.36s]  so that gives us a 44 plus 12 is 56, so that gives us a physical address, correct?
[2145.44s -> 2149.60s]  And so that means in these 64 bits, there's actually some bits left
[2149.60s -> 2152.96s]  that are not being used. And in fact, the bottom 12 bits will basically,
[2152.96s -> 2156.40s]  or the bottom 10 would definitely, the bottom bits are not years ago.
[2156.40s -> 2161.60s]  And in fact, the paging hardware stores there are a bunch of flags
[2161.60s -> 2165.20s]  that control the translation, and we'll talk about those flags in a second.
[2167.68s -> 2170.16s]  But they're there to control the translation,
[2170.16s -> 2172.32s]  and they are stored basically in the bottom 10 bits.
[2173.52s -> 2176.24s]  And it also means, correct, that, you know, if you add these two up,
[2176.24s -> 2181.04s]  that's 54 bits, basically there's 10 bits left that are unused.
[2181.12s -> 2184.40s]  And those 10 bits are again, you know, for future growth.
[2184.96s -> 2188.16s]  So at some point, you might have a new type of RISC-V processor
[2188.16s -> 2191.04s]  that will have slightly different structured page tables,
[2191.04s -> 2195.04s]  and it might actually have bigger than 44 bits for the physical page number.
[2197.68s -> 2198.24s]  Okay, thank you.
[2199.60s -> 2200.96s]  And in fact, you know, you can see it here,
[2200.96s -> 2203.84s]  like if you look at a single entry, correct, that's drawn here,
[2204.72s -> 2209.12s]  you know, there are basically 10 bits left that are not being used.
[2211.04s -> 2214.48s]  Okay, so let's look at the flags for a second, because that's sort of important.
[2215.84s -> 2220.24s]  So every translation in the bottom 10 bits, there are a bunch of flags stored.
[2220.24s -> 2222.88s]  And the first flag is valid.
[2223.76s -> 2227.84s]  And if the valid bit is set, that means this is a valid PTE,
[2228.40s -> 2230.16s]  and you can use it for translation.
[2231.44s -> 2237.04s]  And so we're looking for a little example that I used here with three page directories,
[2237.04s -> 2238.88s]  where only entry zero is used,
[2238.88s -> 2241.68s]  then only entry zero will have the valid bit set,
[2241.68s -> 2245.20s]  and none of the other five and 11 entries will not have the valid bit set.
[2246.72s -> 2250.16s]  And that basically tells the MMU, well, you know,
[2250.16s -> 2252.40s]  you don't have to change down this PTE,
[2252.40s -> 2254.72s]  this PTE just contains no valid information.
[2256.24s -> 2260.56s]  Then R means, you know, you're allowed to read from that page.
[2260.56s -> 2263.52s]  Write means you're allowed to write to that page.
[2263.52s -> 2266.96s]  Execute means you're allowed to execute instructions from it.
[2267.60s -> 2274.32s]  And user means, you know, this page is also accessible by a process running in user space.
[2275.44s -> 2277.28s]  And then the other bits, you know, not that important,
[2277.28s -> 2278.40s]  they all show up at some point,
[2279.12s -> 2280.80s]  but those are sort of the five important bits.
[2284.08s -> 2284.96s]  Does it all make sense?
[2287.52s -> 2288.02s]  Yeah.
[2289.92s -> 2292.72s]  Nithya, I probably mispronounced your name.
[2292.72s -> 2293.52s]  I apologize.
[2295.04s -> 2296.64s]  That's the right pronunciation.
[2296.64s -> 2297.14s]  Thank you.
[2297.92s -> 2301.60s]  I had a quick question about the three page tables.
[2301.60s -> 2302.10s]  Yeah.
[2302.16s -> 2306.56s]  So how are the addresses, or like the PPN values,
[2306.56s -> 2308.80s]  combined to form the final physical address?
[2308.80s -> 2310.00s]  I might have missed that.
[2310.56s -> 2313.36s]  I may have not said it very explicitly.
[2314.16s -> 2316.56s]  So the first PPN, correct, in the top of the page,
[2317.52s -> 2320.64s]  the first PPN in the top level of the page directory
[2320.64s -> 2325.12s]  contains the physical address of the next level down, right?
[2326.00s -> 2328.64s]  And that one contains the one next level down.
[2328.64s -> 2332.64s]  And then in the final one, we still have our Q44 bits,
[2332.64s -> 2335.12s]  that contains then the actual physical address
[2335.12s -> 2337.36s]  off the page that we're actually trying to translate to.
[2338.32s -> 2339.04s]  Ah, okay.
[2339.04s -> 2340.00s]  That makes sense.
[2340.00s -> 2340.40s]  Thank you.
[2340.40s -> 2340.72s]  Okay.
[2340.72s -> 2343.04s]  And one interesting question, just as a side note,
[2343.04s -> 2345.60s]  before, let me answer this, my own question
[2345.60s -> 2347.60s]  before answering the two raised hands here.
[2348.80s -> 2349.84s]  Look back at this picture.
[2350.56s -> 2353.76s]  Why are the physical page numbers stored in these page directories?
[2356.08s -> 2357.84s]  Why not a virtual address?
[2359.76s -> 2362.00s]  Because we need to look it up in memory,
[2362.00s -> 2364.32s]  like look up the next directory in memory.
[2364.32s -> 2365.04s]  Yeah, right.
[2365.04s -> 2367.36s]  We could not have, you know, our translation scheme
[2367.36s -> 2369.12s]  depend on yet another translation scheme.
[2369.12s -> 2369.92s]  You know, we could sort of,
[2369.92s -> 2371.12s]  and it occurs to be intended to look.
[2371.12s -> 2372.72s]  So this just doesn't make sense.
[2372.72s -> 2374.48s]  That is exactly the right answer.
[2374.48s -> 2375.84s]  It has to be a physical number.
[2375.84s -> 2376.88s]  How about the SATP?
[2376.88s -> 2378.08s]  What do you use the SATP?
[2378.08s -> 2378.80s]  What does it store?
[2378.80s -> 2380.80s]  Does it store a physical address or a virtual address?
[2385.12s -> 2390.56s]  Also physical, assuming that the first page directory
[2390.56s -> 2391.84s]  is also in memory, right?
[2391.84s -> 2393.60s]  Yeah, yeah, exactly.
[2393.60s -> 2394.96s]  So it has to be a physical number
[2394.96s -> 2397.12s]  because we're actually trying to use it for translation.
[2398.40s -> 2401.28s]  And so, you know, the SATP needs to know
[2401.28s -> 2402.64s]  what the physical page number is
[2403.36s -> 2405.36s]  or the root of the page directory.
[2407.36s -> 2408.64s]  Okay, there were two other questions
[2408.64s -> 2410.40s]  or two people who raised their hands.
[2410.40s -> 2418.08s]  Could you repeat your question if it hasn't been answered yet?
[2419.04s -> 2422.00s]  So there's a hierarchy of three tables
[2422.56s -> 2426.24s]  and each of them is indexed by a part of the virtual address,
[2426.24s -> 2427.84s]  each nine bits long.
[2430.96s -> 2436.32s]  So I'm not sure I understand how chaining between them happens
[2436.32s -> 2437.76s]  and what it's meant to accomplish.
[2437.92s -> 2440.56s]  Shouldn't it be sufficient to just use those three
[2441.44s -> 2443.44s]  nine-bit addresses to index into each of them?
[2444.96s -> 2445.52s]  That's correct.
[2445.52s -> 2448.48s]  So the top level nine bits are used to index
[2448.48s -> 2450.48s]  in the first page-level directory,
[2450.48s -> 2451.92s]  the second in the next one,
[2451.92s -> 2453.04s]  and the third in the third one.
[2456.56s -> 2459.28s]  So maybe I'm just not understanding this correctly.
[2459.28s -> 2464.24s]  So when a process requests a certain virtual address
[2464.24s -> 2465.44s]  to be looked up,
[2465.44s -> 2469.36s]  it loads into the SATP register or the CPU does
[2469.36s -> 2474.80s]  and that gets the corresponding correct highest-level page table.
[2474.80s -> 2475.30s]  Yeah.
[2475.84s -> 2479.20s]  And then that page table will...
[2480.24s -> 2483.52s]  It will use the top-level nine bits from the 27
[2483.52s -> 2485.12s]  to index into that page directory.
[2486.88s -> 2489.04s]  And then what is the result of that?
[2489.04s -> 2492.00s]  Like if the result is there's nothing there,
[2492.00s -> 2494.80s]  does the MMU create a page table?
[2494.80s -> 2495.52s]  No, no.
[2495.52s -> 2498.00s]  The MMU basically tells the operating system
[2498.00s -> 2498.96s]  or tells the processor,
[2498.96s -> 2500.80s]  sorry, I couldn't translate that address.
[2500.80s -> 2503.84s]  And this turns into a page fault,
[2503.84s -> 2505.20s]  which we'll talk about a little bit later.
[2507.12s -> 2509.44s]  But you just can't not translate the address
[2509.44s -> 2510.48s]  so it doesn't translate it.
[2510.48s -> 2512.24s]  It's like, you know, you can't divide by zero.
[2512.24s -> 2513.60s]  You know, if you try to do that,
[2513.60s -> 2515.28s]  the processor just refuses to do it.
[2518.32s -> 2518.96s]  I see.
[2518.96s -> 2519.46s]  Okay.
[2522.24s -> 2523.84s]  Brandon, more about you, Brandon.
[2524.72s -> 2525.22s]  Yep.
[2525.60s -> 2528.08s]  So I just wanted to make sure I understand how...
[2528.08s -> 2529.84s]  I think maybe we covered this,
[2529.84s -> 2534.16s]  but I want to understand how the kind of intermediate page table,
[2535.28s -> 2537.12s]  how we calculate the physical address of those.
[2538.32s -> 2541.20s]  So is it correct that say if we were trying to find
[2541.20s -> 2543.60s]  a second-level page table's physical address,
[2543.60s -> 2546.96s]  we would take the PPN from the first-level page table,
[2546.96s -> 2548.32s]  that's 44 bits,
[2548.40s -> 2551.60s]  and then we add the 12-bit offset from the original virtual address
[2551.60s -> 2553.84s]  to get the full 56-bit physical address?
[2554.56s -> 2556.56s]  We don't add the offset from the virtual address.
[2556.56s -> 2558.08s]  We just take 12 zero bits.
[2559.12s -> 2561.04s]  So we take the PPN, there's 44 bits,
[2562.64s -> 2564.24s]  12 zero bits in the bottom,
[2564.24s -> 2566.80s]  and that gives us a 56-bit physical address,
[2566.80s -> 2568.56s]  and that's where the next page directory is.
[2568.56s -> 2571.36s]  And this requires that basically every page directory is page aligned.
[2573.76s -> 2574.56s]  I see.
[2574.56s -> 2575.44s]  Okay, that makes sense.
[2575.44s -> 2579.04s]  So these are all great questions,
[2579.04s -> 2581.60s]  and these are all things you're going to be struggling with in the page table lab.
[2581.60s -> 2583.92s]  So it's very good to ask them right now.
[2588.24s -> 2589.92s]  Okay, let me see.
[2592.64s -> 2594.80s]  Yes, okay.
[2594.80s -> 2601.92s]  Let me hold on for a second and collect my thoughts and see where I am.
[2602.32s -> 2605.68s]  Good, good, good.
[2605.68s -> 2608.72s]  Okay, one sort of, you know,
[2608.72s -> 2610.40s]  one other thing that I want to mention,
[2611.12s -> 2612.24s]  because you will see that,
[2613.52s -> 2617.36s]  is that if you think about this, you know, the scheme that I just showed,
[2617.36s -> 2619.36s]  right, what really seems to be going on
[2619.36s -> 2622.64s]  is that when you load or store a value to memory,
[2622.64s -> 2624.96s]  or the processor loads or stores a value to memory,
[2624.96s -> 2627.52s]  we basically have to do three memory lookups, right?
[2627.52s -> 2629.44s]  One in the top-level page directory,
[2629.44s -> 2631.20s]  one in the intermediate page directory,
[2631.20s -> 2633.60s]  and then one in the bottom-level page directory.
[2633.60s -> 2635.12s]  It looks like that, you know,
[2635.12s -> 2637.20s]  any memory reference to a virtual address
[2637.20s -> 2639.68s]  basically requires three memory reads.
[2640.56s -> 2641.84s]  And so that seems expensive.
[2643.12s -> 2645.92s]  And so what happens in practice,
[2645.92s -> 2647.84s]  where almost every processor does this,
[2647.84s -> 2649.76s]  it has a cache sitting on the site
[2649.76s -> 2652.24s]  that contains recently used translations.
[2653.36s -> 2658.96s]  And this is called the translation lookasite buffer.
[2659.92s -> 2663.52s]  And you will see that term quite often,
[2663.52s -> 2665.36s]  and it's called the TLB.
[2666.96s -> 2668.64s]  Basically, it's nothing else than a cache of
[2671.28s -> 2673.20s]  page table entries, PPE entries.
[2676.32s -> 2678.08s]  So when the processor has, you know,
[2678.08s -> 2680.32s]  the first time the processor loads up a virtual address,
[2680.32s -> 2681.20s]  you know, walks this,
[2682.16s -> 2685.04s]  the hardware walks this page,
[2685.04s -> 2686.64s]  the three-level page tables,
[2686.64s -> 2688.00s]  it will come out with, you know,
[2688.00s -> 2691.12s]  the final physical page or the final call PPN
[2691.12s -> 2692.72s]  for that particular virtual address.
[2692.72s -> 2697.20s]  And then basically the TLB stores .vn, .pa, .pn,
[2698.96s -> 2702.16s]  or .pa mapping on the site.
[2702.16s -> 2703.36s]  And so then when the next time
[2703.36s -> 2705.76s]  you refer to that particular virtual address,
[2705.76s -> 2708.32s]  it can just look up straight up in the TLB
[2708.32s -> 2709.84s]  and the TLB will respond
[2709.84s -> 2711.60s]  instead of having to do the page table walk.
[2714.40s -> 2715.20s]  Yep, I'm here.
[2717.20s -> 2722.96s]  So the TLB maps virtual addresses
[2722.96s -> 2725.28s]  to the physical address of the page
[2725.28s -> 2727.04s]  that the virtual address,
[2727.04s -> 2729.44s]  along with the offset maps to, right?
[2730.80s -> 2732.48s]  Wouldn't it be more efficient
[2732.48s -> 2734.72s]  to like cache at the page table level?
[2736.32s -> 2739.36s]  Okay, so let me take a step back here.
[2740.32s -> 2742.08s]  There's many ways of implementing the TLB.
[2743.12s -> 2744.64s]  The most important thing that you need to know
[2744.64s -> 2745.60s]  is that there is a TLB.
[2746.96s -> 2748.88s]  And the exact details of actually
[2748.88s -> 2750.08s]  how the TLB is implemented
[2750.08s -> 2751.28s]  is sort of, you know,
[2751.28s -> 2753.04s]  not a topic that we're going to talk about
[2753.04s -> 2754.08s]  in a great amount of detail.
[2754.80s -> 2755.76s]  In fact, not at all.
[2756.88s -> 2757.92s]  And so this is really something
[2757.92s -> 2759.52s]  that sort of sits inside of the processor
[2759.52s -> 2761.28s]  and is mostly hidden from the operating system.
[2761.28s -> 2762.64s]  The operating system doesn't really know
[2762.64s -> 2763.76s]  how the TLB operates.
[2765.20s -> 2766.72s]  The only thing, the reason you need to know
[2766.72s -> 2768.32s]  that the TLB exists
[2768.32s -> 2770.48s]  is that if you switch page tables,
[2772.08s -> 2774.40s]  then typically the operating system
[2774.48s -> 2776.48s]  needs to tell the processor
[2776.48s -> 2778.00s]  that it's switching page tables
[2779.04s -> 2782.56s]  and the TLB needs to be flushed.
[2785.04s -> 2787.20s]  Because basically you can't use stale entries, right?
[2787.20s -> 2789.12s]  If you switch to a new page table,
[2789.12s -> 2792.00s]  the entries in the TLB may not be valid anymore
[2792.00s -> 2793.76s]  and so they need to be removed
[2793.76s -> 2794.80s]  because otherwise, you know,
[2794.80s -> 2796.24s]  the translation would be incorrect.
[2797.04s -> 2798.64s]  And so the operating system
[2798.64s -> 2803.76s]  is typically aware that there is a TLB
[2803.76s -> 2805.36s]  only basically to tell the hardware
[2805.36s -> 2806.24s]  once in a while saying like,
[2806.24s -> 2807.68s]  okay, well, don't use them anymore
[2808.24s -> 2809.76s]  because I'm going to switch page tables.
[2812.80s -> 2818.00s]  In fact, on the RISC-V,
[2818.00s -> 2819.60s]  the instruction to flush the TLB
[2819.60s -> 2823.12s]  is called sfence underscore VMA.
[2826.00s -> 2829.60s]  That will actually flush the TLB.
[2829.60s -> 2830.10s]  Vivek?
[2830.10s -> 2835.30s]  So I have a question like,
[2835.30s -> 2836.42s]  not regarding TLB,
[2836.42s -> 2839.54s]  but that brought kind of this question.
[2840.34s -> 2842.50s]  The three-level support,
[2842.50s -> 2845.46s]  the three-level paging that we have,
[2846.10s -> 2848.34s]  is it implemented by the operating system
[2848.34s -> 2849.70s]  or the hardware itself?
[2849.70s -> 2850.90s]  It's implemented by the hardware.
[2851.70s -> 2854.02s]  So, you know, this all happens in hardware.
[2854.02s -> 2856.42s]  The MMU is a block of hardware,
[2857.06s -> 2858.50s]  not in the operating system.
[2858.50s -> 2860.02s]  We'll see in a second,
[2860.02s -> 2861.54s]  when we look at XV6,
[2861.54s -> 2863.62s]  that XV6 has a function
[2863.62s -> 2865.30s]  that models the page table walk
[2865.30s -> 2866.34s]  because once in a while,
[2866.34s -> 2868.34s]  you know, SV6 basically has to do
[2868.34s -> 2869.22s]  what the hardware does.
[2870.82s -> 2873.30s]  And so it also does have a function called walk
[2873.30s -> 2875.22s]  that basically does exactly the same thing
[2876.10s -> 2876.90s]  but in software.
[2879.70s -> 2881.30s]  So can I ask a question?
[2882.82s -> 2886.50s]  So where in this scheme
[2886.50s -> 2888.34s]  does the processor cache fit?
[2888.34s -> 2891.38s]  Does it happen before the address translation
[2891.38s -> 2892.02s]  or after?
[2892.82s -> 2893.32s]  Because...
[2893.78s -> 2894.10s]  Yeah, yeah.
[2894.10s -> 2896.18s]  Okay, let me just switch back a little bit.
[2896.18s -> 2896.68s]  A couple...
[2897.78s -> 2898.50s]  Let me see.
[2901.30s -> 2902.66s]  Okay, here's your MMU.
[2902.66s -> 2905.46s]  The way to think about it
[2905.46s -> 2906.50s]  is that all this stuff,
[2908.02s -> 2909.22s]  you know, the whole block
[2909.22s -> 2910.82s]  is inside the processor silicon.
[2912.50s -> 2913.78s]  So there's a RISC-V chip
[2914.42s -> 2916.26s]  and inside of it is the CPU,
[2916.26s -> 2917.46s]  in fact, there are multiple CPU,
[2917.46s -> 2918.90s]  correct, there are four cores
[2918.90s -> 2919.94s]  and there's an MMU
[2920.50s -> 2922.10s]  and, you know, you can think about that
[2922.10s -> 2924.10s]  either on the CPU side,
[2924.10s -> 2925.62s]  you know, there's a TLD.
[2929.54s -> 2930.04s]  Okay?
[2932.58s -> 2933.22s]  That makes sense.
[2934.34s -> 2936.02s]  But I guess my question was about,
[2936.02s -> 2940.26s]  like, cache in terms of not the TLD
[2940.26s -> 2942.18s]  but just normal cache,
[2942.18s -> 2943.54s]  like, because sometimes
[2943.54s -> 2944.66s]  we don't actually go all the way
[2944.66s -> 2945.86s]  to access the memory.
[2946.26s -> 2947.30s]  Yeah, yeah, good point.
[2947.30s -> 2947.94s]  So like I showed,
[2947.94s -> 2949.06s]  like the schema last week,
[2949.06s -> 2951.38s]  correct, Monday of the RISC-V processor,
[2951.38s -> 2952.50s]  it has now one cache,
[2952.50s -> 2953.62s]  it has now two cache.
[2954.66s -> 2956.66s]  Some caches are indexed by physical address
[2957.30s -> 2959.94s]  and some caches are indexed by virtual address.
[2959.94s -> 2961.22s]  So the caches that are indexed
[2961.22s -> 2963.94s]  by virtual address sit before the MMU
[2964.74s -> 2965.86s]  and caches that are indexed
[2965.86s -> 2967.78s]  by physical address sit after the MMU.
[2972.82s -> 2973.46s]  Does that make sense?
[2973.46s -> 2975.30s]  Oh, can I also ask a question?
[2975.30s -> 2975.86s]  Yeah.
[2976.18s -> 2977.06s]  My question is,
[2977.06s -> 2980.02s]  you said that the TLB,
[2980.02s -> 2981.06s]  it walks,
[2981.06s -> 2983.14s]  so like to put stuff into TLB,
[2983.14s -> 2986.42s]  the hardware walks through the page tables.
[2988.10s -> 2990.58s]  Why do we write walk function
[2990.58s -> 2991.70s]  if hardware can do that?
[2992.98s -> 2993.70s]  Very good question.
[2994.90s -> 2995.54s]  One reason,
[2996.26s -> 2996.98s]  there's a couple of reasons
[2996.98s -> 2997.86s]  why we do it
[2997.86s -> 2999.70s]  or why xv6 needs it.
[2999.70s -> 3000.90s]  One is when it actually sets up
[3000.90s -> 3002.02s]  the initial page tables.
[3004.02s -> 3005.30s]  It needs to program
[3005.54s -> 3006.90s]  the three levels
[3006.90s -> 3008.18s]  and so it needs to basically
[3008.18s -> 3009.38s]  emulate the three levels.
[3011.22s -> 3013.30s]  An other example
[3013.30s -> 3015.54s]  that you actually sort of run into
[3015.54s -> 3018.10s]  or are running into in the Cisco lab
[3018.10s -> 3019.38s]  is that when you copy,
[3019.38s -> 3020.82s]  you know, in xv6,
[3020.82s -> 3022.82s]  the kernel has its own page table
[3022.82s -> 3024.58s]  and every user address space
[3024.58s -> 3025.70s]  has its own page table.
[3026.42s -> 3027.62s]  And once in a while,
[3028.26s -> 3029.30s]  for example, in sysinfo,
[3030.18s -> 3031.94s]  the pointer to the sysinfo structure
[3031.94s -> 3033.30s]  that lives in user space,
[3033.86s -> 3035.46s]  the kernel needs to be translated
[3035.46s -> 3036.90s]  to an address that it can use
[3036.90s -> 3037.70s]  to read and write it.
[3038.58s -> 3039.70s]  And so, for example,
[3039.70s -> 3041.38s]  if you're looking copy in
[3041.38s -> 3042.42s]  or copy out,
[3043.46s -> 3046.34s]  basically the kernel translates
[3046.34s -> 3048.34s]  the user virtual address
[3048.34s -> 3052.58s]  using the user page table
[3052.58s -> 3053.94s]  to get out a physical address
[3056.82s -> 3057.70s]  to get an address out
[3057.70s -> 3059.14s]  that actually then the kernel can use
[3059.14s -> 3060.10s]  to read and write that memory.
[3060.10s -> 3063.62s]  So there's a bunch of places
[3063.62s -> 3064.50s]  where this shows up
[3064.50s -> 3065.46s]  and I'll talk about it
[3065.46s -> 3066.34s]  hopefully in, you know,
[3066.34s -> 3067.86s]  whatever, 10 minutes or 15 minutes.
[3068.90s -> 3070.02s]  I have a question.
[3070.02s -> 3072.66s]  Why doesn't the hardware
[3072.66s -> 3074.58s]  like expose that walk function
[3074.58s -> 3075.86s]  so we don't have to write our own
[3075.86s -> 3077.30s]  and like potentially have bugs in it?
[3077.94s -> 3079.70s]  Why isn't there like a, you know,
[3079.70s -> 3080.90s]  maybe a privileged instruction
[3080.90s -> 3082.26s]  that you can pass a virtual address
[3082.26s -> 3083.06s]  and it'll give back
[3083.06s -> 3084.02s]  the physical address?
[3084.58s -> 3085.62s]  Well, this is just like
[3085.62s -> 3086.90s]  just store to the virtual address
[3086.90s -> 3087.38s]  and you get back
[3088.18s -> 3089.38s]  and we'll do it right for you.
[3090.34s -> 3092.26s]  So we'll see later on
[3093.22s -> 3094.90s]  in the next lab,
[3094.90s -> 3096.10s]  the page table app.
[3096.10s -> 3096.98s]  In fact, this is exactly
[3096.98s -> 3097.78s]  what you'll be doing.
[3097.78s -> 3098.82s]  You'll actually set up
[3098.82s -> 3100.42s]  the page table slightly differently
[3100.42s -> 3101.54s]  so that you can avoid
[3101.54s -> 3103.78s]  the walk in copy in
[3103.78s -> 3104.90s]  and copy in string.
[3110.66s -> 3111.86s]  I think this will become clear
[3111.86s -> 3112.66s]  in a second
[3112.66s -> 3113.46s]  when we talk about
[3113.46s -> 3114.74s]  look at the x36, okay?
[3117.94s -> 3118.50s]  Okay, good.
[3120.10s -> 3120.90s]  One more issue.
[3121.46s -> 3123.54s]  Basically, before jumping into x86,
[3123.54s -> 3125.14s]  I wanted to sort of make one point.
[3127.22s -> 3128.10s]  One way to think about
[3131.38s -> 3132.10s]  page tables,
[3134.90s -> 3136.34s]  popular way to phrase this,
[3138.18s -> 3139.22s]  is the page tables
[3139.94s -> 3142.74s]  provide a level of indirection.
[3142.74s -> 3148.10s]  And
[3153.30s -> 3153.80s]  in that,
[3154.66s -> 3155.30s]  and so basically
[3155.30s -> 3156.10s]  this indirection grid,
[3156.10s -> 3157.06s]  what I'm talking about,
[3157.06s -> 3158.26s]  this mapping from virtual address
[3158.26s -> 3159.06s]  to physical address
[3159.70s -> 3160.90s]  and this mapping
[3160.90s -> 3162.34s]  is completely under the control
[3163.30s -> 3164.34s]  of the operating system.
[3166.50s -> 3167.22s]  That's what you've seen
[3168.34s -> 3169.54s]  in the last couple of slides
[3169.54s -> 3170.02s]  that we talked.
[3170.90s -> 3171.62s]  And that means
[3171.70s -> 3173.22s]  that the operating system,
[3173.22s -> 3174.74s]  because it has so much control over,
[3174.74s -> 3176.50s]  it has complete control
[3176.50s -> 3177.30s]  of that translation,
[3178.18s -> 3179.14s]  it can do all kinds
[3179.14s -> 3179.94s]  of interesting tricks.
[3181.46s -> 3182.34s]  And so for example,
[3182.34s -> 3183.22s]  like one trick,
[3183.94s -> 3185.06s]  we talked a little bit about this,
[3185.06s -> 3187.86s]  like if a page entry is invalid
[3187.86s -> 3189.46s]  and will really return a page,
[3189.46s -> 3190.26s]  the hardware will
[3191.38s -> 3192.34s]  raise the page fault.
[3192.98s -> 3194.82s]  In response to the page fault,
[3194.82s -> 3195.54s]  the operating system
[3195.54s -> 3197.30s]  could update the page tables
[3197.30s -> 3198.42s]  and then maybe restart
[3198.42s -> 3199.06s]  the instruction.
[3199.86s -> 3200.82s]  And so there are all kinds
[3200.82s -> 3201.62s]  of things that they can do
[3202.26s -> 3202.98s]  at runtime
[3204.90s -> 3206.58s]  by manipulating the page tables.
[3207.38s -> 3208.58s]  And we're not going
[3208.58s -> 3210.26s]  to talk about that today,
[3210.26s -> 3211.70s]  but in two weeks,
[3211.70s -> 3213.62s]  we'll have a lecture exactly
[3213.62s -> 3214.66s]  sort of about this topic
[3214.66s -> 3216.50s]  about what cool things can you do
[3216.50s -> 3217.70s]  once you have page tables
[3217.70s -> 3218.42s]  and page faults.
[3219.70s -> 3220.34s]  But it's important
[3220.34s -> 3221.06s]  to keep in mind
[3221.86s -> 3222.90s]  that this is
[3222.90s -> 3226.34s]  an incredibly powerful mechanism
[3227.06s -> 3228.18s]  that will provide
[3228.18s -> 3228.98s]  the operating system
[3228.98s -> 3229.94s]  with a tremendous amount
[3230.02s -> 3230.66s]  of flexibility.
[3231.62s -> 3232.66s]  And this is one reason
[3232.66s -> 3233.46s]  why page tables
[3233.46s -> 3234.42s]  are so popular.
[3237.78s -> 3239.62s]  Okay, so what I want to do next
[3239.62s -> 3241.14s]  is actually talk about
[3241.14s -> 3241.78s]  XV6
[3243.54s -> 3244.50s]  and sort of see
[3244.50s -> 3246.10s]  how this all plays out
[3246.10s -> 3247.14s]  in XV6.
[3247.78s -> 3248.42s]  And so the first thing
[3248.42s -> 3248.90s]  I'm going to do
[3249.62s -> 3250.26s]  is I'm going to look
[3250.26s -> 3253.22s]  at the kernel page layout,
[3253.22s -> 3253.78s]  if you will.
[3254.98s -> 3257.14s]  And the mapping
[3257.14s -> 3257.86s]  is on this slide.
[3258.66s -> 3261.46s]  So here's the virtual address space
[3269.06s -> 3269.78s]  of the kernel.
[3271.62s -> 3272.66s]  And here is actually
[3272.66s -> 3273.62s]  the physical memory.
[3273.62s -> 3274.74s]  So this is what basically
[3274.74s -> 3275.54s]  whatever you can think
[3275.54s -> 3276.50s]  about this as DRM.
[3280.02s -> 3280.66s]  And in fact,
[3280.66s -> 3281.30s]  it is not,
[3282.18s -> 3284.18s]  let me take that back immediately.
[3284.18s -> 3285.62s]  One part is DRM
[3285.62s -> 3289.22s]  and one part is actually IO devices.
[3294.58s -> 3294.90s]  And so
[3296.82s -> 3297.70s]  maybe I'm going to talk about
[3297.70s -> 3298.26s]  the physical,
[3298.26s -> 3299.54s]  the right side of the slide
[3299.54s -> 3300.18s]  a little bit first,
[3300.18s -> 3300.90s]  and then we'll talk about
[3300.90s -> 3301.94s]  the left side in a second.
[3302.50s -> 3304.98s]  So the left side of the slide
[3304.98s -> 3305.86s]  is completely determined
[3305.86s -> 3306.50s]  by the hardware.
[3307.46s -> 3308.98s]  And so the hardware designers
[3308.98s -> 3309.78s]  basically determine
[3309.78s -> 3311.22s]  the layout of that fit.
[3311.22s -> 3313.46s]  And if you saw before last week,
[3313.94s -> 3316.26s]  uh, when the kernel starts,
[3316.26s -> 3317.62s]  it starts at this address,
[3317.62s -> 3318.90s]  0x880.
[3320.58s -> 3321.86s]  And that's just determined
[3321.86s -> 3322.90s]  by the hardware designers.
[3323.94s -> 3325.54s]  And so it's usually
[3325.54s -> 3326.18s]  more explicit.
[3327.38s -> 3328.74s]  So if you look at the board,
[3328.74s -> 3329.62s]  this is the same picture
[3329.62s -> 3330.18s]  of the board
[3330.18s -> 3331.46s]  that I showed on the Monday,
[3331.46s -> 3332.10s]  but it's hopefully
[3332.10s -> 3333.38s]  a little bit better picture
[3333.38s -> 3334.50s]  and easier to see.
[3334.50s -> 3336.02s]  Here's our RISC-V processor.
[3336.58s -> 3337.30s]  And we now know,
[3337.30s -> 3337.54s]  correct,
[3337.54s -> 3338.82s]  that in the RISC-V processor
[3338.82s -> 3339.86s]  there are four cores,
[3339.86s -> 3341.46s]  but there's also an MMU
[3341.46s -> 3343.62s]  and there's also a TOB,
[3343.62s -> 3344.66s]  or multiple TOB.
[3344.66s -> 3346.66s]  Every core has its own MMU
[3346.66s -> 3348.18s]  and every core has its own TOB.
[3348.98s -> 3350.82s]  And here are the DRM chips.
[3352.02s -> 3353.46s]  And so basically,
[3353.46s -> 3354.74s]  the designers of the board
[3354.74s -> 3355.70s]  have decided that
[3356.82s -> 3357.62s]  when, you know,
[3358.34s -> 3359.06s]  after, you know,
[3359.06s -> 3359.94s]  the translation
[3359.94s -> 3361.46s]  from virtual to physical address,
[3361.46s -> 3362.66s]  basically physical addresses
[3362.66s -> 3363.86s]  that starting, you know,
[3363.86s -> 3364.74s]  at 0x08,
[3364.74s -> 3365.06s]  you know,
[3365.06s -> 3366.02s]  a lot of zeros
[3366.02s -> 3367.46s]  actually go to the DRM chips.
[3368.90s -> 3369.86s]  And addresses above,
[3369.86s -> 3371.14s]  below 0x08
[3371.14s -> 3372.74s]  may go to different IO devices.
[3373.38s -> 3376.58s]  And so the platform decides,
[3376.58s -> 3377.14s]  basically,
[3377.14s -> 3378.26s]  the designers of this board
[3378.26s -> 3379.30s]  have decided exactly
[3379.30s -> 3380.26s]  with the physical layout.
[3380.90s -> 3381.30s]  And in fact,
[3381.30s -> 3382.18s]  you can look that up,
[3382.18s -> 3383.06s]  the physical layout,
[3383.06s -> 3383.62s]  if you want to.
[3384.34s -> 3385.46s]  Just let me show you that.
[3385.46s -> 3387.06s]  So here's the same manual
[3387.06s -> 3387.78s]  that I showed you
[3392.50s -> 3393.94s]  on Monday.
[3393.94s -> 3395.14s]  And if you go to,
[3395.14s -> 3395.46s]  actually,
[3397.70s -> 3399.70s]  you go to page 31,
[3399.70s -> 3400.10s]  I believe,
[3401.46s -> 3402.58s]  it's the page.
[3403.38s -> 3404.26s]  And if you go down,
[3404.26s -> 3405.06s]  there's a system,
[3405.06s -> 3405.70s]  what's the memory,
[3405.70s -> 3406.66s]  it will spell out
[3406.66s -> 3407.78s]  what the memory map is
[3407.78s -> 3410.34s]  of the board.
[3410.34s -> 3410.90s]  And it will say,
[3410.90s -> 3412.90s]  like at address 00 is reserved,
[3412.90s -> 3413.62s]  nothing is there.
[3415.22s -> 3417.06s]  If you go scroll down
[3417.06s -> 3418.10s]  in this memory map,
[3418.10s -> 3418.34s]  you know,
[3418.34s -> 3420.42s]  you'll see some information
[3420.42s -> 3421.62s]  about all the different things
[3421.62s -> 3422.18s]  that are mapped.
[3422.18s -> 3422.74s]  For example,
[3422.74s -> 3426.10s]  even at board is mapped at 0x1,
[3426.10s -> 3427.30s]  you know, 0x something.
[3429.30s -> 3430.90s]  If you go further down,
[3431.78s -> 3432.74s]  that was too much down.
[3433.78s -> 3434.10s]  Here,
[3434.10s -> 3437.06s]  you see the entry for 0x8000.
[3438.90s -> 3441.46s]  And that actually is DVR memory,
[3441.46s -> 3443.14s]  the off-chip volatile memory.
[3443.14s -> 3444.58s]  And so those are the DRAM chips
[3444.58s -> 3445.30s]  that I just showed you
[3445.30s -> 3446.18s]  on the previous slide.
[3447.62s -> 3448.50s]  And so it's just good
[3448.50s -> 3449.54s]  to keep in your head,
[3449.54s -> 3450.98s]  even though we're talking to Kim Yoo
[3450.98s -> 3452.42s]  and you're all going to see soccer,
[3452.42s -> 3452.98s]  in the end,
[3452.98s -> 3454.02s]  everything is determined
[3454.74s -> 3456.18s]  by the actual board.
[3456.18s -> 3462.34s]  Okay, so go back to my slides.
[3463.14s -> 3466.42s]  So let's look at the layout.
[3466.42s -> 3467.94s]  Yeah, Noah, go ahead.
[3469.62s -> 3469.78s]  Yeah.
[3469.78s -> 3471.38s]  When you say that this layout
[3471.38s -> 3472.74s]  is determined by the hardware,
[3472.74s -> 3473.78s]  do you specifically mean
[3474.34s -> 3475.78s]  like the CPU itself
[3475.78s -> 3477.54s]  or the board on which
[3477.54s -> 3478.98s]  the CPU resides?
[3478.98s -> 3480.58s]  The board in which the CPU resides,
[3480.58s -> 3480.90s]  correct?
[3480.90s -> 3482.18s]  Because the board,
[3482.18s -> 3482.42s]  you know,
[3482.42s -> 3484.34s]  the CPU is that gray thing
[3484.34s -> 3484.82s]  in the middle,
[3484.82s -> 3485.70s]  that square thing,
[3485.78s -> 3487.70s]  saying whatever RISC-V,
[3487.70s -> 3488.82s]  the DRAM chips
[3488.82s -> 3492.18s]  are sitting off the processor,
[3492.18s -> 3492.42s]  correct?
[3492.42s -> 3493.70s]  And it's the board designers
[3493.70s -> 3494.90s]  who put the chip,
[3494.90s -> 3495.54s]  the DRAM,
[3496.26s -> 3498.10s]  the many IO devices all together.
[3499.78s -> 3500.74s]  Got it, thank you.
[3500.74s -> 3501.30s]  In large part,
[3501.30s -> 3502.42s]  correct, of an operating system
[3502.42s -> 3502.74s]  is actually,
[3502.74s -> 3502.90s]  you know,
[3502.90s -> 3504.02s]  the CPU is one part,
[3504.02s -> 3505.06s]  but the IO devices
[3505.06s -> 3506.18s]  are at least as important,
[3506.18s -> 3506.58s]  correct?
[3506.58s -> 3507.46s]  And so when you're writing
[3507.46s -> 3508.50s]  an operating system,
[3508.50s -> 3510.10s]  you both have to deal with the CPU
[3510.10s -> 3510.58s]  as well as,
[3510.58s -> 3510.82s]  you know,
[3510.82s -> 3511.86s]  with the IO devices,
[3511.86s -> 3512.26s]  you know,
[3512.26s -> 3513.22s]  and you want to send a packet
[3513.22s -> 3514.18s]  over the internet.
[3514.18s -> 3515.14s]  Well, somebody has to
[3516.66s -> 3517.46s]  tick all,
[3517.46s -> 3517.78s]  you know,
[3517.78s -> 3518.50s]  the network drive
[3518.50s -> 3519.46s]  or the NIC cards
[3519.46s -> 3520.10s]  to actually do that,
[3520.10s -> 3521.22s]  and that's the operating system.
[3523.62s -> 3523.86s]  So,
[3524.50s -> 3525.54s]  going back to the right side
[3525.54s -> 3526.18s]  of this picture,
[3526.18s -> 3526.34s]  correct,
[3526.34s -> 3528.66s]  which is the physical address layout,
[3528.66s -> 3528.90s]  you know,
[3528.90s -> 3530.02s]  we see basically that,
[3530.02s -> 3530.26s]  you know,
[3530.26s -> 3531.38s]  the bottom was unused
[3531.38s -> 3533.86s]  as I showed you on that document.
[3533.86s -> 3534.58s]  It turns out that
[3534.58s -> 3535.94s]  0x100,
[3535.94s -> 3536.82s]  that physical address,
[3536.82s -> 3538.34s]  that's where the boot ROM is.
[3538.34s -> 3539.62s]  So when you turn on,
[3539.62s -> 3539.86s]  you know,
[3539.86s -> 3540.50s]  that board,
[3540.50s -> 3541.54s]  the first thing that happens
[3541.54s -> 3541.94s]  is actually
[3541.94s -> 3543.46s]  coding the boot ROM runs.
[3544.02s -> 3545.22s]  And when the boot ROM is done,
[3545.78s -> 3546.58s]  it actually will jump
[3546.58s -> 3548.74s]  to this 0x000,
[3548.74s -> 3549.54s]  and it's the job
[3549.54s -> 3550.34s]  of the operating system
[3550.34s -> 3550.82s]  to make sure that
[3550.82s -> 3551.22s]  there's some,
[3551.94s -> 3552.18s]  you know,
[3552.18s -> 3552.90s]  some data there.
[3553.70s -> 3554.18s]  And then there's
[3554.18s -> 3555.46s]  a bunch of other devices
[3555.46s -> 3556.50s]  that we'll talk about.
[3556.50s -> 3556.90s]  There's the,
[3558.50s -> 3559.46s]  an interrupt controller.
[3560.02s -> 3561.14s]  We'll talk about it next week.
[3562.02s -> 3563.14s]  There's a CLINT,
[3563.14s -> 3566.18s]  another part of the interrupt story
[3566.18s -> 3567.62s]  that we'll talk about next week.
[3567.62s -> 3569.14s]  So basically multiple devices
[3569.14s -> 3570.18s]  can generate interrupts.
[3570.18s -> 3571.14s]  There needs to be a plan
[3571.14s -> 3572.10s]  to route those interrupts
[3572.10s -> 3574.90s]  to the appropriate request level,
[3574.90s -> 3575.78s]  and that's all implemented
[3575.78s -> 3578.10s]  by those interrupt controllers.
[3578.98s -> 3580.90s]  And let me finish for a second,
[3580.90s -> 3581.22s]  you know,
[3581.22s -> 3583.70s]  this slide before answering the question.
[3585.22s -> 3586.58s]  Then there's a UART,
[3586.58s -> 3587.62s]  that was the device,
[3588.82s -> 3589.78s]  that was actually the thing
[3589.78s -> 3590.18s]  that actually,
[3590.74s -> 3591.86s]  the device that actually,
[3591.86s -> 3592.50s]  UART device
[3592.50s -> 3593.22s]  that actually interacts
[3593.22s -> 3594.10s]  with the console
[3594.10s -> 3595.22s]  and the display.
[3595.22s -> 3596.42s]  And then there's the virtual,
[3596.42s -> 3597.14s]  there's the disk,
[3598.42s -> 3599.86s]  and that's the device,
[3599.86s -> 3601.14s]  there's where the device
[3601.14s -> 3602.18s]  sits that actually interacts
[3602.18s -> 3602.98s]  with the disk.
[3602.98s -> 3604.42s]  And so when you write
[3604.42s -> 3605.86s]  to a location to address,
[3605.86s -> 3606.26s]  let's say,
[3606.98s -> 3608.34s]  0x200,
[3609.30s -> 3610.66s]  then that physical address
[3610.66s -> 3611.94s]  corresponds to the CLINT.
[3611.94s -> 3612.90s]  And so when you do
[3612.90s -> 3613.62s]  store instruction
[3613.62s -> 3614.74s]  or load instruction,
[3614.74s -> 3616.34s]  you're reading and writing
[3616.34s -> 3618.10s]  to the chip
[3618.10s -> 3620.42s]  that implements the CLINT.
[3621.14s -> 3622.02s]  And we'll see later
[3622.02s -> 3623.14s]  what that exactly means.
[3623.14s -> 3623.70s]  But basically,
[3623.70s -> 3624.50s]  you can think about this
[3624.50s -> 3625.62s]  as interacting directly
[3625.62s -> 3626.34s]  with the device
[3626.34s -> 3626.98s]  and not reading
[3626.98s -> 3628.02s]  and writing physical memory.
[3629.86s -> 3630.74s]  Yeah, there was a question.
[3630.74s -> 3634.34s]  So just trying to make sure
[3634.34s -> 3638.50s]  the addresses below 0x800,
[3638.50s -> 3640.42s]  they don't really exist in DRAM.
[3641.86s -> 3642.74s]  If when we mentioned
[3642.74s -> 3643.38s]  those addresses,
[3643.38s -> 3644.02s]  we directly go
[3644.02s -> 3645.46s]  to the other hardwares.
[3645.46s -> 3646.18s]  Yeah, yeah.
[3646.18s -> 3647.30s]  So if you just go back
[3647.30s -> 3647.86s]  to this picture,
[3648.58s -> 3650.58s]  anything above 0x100,
[3653.46s -> 3654.74s]  that's these DRAM chips.
[3656.26s -> 3658.34s]  And I can't draw,
[3658.34s -> 3658.98s]  I can't point you
[3658.98s -> 3659.54s]  to the CLINT,
[3660.34s -> 3661.06s]  but like for example,
[3661.06s -> 3662.90s]  here's the evenet.
[3664.18s -> 3664.74s]  And so that's,
[3664.74s -> 3666.02s]  it's a particular physical address
[3666.02s -> 3666.90s]  and we can write,
[3666.90s -> 3667.14s]  you know,
[3667.14s -> 3668.34s]  with load and store instructions,
[3668.34s -> 3670.10s]  this is called memory mapped IO.
[3670.10s -> 3670.82s]  We can do load
[3670.82s -> 3671.70s]  and store instructions,
[3671.70s -> 3672.58s]  we can program
[3672.58s -> 3673.54s]  the evenet controller.
[3677.78s -> 3678.90s]  I also have a question.
[3679.86s -> 3681.54s]  Why is this big chunk
[3681.54s -> 3683.14s]  at the top says unused?
[3683.70s -> 3684.82s]  Why is it not used?
[3685.38s -> 3686.90s]  Oh, okay.
[3686.90s -> 3687.54s]  So remember,
[3687.54s -> 3689.86s]  not every machine,
[3689.86s -> 3690.50s]  not every,
[3690.50s -> 3691.54s]  so there's two
[3691.54s -> 3694.34s]  to the power of 56 bytes
[3694.34s -> 3695.38s]  of physical address space,
[3696.26s -> 3697.46s]  but you don't have to,
[3697.46s -> 3697.78s]  you know,
[3697.78s -> 3698.98s]  plug in that much memory
[3698.98s -> 3699.70s]  into the board
[3699.70s -> 3700.42s]  if you don't want to.
[3701.14s -> 3702.34s]  And so some parts of it
[3702.34s -> 3703.14s]  may be unused
[3703.70s -> 3704.50s]  depending on how much,
[3704.50s -> 3704.74s]  you know,
[3704.74s -> 3705.46s]  DRAM chips
[3705.46s -> 3706.34s]  are sitting on the board.
[3710.50s -> 3710.98s]  In fact,
[3710.98s -> 3711.94s]  like in XV6,
[3712.58s -> 3713.78s]  we, I think,
[3713.78s -> 3716.66s]  limit ourselves to 128 megabytes.
[3718.50s -> 3719.14s]  And no more.
[3723.62s -> 3724.26s]  So when,
[3726.58s -> 3728.74s]  when a load restore instruction
[3728.74s -> 3730.34s]  goes out of the CPU,
[3731.46s -> 3732.18s]  does that go,
[3733.06s -> 3733.30s]  like,
[3734.10s -> 3734.98s]  where does it get
[3734.98s -> 3736.50s]  routed to the correct IO,
[3736.50s -> 3738.42s]  like already from the CPU?
[3738.42s -> 3739.54s]  So kind of like,
[3739.54s -> 3741.70s]  if the CPU before it sends it out,
[3741.70s -> 3742.10s]  it says,
[3742.10s -> 3742.34s]  okay,
[3742.34s -> 3744.42s]  if it's lower than 0x8
[3744.42s -> 3745.78s]  and all the zeros,
[3745.78s -> 3746.90s]  then I'm going to send it
[3746.90s -> 3748.50s]  to like the correct IO device.
[3748.50s -> 3749.22s]  And then otherwise,
[3749.22s -> 3751.06s]  I'm going to send it to the,
[3752.26s -> 3753.46s]  to the memory,
[3753.46s -> 3754.50s]  like the DRAM chip.
[3755.70s -> 3756.26s]  You can think about it
[3756.26s -> 3757.30s]  as a demultiplexer
[3757.30s -> 3758.34s]  sitting on the inside
[3758.34s -> 3761.38s]  of the RISC-V block.
[3761.38s -> 3762.74s]  Oh, so it's inside of that block.
[3763.94s -> 3764.18s]  Okay.
[3766.26s -> 3767.62s]  There's your memory controller
[3767.62s -> 3769.30s]  and there's the routing.
[3772.82s -> 3773.30s]  You could,
[3773.30s -> 3774.02s]  it's very important
[3774.02s -> 3774.66s]  to have that sort of
[3774.66s -> 3775.46s]  all clear in your head.
[3776.90s -> 3781.30s]  Okay, so now I want to switch
[3781.30s -> 3782.50s]  to the right side
[3782.50s -> 3783.22s]  of this picture.
[3783.78s -> 3784.82s]  And this is basically
[3784.82s -> 3786.26s]  what XV6 sets up
[3786.90s -> 3789.62s]  to the virtual dress space
[3789.62s -> 3790.74s]  that XV6 sets up.
[3790.74s -> 3792.26s]  So when the machine boots,
[3792.82s -> 3794.74s]  there's no page enable yet.
[3795.78s -> 3797.46s]  XV6 sets up the first,
[3797.46s -> 3797.70s]  you know,
[3798.26s -> 3799.14s]  page tables
[3799.14s -> 3800.42s]  in the first virtual dress space.
[3800.42s -> 3800.98s]  And that's actually
[3800.98s -> 3801.78s]  the virtual dress space
[3801.78s -> 3802.58s]  that the kernel uses.
[3802.58s -> 3803.30s]  And we'll look at it
[3803.30s -> 3804.82s]  in a second at the code.
[3805.54s -> 3807.62s]  But, and this is the layout.
[3807.62s -> 3808.34s]  And it turns out,
[3809.38s -> 3809.78s]  you know,
[3809.78s -> 3811.22s]  because we want to keep XV6
[3811.22s -> 3812.34s]  as simple as possible,
[3812.34s -> 3813.70s]  it's easy for you to understand
[3814.26s -> 3815.86s]  the mapping from virtual
[3816.74s -> 3817.46s]  to physical
[3818.98s -> 3820.58s]  is mostly an identity mapping.
[3826.26s -> 3827.94s]  So basically what that means is that
[3828.50s -> 3830.42s]  the virtual dress 0x200
[3831.54s -> 3833.54s]  maps to physical address 0x2000.
[3834.50s -> 3835.86s]  So the kernel will set up
[3835.86s -> 3838.10s]  the page tables exactly in that way.
[3838.10s -> 3839.86s]  And so that means basically that,
[3839.86s -> 3840.10s]  you know,
[3840.10s -> 3841.54s]  sort of all virtual addresses
[3841.54s -> 3842.82s]  below this top,
[3844.26s -> 3846.10s]  which is the top of physical memory,
[3846.10s -> 3848.18s]  are identical to the physical addresses
[3848.18s -> 3849.30s]  that are actually being used
[3849.94s -> 3850.74s]  on the right side.
[3851.38s -> 3852.10s]  And so this is like
[3852.10s -> 3853.70s]  why all the arrows are straight
[3853.70s -> 3854.42s]  because it's an,
[3854.42s -> 3854.66s]  you know,
[3854.66s -> 3855.46s]  identity mapping.
[3857.54s -> 3857.86s]  Okay.
[3859.06s -> 3861.30s]  There's a small changes to this.
[3861.94s -> 3864.74s]  There are two important things to mention.
[3866.50s -> 3867.54s]  Amir, hold on a second
[3868.18s -> 3869.70s]  while I try to first mention
[3869.70s -> 3871.06s]  the two important things to mention.
[3872.50s -> 3873.22s]  First of all,
[3873.22s -> 3874.98s]  there's some pages,
[3874.98s -> 3876.98s]  some mappings very high up in memory.
[3881.46s -> 3882.10s]  There's some pages
[3882.10s -> 3883.46s]  very high up in memory.
[3883.46s -> 3884.10s]  For example,
[3884.66s -> 3885.54s]  the stack,
[3886.66s -> 3888.42s]  the kernel stack actually sits up.
[3888.42s -> 3890.02s]  It's also mapped high up in memory.
[3890.90s -> 3892.42s]  And the reason it's high up in memory
[3892.42s -> 3894.50s]  is because we have a guard page below it
[3894.50s -> 3895.94s]  that is not mapped.
[3895.94s -> 3899.14s]  So the PTE entry below the kernel stack
[3899.14s -> 3900.10s]  or one of the kernel stacks
[3900.10s -> 3901.70s]  actually does not have
[3902.34s -> 3903.30s]  its valid bit set.
[3903.94s -> 3905.38s]  And so if,
[3905.38s -> 3905.94s]  you know,
[3905.94s -> 3907.86s]  the kernel runs off its stack
[3907.86s -> 3910.02s]  and will result in a page fault,
[3910.02s -> 3911.46s]  which is better than basically,
[3911.46s -> 3911.70s]  you know,
[3911.70s -> 3913.14s]  scribbling over some other memory
[3913.14s -> 3914.26s]  that the kernel has.
[3914.26s -> 3915.38s]  You get an immediate panic
[3915.38s -> 3915.86s]  and you know that
[3915.86s -> 3916.98s]  something's bad with the stack.
[3918.90s -> 3919.30s]  And of course,
[3919.30s -> 3921.30s]  we don't want to waste physical memory.
[3921.30s -> 3922.50s]  And so when we do that
[3922.50s -> 3923.54s]  by basically
[3923.54s -> 3924.58s]  putting the stack high
[3925.94s -> 3928.02s]  in a guard page,
[3928.02s -> 3930.18s]  an empty guard PTE entry below it.
[3931.06s -> 3932.82s]  And the guard PTE page
[3932.82s -> 3933.78s]  doesn't really consume
[3933.78s -> 3934.58s]  any physical memory
[3934.58s -> 3935.54s]  where it's sitting high up
[3935.54s -> 3936.58s]  in the virtual address space.
[3936.58s -> 3938.58s]  So nothing is being consumed.
[3939.46s -> 3940.18s]  But that means
[3940.18s -> 3941.70s]  that the showing this KStack page,
[3941.70s -> 3942.18s]  for example,
[3942.18s -> 3942.98s]  is mapped twice.
[3943.54s -> 3945.38s]  It's mapped at a high address
[3945.38s -> 3946.82s]  and it's mapped directly,
[3946.82s -> 3947.14s]  you know,
[3947.14s -> 3948.18s]  by one of the addresses
[3948.18s -> 3949.22s]  that below fist hop.
[3950.74s -> 3951.78s]  And so you can do,
[3951.78s -> 3952.98s]  this is one example
[3952.98s -> 3954.90s]  of all these sort of cool things
[3954.90s -> 3956.42s]  you can do with page tables.
[3956.42s -> 3958.26s]  You can map a physical address twice.
[3958.82s -> 3960.50s]  You cannot map a physical address.
[3961.54s -> 3961.78s]  You know,
[3961.78s -> 3963.06s]  it can be one-to-one mapping,
[3963.06s -> 3963.94s]  one-to-many mapping,
[3963.94s -> 3965.14s]  many-to-one mapping,
[3965.14s -> 3966.50s]  all that kind of stuff is possible.
[3967.46s -> 3969.70s]  xv6 doesn't really use many of them,
[3969.70s -> 3970.74s]  but there's a couple places
[3970.74s -> 3972.10s]  we use those tricks.
[3972.10s -> 3973.78s]  And the stack in the guard page
[3973.78s -> 3974.66s]  is one example
[3974.66s -> 3975.70s]  of one of the cool trick
[3975.70s -> 3977.62s]  that xv6 uses,
[3977.62s -> 3978.98s]  mostly to track down bugs.
[3981.06s -> 3981.62s]  The second thing
[3981.62s -> 3982.26s]  I wanted to mention
[3982.26s -> 3983.78s]  is that the permissions.
[3984.82s -> 3985.54s]  So for example,
[3985.54s -> 3986.74s]  the kernel text,
[3986.74s -> 3988.02s]  the pages for the kernel text
[3988.02s -> 3989.70s]  are mapped read and x,
[3989.70s -> 3990.98s]  meaning you can read it
[3990.98s -> 3992.02s]  and execute it,
[3992.02s -> 3993.78s]  but you cannot write the kernel text.
[3993.78s -> 3994.18s]  And again,
[3994.18s -> 3996.34s]  this is basically the void box
[3996.34s -> 3997.86s]  so that we catch them early.
[3997.86s -> 3998.50s]  Kernel data,
[3998.50s -> 3998.90s]  of course,
[3998.90s -> 4000.42s]  needs to be able to be written to.
[4000.42s -> 4001.22s]  And so it has,
[4001.22s -> 4002.10s]  is mapped read write,
[4002.74s -> 4003.94s]  but you cannot execute
[4005.14s -> 4007.22s]  out of kernel data pages,
[4007.22s -> 4007.78s]  instructions.
[4009.30s -> 4010.58s]  So the x data is not set.
[4014.10s -> 4014.90s]  Does it all make sense?
[4016.58s -> 4018.18s]  I skipped one or two questions.
[4018.18s -> 4019.22s]  So if these questions
[4019.22s -> 4020.26s]  are still not answered,
[4020.26s -> 4020.98s]  please ask them.
[4023.94s -> 4025.14s]  We have a question in the chat.
[4026.74s -> 4028.50s]  Do we have multiple kernel stacks
[4028.50s -> 4029.62s]  for different processes?
[4029.62s -> 4030.82s]  Like will we have n
[4030.82s -> 4032.42s]  k-stacks for n processes?
[4033.22s -> 4033.78s]  Answer is yes.
[4035.06s -> 4036.26s]  So every process,
[4036.26s -> 4037.06s]  every user process
[4037.06s -> 4038.74s]  has a corresponding kernel stack.
[4041.30s -> 4041.94s]  And we'll see that
[4041.94s -> 4042.82s]  in a little bit later.
[4045.54s -> 4046.04s]  Okay.
[4047.46s -> 4048.10s]  Okay, so let me,
[4049.54s -> 4050.42s]  Samir, go ahead.
[4052.26s -> 4054.26s]  So would the virtual memory
[4054.26s -> 4056.10s]  of another application
[4056.98s -> 4057.70s]  map to somewhere
[4057.70s -> 4058.74s]  in the physical memory
[4058.74s -> 4060.10s]  in the unused space or?
[4060.74s -> 4062.82s]  Yes, very good point.
[4062.82s -> 4064.82s]  So there's a bunch
[4064.82s -> 4065.70s]  of physical memory, correct?
[4065.70s -> 4066.58s]  Here's free memory.
[4068.66s -> 4069.46s]  And that's free memory
[4069.46s -> 4070.34s]  here too, right?
[4071.22s -> 4072.58s]  And we use that
[4072.58s -> 4074.34s]  or actually use that free memory
[4074.34s -> 4075.94s]  to basically store pages
[4075.94s -> 4078.58s]  of page tables of user processes
[4078.58s -> 4079.70s]  as well as, you know,
[4079.70s -> 4081.46s]  the text and data
[4081.46s -> 4082.66s]  of user level processes.
[4084.02s -> 4085.14s]  And if we run many, many,
[4085.14s -> 4086.26s]  many user level processes,
[4086.26s -> 4086.66s]  at some point,
[4086.66s -> 4087.86s]  we'll run out of free memory
[4087.86s -> 4089.14s]  and then basically fork
[4089.14s -> 4091.22s]  or exec will return an error.
[4093.22s -> 4093.86s]  But that means that
[4093.86s -> 4095.06s]  the virtual space
[4095.06s -> 4096.74s]  for processes
[4096.74s -> 4097.38s]  are much smaller
[4097.38s -> 4098.50s]  than the virtual space
[4098.50s -> 4100.10s]  for the kernel, right?
[4100.74s -> 4101.62s]  Well, the virtual space
[4101.62s -> 4103.46s]  is the same as the same
[4104.34s -> 4105.38s]  size in principle,
[4105.38s -> 4106.82s]  but it will be less populated.
[4111.06s -> 4112.82s]  Let's go look at some code
[4112.82s -> 4113.70s]  and I think all the stuff
[4113.70s -> 4114.58s]  becomes a little bit more clear.
[4116.50s -> 4117.38s]  Just one small thing.
[4119.30s -> 4120.10s]  So given that
[4121.06s -> 4121.86s]  a lot of the,
[4121.86s -> 4122.98s]  like each process
[4122.98s -> 4123.86s]  has a big part
[4123.86s -> 4125.14s]  of the memory mapped
[4125.14s -> 4126.58s]  to the same location,
[4126.58s -> 4127.86s]  is that optimized
[4127.86s -> 4129.86s]  by like consolidating
[4129.86s -> 4130.98s]  that into one place,
[4130.98s -> 4132.02s]  that mapping or no?
[4133.06s -> 4133.94s]  You could.
[4133.94s -> 4135.38s]  XVC does not do that.
[4136.42s -> 4138.02s]  Like one of the challenge exercises
[4138.02s -> 4139.46s]  in the page table app
[4139.46s -> 4140.58s]  is to actually implement that.
[4142.74s -> 4143.38s]  I see.
[4143.38s -> 4144.34s]  And the real operating system
[4144.34s -> 4144.82s]  would do that.
[4146.98s -> 4148.50s]  Yeah, that makes sense.
[4148.50s -> 4149.14s]  Very good question.
[4150.50s -> 4151.46s]  And I think you get a sense
[4151.46s -> 4152.18s]  of like what all kinds
[4152.18s -> 4152.98s]  of things are possible
[4152.98s -> 4154.10s]  once you have page tables.
[4157.06s -> 4159.22s]  Okay, so let's do the usual thing.
[4160.98s -> 4163.06s]  Boot our XVC again
[4163.06s -> 4163.78s]  and again, you know,
[4163.78s -> 4164.74s]  QEMU is just basically
[4164.74s -> 4165.54s]  implementing the board.
[4167.62s -> 4170.18s]  And, you know, let's, oops.
[4178.02s -> 4180.02s]  So last time we looked at
[4180.66s -> 4181.94s]  how the booting happens, correct?
[4181.94s -> 4182.98s]  And then we got to main.
[4182.98s -> 4183.54s]  And then basically
[4183.54s -> 4184.34s]  one of the things that
[4185.86s -> 4186.42s]  the kernel,
[4188.26s -> 4188.98s]  one of the functions
[4188.98s -> 4190.34s]  is called KVM in it.
[4190.34s -> 4191.22s]  And that actually sets up
[4191.22s -> 4192.74s]  the address space for the kernel.
[4193.30s -> 4194.98s]  And so we saw in the picture
[4194.98s -> 4195.94s]  or in the previous slide,
[4195.94s -> 4197.54s]  what that, you know, looks like.
[4197.54s -> 4198.74s]  And here we're going to see,
[4198.74s -> 4199.38s]  seeing code,
[4199.38s -> 4200.58s]  how it actually is being set up.
[4206.66s -> 4208.42s]  And why?
[4208.42s -> 4209.30s]  Hold on.
[4209.30s -> 4210.74s]  Something is not going
[4210.74s -> 4211.70s]  as I want it to.
[4213.46s -> 4214.66s]  Am I in the right directories?
[4219.30s -> 4220.34s]  Hold on a second here
[4220.34s -> 4220.98s]  while I'm trying
[4220.98s -> 4222.26s]  to sort out my problems.
[4224.82s -> 4225.62s]  That is good.
[4229.62s -> 4231.30s]  And in the right directories.
[4231.86s -> 4232.18s]  Yeah.
[4232.74s -> 4232.98s]  Okay.
[4233.70s -> 4234.26s]  GDP.
[4236.26s -> 4237.14s]  And let's set a break
[4237.14s -> 4238.42s]  from the main just to make sure.
[4239.30s -> 4239.70s]  Good.
[4239.70s -> 4241.22s]  And then set a break point
[4241.22s -> 4243.62s]  at KVM in it.
[4244.50s -> 4245.94s]  Actually, I can just step to it now.
[4246.90s -> 4247.70s]  Next.
[4247.70s -> 4248.66s]  Console in it.
[4248.66s -> 4249.54s]  Grand dev in it.
[4249.54s -> 4250.34s]  We saw that before.
[4251.86s -> 4253.06s]  Physical memory allocator.
[4255.30s -> 4260.34s]  And now something happens
[4260.34s -> 4261.70s]  that I'm not expecting.
[4265.86s -> 4267.22s]  What is going on?
[4270.66s -> 4271.54s]  Of course, I ran this
[4271.54s -> 4272.58s]  right before lecture.
[4272.58s -> 4273.06s]  Oh, here.
[4273.06s -> 4273.78s]  That's what's going on.
[4273.78s -> 4274.66s]  That actually is printing.
[4275.70s -> 4276.02s]  Okay.
[4278.82s -> 4279.70s]  Interesting.
[4279.70s -> 4279.94s]  Okay.
[4279.94s -> 4280.66s]  One more time.
[4280.66s -> 4283.06s]  See if I can get lucky.
[4283.06s -> 4283.30s]  More.
[4297.14s -> 4297.78s]  Continue.
[4297.94s -> 4299.86s]  Hopefully it will get there.
[4300.90s -> 4301.86s]  It's going to wait a little bit.
[4301.86s -> 4302.34s]  Okay, great.
[4302.34s -> 4304.02s]  We're at the KVM in it.
[4304.02s -> 4305.06s]  So basically we're now
[4305.06s -> 4306.26s]  this function here
[4306.26s -> 4307.30s]  on the right side
[4307.30s -> 4308.18s]  in the Emacs buffer.
[4308.18s -> 4308.74s]  You can see it.
[4310.42s -> 4314.18s]  And I think I modified
[4314.18s -> 4315.06s]  the function slightly.
[4315.94s -> 4316.66s]  I hope I did.
[4321.38s -> 4321.94s]  I think I did.
[4321.94s -> 4322.42s]  Well, we'll see.
[4324.10s -> 4325.06s]  And what I'm going to do
[4325.06s -> 4326.42s]  is I'm going to walk
[4326.42s -> 4327.38s]  step into that function.
[4328.74s -> 4330.18s]  It will do the layout split.
[4330.18s -> 4331.06s]  It's easier to see.
[4331.86s -> 4332.82s]  And this is the first thing
[4332.82s -> 4333.38s]  that you can see
[4333.38s -> 4334.18s]  is actually the kernel
[4334.18s -> 4334.82s]  actually allocates
[4334.82s -> 4335.70s]  a physical page
[4335.70s -> 4337.46s]  for the top-level page directory.
[4338.42s -> 4340.90s]  And then it zeroes it out
[4340.90s -> 4342.74s]  so that all the PTE entries are zero.
[4343.54s -> 4344.74s]  And then basically it starts
[4344.74s -> 4347.78s]  mapping in every device,
[4347.78s -> 4349.22s]  IO device, one by one.
[4349.86s -> 4350.90s]  And so, for example,
[4350.90s -> 4352.02s]  the UART zero,
[4352.02s -> 4353.22s]  it basically starts mapping
[4353.22s -> 4353.86s]  and maps that
[4353.86s -> 4356.18s]  into the kernel address space.
[4356.18s -> 4357.70s]  And so we can look at
[4357.70s -> 4359.46s]  the file for WIM layout.
[4359.46s -> 4362.18s]  It basically translates page 31
[4362.18s -> 4362.98s]  that I showed you
[4362.98s -> 4363.86s]  from the document
[4363.86s -> 4364.90s]  into a bunch of constants
[4364.90s -> 4365.54s]  that we're using.
[4366.18s -> 4366.90s]  And so, for example,
[4366.90s -> 4367.54s]  here it says
[4367.54s -> 4368.50s]  we want the address of U
[4369.14s -> 4370.66s]  0x1000 is.
[4373.78s -> 4374.74s]  Over to UART is.
[4375.38s -> 4376.82s]  And so, you know,
[4376.82s -> 4377.70s]  we can basically
[4378.90s -> 4380.34s]  map it into the address space
[4380.34s -> 4382.26s]  by calling this function KVM map,
[4382.26s -> 4383.38s]  which I'll look at in a second.
[4384.34s -> 4387.94s]  And then in the first exercise
[4387.94s -> 4389.46s]  of the page table lab,
[4389.46s -> 4390.82s]  you are asked to implement
[4390.82s -> 4391.94s]  the function called VM print.
[4392.82s -> 4394.66s]  And I implemented it too.
[4394.66s -> 4396.18s]  And I'm going to step over it
[4396.18s -> 4397.30s]  and we'll see basically
[4398.50s -> 4399.46s]  the page tables,
[4400.82s -> 4401.70s]  the kernel page table
[4401.70s -> 4402.66s]  as it is set up
[4402.66s -> 4404.98s]  after that one call to PVM map.
[4404.98s -> 4405.78s]  So I'm going to do that
[4406.42s -> 4407.78s]  and boom, it prints out something.
[4408.42s -> 4409.14s]  And so we're going to look at
[4409.14s -> 4410.34s]  a little bit of the output here.
[4410.34s -> 4411.46s]  So here's the page table.
[4411.46s -> 4413.94s]  That is the physical address
[4414.58s -> 4415.62s]  of the top level
[4417.70s -> 4418.42s]  page directory.
[4418.42s -> 4419.22s]  So the thing that actually
[4419.22s -> 4420.26s]  sits in SATP
[4420.26s -> 4421.86s]  or will sit in SATP.
[4422.82s -> 4423.70s]  And then, you know,
[4423.70s -> 4425.94s]  we have entry zero
[4425.94s -> 4427.14s]  of the top level page directory
[4427.14s -> 4429.86s]  has one PT entry in it.
[4431.46s -> 4433.14s]  And that is the
[4433.14s -> 4434.26s]  contains the physical address
[4434.26s -> 4435.22s]  for the middle level
[4435.22s -> 4436.18s]  page table directory.
[4436.74s -> 4437.46s]  The middle page
[4437.46s -> 4439.54s]  table directory has one entry,
[4439.54s -> 4441.06s]  namely 128.
[4441.06s -> 4442.26s]  And that points to the bottom
[4442.26s -> 4443.38s]  page table directory
[4443.38s -> 4443.86s]  and the bottom
[4443.86s -> 4444.74s]  page table directory
[4444.74s -> 4445.54s]  has the entry then
[4445.54s -> 4446.90s]  for the physical page.
[4447.62s -> 4448.74s]  And you can see indeed
[4448.74s -> 4450.26s]  that the physical address,
[4450.26s -> 4451.06s]  you know, for that
[4451.06s -> 4454.26s]  the bottom level is 0x1000
[4454.26s -> 4457.14s]  corresponding to us0, right?
[4457.14s -> 4458.18s]  So basically,
[4458.18s -> 4460.98s]  virtual address 1000
[4460.98s -> 4463.78s]  translates to physical address 11100.
[4465.62s -> 4466.42s]  And we can sort of
[4466.42s -> 4467.22s]  double check that this is
[4467.86s -> 4469.54s]  indeed all legit, right?
[4469.54s -> 4472.26s]  By let's take that address
[4474.90s -> 4477.54s]  on that 0x100L
[4477.54s -> 4478.74s]  and we're going to shift to 12.
[4480.74s -> 4481.46s]  And that should be,
[4483.30s -> 4483.54s]  you know,
[4483.54s -> 4484.74s]  that gives us the top level
[4484.74s -> 4486.50s]  27 bits.
[4487.22s -> 4488.18s]  We shifted 9.
[4489.06s -> 4491.14s]  So I'm going to take 0x100
[4492.58s -> 4496.02s]  1000 101 more.
[4496.02s -> 4497.30s]  And we're going to shift at 9
[4497.94s -> 4498.74s]  and print that.
[4499.54s -> 4502.82s]  And that is 0x0
[4502.82s -> 4504.58s]  and actually we print 0x0
[4504.58s -> 4506.50s]  as a decimal number.
[4506.50s -> 4507.86s]  It's going to be 128.
[4509.38s -> 4511.46s]  OK, so we see actually
[4511.46s -> 4512.26s]  sort of, you know,
[4512.26s -> 4513.38s]  it all sort of makes sense.
[4514.10s -> 4515.06s]  We also see,
[4515.06s -> 4516.42s]  I printed out the flags here
[4517.70s -> 4518.42s]  and, you know,
[4518.42s -> 4521.30s]  the bottom level has read, write
[4521.30s -> 4523.86s]  and invalid
[4523.86s -> 4524.90s]  because valid is 1.
[4526.66s -> 4527.62s]  Any questions about this?
[4529.94s -> 4535.94s]  OK, so the kernel
[4535.94s -> 4536.74s]  basically proceeds,
[4538.02s -> 4538.34s]  you know,
[4538.34s -> 4538.98s]  doing,
[4538.98s -> 4539.94s]  setting up the whole
[4539.94s -> 4541.06s]  address space in this way.
[4542.66s -> 4544.50s]  And so we've called KVM map,
[4544.50s -> 4544.74s]  you know,
[4544.74s -> 4545.70s]  for Verge.io,
[4545.70s -> 4546.34s]  for the claims,
[4546.34s -> 4546.98s]  for the click.
[4547.62s -> 4550.26s]  It maps the kernel text,
[4550.26s -> 4551.54s]  maps the kernel memory,
[4551.54s -> 4552.74s]  for kernel data,
[4552.74s -> 4553.94s]  and then the trampoline page
[4553.94s -> 4555.06s]  that we'll talk about next week.
[4556.02s -> 4556.66s]  And so in fact,
[4556.66s -> 4556.90s]  you know,
[4556.90s -> 4557.62s]  we can sort of single
[4557.62s -> 4558.34s]  step through this
[4558.34s -> 4559.22s]  and then see
[4559.22s -> 4561.14s]  what the final page directory
[4561.14s -> 4561.62s]  looks like.
[4564.18s -> 4565.30s]  So next,
[4565.30s -> 4565.86s]  next,
[4565.86s -> 4566.18s]  next,
[4566.18s -> 4566.50s]  next.
[4567.54s -> 4568.10s]  Basically,
[4568.10s -> 4568.34s]  you know,
[4568.34s -> 4569.30s]  we're set to trampoline.
[4569.30s -> 4570.18s]  And so now we're going to print
[4570.18s -> 4571.78s]  the complete page table directory.
[4572.42s -> 4573.06s]  And, you know,
[4573.06s -> 4573.38s]  we see,
[4574.18s -> 4574.66s]  you know,
[4574.66s -> 4576.98s]  basically a lot of PTEs
[4576.98s -> 4579.46s]  actually being set up.
[4580.66s -> 4581.38s]  And we're not going to
[4581.38s -> 4581.94s]  really talk about it
[4581.94s -> 4582.66s]  in any detail.
[4583.70s -> 4584.18s]  But, you know,
[4584.18s -> 4584.98s]  basically it fills out
[4584.98s -> 4586.82s]  the page directory
[4587.54s -> 4588.34s]  to actually create
[4588.34s -> 4589.30s]  that virtual mapping,
[4589.30s -> 4590.26s]  mapping that we basically
[4590.26s -> 4591.38s]  saw on the previous slide.
[4593.06s -> 4594.02s]  When I inspect,
[4594.02s -> 4594.74s]  what I want to do next
[4594.74s -> 4596.02s]  is actually much more interesting.
[4598.02s -> 4598.26s]  Yeah,
[4598.26s -> 4598.66s]  I'm going to,
[4600.50s -> 4600.74s]  yeah,
[4600.74s -> 4601.94s]  I want to go here actually.
[4601.94s -> 4603.38s]  I guess I maybe already did this.
[4604.18s -> 4605.14s]  We're at 21.
[4605.14s -> 4605.94s]  No, I'm 21.
[4605.94s -> 4606.18s]  Okay,
[4606.18s -> 4607.22s]  so single step not.
[4608.90s -> 4609.14s]  Okay,
[4609.14s -> 4609.62s]  that's too bad.
[4609.62s -> 4610.34s]  I got past that.
[4610.34s -> 4611.54s]  But basically,
[4613.70s -> 4615.70s]  let me restart this.
[4616.82s -> 4625.14s]  And I want to break point at KVM in at heart.
[4628.82s -> 4629.62s]  And continue.
[4631.86s -> 4632.18s]  Boom,
[4632.18s -> 4632.82s]  I'm now here
[4633.38s -> 4634.74s]  at KVM in at heart.
[4634.74s -> 4635.62s]  And you see here,
[4635.62s -> 4637.30s]  basically that we're writing
[4637.30s -> 4638.50s]  the SAPP register.
[4638.50s -> 4639.46s]  So basically the kernel
[4639.46s -> 4640.18s]  is going to enable
[4641.54s -> 4642.50s]  the page table
[4642.50s -> 4644.18s]  or the heart the MMU
[4644.18s -> 4645.14s]  to basically start using
[4645.14s -> 4645.78s]  the page table
[4645.78s -> 4646.66s]  that we just set up.
[4647.78s -> 4650.74s]  And one interesting question.
[4651.54s -> 4651.86s]  Okay,
[4651.86s -> 4653.54s]  I'm going to do a layout split again.
[4654.82s -> 4656.90s]  So somewhere here,
[4656.90s -> 4657.30s]  correct,
[4657.30s -> 4657.78s]  is going to be,
[4659.54s -> 4660.90s]  here's the instruction.
[4662.26s -> 4664.82s]  And so once,
[4665.38s -> 4667.38s]  so something really dramatic happens
[4667.94s -> 4669.38s]  after executing this instruction.
[4671.38s -> 4672.58s]  Once I say the,
[4672.58s -> 4672.82s]  you know,
[4672.82s -> 4674.58s]  I can't see the assembly instruction exactly,
[4674.58s -> 4678.82s]  but once this instruction is executed,
[4678.82s -> 4680.42s]  what will happen with the next address
[4680.42s -> 4681.38s]  that's being translated?
[4686.58s -> 4687.22s]  Well,
[4687.22s -> 4688.26s]  at the point that we execute
[4688.26s -> 4689.22s]  this instruction,
[4689.22s -> 4691.14s]  before executing this instruction,
[4691.14s -> 4692.82s]  there's no page tables enabled yet.
[4692.82s -> 4694.10s]  So no translation happens.
[4694.66s -> 4695.70s]  But the next,
[4695.70s -> 4696.58s]  and then the program counter
[4696.58s -> 4697.78s]  is updated by four.
[4698.50s -> 4699.54s]  And then the next instruction
[4699.54s -> 4700.34s]  is executed.
[4700.34s -> 4701.14s]  And the program counter
[4701.14s -> 4701.94s]  will be translated
[4701.94s -> 4702.90s]  using the virtual page
[4703.54s -> 4704.42s]  page table memory.
[4705.30s -> 4706.66s]  And so this is a,
[4706.66s -> 4706.90s]  you know,
[4706.90s -> 4707.94s]  the way to think about this,
[4707.94s -> 4709.78s]  this is a dramatic moment.
[4709.78s -> 4710.58s]  Because basically,
[4710.58s -> 4712.66s]  the whole address translation
[4712.66s -> 4713.54s]  is starting to enable
[4713.54s -> 4714.58s]  and every address means
[4714.58s -> 4716.34s]  maybe potentially something different,
[4717.78s -> 4718.02s]  right?
[4718.02s -> 4719.06s]  Because before we were running
[4719.06s -> 4720.42s]  your like the physical addresses
[4720.42s -> 4721.22s]  and then the page table
[4721.22s -> 4721.86s]  Henry set up
[4721.86s -> 4722.98s]  and whatever is in the mapping,
[4722.98s -> 4724.50s]  that is now the new meaning
[4724.50s -> 4725.38s]  of a virtual address.
[4727.06s -> 4728.74s]  And this is how this works out.
[4728.74s -> 4728.98s]  You know,
[4728.98s -> 4730.10s]  the fact that this actually works out
[4730.10s -> 4730.98s]  is sort of remarkable
[4730.98s -> 4732.74s]  because like the next instruction,
[4732.74s -> 4733.78s]  the next value
[4733.78s -> 4734.66s]  is a virtual address
[4734.66s -> 4735.70s]  and not a physical address.
[4737.46s -> 4738.34s]  Next instruction is going to be
[4738.34s -> 4738.82s]  this whatever,
[4738.82s -> 4739.30s]  0x1110.
[4740.90s -> 4742.10s]  And why does this work out?
[4744.10s -> 4745.22s]  Well, the reason it works out
[4745.22s -> 4746.42s]  is because the kernel is set up
[4746.42s -> 4747.94s]  with an identity page mapping.
[4747.94s -> 4750.02s]  So after we enabled
[4750.02s -> 4751.94s]  the virtual paging hardware,
[4751.94s -> 4752.50s]  we actually,
[4752.50s -> 4752.74s]  you know,
[4752.74s -> 4754.90s]  this translate will translate again
[4754.90s -> 4756.42s]  to the same physical address.
[4756.42s -> 4757.30s]  And so indeed,
[4757.30s -> 4757.62s]  you know,
[4757.62s -> 4758.66s]  we'll actually end up,
[4758.66s -> 4759.46s]  you know,
[4759.46s -> 4761.22s]  executing the right instruction
[4761.22s -> 4762.02s]  because that's actually
[4762.02s -> 4762.90s]  exactly the instruction
[4762.90s -> 4763.78s]  with the memory location
[4763.78s -> 4764.98s]  that the virtual hardware
[4764.98s -> 4765.70s]  is programmed for.
[4767.22s -> 4768.26s]  So does this make sense?
[4771.06s -> 4771.54s]  Again,
[4771.54s -> 4773.30s]  one reason why programming
[4773.30s -> 4775.06s]  with virtual memory is difficult
[4775.06s -> 4776.26s]  is because once you execute
[4776.26s -> 4778.18s]  one of these SAP instructions,
[4778.18s -> 4778.66s]  you know,
[4778.66s -> 4779.62s]  you load a page table
[4779.62s -> 4782.58s]  in the SAP register,
[4782.58s -> 4784.18s]  your world completely changes
[4784.90s -> 4786.10s]  and every address
[4786.10s -> 4786.90s]  is now translated
[4786.90s -> 4787.70s]  with the page table
[4787.70s -> 4788.42s]  that you set up.
[4789.70s -> 4790.58s]  And so what happens
[4790.58s -> 4791.30s]  if the page table
[4791.30s -> 4792.18s]  is set up incorrectly?
[4793.06s -> 4793.62s]  What would you,
[4794.42s -> 4795.14s]  what might happen?
[4801.86s -> 4802.74s]  Anybody who wants to
[4803.54s -> 4804.34s]  say to answer it
[4804.34s -> 4805.46s]  or answer it in the chat,
[4805.46s -> 4805.94s]  either way?
[4808.74s -> 4810.34s]  You could override kernel data.
[4811.14s -> 4811.38s]  Yeah,
[4811.38s -> 4812.50s]  you could override kernel data.
[4812.50s -> 4813.22s]  What else could happen?
[4813.22s -> 4813.46s]  Yeah,
[4813.46s -> 4814.10s]  page fault,
[4814.10s -> 4814.34s]  you know,
[4814.34s -> 4816.34s]  basically the mapping
[4816.34s -> 4818.10s]  may be incorrect
[4818.10s -> 4818.98s]  and basically the address
[4818.98s -> 4820.18s]  can be translated at all.
[4820.18s -> 4821.22s]  And so the kernel can,
[4821.22s -> 4821.46s]  you know,
[4821.46s -> 4822.82s]  the project hardware won't do it
[4822.82s -> 4824.02s]  and the kernel just stops,
[4824.02s -> 4824.58s]  it panics.
[4826.90s -> 4827.70s]  Does that make sense?
[4828.26s -> 4829.94s]  So if you get a bug
[4829.94s -> 4830.90s]  in your page tables,
[4831.78s -> 4832.10s]  you know,
[4832.10s -> 4832.74s]  you're going to see
[4832.74s -> 4835.94s]  bizarre errors or crashes.
[4836.98s -> 4838.18s]  And so one reason that,
[4838.18s -> 4838.58s]  for example,
[4838.58s -> 4839.62s]  the next lab,
[4839.62s -> 4840.50s]  the page table lab
[4840.50s -> 4841.54s]  that we'll hand out
[4841.54s -> 4842.58s]  or release tonight
[4843.14s -> 4844.02s]  is going to be hard
[4844.02s -> 4845.22s]  is because those kind of bugs
[4845.22s -> 4845.78s]  will show up
[4846.34s -> 4847.86s]  and you're not careful enough
[4847.86s -> 4849.46s]  or you haven't fully internalized
[4849.46s -> 4850.26s]  some aspect yet
[4850.82s -> 4851.94s]  and you're basically going
[4851.94s -> 4852.98s]  to get a kernel crash
[4853.54s -> 4854.90s]  and you're going to have a hard time
[4854.90s -> 4855.70s]  where you will take
[4855.70s -> 4857.06s]  a little bit of time and energy
[4857.06s -> 4858.18s]  and detective work
[4858.18s -> 4859.46s]  to basically track down
[4859.46s -> 4860.26s]  why that happened.
[4861.62s -> 4862.74s]  And that's just the,
[4863.62s -> 4864.74s]  that's just part of like
[4864.74s -> 4865.86s]  programming virtual memory
[4866.74s -> 4868.58s]  because it's such a powerful primitive,
[4868.58s -> 4868.82s]  you know,
[4868.82s -> 4869.70s]  if you get it wrong,
[4869.70s -> 4870.58s]  you're also going to have
[4871.70s -> 4872.74s]  powerful consequences.
[4876.34s -> 4876.66s]  Yep,
[4876.66s -> 4878.10s]  the other hand is a great amount of fun.
[4878.10s -> 4878.98s]  So I don't want to end
[4878.98s -> 4879.78s]  on a negative note.
[4880.74s -> 4883.06s]  Uh, but that will give you
[4883.06s -> 4884.18s]  sort of a real understanding
[4884.18s -> 4885.14s]  of actually what really
[4885.14s -> 4886.02s]  virtual memory is
[4886.02s -> 4886.74s]  and what it can do.
[4888.34s -> 4889.78s]  Okay, I think I'm running out of time,
[4889.78s -> 4891.22s]  so I'm going to stop here
[4891.22s -> 4892.42s]  so people have time to go
[4892.42s -> 4893.14s]  to the next class
[4893.14s -> 4893.86s]  or next activity.
[4894.66s -> 4896.50s]  But if you have any questions left,
[4896.50s -> 4896.74s]  you know,
[4896.74s -> 4897.62s]  please hang on
[4897.62s -> 4898.66s]  and ask them
[4899.70s -> 4901.86s]  and we'll see you on Monday.
[4903.54s -> 4904.90s]  And good luck with
[4904.90s -> 4906.18s]  finishing the Cisco lab.
[4906.50s -> 4908.82s]  Hi, I have a question about Guac.
[4910.26s -> 4911.22s]  So it says,
[4911.22s -> 4912.26s]  and in the code,
[4912.26s -> 4913.22s]  it returns the,
[4914.26s -> 4917.22s]  like the first tables PTE.
[4917.86s -> 4918.26s]  Yeah.
[4918.26s -> 4918.76s]  Right.
[4920.02s -> 4922.02s]  But how does it work then?
[4922.02s -> 4923.06s]  Like the other functions
[4923.06s -> 4926.02s]  when they expect the actual PTE,
[4926.82s -> 4928.66s]  like the physical address.
[4930.18s -> 4932.58s]  Yeah, so basically,
[4932.58s -> 4934.42s]  this returns the PTE
[4935.14s -> 4935.54s]  basically,
[4935.54s -> 4938.50s]  this returns the PTE entry
[4938.50s -> 4939.70s]  in the page table, right?
[4940.34s -> 4941.46s]  And the kernel can read
[4941.46s -> 4942.58s]  and write page table entries.
[4944.02s -> 4945.70s]  And so now you can stick
[4945.70s -> 4947.06s]  values into the PTE.
[4949.38s -> 4951.54s]  And so maybe I can draw a picture
[4951.54s -> 4952.50s]  if that is helpful.
[4954.50s -> 4954.90s]  Let's see.
[4954.90s -> 4961.38s]  Let's see.
[4964.02s -> 4964.66s]  So basically,
[4964.66s -> 4965.78s]  we have a page directory
[4973.22s -> 4974.66s]  and you know,
[4975.38s -> 4976.26s]  this walk code.
[4976.26s -> 4977.14s]  So the page directory
[4977.14s -> 4980.10s]  has 512 PTEs in it.
[4985.14s -> 4986.02s]  Here's zero,
[4986.02s -> 4986.98s]  here's five and 11.
[4987.86s -> 4988.58s]  And basically,
[4988.58s -> 4989.94s]  what the function does,
[4989.94s -> 4991.14s]  it returns a pointer
[4991.70s -> 4993.22s]  to one of these PTEs.
[4994.18s -> 4995.78s]  And so that's just a virtual address
[4995.78s -> 4996.66s]  and it just points to
[4996.66s -> 4997.62s]  that particular PTE.
[4998.50s -> 5000.10s]  And now the kernel can,
[5000.10s -> 5000.58s]  you know,
[5000.58s -> 5001.70s]  manipulate that PTE
[5001.70s -> 5002.58s]  by like whatever
[5002.58s -> 5003.62s]  writing values to it,
[5004.26s -> 5005.38s]  like some physical address,
[5006.18s -> 5008.26s]  maybe with some permissions
[5008.26s -> 5008.90s]  ordered into it
[5008.90s -> 5010.26s]  for the bottom 10 bits.
[5012.02s -> 5012.90s]  And then that basically
[5012.90s -> 5014.34s]  updates the page table directory
[5014.34s -> 5015.38s]  and then later on,
[5015.38s -> 5017.22s]  when you load that into the SATP,
[5018.02s -> 5018.98s]  now that effect,
[5018.98s -> 5020.66s]  that change will go into effect.
[5023.54s -> 5024.42s]  Does that make sense?
[5025.46s -> 5026.34s]  Yeah, that makes sense.
[5026.34s -> 5027.46s]  I guess I was just confused,
[5027.46s -> 5029.06s]  like why does it do the work
[5029.06s -> 5030.26s]  of going all the way
[5030.26s -> 5032.66s]  to the third page table
[5032.66s -> 5034.26s]  and then only return
[5034.26s -> 5035.62s]  the first PTE?
[5036.26s -> 5037.22s]  No, the return is actually
[5037.22s -> 5038.34s]  the bottom one.
[5040.18s -> 5040.50s]  Actually,
[5040.50s -> 5041.46s]  let me be careful.
[5041.70s -> 5044.50s]  If you notice,
[5044.50s -> 5045.78s]  it goes through the end levels.
[5045.78s -> 5046.90s]  So it starts at level two
[5046.90s -> 5047.86s]  and then it goes to level one
[5047.86s -> 5048.98s]  then it goes to level zero.
[5050.02s -> 5052.34s]  If the alloc bit is set
[5053.38s -> 5055.06s]  and level doesn't exist,
[5055.06s -> 5056.10s]  it will create
[5056.10s -> 5057.86s]  the intermediate page table directory
[5058.74s -> 5059.86s]  and zero it out
[5059.86s -> 5061.14s]  and then keep going in the loop.
[5061.94s -> 5063.46s]  So if alloc is set,
[5063.46s -> 5064.50s]  you always end up
[5064.50s -> 5065.62s]  on the bottom PTE.
[5066.74s -> 5068.34s]  If alloc is not set,
[5068.34s -> 5070.50s]  you stop at the first PTE
[5070.50s -> 5071.54s]  that doesn't have a value.
[5073.78s -> 5074.74s]  Okay, that makes sense.
[5074.74s -> 5076.02s]  This is the last one.
[5076.02s -> 5077.30s]  The actual one that
[5077.30s -> 5077.94s]  you're going to have.
[5077.94s -> 5078.26s]  Okay.
[5079.70s -> 5080.58s]  Okay, thank you.
[5085.06s -> 5085.86s]  Any other questions?
[5089.30s -> 5090.18s]  So I have a question.
[5091.54s -> 5093.38s]  Basically, everything made sense
[5093.38s -> 5094.58s]  until we mapped
[5094.58s -> 5095.78s]  the virtual addresses
[5096.58s -> 5097.22s]  of the kernel
[5097.22s -> 5098.42s]  to the physical addresses.
[5099.30s -> 5103.94s]  So my understanding is that
[5103.94s -> 5105.06s]  each process will have
[5105.06s -> 5106.10s]  its own page table
[5106.10s -> 5108.10s]  which is also a three-level tree
[5108.10s -> 5110.26s]  which maps its virtual addresses
[5110.26s -> 5111.86s]  to physical addresses.
[5111.86s -> 5112.66s]  But then when we map
[5113.94s -> 5115.14s]  the kernel virtual addresses
[5115.14s -> 5116.26s]  to physical addresses,
[5116.26s -> 5117.38s]  I don't think we accounted
[5117.38s -> 5118.74s]  for the actual tree
[5118.74s -> 5121.62s]  of the virtual addresses
[5121.62s -> 5122.34s]  of the kernel
[5122.34s -> 5124.98s]  or where other processes
[5124.98s -> 5127.06s]  will have their virtual addresses
[5127.62s -> 5129.62s]  and I'm sorry,
[5129.62s -> 5130.58s]  virtual addresses
[5131.78s -> 5133.30s]  like the page table trees
[5133.30s -> 5135.78s]  and whatever the page table tree
[5135.78s -> 5138.02s]  points at in the physical memory.
[5138.66s -> 5140.74s]  Yeah, so you're back
[5140.74s -> 5141.78s]  from this slide
[5141.78s -> 5144.98s]  with the kernel address space,
[5144.98s -> 5146.18s]  the virtual kernel address space.
[5146.74s -> 5148.10s]  And so when the kernel
[5148.10s -> 5148.90s]  allocates a proc
[5150.42s -> 5151.78s]  and the page tables
[5151.78s -> 5152.90s]  for that particular process,
[5152.90s -> 5153.94s]  they're going to be allocated
[5154.50s -> 5156.34s]  out of memory here.
[5156.34s -> 5157.86s]  Memory is not being used yet.
[5159.06s -> 5160.18s]  And the kernel
[5160.18s -> 5161.06s]  is going to program
[5162.66s -> 5163.46s]  we'll probably allocate
[5163.46s -> 5164.18s]  a couple pages
[5164.18s -> 5165.38s]  for the page table
[5165.38s -> 5166.82s]  of the user-level process
[5166.82s -> 5168.18s]  and we'll fill in the PTEs.
[5169.62s -> 5170.58s]  And then at some point
[5170.58s -> 5173.06s]  when the kernel runs that process
[5173.06s -> 5175.38s]  it will load the root
[5176.42s -> 5177.38s]  physical address
[5177.38s -> 5178.50s]  for those pages
[5178.50s -> 5179.30s]  that it allocated
[5179.30s -> 5180.26s]  for that page table
[5180.26s -> 5181.78s]  or basically for the page table
[5181.78s -> 5182.34s]  that it built
[5182.34s -> 5183.78s]  into the SATP register.
[5184.82s -> 5185.62s]  And at that point,
[5186.26s -> 5188.74s]  the processor will run
[5188.74s -> 5190.18s]  with the virtual address space
[5190.18s -> 5191.46s]  that the kernel constructed
[5191.46s -> 5192.58s]  for that particular process.
[5195.54s -> 5196.74s]  So the kernel give up
[5197.38s -> 5198.34s]  some of its memory
[5199.46s -> 5200.50s]  for processes
[5200.50s -> 5201.14s]  and then
[5201.14s -> 5203.14s]  but then the virtual space
[5203.14s -> 5204.66s]  in theory is as big
[5204.66s -> 5205.62s]  for the process
[5205.62s -> 5207.30s]  as the kernel
[5208.02s -> 5208.90s]  but in reality
[5208.90s -> 5209.78s]  it's really not.
[5210.58s -> 5211.14s]  Yeah, for example,
[5212.18s -> 5212.90s]  usually the picture
[5212.90s -> 5213.46s]  with the layout
[5213.46s -> 5214.42s]  of a virtual address space
[5214.42s -> 5215.78s]  of a user-level process
[5215.78s -> 5216.26s]  and again
[5216.26s -> 5217.86s]  it goes from zero to max VA
[5220.18s -> 5220.82s]  in the same way
[5220.82s -> 5223.94s]  as the kernel address space does
[5223.94s -> 5224.82s]  and it basically has
[5224.82s -> 5225.94s]  its own set of page tables
[5225.94s -> 5226.98s]  to map those
[5226.98s -> 5228.10s]  due to translation
[5228.74s -> 5229.70s]  that the kernel set up.
[5231.46s -> 5233.06s]  But we can't actually use
[5233.06s -> 5234.74s]  all of the max VA virtual
[5234.74s -> 5235.46s]  No, we cannot
[5236.02s -> 5237.14s]  if we run out of memory.
[5239.78s -> 5241.06s]  So many of the processes
[5241.06s -> 5242.02s]  are much much smaller
[5242.02s -> 5242.34s]  correct
[5242.34s -> 5244.74s]  than all of the virtual address space.
[5248.10s -> 5248.82s]  I see, thank you.
[5251.46s -> 5252.74s]  I've got a quick question.
[5252.74s -> 5252.98s]  Yeah.
[5254.74s -> 5256.74s]  Could you go back to the walk code?
[5256.74s -> 5257.94s]  Yeah, yeah, yeah, absolutely.
[5260.50s -> 5261.62s]  One of my favorite functions.
[5264.10s -> 5264.90s]  So I guess
[5266.42s -> 5268.50s]  and one thing I'm confused about is
[5268.50s -> 5269.30s]  after you write
[5269.30s -> 5270.50s]  to the satp register
[5271.14s -> 5273.06s]  can the kernel even access
[5273.06s -> 5274.90s]  physical addresses directly?
[5274.90s -> 5276.10s]  So it looks like in the code
[5276.10s -> 5277.14s]  that it's converting
[5277.14s -> 5278.02s]  you know like page tables
[5278.02s -> 5279.38s]  being set to a physical address
[5279.38s -> 5280.98s]  but if satp is set
[5282.74s -> 5283.70s]  won't that be interpreted
[5283.70s -> 5285.14s]  as a virtual address?
[5286.18s -> 5289.38s]  Yeah, so okay.
[5289.38s -> 5290.26s]  So let's look at
[5291.46s -> 5292.90s]  whatever the hard in it.
[5297.94s -> 5298.18s]  So
[5298.18s -> 5301.06s]  this is kvm
[5301.06s -> 5302.50s]  so build to the kernel address space.
[5304.50s -> 5305.62s]  The kernel page table
[5308.10s -> 5309.70s]  initially is a physical
[5310.66s -> 5311.46s]  and there's an address
[5311.46s -> 5312.26s]  is translated to
[5313.46s -> 5314.66s]  a physical address
[5314.66s -> 5315.78s]  and that's actually written
[5315.78s -> 5317.22s]  into the satp register.
[5319.46s -> 5320.42s]  And at that point
[5320.42s -> 5321.14s]  you know we're running
[5321.14s -> 5322.66s]  with the address space
[5322.66s -> 5323.94s]  that we constructed
[5323.94s -> 5325.22s]  like right before here
[5325.22s -> 5326.26s]  in this kvm in it.
[5328.26s -> 5330.02s]  And kvm map is basically
[5330.02s -> 5331.62s]  nothing else than calling
[5333.94s -> 5335.70s]  walk for every address
[5335.70s -> 5337.30s]  or every page in that range.
[5338.58s -> 5339.70s]  And so what was your question?
[5342.18s -> 5342.82s]  I guess it's
[5343.62s -> 5345.62s]  does walk still work the same way
[5345.62s -> 5348.34s]  if you call it after satp is set?
[5348.98s -> 5349.78s]  Yeah, why?
[5353.78s -> 5354.66s]  Why will it work out?
[5354.66s -> 5355.70s]  The reason it will work out
[5355.70s -> 5356.74s]  is because the kernel set up
[5356.74s -> 5357.62s]  an identity mapping.
[5358.58s -> 5360.82s]  Ah, okay.
[5361.94s -> 5362.82s]  Right, right.
[5363.62s -> 5364.18s]  Very important.
[5364.90s -> 5365.62s]  Very good question.
[5366.74s -> 5367.62s]  Like a lot of things
[5367.62s -> 5368.66s]  just happen to work out
[5368.66s -> 5369.22s]  because actually
[5369.22s -> 5370.50s]  the identity mapping is set up.
[5372.90s -> 5373.54s]  I see.
[5374.50s -> 5375.94s]  Okay, I think that makes sense.
[5375.94s -> 5377.22s]  Yeah, thanks.
[5379.54s -> 5380.42s]  I have a quick question.
[5381.94s -> 5384.50s]  Where the satp register is stored
[5384.50s -> 5385.86s]  for all of the processes?
[5386.50s -> 5389.30s]  There's only one satp per core
[5390.50s -> 5391.94s]  but in every proc structure
[5394.42s -> 5395.94s]  in every looking proc.h
[5397.46s -> 5398.18s]  there is a
[5402.50s -> 5404.50s]  pointer to the page table here.
[5404.50s -> 5405.94s]  Okay, that makes sense.
[5405.94s -> 5406.18s]  Yep.
[5406.82s -> 5407.38s]  And also
[5408.42s -> 5411.54s]  with regards to the three page tables
[5411.54s -> 5413.38s]  are like the three tables
[5413.38s -> 5415.46s]  that can complete the full address
[5415.54s -> 5416.98s]  and help you get a full address
[5416.98s -> 5418.74s]  for even something.
[5419.78s -> 5421.38s]  How does how is that better
[5421.38s -> 5422.82s]  I guess than having
[5423.38s -> 5424.74s]  one giant page table?
[5424.74s -> 5426.26s]  I didn't really fully understand that.
[5426.26s -> 5428.50s]  Okay, good question.
[5428.50s -> 5429.22s]  The reason is
[5429.22s -> 5430.74s]  is because in the free level page table
[5430.74s -> 5432.34s]  you can leave a lot of entries empty.
[5433.30s -> 5434.34s]  So for example
[5434.34s -> 5436.18s]  if you leave an entry
[5436.18s -> 5437.62s]  in the top level page table
[5437.62s -> 5438.66s]  directly empty
[5438.66s -> 5439.86s]  you don't have to create
[5439.86s -> 5441.38s]  middle level page tables
[5441.38s -> 5443.30s]  or bottom level page tables at all
[5443.30s -> 5444.10s]  for those entries.
[5444.82s -> 5445.30s]  Okay.
[5445.38s -> 5446.50s]  And so like this means
[5446.50s -> 5448.02s]  like a big swath
[5448.02s -> 5449.46s]  of the whole virtual address space
[5449.46s -> 5450.18s]  doesn't have to have
[5450.18s -> 5451.30s]  any mappings at all.
[5453.14s -> 5453.94s]  Okay, okay.
[5453.94s -> 5455.30s]  You don't have the table there.
[5455.30s -> 5456.10s]  It just doesn't exist.
[5457.30s -> 5458.26s]  So you're basically
[5458.26s -> 5460.66s]  allocating these chunks on demand
[5460.66s -> 5462.18s]  as opposed to adding the entire thing.
[5462.18s -> 5463.38s]  Okay, that makes sense.
[5463.38s -> 5464.10s]  Yeah, you start out
[5464.10s -> 5466.34s]  basically with three pages
[5466.34s -> 5467.46s]  namely one for the top level
[5467.46s -> 5468.82s]  one for the one intermediate
[5468.82s -> 5470.66s]  and one for the one bottom level
[5471.46s -> 5472.58s]  and then as you go
[5472.58s -> 5474.50s]  you create more page table directories.
[5474.98s -> 5476.10s]  Okay, okay, cool.
[5477.30s -> 5478.50s]  Cool, thank you so much.
[5478.50s -> 5479.06s]  You're welcome.
[5481.06s -> 5482.02s]  Any more questions?
[5482.82s -> 5484.26s]  I'm sorry, I have another one.
[5484.26s -> 5486.10s]  It's really, really small
[5486.10s -> 5491.38s]  but in the vm.c on line 43
[5491.38s -> 5492.10s]  Yeah, hold on.
[5492.10s -> 5494.26s]  Sorry, 40, line 40, yeah.
[5495.30s -> 5496.26s]  It says that it
[5496.98s -> 5498.74s]  no, never mind 43, my bad.
[5499.86s -> 5501.46s]  It says physical stop
[5501.46s -> 5504.98s]  minus un64 e-text
[5504.98s -> 5505.86s]  but wouldn't that
[5506.58s -> 5508.18s]  wouldn't that go over the
[5509.70s -> 5510.98s]  I guess the memory
[5510.98s -> 5512.10s]  that we shouldn't
[5512.90s -> 5514.02s]  top touch?
[5514.02s -> 5515.30s]  I don't know if that made sense
[5515.30s -> 5517.86s]  but wouldn't that go
[5519.38s -> 5521.06s]  I guess I don't understand
[5521.06s -> 5522.74s]  wouldn't that go over free memory?
[5525.30s -> 5526.98s]  No, I don't think so.
[5528.10s -> 5529.06s]  So current base is
[5529.06s -> 5531.78s]  0x880000, correct?
[5531.78s -> 5533.62s]  So that's the beginning of memory
[5534.82s -> 5536.66s]  and kernel sits there
[5536.66s -> 5538.82s]  and basically
[5540.82s -> 5543.46s]  this thing is a size, right?
[5543.46s -> 5545.94s]  So e-text is the last address of the kernel
[5546.50s -> 5547.70s]  subtract current base
[5547.70s -> 5549.54s]  and basically gives you the size of the kernel
[5551.78s -> 5553.86s]  in bytes
[5554.74s -> 5555.62s]  and you know
[5555.62s -> 5556.90s]  I don't know how much it is
[5556.90s -> 5560.34s]  but it's like 60 or 90 pages
[5560.34s -> 5561.14s]  or something like that
[5562.82s -> 5564.34s]  and so this maps is basically
[5564.34s -> 5565.62s]  the text part of the kernel
[5567.62s -> 5570.34s]  and there's enough space
[5571.94s -> 5574.10s]  there's enough DRAM to map that
[5575.62s -> 5576.42s]  the kernel text
[5576.98s -> 5578.42s]  I'm not sure I'm answering your question
[5578.42s -> 5578.92s]  but
[5579.38s -> 5581.62s]  Oh, I think I understand
[5582.18s -> 5585.54s]  I thought that e-text starts somewhere else
[5585.62s -> 5586.74s]  Okay, I think I understand now
[5586.74s -> 5587.06s]  Thank you
[5587.06s -> 5589.22s]  Okay, e-text is basically the last instruction
[5589.22s -> 5590.98s]  the address of the last instruction of the kernel
[5591.94s -> 5593.38s]  Okay, okay
